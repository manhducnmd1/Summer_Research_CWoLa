{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b65c873",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import colors as mcolors\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from scipy import interpolate\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07877ffd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-14 14:07:09.679638: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2024-08-14 14:07:11.246174: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: NVIDIA TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:3b:00.0\n",
      "2024-08-14 14:07:11.246429: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2024-08-14 14:07:11.247819: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2024-08-14 14:07:11.249012: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2024-08-14 14:07:11.249321: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2024-08-14 14:07:11.250852: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2024-08-14 14:07:11.252058: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2024-08-14 14:07:11.255684: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2024-08-14 14:07:11.256562: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "from tensorflow.python.client import device_lib\n",
    "physical_gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_gpus[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1185928d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(5000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 5 seconds\n"
     ]
    }
   ],
   "source": [
    "#Reading files into a log\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "nblog = open(\"nb_id.log\", \"a+\")\n",
    "sys.stdout.echo = nblog\n",
    "sys.stderr.echo = nblog\n",
    "\n",
    "get_ipython().log.handlers[0].stream = nblog\n",
    "get_ipython().log.setLevel(logging.INFO)\n",
    "\n",
    "%autosave 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc373ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f22518c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f09118ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the CWoLA model\n",
    "def CWoLA(p_i):\n",
    "    \n",
    "    input_1 = keras.layers.Input(shape = (p_i,p_i,1), name = \"jet_1\")\n",
    "    #x = keras.layers.Input(shape = (p_i,p_i,2), name = \"jet1and2\")\n",
    "    #input_1 = keras.layers.Lambda(lambda x: x[:,:,:,0:1])\n",
    "    #input_2 = keras.layers.Lambda(lambda x: x[:,:,:,1:2])\n",
    "    #y = input_1(x)\n",
    "    #z = input_2(x)\n",
    "    input_2 = keras.layers.Input(shape = (p_i,p_i,1), name = \"jet_2\")    \n",
    "    input_3 = keras.layers.Input(shape = (2), name = \"all_1\")\n",
    "    input_4 = keras.layers.Input(shape = (2), name = \"all_2\")\n",
    "    \n",
    "    \n",
    "    y = keras.layers.BatchNormalization()(input_1)\n",
    "    z = keras.layers.BatchNormalization()(input_2)  \n",
    "\n",
    "    y_1 = keras.layers.BatchNormalization()(input_3)\n",
    "    z_1 = keras.layers.BatchNormalization()(input_4)\n",
    "    \n",
    "    y_2 = keras.layers.Concatenate()([y_1, z_1])\n",
    "    \n",
    "    z_2 = keras.layers.Concatenate()([y, z])\n",
    "    cnn = keras.Sequential([\n",
    "        keras.layers.Conv2D(64, (5,5), padding = 'same', activation = 'relu'),\n",
    "        keras.layers.MaxPool2D(pool_size = (2,2)),\n",
    "        keras.layers.Conv2D(64, (5, 5), padding = 'same', activation = 'relu'),\n",
    "        keras.layers.MaxPool2D(pool_size = (2,2)),\n",
    "        keras.layers.Conv2D(128, (3,3), padding = 'same', activation = 'relu'),\n",
    "        keras.layers.MaxPool2D(pool_size = (2,2)),    \n",
    "        keras.layers.Conv2D(128, (3,3), padding = 'same', activation = 'relu'),\n",
    "        keras.layers.Flatten(),\n",
    "    ])\n",
    "        \n",
    "    dnn = keras.Sequential([\n",
    "          keras.layers.Dense(128, activation = 'relu'),\n",
    "          keras.layers.Dense(128, activation = 'relu'),\n",
    "          keras.layers.Dense(128, activation = 'relu'),\n",
    "          keras.layers.Dense(1, activation = 'sigmoid')\n",
    "    ])\n",
    "    ann = keras.Sequential([keras.layers.Dense(128, activation = 'relu'),\n",
    "                            keras.layers.Dense(128, activation = 'relu'),\n",
    "                            keras.layers.Dense(1, activation = 'sigmoid')\n",
    "    ])\n",
    "    x_1 = dnn(cnn(z_2))\n",
    "    x_3 = ann(y_2)\n",
    "    x_out = x_3\n",
    "    #x_out = keras.layers.Multiply()([x_1, x_3])\n",
    "    return keras.Model(         \n",
    "    inputs=[input_1, input_2, input_3, input_4],\n",
    "    outputs=x_out)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359ecc9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d09cb3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with significance = 0.32, run 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-14 14:08:07.363633: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "2024-08-14 14:08:07.400795: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3200000000 Hz\n",
      "2024-08-14 14:08:07.403680: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55936b515160 executing computations on platform Host. Devices:\n",
      "2024-08-14 14:08:07.403719: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version\n",
      "2024-08-14 14:08:07.406515: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: NVIDIA TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:3b:00.0\n",
      "2024-08-14 14:08:07.406651: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2024-08-14 14:08:07.406688: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2024-08-14 14:08:07.406716: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2024-08-14 14:08:07.406745: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2024-08-14 14:08:07.406768: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2024-08-14 14:08:07.406796: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2024-08-14 14:08:07.406823: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2024-08-14 14:08:07.409686: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
      "2024-08-14 14:08:07.409746: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2024-08-14 14:08:07.550757: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2024-08-14 14:08:07.550791: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
      "2024-08-14 14:08:07.550805: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
      "2024-08-14 14:08:07.554785: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11446 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:3b:00.0, compute capability: 6.1)\n",
      "2024-08-14 14:08:07.556755: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55936f4be7e0 executing computations on platform CUDA. Devices:\n",
      "2024-08-14 14:08:07.556796: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): NVIDIA TITAN Xp, Compute Capability 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40901 samples, validate on 10226 samples\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-14 14:08:09.396239: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40901/40901 [==============================] - 2s 41us/sample - loss: 0.6944 - accuracy: 0.5038 - val_loss: 0.6935 - val_accuracy: 0.4878\n",
      "Epoch 2/1000\n",
      "40901/40901 [==============================] - 1s 14us/sample - loss: 0.6930 - accuracy: 0.5077 - val_loss: 0.6932 - val_accuracy: 0.5004\n",
      "Epoch 3/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6929 - accuracy: 0.5108 - val_loss: 0.6929 - val_accuracy: 0.5086\n",
      "Epoch 4/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6928 - accuracy: 0.5111 - val_loss: 0.6929 - val_accuracy: 0.5104\n",
      "Epoch 5/1000\n",
      "40901/40901 [==============================] - 1s 12us/sample - loss: 0.6927 - accuracy: 0.5139 - val_loss: 0.6929 - val_accuracy: 0.5109\n",
      "Epoch 6/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6927 - accuracy: 0.5138 - val_loss: 0.6927 - val_accuracy: 0.5151\n",
      "Epoch 7/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6926 - accuracy: 0.5143 - val_loss: 0.6926 - val_accuracy: 0.5146\n",
      "Epoch 8/1000\n",
      "40901/40901 [==============================] - 1s 12us/sample - loss: 0.6926 - accuracy: 0.5160 - val_loss: 0.6927 - val_accuracy: 0.5159\n",
      "Epoch 9/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6926 - accuracy: 0.5156 - val_loss: 0.6927 - val_accuracy: 0.5166\n",
      "Epoch 10/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6925 - accuracy: 0.5160 - val_loss: 0.6927 - val_accuracy: 0.5167\n",
      "Epoch 11/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6925 - accuracy: 0.5131 - val_loss: 0.6928 - val_accuracy: 0.5157\n",
      "Epoch 12/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6926 - accuracy: 0.5152 - val_loss: 0.6927 - val_accuracy: 0.5177\n",
      "Epoch 13/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5187 - val_loss: 0.6928 - val_accuracy: 0.5161\n",
      "Epoch 14/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5145 - val_loss: 0.6924 - val_accuracy: 0.5187\n",
      "Epoch 15/1000\n",
      "40901/40901 [==============================] - 1s 12us/sample - loss: 0.6925 - accuracy: 0.5150 - val_loss: 0.6925 - val_accuracy: 0.5150\n",
      "Epoch 16/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5157 - val_loss: 0.6925 - val_accuracy: 0.5181\n",
      "Epoch 17/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5178 - val_loss: 0.6924 - val_accuracy: 0.5168\n",
      "Epoch 18/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5154 - val_loss: 0.6924 - val_accuracy: 0.5169\n",
      "Epoch 19/1000\n",
      "40901/40901 [==============================] - 1s 12us/sample - loss: 0.6924 - accuracy: 0.5151 - val_loss: 0.6925 - val_accuracy: 0.5160\n",
      "Epoch 20/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5161 - val_loss: 0.6925 - val_accuracy: 0.5177\n",
      "Epoch 21/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5176 - val_loss: 0.6925 - val_accuracy: 0.5170\n",
      "Epoch 22/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5173 - val_loss: 0.6926 - val_accuracy: 0.5176\n",
      "Epoch 23/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5158 - val_loss: 0.6926 - val_accuracy: 0.5184\n",
      "Epoch 24/1000\n",
      "40901/40901 [==============================] - 1s 12us/sample - loss: 0.6923 - accuracy: 0.5164 - val_loss: 0.6925 - val_accuracy: 0.5178\n",
      "Epoch 25/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5179 - val_loss: 0.6923 - val_accuracy: 0.5160\n",
      "Epoch 26/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5171 - val_loss: 0.6924 - val_accuracy: 0.5191\n",
      "Epoch 27/1000\n",
      "40901/40901 [==============================] - 1s 12us/sample - loss: 0.6923 - accuracy: 0.5172 - val_loss: 0.6926 - val_accuracy: 0.5152\n",
      "Epoch 28/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5175 - val_loss: 0.6924 - val_accuracy: 0.5163\n",
      "Epoch 29/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5167 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 30/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5172 - val_loss: 0.6925 - val_accuracy: 0.5182\n",
      "Epoch 31/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5167 - val_loss: 0.6925 - val_accuracy: 0.5190\n",
      "Epoch 32/1000\n",
      "40901/40901 [==============================] - 1s 14us/sample - loss: 0.6922 - accuracy: 0.5169 - val_loss: 0.6924 - val_accuracy: 0.5199\n",
      "Epoch 33/1000\n",
      "40901/40901 [==============================] - 1s 16us/sample - loss: 0.6922 - accuracy: 0.5159 - val_loss: 0.6924 - val_accuracy: 0.5180\n",
      "Epoch 34/1000\n",
      "40901/40901 [==============================] - 1s 15us/sample - loss: 0.6921 - accuracy: 0.5167 - val_loss: 0.6925 - val_accuracy: 0.5179\n",
      "Epoch 35/1000\n",
      "40901/40901 [==============================] - 1s 15us/sample - loss: 0.6921 - accuracy: 0.5182 - val_loss: 0.6924 - val_accuracy: 0.5167\n",
      "Epoch 36/1000\n",
      "40901/40901 [==============================] - 1s 14us/sample - loss: 0.6921 - accuracy: 0.5184 - val_loss: 0.6924 - val_accuracy: 0.5176\n",
      "Epoch 37/1000\n",
      "40901/40901 [==============================] - 1s 15us/sample - loss: 0.6921 - accuracy: 0.5180 - val_loss: 0.6925 - val_accuracy: 0.5171\n",
      "Epoch 38/1000\n",
      "40901/40901 [==============================] - 1s 14us/sample - loss: 0.6921 - accuracy: 0.5186 - val_loss: 0.6925 - val_accuracy: 0.5169\n",
      "Epoch 39/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5170 - val_loss: 0.6924 - val_accuracy: 0.5196\n",
      "Epoch 40/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5176 - val_loss: 0.6924 - val_accuracy: 0.5212\n",
      "Epoch 41/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5179 - val_loss: 0.6924 - val_accuracy: 0.5182\n",
      "Epoch 42/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5179 - val_loss: 0.6924 - val_accuracy: 0.5189\n",
      "Epoch 43/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5189 - val_loss: 0.6926 - val_accuracy: 0.5190\n",
      "Epoch 44/1000\n",
      "40901/40901 [==============================] - 1s 12us/sample - loss: 0.6921 - accuracy: 0.5172 - val_loss: 0.6924 - val_accuracy: 0.5186\n",
      "Epoch 45/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5176 - val_loss: 0.6924 - val_accuracy: 0.5186\n",
      "Epoch 46/1000\n",
      "40901/40901 [==============================] - 1s 14us/sample - loss: 0.6920 - accuracy: 0.5200 - val_loss: 0.6925 - val_accuracy: 0.5153\n",
      "Epoch 47/1000\n",
      "40901/40901 [==============================] - 1s 14us/sample - loss: 0.6920 - accuracy: 0.5187 - val_loss: 0.6923 - val_accuracy: 0.5206\n",
      "Epoch 48/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5180 - val_loss: 0.6924 - val_accuracy: 0.5190\n",
      "Epoch 49/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5177 - val_loss: 0.6925 - val_accuracy: 0.5192\n",
      "Epoch 50/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5177 - val_loss: 0.6923 - val_accuracy: 0.5192\n",
      "Epoch 51/1000\n",
      "40901/40901 [==============================] - 0s 12us/sample - loss: 0.6920 - accuracy: 0.5174 - val_loss: 0.6924 - val_accuracy: 0.5199\n",
      "Epoch 52/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5185 - val_loss: 0.6923 - val_accuracy: 0.5213\n",
      "Epoch 53/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5186 - val_loss: 0.6925 - val_accuracy: 0.5149\n",
      "Epoch 54/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5198 - val_loss: 0.6923 - val_accuracy: 0.5210\n",
      "Epoch 55/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40901/40901 [==============================] - 1s 14us/sample - loss: 0.6920 - accuracy: 0.5179 - val_loss: 0.6925 - val_accuracy: 0.5182\n",
      "Epoch 56/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5186 - val_loss: 0.6924 - val_accuracy: 0.5217\n",
      "Epoch 57/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5194 - val_loss: 0.6923 - val_accuracy: 0.5167\n",
      "Epoch 58/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5177 - val_loss: 0.6924 - val_accuracy: 0.5186\n",
      "Epoch 59/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5190 - val_loss: 0.6924 - val_accuracy: 0.5181\n",
      "Epoch 60/1000\n",
      "40901/40901 [==============================] - 1s 12us/sample - loss: 0.6920 - accuracy: 0.5186 - val_loss: 0.6924 - val_accuracy: 0.5212\n",
      "Epoch 61/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5205 - val_loss: 0.6923 - val_accuracy: 0.5185\n",
      "Epoch 62/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5197 - val_loss: 0.6924 - val_accuracy: 0.5168\n",
      "Epoch 63/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5214 - val_loss: 0.6924 - val_accuracy: 0.5217\n",
      "Epoch 64/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5186 - val_loss: 0.6926 - val_accuracy: 0.5223\n",
      "Epoch 65/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5192 - val_loss: 0.6925 - val_accuracy: 0.5143\n",
      "Epoch 66/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5185 - val_loss: 0.6924 - val_accuracy: 0.5174\n",
      "Epoch 67/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5195 - val_loss: 0.6925 - val_accuracy: 0.5185\n",
      "Epoch 68/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5199 - val_loss: 0.6924 - val_accuracy: 0.5172\n",
      "Epoch 69/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5206 - val_loss: 0.6922 - val_accuracy: 0.5167\n",
      "Epoch 70/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5208 - val_loss: 0.6923 - val_accuracy: 0.5185\n",
      "Epoch 71/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5187 - val_loss: 0.6923 - val_accuracy: 0.5180\n",
      "Epoch 72/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5203 - val_loss: 0.6923 - val_accuracy: 0.5182\n",
      "Epoch 73/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5201 - val_loss: 0.6925 - val_accuracy: 0.5218\n",
      "Epoch 74/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5211 - val_loss: 0.6924 - val_accuracy: 0.5152\n",
      "Epoch 75/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5197 - val_loss: 0.6924 - val_accuracy: 0.5188\n",
      "Epoch 76/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5191 - val_loss: 0.6924 - val_accuracy: 0.5193\n",
      "Epoch 77/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5193 - val_loss: 0.6926 - val_accuracy: 0.5166\n",
      "Epoch 78/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5207 - val_loss: 0.6924 - val_accuracy: 0.5185\n",
      "Epoch 79/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5202 - val_loss: 0.6923 - val_accuracy: 0.5203\n",
      "Epoch 80/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5204 - val_loss: 0.6925 - val_accuracy: 0.5213\n",
      "Epoch 81/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5214 - val_loss: 0.6924 - val_accuracy: 0.5196\n",
      "Epoch 82/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5211 - val_loss: 0.6925 - val_accuracy: 0.5199\n",
      "Epoch 83/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5224 - val_loss: 0.6926 - val_accuracy: 0.5197\n",
      "Epoch 84/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5192 - val_loss: 0.6925 - val_accuracy: 0.5182\n",
      "Epoch 85/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5183 - val_loss: 0.6925 - val_accuracy: 0.5191\n",
      "Epoch 86/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5215 - val_loss: 0.6922 - val_accuracy: 0.5148\n",
      "Epoch 87/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5201 - val_loss: 0.6923 - val_accuracy: 0.5188\n",
      "Epoch 88/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5181 - val_loss: 0.6924 - val_accuracy: 0.5201\n",
      "Epoch 89/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5190 - val_loss: 0.6923 - val_accuracy: 0.5178\n",
      "Epoch 90/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5214 - val_loss: 0.6923 - val_accuracy: 0.5206\n",
      "Epoch 91/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5198 - val_loss: 0.6923 - val_accuracy: 0.5193\n",
      "Epoch 92/1000\n",
      "40901/40901 [==============================] - 1s 12us/sample - loss: 0.6918 - accuracy: 0.5185 - val_loss: 0.6925 - val_accuracy: 0.5181\n",
      "Epoch 93/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5215 - val_loss: 0.6924 - val_accuracy: 0.5199\n",
      "Epoch 94/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5191 - val_loss: 0.6923 - val_accuracy: 0.5186\n",
      "Epoch 95/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5224 - val_loss: 0.6923 - val_accuracy: 0.5170\n",
      "Epoch 96/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5208 - val_loss: 0.6923 - val_accuracy: 0.5182\n",
      "Epoch 97/1000\n",
      "40901/40901 [==============================] - 1s 14us/sample - loss: 0.6916 - accuracy: 0.5217 - val_loss: 0.6923 - val_accuracy: 0.5152\n",
      "Epoch 98/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5201 - val_loss: 0.6923 - val_accuracy: 0.5163\n",
      "Epoch 99/1000\n",
      "40901/40901 [==============================] - 1s 12us/sample - loss: 0.6916 - accuracy: 0.5198 - val_loss: 0.6925 - val_accuracy: 0.5169\n",
      "Epoch 100/1000\n",
      "40901/40901 [==============================] - 1s 12us/sample - loss: 0.6917 - accuracy: 0.5223 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 101/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5207 - val_loss: 0.6925 - val_accuracy: 0.5152\n",
      "Epoch 102/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5203 - val_loss: 0.6925 - val_accuracy: 0.5176\n",
      "Epoch 103/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5207 - val_loss: 0.6923 - val_accuracy: 0.5168\n",
      "Epoch 104/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5199 - val_loss: 0.6924 - val_accuracy: 0.5155\n",
      "Epoch 105/1000\n",
      "40901/40901 [==============================] - 1s 12us/sample - loss: 0.6916 - accuracy: 0.5216 - val_loss: 0.6925 - val_accuracy: 0.5208\n",
      "Epoch 106/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5211 - val_loss: 0.6925 - val_accuracy: 0.5152\n",
      "Epoch 107/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5212 - val_loss: 0.6924 - val_accuracy: 0.5171\n",
      "Epoch 108/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5211 - val_loss: 0.6926 - val_accuracy: 0.5183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109/1000\n",
      "40901/40901 [==============================] - 1s 12us/sample - loss: 0.6916 - accuracy: 0.5211 - val_loss: 0.6924 - val_accuracy: 0.5185\n",
      "Epoch 110/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5216 - val_loss: 0.6926 - val_accuracy: 0.5153\n",
      "Epoch 111/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5197 - val_loss: 0.6924 - val_accuracy: 0.5170\n",
      "Epoch 112/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5205 - val_loss: 0.6925 - val_accuracy: 0.5177\n",
      "Epoch 113/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5206 - val_loss: 0.6923 - val_accuracy: 0.5174\n",
      "Epoch 114/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5201 - val_loss: 0.6924 - val_accuracy: 0.5181\n",
      "Epoch 115/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5215 - val_loss: 0.6925 - val_accuracy: 0.5177\n",
      "Epoch 116/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5220 - val_loss: 0.6924 - val_accuracy: 0.5187\n",
      "Training with significance = 0.32, run 1\n",
      "Train on 40901 samples, validate on 10226 samples\n",
      "Epoch 1/1000\n",
      "40901/40901 [==============================] - 1s 34us/sample - loss: 0.6941 - accuracy: 0.4999 - val_loss: 0.6936 - val_accuracy: 0.5010\n",
      "Epoch 2/1000\n",
      "40901/40901 [==============================] - 1s 14us/sample - loss: 0.6930 - accuracy: 0.5090 - val_loss: 0.6927 - val_accuracy: 0.5127\n",
      "Epoch 3/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6926 - accuracy: 0.5123 - val_loss: 0.6929 - val_accuracy: 0.5094\n",
      "Epoch 4/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6925 - accuracy: 0.5149 - val_loss: 0.6920 - val_accuracy: 0.5196\n",
      "Epoch 5/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6925 - accuracy: 0.5147 - val_loss: 0.6920 - val_accuracy: 0.5203\n",
      "Epoch 6/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5154 - val_loss: 0.6918 - val_accuracy: 0.5201\n",
      "Epoch 7/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5151 - val_loss: 0.6917 - val_accuracy: 0.5259\n",
      "Epoch 8/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5169 - val_loss: 0.6918 - val_accuracy: 0.5213\n",
      "Epoch 9/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5170 - val_loss: 0.6916 - val_accuracy: 0.5234\n",
      "Epoch 10/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5161 - val_loss: 0.6918 - val_accuracy: 0.5212\n",
      "Epoch 11/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5168 - val_loss: 0.6918 - val_accuracy: 0.5224\n",
      "Epoch 12/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5164 - val_loss: 0.6918 - val_accuracy: 0.5210\n",
      "Epoch 13/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5160 - val_loss: 0.6920 - val_accuracy: 0.5195\n",
      "Epoch 14/1000\n",
      "40901/40901 [==============================] - 1s 14us/sample - loss: 0.6922 - accuracy: 0.5172 - val_loss: 0.6919 - val_accuracy: 0.5190\n",
      "Epoch 15/1000\n",
      "40901/40901 [==============================] - 1s 14us/sample - loss: 0.6921 - accuracy: 0.5185 - val_loss: 0.6918 - val_accuracy: 0.5225\n",
      "Epoch 16/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5155 - val_loss: 0.6919 - val_accuracy: 0.5218\n",
      "Epoch 17/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5172 - val_loss: 0.6919 - val_accuracy: 0.5218\n",
      "Epoch 18/1000\n",
      "40901/40901 [==============================] - 1s 14us/sample - loss: 0.6920 - accuracy: 0.5186 - val_loss: 0.6923 - val_accuracy: 0.5199\n",
      "Epoch 19/1000\n",
      "40901/40901 [==============================] - 1s 14us/sample - loss: 0.6921 - accuracy: 0.5164 - val_loss: 0.6918 - val_accuracy: 0.5212\n",
      "Epoch 20/1000\n",
      "40901/40901 [==============================] - 1s 14us/sample - loss: 0.6921 - accuracy: 0.5184 - val_loss: 0.6919 - val_accuracy: 0.5224\n",
      "Epoch 21/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5186 - val_loss: 0.6918 - val_accuracy: 0.5236\n",
      "Epoch 22/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5172 - val_loss: 0.6917 - val_accuracy: 0.5247\n",
      "Epoch 23/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5186 - val_loss: 0.6920 - val_accuracy: 0.5204\n",
      "Epoch 24/1000\n",
      "40901/40901 [==============================] - 1s 14us/sample - loss: 0.6920 - accuracy: 0.5196 - val_loss: 0.6917 - val_accuracy: 0.5239\n",
      "Epoch 25/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5184 - val_loss: 0.6919 - val_accuracy: 0.5190\n",
      "Epoch 26/1000\n",
      "40901/40901 [==============================] - 1s 14us/sample - loss: 0.6919 - accuracy: 0.5188 - val_loss: 0.6917 - val_accuracy: 0.5245\n",
      "Epoch 27/1000\n",
      "40901/40901 [==============================] - 1s 14us/sample - loss: 0.6920 - accuracy: 0.5185 - val_loss: 0.6921 - val_accuracy: 0.5180\n",
      "Epoch 28/1000\n",
      "40901/40901 [==============================] - 1s 14us/sample - loss: 0.6921 - accuracy: 0.5189 - val_loss: 0.6919 - val_accuracy: 0.5218\n",
      "Epoch 29/1000\n",
      "40901/40901 [==============================] - 1s 14us/sample - loss: 0.6919 - accuracy: 0.5208 - val_loss: 0.6920 - val_accuracy: 0.5220\n",
      "Epoch 30/1000\n",
      "40901/40901 [==============================] - 1s 14us/sample - loss: 0.6919 - accuracy: 0.5201 - val_loss: 0.6918 - val_accuracy: 0.5248\n",
      "Epoch 31/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5186 - val_loss: 0.6917 - val_accuracy: 0.5218\n",
      "Epoch 32/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5180 - val_loss: 0.6919 - val_accuracy: 0.5222\n",
      "Epoch 33/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5202 - val_loss: 0.6917 - val_accuracy: 0.5239\n",
      "Epoch 34/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5212 - val_loss: 0.6917 - val_accuracy: 0.5243\n",
      "Epoch 35/1000\n",
      "40901/40901 [==============================] - 1s 14us/sample - loss: 0.6918 - accuracy: 0.5210 - val_loss: 0.6915 - val_accuracy: 0.5238\n",
      "Epoch 36/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5196 - val_loss: 0.6918 - val_accuracy: 0.5221\n",
      "Epoch 37/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5190 - val_loss: 0.6924 - val_accuracy: 0.5175\n",
      "Epoch 38/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5189 - val_loss: 0.6922 - val_accuracy: 0.5188\n",
      "Epoch 39/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5183 - val_loss: 0.6918 - val_accuracy: 0.5217\n",
      "Epoch 40/1000\n",
      "40901/40901 [==============================] - 1s 14us/sample - loss: 0.6918 - accuracy: 0.5186 - val_loss: 0.6916 - val_accuracy: 0.5231\n",
      "Epoch 41/1000\n",
      "40901/40901 [==============================] - 1s 14us/sample - loss: 0.6918 - accuracy: 0.5177 - val_loss: 0.6918 - val_accuracy: 0.5223\n",
      "Epoch 42/1000\n",
      "40901/40901 [==============================] - 1s 14us/sample - loss: 0.6919 - accuracy: 0.5207 - val_loss: 0.6917 - val_accuracy: 0.5223\n",
      "Epoch 43/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5222 - val_loss: 0.6917 - val_accuracy: 0.5211\n",
      "Epoch 44/1000\n",
      "40901/40901 [==============================] - 1s 12us/sample - loss: 0.6917 - accuracy: 0.5199 - val_loss: 0.6919 - val_accuracy: 0.5227\n",
      "Epoch 45/1000\n",
      "40901/40901 [==============================] - 1s 12us/sample - loss: 0.6919 - accuracy: 0.5183 - val_loss: 0.6919 - val_accuracy: 0.5243\n",
      "Epoch 46/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5177 - val_loss: 0.6918 - val_accuracy: 0.5202\n",
      "Epoch 47/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5215 - val_loss: 0.6918 - val_accuracy: 0.5237\n",
      "Epoch 48/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5225 - val_loss: 0.6918 - val_accuracy: 0.5212\n",
      "Epoch 49/1000\n",
      "40901/40901 [==============================] - 1s 14us/sample - loss: 0.6918 - accuracy: 0.5206 - val_loss: 0.6925 - val_accuracy: 0.5124\n",
      "Epoch 50/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5202 - val_loss: 0.6919 - val_accuracy: 0.5198\n",
      "Epoch 51/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5198 - val_loss: 0.6920 - val_accuracy: 0.5220\n",
      "Epoch 52/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5197 - val_loss: 0.6918 - val_accuracy: 0.5199\n",
      "Epoch 53/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5179 - val_loss: 0.6919 - val_accuracy: 0.5215\n",
      "Epoch 54/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5194 - val_loss: 0.6919 - val_accuracy: 0.5228\n",
      "Epoch 55/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5198 - val_loss: 0.6917 - val_accuracy: 0.5228\n",
      "Epoch 56/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5190 - val_loss: 0.6921 - val_accuracy: 0.5203\n",
      "Epoch 57/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5201 - val_loss: 0.6916 - val_accuracy: 0.5270\n",
      "Epoch 58/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5219 - val_loss: 0.6917 - val_accuracy: 0.5234\n",
      "Epoch 59/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5196 - val_loss: 0.6920 - val_accuracy: 0.5198\n",
      "Epoch 60/1000\n",
      "40901/40901 [==============================] - 1s 14us/sample - loss: 0.6916 - accuracy: 0.5208 - val_loss: 0.6919 - val_accuracy: 0.5199\n",
      "Epoch 61/1000\n",
      "40901/40901 [==============================] - 1s 14us/sample - loss: 0.6916 - accuracy: 0.5220 - val_loss: 0.6920 - val_accuracy: 0.5210\n",
      "Epoch 62/1000\n",
      "40901/40901 [==============================] - 1s 14us/sample - loss: 0.6916 - accuracy: 0.5216 - val_loss: 0.6917 - val_accuracy: 0.5196\n",
      "Epoch 63/1000\n",
      "40901/40901 [==============================] - 1s 14us/sample - loss: 0.6916 - accuracy: 0.5206 - val_loss: 0.6917 - val_accuracy: 0.5206\n",
      "Epoch 64/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5197 - val_loss: 0.6918 - val_accuracy: 0.5236\n",
      "Epoch 65/1000\n",
      "40901/40901 [==============================] - 1s 14us/sample - loss: 0.6916 - accuracy: 0.5201 - val_loss: 0.6919 - val_accuracy: 0.5217\n",
      "Training with significance = 0.32, run 2\n",
      "Train on 40901 samples, validate on 10226 samples\n",
      "Epoch 1/1000\n",
      "40901/40901 [==============================] - 1s 34us/sample - loss: 0.6937 - accuracy: 0.5068 - val_loss: 0.6935 - val_accuracy: 0.4983\n",
      "Epoch 2/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6926 - accuracy: 0.5166 - val_loss: 0.6931 - val_accuracy: 0.5068\n",
      "Epoch 3/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6925 - accuracy: 0.5161 - val_loss: 0.6931 - val_accuracy: 0.5069\n",
      "Epoch 4/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5154 - val_loss: 0.6930 - val_accuracy: 0.5129\n",
      "Epoch 5/1000\n",
      "40901/40901 [==============================] - 1s 14us/sample - loss: 0.6925 - accuracy: 0.5159 - val_loss: 0.6932 - val_accuracy: 0.5122\n",
      "Epoch 6/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5171 - val_loss: 0.6932 - val_accuracy: 0.5102\n",
      "Epoch 7/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5166 - val_loss: 0.6933 - val_accuracy: 0.5100\n",
      "Epoch 8/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5190 - val_loss: 0.6931 - val_accuracy: 0.5106\n",
      "Epoch 9/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5187 - val_loss: 0.6931 - val_accuracy: 0.5088\n",
      "Epoch 10/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5171 - val_loss: 0.6931 - val_accuracy: 0.5114\n",
      "Epoch 11/1000\n",
      "40901/40901 [==============================] - 1s 14us/sample - loss: 0.6922 - accuracy: 0.5181 - val_loss: 0.6931 - val_accuracy: 0.5097\n",
      "Epoch 12/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5180 - val_loss: 0.6931 - val_accuracy: 0.5108\n",
      "Epoch 13/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5182 - val_loss: 0.6932 - val_accuracy: 0.5080\n",
      "Epoch 14/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5188 - val_loss: 0.6932 - val_accuracy: 0.5102\n",
      "Epoch 15/1000\n",
      "40901/40901 [==============================] - 1s 14us/sample - loss: 0.6921 - accuracy: 0.5185 - val_loss: 0.6932 - val_accuracy: 0.5081\n",
      "Epoch 16/1000\n",
      "40901/40901 [==============================] - 1s 14us/sample - loss: 0.6921 - accuracy: 0.5193 - val_loss: 0.6931 - val_accuracy: 0.5087\n",
      "Epoch 17/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5185 - val_loss: 0.6932 - val_accuracy: 0.5107\n",
      "Epoch 18/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5190 - val_loss: 0.6931 - val_accuracy: 0.5102\n",
      "Epoch 19/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5205 - val_loss: 0.6931 - val_accuracy: 0.5097\n",
      "Epoch 20/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5191 - val_loss: 0.6931 - val_accuracy: 0.5117\n",
      "Epoch 21/1000\n",
      "40901/40901 [==============================] - 1s 14us/sample - loss: 0.6919 - accuracy: 0.5202 - val_loss: 0.6932 - val_accuracy: 0.5076\n",
      "Epoch 22/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5176 - val_loss: 0.6930 - val_accuracy: 0.5083\n",
      "Epoch 23/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5186 - val_loss: 0.6930 - val_accuracy: 0.5107\n",
      "Epoch 24/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5184 - val_loss: 0.6933 - val_accuracy: 0.5086\n",
      "Epoch 25/1000\n",
      "40901/40901 [==============================] - 1s 14us/sample - loss: 0.6919 - accuracy: 0.5181 - val_loss: 0.6931 - val_accuracy: 0.5083\n",
      "Epoch 26/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5197 - val_loss: 0.6932 - val_accuracy: 0.5115\n",
      "Epoch 27/1000\n",
      "40901/40901 [==============================] - 1s 14us/sample - loss: 0.6919 - accuracy: 0.5176 - val_loss: 0.6930 - val_accuracy: 0.5099\n",
      "Epoch 28/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5209 - val_loss: 0.6931 - val_accuracy: 0.5094\n",
      "Epoch 29/1000\n",
      "40901/40901 [==============================] - 1s 14us/sample - loss: 0.6919 - accuracy: 0.5199 - val_loss: 0.6931 - val_accuracy: 0.5099\n",
      "Epoch 30/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5201 - val_loss: 0.6933 - val_accuracy: 0.5098\n",
      "Epoch 31/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5192 - val_loss: 0.6930 - val_accuracy: 0.5096\n",
      "Epoch 32/1000\n",
      "40901/40901 [==============================] - 1s 14us/sample - loss: 0.6917 - accuracy: 0.5205 - val_loss: 0.6929 - val_accuracy: 0.5118\n",
      "Epoch 33/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5192 - val_loss: 0.6930 - val_accuracy: 0.5109\n",
      "Epoch 34/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5201 - val_loss: 0.6931 - val_accuracy: 0.5111\n",
      "Epoch 35/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5213 - val_loss: 0.6933 - val_accuracy: 0.5093\n",
      "Epoch 36/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5205 - val_loss: 0.6930 - val_accuracy: 0.5075\n",
      "Epoch 37/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5202 - val_loss: 0.6929 - val_accuracy: 0.5105\n",
      "Epoch 38/1000\n",
      "40901/40901 [==============================] - 1s 14us/sample - loss: 0.6918 - accuracy: 0.5224 - val_loss: 0.6928 - val_accuracy: 0.5119\n",
      "Epoch 39/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5199 - val_loss: 0.6931 - val_accuracy: 0.5116\n",
      "Epoch 40/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5207 - val_loss: 0.6931 - val_accuracy: 0.5103\n",
      "Epoch 41/1000\n",
      "40901/40901 [==============================] - 1s 14us/sample - loss: 0.6917 - accuracy: 0.5197 - val_loss: 0.6931 - val_accuracy: 0.5110\n",
      "Epoch 42/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5194 - val_loss: 0.6932 - val_accuracy: 0.5074\n",
      "Epoch 43/1000\n",
      "40901/40901 [==============================] - 1s 14us/sample - loss: 0.6917 - accuracy: 0.5196 - val_loss: 0.6930 - val_accuracy: 0.5094\n",
      "Epoch 44/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5220 - val_loss: 0.6930 - val_accuracy: 0.5097\n",
      "Epoch 45/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5194 - val_loss: 0.6932 - val_accuracy: 0.5113\n",
      "Epoch 46/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5227 - val_loss: 0.6931 - val_accuracy: 0.5106\n",
      "Epoch 47/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5207 - val_loss: 0.6933 - val_accuracy: 0.5080\n",
      "Epoch 48/1000\n",
      "40901/40901 [==============================] - 1s 14us/sample - loss: 0.6916 - accuracy: 0.5222 - val_loss: 0.6931 - val_accuracy: 0.5118\n",
      "Epoch 49/1000\n",
      "40901/40901 [==============================] - 1s 14us/sample - loss: 0.6917 - accuracy: 0.5205 - val_loss: 0.6931 - val_accuracy: 0.5111\n",
      "Epoch 50/1000\n",
      "40901/40901 [==============================] - 1s 14us/sample - loss: 0.6916 - accuracy: 0.5187 - val_loss: 0.6929 - val_accuracy: 0.5125\n",
      "Epoch 51/1000\n",
      "40901/40901 [==============================] - 1s 14us/sample - loss: 0.6916 - accuracy: 0.5206 - val_loss: 0.6932 - val_accuracy: 0.5097\n",
      "Epoch 52/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5197 - val_loss: 0.6929 - val_accuracy: 0.5088\n",
      "Epoch 53/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5222 - val_loss: 0.6933 - val_accuracy: 0.5118\n",
      "Epoch 54/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5208 - val_loss: 0.6930 - val_accuracy: 0.5097\n",
      "Epoch 55/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5199 - val_loss: 0.6932 - val_accuracy: 0.5093\n",
      "Epoch 56/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5204 - val_loss: 0.6933 - val_accuracy: 0.5112\n",
      "Epoch 57/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5223 - val_loss: 0.6929 - val_accuracy: 0.5114\n",
      "Epoch 58/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5216 - val_loss: 0.6930 - val_accuracy: 0.5102\n",
      "Epoch 59/1000\n",
      "40901/40901 [==============================] - 1s 14us/sample - loss: 0.6916 - accuracy: 0.5222 - val_loss: 0.6930 - val_accuracy: 0.5103\n",
      "Epoch 60/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5226 - val_loss: 0.6931 - val_accuracy: 0.5097\n",
      "Epoch 61/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5226 - val_loss: 0.6932 - val_accuracy: 0.5103\n",
      "Epoch 62/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5204 - val_loss: 0.6932 - val_accuracy: 0.5094\n",
      "Epoch 63/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5228 - val_loss: 0.6931 - val_accuracy: 0.5108\n",
      "Epoch 64/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5209 - val_loss: 0.6931 - val_accuracy: 0.5087\n",
      "Epoch 65/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5219 - val_loss: 0.6930 - val_accuracy: 0.5091\n",
      "Epoch 66/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5217 - val_loss: 0.6931 - val_accuracy: 0.5092\n",
      "Epoch 67/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5207 - val_loss: 0.6933 - val_accuracy: 0.5121\n",
      "Epoch 68/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5206 - val_loss: 0.6930 - val_accuracy: 0.5110\n",
      "Training with significance = 0.32, run 3\n",
      "Train on 40901 samples, validate on 10226 samples\n",
      "Epoch 1/1000\n",
      "40901/40901 [==============================] - 1s 27us/sample - loss: 0.6937 - accuracy: 0.5056 - val_loss: 0.6933 - val_accuracy: 0.5038\n",
      "Epoch 2/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6929 - accuracy: 0.5137 - val_loss: 0.6929 - val_accuracy: 0.5086\n",
      "Epoch 3/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6927 - accuracy: 0.5154 - val_loss: 0.6926 - val_accuracy: 0.5130\n",
      "Epoch 4/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6925 - accuracy: 0.5161 - val_loss: 0.6927 - val_accuracy: 0.5080\n",
      "Epoch 5/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5174 - val_loss: 0.6929 - val_accuracy: 0.5117\n",
      "Epoch 6/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5161 - val_loss: 0.6929 - val_accuracy: 0.5120\n",
      "Epoch 7/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5183 - val_loss: 0.6927 - val_accuracy: 0.5085\n",
      "Epoch 8/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5174 - val_loss: 0.6928 - val_accuracy: 0.5091\n",
      "Epoch 9/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5171 - val_loss: 0.6927 - val_accuracy: 0.5082\n",
      "Epoch 10/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5166 - val_loss: 0.6928 - val_accuracy: 0.5081\n",
      "Epoch 11/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5165 - val_loss: 0.6928 - val_accuracy: 0.5087\n",
      "Epoch 12/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5183 - val_loss: 0.6928 - val_accuracy: 0.5088\n",
      "Epoch 13/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5174 - val_loss: 0.6928 - val_accuracy: 0.5092\n",
      "Epoch 14/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5185 - val_loss: 0.6928 - val_accuracy: 0.5092\n",
      "Epoch 15/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5192 - val_loss: 0.6929 - val_accuracy: 0.5088\n",
      "Epoch 16/1000\n",
      "40901/40901 [==============================] - 1s 14us/sample - loss: 0.6920 - accuracy: 0.5190 - val_loss: 0.6927 - val_accuracy: 0.5087\n",
      "Epoch 17/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5196 - val_loss: 0.6928 - val_accuracy: 0.5108\n",
      "Epoch 18/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5177 - val_loss: 0.6929 - val_accuracy: 0.5111\n",
      "Epoch 19/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5193 - val_loss: 0.6929 - val_accuracy: 0.5099\n",
      "Epoch 20/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5211 - val_loss: 0.6929 - val_accuracy: 0.5095\n",
      "Epoch 21/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5189 - val_loss: 0.6930 - val_accuracy: 0.5107\n",
      "Epoch 22/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5194 - val_loss: 0.6929 - val_accuracy: 0.5099\n",
      "Epoch 23/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5198 - val_loss: 0.6930 - val_accuracy: 0.5082\n",
      "Epoch 24/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5202 - val_loss: 0.6929 - val_accuracy: 0.5091\n",
      "Epoch 25/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5201 - val_loss: 0.6928 - val_accuracy: 0.5079\n",
      "Epoch 26/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5213 - val_loss: 0.6932 - val_accuracy: 0.5125\n",
      "Epoch 27/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5184 - val_loss: 0.6929 - val_accuracy: 0.5092\n",
      "Epoch 28/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5203 - val_loss: 0.6929 - val_accuracy: 0.5097\n",
      "Epoch 29/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5201 - val_loss: 0.6928 - val_accuracy: 0.5090\n",
      "Epoch 30/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5212 - val_loss: 0.6928 - val_accuracy: 0.5113\n",
      "Epoch 31/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5207 - val_loss: 0.6929 - val_accuracy: 0.5084\n",
      "Epoch 32/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5207 - val_loss: 0.6929 - val_accuracy: 0.5092\n",
      "Epoch 33/1000\n",
      "40901/40901 [==============================] - 1s 14us/sample - loss: 0.6918 - accuracy: 0.5193 - val_loss: 0.6929 - val_accuracy: 0.5094\n",
      "Training with significance = 0.32, run 4\n",
      "Train on 40901 samples, validate on 10226 samples\n",
      "Epoch 1/1000\n",
      "40901/40901 [==============================] - 1s 28us/sample - loss: 0.6928 - accuracy: 0.5109 - val_loss: 0.6936 - val_accuracy: 0.5029\n",
      "Epoch 2/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6926 - accuracy: 0.5141 - val_loss: 0.6927 - val_accuracy: 0.5111\n",
      "Epoch 3/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6925 - accuracy: 0.5153 - val_loss: 0.6922 - val_accuracy: 0.5195\n",
      "Epoch 4/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5149 - val_loss: 0.6922 - val_accuracy: 0.5179\n",
      "Epoch 5/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5151 - val_loss: 0.6923 - val_accuracy: 0.5145\n",
      "Epoch 6/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5139 - val_loss: 0.6921 - val_accuracy: 0.5196\n",
      "Epoch 7/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5149 - val_loss: 0.6921 - val_accuracy: 0.5177\n",
      "Epoch 8/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5159 - val_loss: 0.6922 - val_accuracy: 0.5163\n",
      "Epoch 9/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5167 - val_loss: 0.6921 - val_accuracy: 0.5164\n",
      "Epoch 10/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5156 - val_loss: 0.6921 - val_accuracy: 0.5180\n",
      "Epoch 11/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5152 - val_loss: 0.6922 - val_accuracy: 0.5196\n",
      "Epoch 12/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5186 - val_loss: 0.6920 - val_accuracy: 0.5168\n",
      "Epoch 13/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5165 - val_loss: 0.6922 - val_accuracy: 0.5180\n",
      "Epoch 14/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5170 - val_loss: 0.6921 - val_accuracy: 0.5160\n",
      "Epoch 15/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5175 - val_loss: 0.6920 - val_accuracy: 0.5170\n",
      "Epoch 16/1000\n",
      "40901/40901 [==============================] - 0s 12us/sample - loss: 0.6919 - accuracy: 0.5185 - val_loss: 0.6920 - val_accuracy: 0.5164\n",
      "Epoch 17/1000\n",
      "40901/40901 [==============================] - 0s 12us/sample - loss: 0.6920 - accuracy: 0.5165 - val_loss: 0.6920 - val_accuracy: 0.5160\n",
      "Epoch 18/1000\n",
      "40901/40901 [==============================] - 0s 12us/sample - loss: 0.6919 - accuracy: 0.5194 - val_loss: 0.6919 - val_accuracy: 0.5196\n",
      "Epoch 19/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5162 - val_loss: 0.6920 - val_accuracy: 0.5155\n",
      "Epoch 20/1000\n",
      "40901/40901 [==============================] - 1s 12us/sample - loss: 0.6918 - accuracy: 0.5211 - val_loss: 0.6920 - val_accuracy: 0.5138\n",
      "Epoch 21/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5185 - val_loss: 0.6921 - val_accuracy: 0.5159\n",
      "Epoch 22/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5181 - val_loss: 0.6920 - val_accuracy: 0.5162\n",
      "Epoch 23/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5183 - val_loss: 0.6920 - val_accuracy: 0.5147\n",
      "Epoch 24/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5178 - val_loss: 0.6922 - val_accuracy: 0.5191\n",
      "Epoch 25/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5194 - val_loss: 0.6921 - val_accuracy: 0.5147\n",
      "Epoch 26/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5192 - val_loss: 0.6921 - val_accuracy: 0.5140\n",
      "Epoch 27/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5200 - val_loss: 0.6921 - val_accuracy: 0.5136\n",
      "Epoch 28/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5183 - val_loss: 0.6922 - val_accuracy: 0.5156\n",
      "Epoch 29/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5204 - val_loss: 0.6921 - val_accuracy: 0.5146\n",
      "Epoch 30/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5186 - val_loss: 0.6921 - val_accuracy: 0.5133\n",
      "Epoch 31/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5199 - val_loss: 0.6920 - val_accuracy: 0.5150\n",
      "Epoch 32/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5205 - val_loss: 0.6920 - val_accuracy: 0.5137\n",
      "Epoch 33/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5211 - val_loss: 0.6920 - val_accuracy: 0.5190\n",
      "Epoch 34/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5205 - val_loss: 0.6922 - val_accuracy: 0.5134\n",
      "Epoch 35/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5209 - val_loss: 0.6922 - val_accuracy: 0.5198\n",
      "Epoch 36/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5210 - val_loss: 0.6921 - val_accuracy: 0.5126\n",
      "Epoch 37/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5209 - val_loss: 0.6921 - val_accuracy: 0.5143\n",
      "Epoch 38/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5203 - val_loss: 0.6921 - val_accuracy: 0.5124\n",
      "Epoch 39/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5201 - val_loss: 0.6920 - val_accuracy: 0.5177\n",
      "Epoch 40/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5201 - val_loss: 0.6921 - val_accuracy: 0.5176\n",
      "Epoch 41/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5183 - val_loss: 0.6921 - val_accuracy: 0.5139\n",
      "Epoch 42/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5230 - val_loss: 0.6921 - val_accuracy: 0.5183\n",
      "Epoch 43/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5224 - val_loss: 0.6920 - val_accuracy: 0.5159\n",
      "Epoch 44/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5222 - val_loss: 0.6921 - val_accuracy: 0.5154\n",
      "Epoch 45/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5195 - val_loss: 0.6922 - val_accuracy: 0.5139\n",
      "Epoch 46/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5224 - val_loss: 0.6923 - val_accuracy: 0.5172\n",
      "Epoch 47/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5189 - val_loss: 0.6921 - val_accuracy: 0.5183\n",
      "Epoch 48/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5206 - val_loss: 0.6920 - val_accuracy: 0.5153\n",
      "Training with significance = 0.32, run 5\n",
      "Train on 40901 samples, validate on 10226 samples\n",
      "Epoch 1/1000\n",
      "40901/40901 [==============================] - 1s 34us/sample - loss: 0.6931 - accuracy: 0.5068 - val_loss: 0.6928 - val_accuracy: 0.5034\n",
      "Epoch 2/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6927 - accuracy: 0.5091 - val_loss: 0.6925 - val_accuracy: 0.5145\n",
      "Epoch 3/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6927 - accuracy: 0.5110 - val_loss: 0.6923 - val_accuracy: 0.5168\n",
      "Epoch 4/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6925 - accuracy: 0.5118 - val_loss: 0.6922 - val_accuracy: 0.5163\n",
      "Epoch 5/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6925 - accuracy: 0.5102 - val_loss: 0.6921 - val_accuracy: 0.5174\n",
      "Epoch 6/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5137 - val_loss: 0.6921 - val_accuracy: 0.5197\n",
      "Epoch 7/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5130 - val_loss: 0.6920 - val_accuracy: 0.5202\n",
      "Epoch 8/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5135 - val_loss: 0.6920 - val_accuracy: 0.5208\n",
      "Epoch 9/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5148 - val_loss: 0.6920 - val_accuracy: 0.5206\n",
      "Epoch 10/1000\n",
      "40901/40901 [==============================] - 1s 12us/sample - loss: 0.6923 - accuracy: 0.5137 - val_loss: 0.6921 - val_accuracy: 0.5173\n",
      "Epoch 11/1000\n",
      "40901/40901 [==============================] - 1s 12us/sample - loss: 0.6922 - accuracy: 0.5154 - val_loss: 0.6920 - val_accuracy: 0.5189\n",
      "Epoch 12/1000\n",
      "40901/40901 [==============================] - 1s 12us/sample - loss: 0.6922 - accuracy: 0.5135 - val_loss: 0.6921 - val_accuracy: 0.5245\n",
      "Epoch 13/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5152 - val_loss: 0.6922 - val_accuracy: 0.5202\n",
      "Epoch 14/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5144 - val_loss: 0.6921 - val_accuracy: 0.5153\n",
      "Epoch 15/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5162 - val_loss: 0.6921 - val_accuracy: 0.5205\n",
      "Epoch 16/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5144 - val_loss: 0.6920 - val_accuracy: 0.5199\n",
      "Epoch 17/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5176 - val_loss: 0.6921 - val_accuracy: 0.5231\n",
      "Epoch 18/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5154 - val_loss: 0.6921 - val_accuracy: 0.5159\n",
      "Epoch 19/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5177 - val_loss: 0.6922 - val_accuracy: 0.5242\n",
      "Epoch 20/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5171 - val_loss: 0.6920 - val_accuracy: 0.5139\n",
      "Epoch 21/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5175 - val_loss: 0.6920 - val_accuracy: 0.5206\n",
      "Epoch 22/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5154 - val_loss: 0.6920 - val_accuracy: 0.5201\n",
      "Epoch 23/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5176 - val_loss: 0.6920 - val_accuracy: 0.5195\n",
      "Epoch 24/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5155 - val_loss: 0.6919 - val_accuracy: 0.5198\n",
      "Epoch 25/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5192 - val_loss: 0.6920 - val_accuracy: 0.5230\n",
      "Epoch 26/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5185 - val_loss: 0.6920 - val_accuracy: 0.5206\n",
      "Epoch 27/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5187 - val_loss: 0.6920 - val_accuracy: 0.5209\n",
      "Epoch 28/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5186 - val_loss: 0.6922 - val_accuracy: 0.5205\n",
      "Epoch 29/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5177 - val_loss: 0.6921 - val_accuracy: 0.5209\n",
      "Epoch 30/1000\n",
      "40901/40901 [==============================] - 1s 14us/sample - loss: 0.6919 - accuracy: 0.5170 - val_loss: 0.6920 - val_accuracy: 0.5198\n",
      "Epoch 31/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5183 - val_loss: 0.6921 - val_accuracy: 0.5208\n",
      "Epoch 32/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5202 - val_loss: 0.6920 - val_accuracy: 0.5196\n",
      "Epoch 33/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5190 - val_loss: 0.6921 - val_accuracy: 0.5210\n",
      "Epoch 34/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5184 - val_loss: 0.6920 - val_accuracy: 0.5206\n",
      "Epoch 35/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5202 - val_loss: 0.6920 - val_accuracy: 0.5216\n",
      "Epoch 36/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5168 - val_loss: 0.6920 - val_accuracy: 0.5185\n",
      "Epoch 37/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5185 - val_loss: 0.6920 - val_accuracy: 0.5203\n",
      "Epoch 38/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5191 - val_loss: 0.6921 - val_accuracy: 0.5157\n",
      "Epoch 39/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5168 - val_loss: 0.6921 - val_accuracy: 0.5198\n",
      "Epoch 40/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5186 - val_loss: 0.6921 - val_accuracy: 0.5189\n",
      "Epoch 41/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5197 - val_loss: 0.6920 - val_accuracy: 0.5209\n",
      "Epoch 42/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5185 - val_loss: 0.6921 - val_accuracy: 0.5226\n",
      "Epoch 43/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5186 - val_loss: 0.6920 - val_accuracy: 0.5188\n",
      "Epoch 44/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5180 - val_loss: 0.6919 - val_accuracy: 0.5202\n",
      "Epoch 45/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5201 - val_loss: 0.6920 - val_accuracy: 0.5168\n",
      "Epoch 46/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5184 - val_loss: 0.6920 - val_accuracy: 0.5214\n",
      "Epoch 47/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5193 - val_loss: 0.6920 - val_accuracy: 0.5217\n",
      "Epoch 48/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5178 - val_loss: 0.6921 - val_accuracy: 0.5125\n",
      "Epoch 49/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5183 - val_loss: 0.6921 - val_accuracy: 0.5174\n",
      "Epoch 50/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5210 - val_loss: 0.6920 - val_accuracy: 0.5188\n",
      "Epoch 51/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5181 - val_loss: 0.6921 - val_accuracy: 0.5186\n",
      "Epoch 52/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5184 - val_loss: 0.6921 - val_accuracy: 0.5171\n",
      "Epoch 53/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5193 - val_loss: 0.6921 - val_accuracy: 0.5229\n",
      "Epoch 54/1000\n",
      "40901/40901 [==============================] - 1s 12us/sample - loss: 0.6917 - accuracy: 0.5189 - val_loss: 0.6920 - val_accuracy: 0.5190\n",
      "Training with significance = 0.32, run 6\n",
      "Train on 40901 samples, validate on 10226 samples\n",
      "Epoch 1/1000\n",
      "40901/40901 [==============================] - 1s 34us/sample - loss: 0.6933 - accuracy: 0.5057 - val_loss: 0.6933 - val_accuracy: 0.5060\n",
      "Epoch 2/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6928 - accuracy: 0.5111 - val_loss: 0.6925 - val_accuracy: 0.5149\n",
      "Epoch 3/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6927 - accuracy: 0.5120 - val_loss: 0.6923 - val_accuracy: 0.5129\n",
      "Epoch 4/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6926 - accuracy: 0.5137 - val_loss: 0.6921 - val_accuracy: 0.5228\n",
      "Epoch 5/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6925 - accuracy: 0.5153 - val_loss: 0.6922 - val_accuracy: 0.5142\n",
      "Epoch 6/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6925 - accuracy: 0.5145 - val_loss: 0.6921 - val_accuracy: 0.5206\n",
      "Epoch 7/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6926 - accuracy: 0.5137 - val_loss: 0.6920 - val_accuracy: 0.5222\n",
      "Epoch 8/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5145 - val_loss: 0.6919 - val_accuracy: 0.5224\n",
      "Epoch 9/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6925 - accuracy: 0.5159 - val_loss: 0.6920 - val_accuracy: 0.5235\n",
      "Epoch 10/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5149 - val_loss: 0.6923 - val_accuracy: 0.5185\n",
      "Epoch 11/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6925 - accuracy: 0.5152 - val_loss: 0.6920 - val_accuracy: 0.5229\n",
      "Epoch 12/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5164 - val_loss: 0.6919 - val_accuracy: 0.5231\n",
      "Epoch 13/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5160 - val_loss: 0.6920 - val_accuracy: 0.5208\n",
      "Epoch 14/1000\n",
      "40901/40901 [==============================] - 1s 14us/sample - loss: 0.6923 - accuracy: 0.5169 - val_loss: 0.6919 - val_accuracy: 0.5233\n",
      "Epoch 15/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5166 - val_loss: 0.6919 - val_accuracy: 0.5231\n",
      "Epoch 16/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5153 - val_loss: 0.6919 - val_accuracy: 0.5224\n",
      "Epoch 17/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5159 - val_loss: 0.6919 - val_accuracy: 0.5228\n",
      "Epoch 18/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5169 - val_loss: 0.6918 - val_accuracy: 0.5224\n",
      "Epoch 19/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5154 - val_loss: 0.6920 - val_accuracy: 0.5210\n",
      "Epoch 20/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5158 - val_loss: 0.6919 - val_accuracy: 0.5228\n",
      "Epoch 21/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5154 - val_loss: 0.6920 - val_accuracy: 0.5220\n",
      "Epoch 22/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5167 - val_loss: 0.6920 - val_accuracy: 0.5219\n",
      "Epoch 23/1000\n",
      "40901/40901 [==============================] - 1s 12us/sample - loss: 0.6922 - accuracy: 0.5167 - val_loss: 0.6920 - val_accuracy: 0.5224\n",
      "Epoch 24/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5159 - val_loss: 0.6920 - val_accuracy: 0.5218\n",
      "Epoch 25/1000\n",
      "40901/40901 [==============================] - 1s 12us/sample - loss: 0.6921 - accuracy: 0.5184 - val_loss: 0.6918 - val_accuracy: 0.5226\n",
      "Epoch 26/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5169 - val_loss: 0.6920 - val_accuracy: 0.5221\n",
      "Epoch 27/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5160 - val_loss: 0.6920 - val_accuracy: 0.5235\n",
      "Epoch 28/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5167 - val_loss: 0.6919 - val_accuracy: 0.5223\n",
      "Epoch 29/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5166 - val_loss: 0.6919 - val_accuracy: 0.5226\n",
      "Epoch 30/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5184 - val_loss: 0.6920 - val_accuracy: 0.5223\n",
      "Epoch 31/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5178 - val_loss: 0.6919 - val_accuracy: 0.5216\n",
      "Epoch 32/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5172 - val_loss: 0.6919 - val_accuracy: 0.5185\n",
      "Epoch 33/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5167 - val_loss: 0.6920 - val_accuracy: 0.5219\n",
      "Epoch 34/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5182 - val_loss: 0.6919 - val_accuracy: 0.5204\n",
      "Epoch 35/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5174 - val_loss: 0.6920 - val_accuracy: 0.5209\n",
      "Epoch 36/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5171 - val_loss: 0.6920 - val_accuracy: 0.5197\n",
      "Epoch 37/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5154 - val_loss: 0.6919 - val_accuracy: 0.5224\n",
      "Epoch 38/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5173 - val_loss: 0.6920 - val_accuracy: 0.5219\n",
      "Epoch 39/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5171 - val_loss: 0.6919 - val_accuracy: 0.5214\n",
      "Epoch 40/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5167 - val_loss: 0.6920 - val_accuracy: 0.5222\n",
      "Epoch 41/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5183 - val_loss: 0.6921 - val_accuracy: 0.5197\n",
      "Epoch 42/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5158 - val_loss: 0.6920 - val_accuracy: 0.5218\n",
      "Epoch 43/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5180 - val_loss: 0.6918 - val_accuracy: 0.5223\n",
      "Epoch 44/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5171 - val_loss: 0.6918 - val_accuracy: 0.5216\n",
      "Epoch 45/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5188 - val_loss: 0.6919 - val_accuracy: 0.5217\n",
      "Epoch 46/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5170 - val_loss: 0.6919 - val_accuracy: 0.5208\n",
      "Epoch 47/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5186 - val_loss: 0.6919 - val_accuracy: 0.5195\n",
      "Epoch 48/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5184 - val_loss: 0.6919 - val_accuracy: 0.5238\n",
      "Epoch 49/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5179 - val_loss: 0.6918 - val_accuracy: 0.5189\n",
      "Epoch 50/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5172 - val_loss: 0.6919 - val_accuracy: 0.5218\n",
      "Epoch 51/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5193 - val_loss: 0.6919 - val_accuracy: 0.5220\n",
      "Epoch 52/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5189 - val_loss: 0.6922 - val_accuracy: 0.5183\n",
      "Epoch 53/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5186 - val_loss: 0.6921 - val_accuracy: 0.5201\n",
      "Epoch 54/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5200 - val_loss: 0.6920 - val_accuracy: 0.5229\n",
      "Epoch 55/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5185 - val_loss: 0.6920 - val_accuracy: 0.5219\n",
      "Epoch 56/1000\n",
      "40901/40901 [==============================] - 1s 12us/sample - loss: 0.6918 - accuracy: 0.5185 - val_loss: 0.6919 - val_accuracy: 0.5204\n",
      "Epoch 57/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5195 - val_loss: 0.6920 - val_accuracy: 0.5198\n",
      "Epoch 58/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5176 - val_loss: 0.6920 - val_accuracy: 0.5201\n",
      "Epoch 59/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5196 - val_loss: 0.6920 - val_accuracy: 0.5197\n",
      "Epoch 60/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5172 - val_loss: 0.6919 - val_accuracy: 0.5218\n",
      "Epoch 61/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5170 - val_loss: 0.6918 - val_accuracy: 0.5213\n",
      "Epoch 62/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5174 - val_loss: 0.6920 - val_accuracy: 0.5211\n",
      "Epoch 63/1000\n",
      "40901/40901 [==============================] - 1s 12us/sample - loss: 0.6918 - accuracy: 0.5187 - val_loss: 0.6920 - val_accuracy: 0.5228\n",
      "Epoch 64/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5210 - val_loss: 0.6919 - val_accuracy: 0.5195\n",
      "Epoch 65/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5179 - val_loss: 0.6919 - val_accuracy: 0.5224\n",
      "Epoch 66/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5203 - val_loss: 0.6919 - val_accuracy: 0.5188\n",
      "Epoch 67/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5202 - val_loss: 0.6918 - val_accuracy: 0.5219\n",
      "Epoch 68/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5183 - val_loss: 0.6920 - val_accuracy: 0.5235\n",
      "Epoch 69/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5179 - val_loss: 0.6920 - val_accuracy: 0.5211\n",
      "Epoch 70/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5190 - val_loss: 0.6920 - val_accuracy: 0.5189\n",
      "Epoch 71/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5194 - val_loss: 0.6921 - val_accuracy: 0.5184\n",
      "Epoch 72/1000\n",
      "40901/40901 [==============================] - 1s 12us/sample - loss: 0.6917 - accuracy: 0.5195 - val_loss: 0.6921 - val_accuracy: 0.5199\n",
      "Epoch 73/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5206 - val_loss: 0.6920 - val_accuracy: 0.5206\n",
      "Epoch 74/1000\n",
      "40901/40901 [==============================] - 1s 12us/sample - loss: 0.6918 - accuracy: 0.5194 - val_loss: 0.6922 - val_accuracy: 0.5194\n",
      "Training with significance = 0.32, run 7\n",
      "Train on 40901 samples, validate on 10226 samples\n",
      "Epoch 1/1000\n",
      "40901/40901 [==============================] - 1s 27us/sample - loss: 0.6932 - accuracy: 0.5088 - val_loss: 0.6931 - val_accuracy: 0.5082\n",
      "Epoch 2/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6925 - accuracy: 0.5145 - val_loss: 0.6930 - val_accuracy: 0.5115\n",
      "Epoch 3/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5159 - val_loss: 0.6931 - val_accuracy: 0.5050\n",
      "Epoch 4/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5167 - val_loss: 0.6930 - val_accuracy: 0.5076\n",
      "Epoch 5/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5173 - val_loss: 0.6930 - val_accuracy: 0.5045\n",
      "Epoch 6/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5183 - val_loss: 0.6931 - val_accuracy: 0.5056\n",
      "Epoch 7/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5173 - val_loss: 0.6930 - val_accuracy: 0.5051\n",
      "Epoch 8/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5163 - val_loss: 0.6933 - val_accuracy: 0.5057\n",
      "Epoch 9/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5187 - val_loss: 0.6932 - val_accuracy: 0.5031\n",
      "Epoch 10/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5184 - val_loss: 0.6933 - val_accuracy: 0.5058\n",
      "Epoch 11/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5175 - val_loss: 0.6933 - val_accuracy: 0.5050\n",
      "Epoch 12/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5192 - val_loss: 0.6933 - val_accuracy: 0.5039\n",
      "Epoch 13/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5179 - val_loss: 0.6933 - val_accuracy: 0.5054\n",
      "Epoch 14/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5181 - val_loss: 0.6934 - val_accuracy: 0.5047\n",
      "Epoch 15/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5177 - val_loss: 0.6934 - val_accuracy: 0.5054\n",
      "Epoch 16/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5196 - val_loss: 0.6934 - val_accuracy: 0.5036\n",
      "Epoch 17/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5188 - val_loss: 0.6935 - val_accuracy: 0.5038\n",
      "Epoch 18/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5183 - val_loss: 0.6933 - val_accuracy: 0.5019\n",
      "Epoch 19/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5191 - val_loss: 0.6934 - val_accuracy: 0.5051\n",
      "Epoch 20/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5181 - val_loss: 0.6936 - val_accuracy: 0.5054\n",
      "Epoch 21/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5195 - val_loss: 0.6935 - val_accuracy: 0.5040\n",
      "Epoch 22/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5204 - val_loss: 0.6934 - val_accuracy: 0.5027\n",
      "Epoch 23/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5197 - val_loss: 0.6935 - val_accuracy: 0.5041\n",
      "Epoch 24/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5215 - val_loss: 0.6935 - val_accuracy: 0.5057\n",
      "Epoch 25/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5206 - val_loss: 0.6935 - val_accuracy: 0.5041\n",
      "Epoch 26/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5194 - val_loss: 0.6935 - val_accuracy: 0.5046\n",
      "Epoch 27/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5186 - val_loss: 0.6938 - val_accuracy: 0.5042\n",
      "Epoch 28/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5197 - val_loss: 0.6936 - val_accuracy: 0.5048\n",
      "Epoch 29/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5211 - val_loss: 0.6935 - val_accuracy: 0.5048\n",
      "Epoch 30/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5207 - val_loss: 0.6935 - val_accuracy: 0.5035\n",
      "Epoch 31/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5212 - val_loss: 0.6937 - val_accuracy: 0.5044\n",
      "Epoch 32/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5219 - val_loss: 0.6935 - val_accuracy: 0.5049\n",
      "Training with significance = 0.32, run 8\n",
      "Train on 40901 samples, validate on 10226 samples\n",
      "Epoch 1/1000\n",
      "40901/40901 [==============================] - 1s 28us/sample - loss: 0.6941 - accuracy: 0.5032 - val_loss: 0.6935 - val_accuracy: 0.5017\n",
      "Epoch 2/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6929 - accuracy: 0.5097 - val_loss: 0.6929 - val_accuracy: 0.5107\n",
      "Epoch 3/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6926 - accuracy: 0.5120 - val_loss: 0.6927 - val_accuracy: 0.5185\n",
      "Epoch 4/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6925 - accuracy: 0.5136 - val_loss: 0.6926 - val_accuracy: 0.5166\n",
      "Epoch 5/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6925 - accuracy: 0.5142 - val_loss: 0.6926 - val_accuracy: 0.5149\n",
      "Epoch 6/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5140 - val_loss: 0.6925 - val_accuracy: 0.5200\n",
      "Epoch 7/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5134 - val_loss: 0.6924 - val_accuracy: 0.5186\n",
      "Epoch 8/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5164 - val_loss: 0.6926 - val_accuracy: 0.5162\n",
      "Epoch 9/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5159\n",
      "Epoch 10/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5131 - val_loss: 0.6924 - val_accuracy: 0.5173\n",
      "Epoch 11/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5176 - val_loss: 0.6924 - val_accuracy: 0.5165\n",
      "Epoch 12/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5163 - val_loss: 0.6924 - val_accuracy: 0.5180\n",
      "Epoch 13/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5171 - val_loss: 0.6923 - val_accuracy: 0.5209\n",
      "Epoch 14/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5180 - val_loss: 0.6924 - val_accuracy: 0.5188\n",
      "Epoch 15/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5165 - val_loss: 0.6923 - val_accuracy: 0.5215\n",
      "Epoch 16/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5156 - val_loss: 0.6924 - val_accuracy: 0.5162\n",
      "Epoch 17/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5167 - val_loss: 0.6923 - val_accuracy: 0.5210\n",
      "Epoch 18/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5180 - val_loss: 0.6923 - val_accuracy: 0.5224\n",
      "Epoch 19/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5169 - val_loss: 0.6923 - val_accuracy: 0.5189\n",
      "Epoch 20/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5175 - val_loss: 0.6923 - val_accuracy: 0.5177\n",
      "Epoch 21/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5170 - val_loss: 0.6923 - val_accuracy: 0.5189\n",
      "Epoch 22/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5171 - val_loss: 0.6924 - val_accuracy: 0.5156\n",
      "Epoch 23/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5176 - val_loss: 0.6922 - val_accuracy: 0.5211\n",
      "Epoch 24/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5171 - val_loss: 0.6922 - val_accuracy: 0.5213\n",
      "Epoch 25/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5172 - val_loss: 0.6922 - val_accuracy: 0.5199\n",
      "Epoch 26/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5171 - val_loss: 0.6923 - val_accuracy: 0.5163\n",
      "Epoch 27/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5210 - val_loss: 0.6923 - val_accuracy: 0.5159\n",
      "Epoch 28/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5176 - val_loss: 0.6923 - val_accuracy: 0.5156\n",
      "Epoch 29/1000\n",
      "40901/40901 [==============================] - 1s 14us/sample - loss: 0.6919 - accuracy: 0.5189 - val_loss: 0.6922 - val_accuracy: 0.5208\n",
      "Epoch 30/1000\n",
      "40901/40901 [==============================] - 1s 14us/sample - loss: 0.6918 - accuracy: 0.5182 - val_loss: 0.6922 - val_accuracy: 0.5194\n",
      "Epoch 31/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5192 - val_loss: 0.6925 - val_accuracy: 0.5170\n",
      "Epoch 32/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5184 - val_loss: 0.6923 - val_accuracy: 0.5177\n",
      "Epoch 33/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5208 - val_loss: 0.6923 - val_accuracy: 0.5156\n",
      "Epoch 34/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5193 - val_loss: 0.6923 - val_accuracy: 0.5170\n",
      "Epoch 35/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5203 - val_loss: 0.6923 - val_accuracy: 0.5144\n",
      "Epoch 36/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5188 - val_loss: 0.6923 - val_accuracy: 0.5153\n",
      "Epoch 37/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5187 - val_loss: 0.6924 - val_accuracy: 0.5158\n",
      "Epoch 38/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5212 - val_loss: 0.6923 - val_accuracy: 0.5191\n",
      "Epoch 39/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5185 - val_loss: 0.6923 - val_accuracy: 0.5156\n",
      "Epoch 40/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5184 - val_loss: 0.6922 - val_accuracy: 0.5228\n",
      "Epoch 41/1000\n",
      "40901/40901 [==============================] - 1s 12us/sample - loss: 0.6918 - accuracy: 0.5185 - val_loss: 0.6923 - val_accuracy: 0.5164\n",
      "Epoch 42/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5200 - val_loss: 0.6922 - val_accuracy: 0.5186\n",
      "Epoch 43/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5193 - val_loss: 0.6923 - val_accuracy: 0.5153\n",
      "Epoch 44/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5197 - val_loss: 0.6922 - val_accuracy: 0.5201\n",
      "Epoch 45/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5204 - val_loss: 0.6923 - val_accuracy: 0.5160\n",
      "Epoch 46/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5206 - val_loss: 0.6924 - val_accuracy: 0.5155\n",
      "Epoch 47/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5200 - val_loss: 0.6922 - val_accuracy: 0.5191\n",
      "Epoch 48/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5197 - val_loss: 0.6924 - val_accuracy: 0.5145\n",
      "Epoch 49/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5195 - val_loss: 0.6924 - val_accuracy: 0.5150\n",
      "Epoch 50/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5204 - val_loss: 0.6922 - val_accuracy: 0.5189\n",
      "Epoch 51/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5211 - val_loss: 0.6922 - val_accuracy: 0.5189\n",
      "Epoch 52/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5200 - val_loss: 0.6922 - val_accuracy: 0.5195\n",
      "Epoch 53/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5205 - val_loss: 0.6923 - val_accuracy: 0.5167\n",
      "Epoch 54/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5194 - val_loss: 0.6922 - val_accuracy: 0.5183\n",
      "Epoch 55/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5218 - val_loss: 0.6926 - val_accuracy: 0.5169\n",
      "Epoch 56/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5196 - val_loss: 0.6922 - val_accuracy: 0.5181\n",
      "Epoch 57/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5196 - val_loss: 0.6922 - val_accuracy: 0.5164\n",
      "Epoch 58/1000\n",
      "40901/40901 [==============================] - 1s 14us/sample - loss: 0.6915 - accuracy: 0.5199 - val_loss: 0.6922 - val_accuracy: 0.5206\n",
      "Epoch 59/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5187 - val_loss: 0.6924 - val_accuracy: 0.5170\n",
      "Epoch 60/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5204 - val_loss: 0.6922 - val_accuracy: 0.5169\n",
      "Epoch 61/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5203 - val_loss: 0.6924 - val_accuracy: 0.5176\n",
      "Epoch 62/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5232 - val_loss: 0.6924 - val_accuracy: 0.5159\n",
      "Epoch 63/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5206 - val_loss: 0.6922 - val_accuracy: 0.5194\n",
      "Epoch 64/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5205 - val_loss: 0.6922 - val_accuracy: 0.5185\n",
      "Epoch 65/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5207 - val_loss: 0.6925 - val_accuracy: 0.5179\n",
      "Epoch 66/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5213 - val_loss: 0.6923 - val_accuracy: 0.5172\n",
      "Epoch 67/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5188 - val_loss: 0.6923 - val_accuracy: 0.5161\n",
      "Epoch 68/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5222 - val_loss: 0.6924 - val_accuracy: 0.5174\n",
      "Epoch 69/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5204 - val_loss: 0.6922 - val_accuracy: 0.5186\n",
      "Epoch 70/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5197 - val_loss: 0.6922 - val_accuracy: 0.5172\n",
      "Epoch 71/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5200 - val_loss: 0.6925 - val_accuracy: 0.5152\n",
      "Epoch 72/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5204 - val_loss: 0.6922 - val_accuracy: 0.5178\n",
      "Epoch 73/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5210 - val_loss: 0.6922 - val_accuracy: 0.5150\n",
      "Epoch 74/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5213 - val_loss: 0.6924 - val_accuracy: 0.5178\n",
      "Epoch 75/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5201 - val_loss: 0.6922 - val_accuracy: 0.5179\n",
      "Epoch 76/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5201 - val_loss: 0.6923 - val_accuracy: 0.5179\n",
      "Epoch 77/1000\n",
      "40901/40901 [==============================] - 1s 12us/sample - loss: 0.6915 - accuracy: 0.5207 - val_loss: 0.6922 - val_accuracy: 0.5181\n",
      "Epoch 78/1000\n",
      "40901/40901 [==============================] - 1s 12us/sample - loss: 0.6915 - accuracy: 0.5211 - val_loss: 0.6923 - val_accuracy: 0.5152\n",
      "Epoch 79/1000\n",
      "40901/40901 [==============================] - 0s 12us/sample - loss: 0.6915 - accuracy: 0.5206 - val_loss: 0.6924 - val_accuracy: 0.5193\n",
      "Epoch 80/1000\n",
      "40901/40901 [==============================] - 1s 12us/sample - loss: 0.6914 - accuracy: 0.5216 - val_loss: 0.6926 - val_accuracy: 0.5177\n",
      "Epoch 81/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5193 - val_loss: 0.6922 - val_accuracy: 0.5163\n",
      "Epoch 82/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5219 - val_loss: 0.6923 - val_accuracy: 0.5186\n",
      "Epoch 83/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5231 - val_loss: 0.6922 - val_accuracy: 0.5178\n",
      "Epoch 84/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5223 - val_loss: 0.6924 - val_accuracy: 0.5177\n",
      "Epoch 85/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5220 - val_loss: 0.6923 - val_accuracy: 0.5167\n",
      "Epoch 86/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5218 - val_loss: 0.6923 - val_accuracy: 0.5156\n",
      "Epoch 87/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5210 - val_loss: 0.6925 - val_accuracy: 0.5170\n",
      "Epoch 88/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5202 - val_loss: 0.6924 - val_accuracy: 0.5176\n",
      "Epoch 89/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5215 - val_loss: 0.6922 - val_accuracy: 0.5169\n",
      "Epoch 90/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5241 - val_loss: 0.6922 - val_accuracy: 0.5189\n",
      "Epoch 91/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5216 - val_loss: 0.6922 - val_accuracy: 0.5168\n",
      "Epoch 92/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5218 - val_loss: 0.6922 - val_accuracy: 0.5182\n",
      "Epoch 93/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5216 - val_loss: 0.6926 - val_accuracy: 0.5155\n",
      "Epoch 94/1000\n",
      "40901/40901 [==============================] - 1s 14us/sample - loss: 0.6914 - accuracy: 0.5216 - val_loss: 0.6923 - val_accuracy: 0.5153\n",
      "Epoch 95/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5204 - val_loss: 0.6922 - val_accuracy: 0.5194\n",
      "Epoch 96/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5247 - val_loss: 0.6926 - val_accuracy: 0.5142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5212 - val_loss: 0.6923 - val_accuracy: 0.5139\n",
      "Epoch 98/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5224 - val_loss: 0.6924 - val_accuracy: 0.5152\n",
      "Epoch 99/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5230 - val_loss: 0.6923 - val_accuracy: 0.5190\n",
      "Epoch 100/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5245 - val_loss: 0.6922 - val_accuracy: 0.5184\n",
      "Epoch 101/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5210 - val_loss: 0.6922 - val_accuracy: 0.5192\n",
      "Epoch 102/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5212 - val_loss: 0.6922 - val_accuracy: 0.5184\n",
      "Training with significance = 0.32, run 9\n",
      "Train on 40901 samples, validate on 10226 samples\n",
      "Epoch 1/1000\n",
      "40901/40901 [==============================] - 1s 34us/sample - loss: 0.6945 - accuracy: 0.5011 - val_loss: 0.6937 - val_accuracy: 0.4969\n",
      "Epoch 2/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6928 - accuracy: 0.5128 - val_loss: 0.6933 - val_accuracy: 0.5018\n",
      "Epoch 3/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6927 - accuracy: 0.5111 - val_loss: 0.6928 - val_accuracy: 0.5118\n",
      "Epoch 4/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6927 - accuracy: 0.5126 - val_loss: 0.6929 - val_accuracy: 0.5092\n",
      "Epoch 5/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6925 - accuracy: 0.5128 - val_loss: 0.6928 - val_accuracy: 0.5119\n",
      "Epoch 6/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6925 - accuracy: 0.5133 - val_loss: 0.6929 - val_accuracy: 0.5094\n",
      "Epoch 7/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5147 - val_loss: 0.6927 - val_accuracy: 0.5144\n",
      "Epoch 8/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5137 - val_loss: 0.6927 - val_accuracy: 0.5127\n",
      "Epoch 9/1000\n",
      "40901/40901 [==============================] - 0s 12us/sample - loss: 0.6924 - accuracy: 0.5135 - val_loss: 0.6928 - val_accuracy: 0.5125\n",
      "Epoch 10/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5152 - val_loss: 0.6927 - val_accuracy: 0.5143\n",
      "Epoch 11/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5135 - val_loss: 0.6927 - val_accuracy: 0.5126\n",
      "Epoch 12/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5147 - val_loss: 0.6926 - val_accuracy: 0.5131\n",
      "Epoch 13/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5147 - val_loss: 0.6928 - val_accuracy: 0.5121\n",
      "Epoch 14/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5154 - val_loss: 0.6926 - val_accuracy: 0.5158\n",
      "Epoch 15/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5141 - val_loss: 0.6928 - val_accuracy: 0.5111\n",
      "Epoch 16/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5178 - val_loss: 0.6926 - val_accuracy: 0.5131\n",
      "Epoch 17/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5160 - val_loss: 0.6926 - val_accuracy: 0.5134\n",
      "Epoch 18/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5175 - val_loss: 0.6927 - val_accuracy: 0.5125\n",
      "Epoch 19/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5176 - val_loss: 0.6926 - val_accuracy: 0.5142\n",
      "Epoch 20/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5167 - val_loss: 0.6926 - val_accuracy: 0.5141\n",
      "Epoch 21/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5183 - val_loss: 0.6927 - val_accuracy: 0.5114\n",
      "Epoch 22/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5182 - val_loss: 0.6926 - val_accuracy: 0.5124\n",
      "Epoch 23/1000\n",
      "40901/40901 [==============================] - 1s 14us/sample - loss: 0.6921 - accuracy: 0.5168 - val_loss: 0.6926 - val_accuracy: 0.5109\n",
      "Epoch 24/1000\n",
      "40901/40901 [==============================] - 1s 14us/sample - loss: 0.6920 - accuracy: 0.5200 - val_loss: 0.6925 - val_accuracy: 0.5146\n",
      "Epoch 25/1000\n",
      "40901/40901 [==============================] - 1s 14us/sample - loss: 0.6920 - accuracy: 0.5183 - val_loss: 0.6927 - val_accuracy: 0.5089\n",
      "Epoch 26/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5197 - val_loss: 0.6925 - val_accuracy: 0.5145\n",
      "Epoch 27/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5177 - val_loss: 0.6926 - val_accuracy: 0.5155\n",
      "Epoch 28/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5172 - val_loss: 0.6926 - val_accuracy: 0.5140\n",
      "Epoch 29/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5189 - val_loss: 0.6926 - val_accuracy: 0.5126\n",
      "Epoch 30/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5190 - val_loss: 0.6926 - val_accuracy: 0.5116\n",
      "Epoch 31/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5187 - val_loss: 0.6926 - val_accuracy: 0.5122\n",
      "Epoch 32/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5200 - val_loss: 0.6925 - val_accuracy: 0.5144\n",
      "Epoch 33/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5173 - val_loss: 0.6925 - val_accuracy: 0.5129\n",
      "Epoch 34/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5174 - val_loss: 0.6927 - val_accuracy: 0.5068\n",
      "Epoch 35/1000\n",
      "40901/40901 [==============================] - 1s 14us/sample - loss: 0.6919 - accuracy: 0.5184 - val_loss: 0.6926 - val_accuracy: 0.5159\n",
      "Epoch 36/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5199 - val_loss: 0.6926 - val_accuracy: 0.5122\n",
      "Epoch 37/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5185 - val_loss: 0.6926 - val_accuracy: 0.5105\n",
      "Epoch 38/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5181 - val_loss: 0.6931 - val_accuracy: 0.5001\n",
      "Epoch 39/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5196 - val_loss: 0.6926 - val_accuracy: 0.5110\n",
      "Epoch 40/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5197 - val_loss: 0.6927 - val_accuracy: 0.5108\n",
      "Epoch 41/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5187 - val_loss: 0.6926 - val_accuracy: 0.5089\n",
      "Epoch 42/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5199 - val_loss: 0.6926 - val_accuracy: 0.5105\n",
      "Epoch 43/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5194 - val_loss: 0.6927 - val_accuracy: 0.5079\n",
      "Epoch 44/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5202 - val_loss: 0.6926 - val_accuracy: 0.5122\n",
      "Epoch 45/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5184 - val_loss: 0.6925 - val_accuracy: 0.5147\n",
      "Epoch 46/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5201 - val_loss: 0.6926 - val_accuracy: 0.5145\n",
      "Epoch 47/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5197 - val_loss: 0.6926 - val_accuracy: 0.5085\n",
      "Epoch 48/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5208 - val_loss: 0.6925 - val_accuracy: 0.5109\n",
      "Epoch 49/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5183 - val_loss: 0.6925 - val_accuracy: 0.5136\n",
      "Epoch 50/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5200 - val_loss: 0.6926 - val_accuracy: 0.5104\n",
      "Epoch 51/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5208 - val_loss: 0.6926 - val_accuracy: 0.5119\n",
      "Epoch 52/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5215 - val_loss: 0.6927 - val_accuracy: 0.5066\n",
      "Epoch 53/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5208 - val_loss: 0.6926 - val_accuracy: 0.5124\n",
      "Epoch 54/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5203 - val_loss: 0.6925 - val_accuracy: 0.5104\n",
      "Epoch 55/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5199 - val_loss: 0.6926 - val_accuracy: 0.5110\n",
      "Epoch 56/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5191 - val_loss: 0.6926 - val_accuracy: 0.5126\n",
      "Epoch 57/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5193 - val_loss: 0.6925 - val_accuracy: 0.5127\n",
      "Epoch 58/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5195 - val_loss: 0.6926 - val_accuracy: 0.5101\n",
      "Epoch 59/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5206 - val_loss: 0.6927 - val_accuracy: 0.5040\n",
      "Epoch 60/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5197 - val_loss: 0.6925 - val_accuracy: 0.5113\n",
      "Epoch 61/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5202 - val_loss: 0.6926 - val_accuracy: 0.5095\n",
      "Epoch 62/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5214 - val_loss: 0.6926 - val_accuracy: 0.5104\n",
      "Epoch 63/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5215 - val_loss: 0.6927 - val_accuracy: 0.5076\n",
      "Epoch 64/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5206 - val_loss: 0.6926 - val_accuracy: 0.5084\n",
      "Epoch 65/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5206 - val_loss: 0.6926 - val_accuracy: 0.5085\n",
      "Epoch 66/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5206 - val_loss: 0.6927 - val_accuracy: 0.5070\n",
      "Epoch 67/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5219 - val_loss: 0.6926 - val_accuracy: 0.5111\n",
      "Epoch 68/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5207 - val_loss: 0.6925 - val_accuracy: 0.5055\n",
      "Epoch 69/1000\n",
      "40901/40901 [==============================] - 1s 12us/sample - loss: 0.6916 - accuracy: 0.5232 - val_loss: 0.6925 - val_accuracy: 0.5138\n",
      "Epoch 70/1000\n",
      "40901/40901 [==============================] - 0s 12us/sample - loss: 0.6916 - accuracy: 0.5202 - val_loss: 0.6928 - val_accuracy: 0.5076\n",
      "Epoch 71/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5222 - val_loss: 0.6926 - val_accuracy: 0.5118\n",
      "Epoch 72/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5211 - val_loss: 0.6926 - val_accuracy: 0.5095\n",
      "Epoch 73/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5233 - val_loss: 0.6926 - val_accuracy: 0.5114\n",
      "Epoch 74/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5221 - val_loss: 0.6927 - val_accuracy: 0.5116\n",
      "Epoch 75/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5215 - val_loss: 0.6928 - val_accuracy: 0.5073\n",
      "Epoch 76/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5215 - val_loss: 0.6928 - val_accuracy: 0.5040\n",
      "Epoch 77/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5221 - val_loss: 0.6926 - val_accuracy: 0.5072\n",
      "Epoch 78/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5219 - val_loss: 0.6925 - val_accuracy: 0.5115\n",
      "Epoch 79/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5225 - val_loss: 0.6925 - val_accuracy: 0.5117\n",
      "Epoch 80/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5215 - val_loss: 0.6927 - val_accuracy: 0.5075\n",
      "Epoch 81/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5210 - val_loss: 0.6928 - val_accuracy: 0.5060\n",
      "Epoch 82/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5218 - val_loss: 0.6926 - val_accuracy: 0.5063\n",
      "Epoch 83/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5239 - val_loss: 0.6927 - val_accuracy: 0.5064\n",
      "Epoch 84/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5218 - val_loss: 0.6926 - val_accuracy: 0.5101\n",
      "Epoch 85/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5229 - val_loss: 0.6927 - val_accuracy: 0.5066\n",
      "Epoch 86/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5226 - val_loss: 0.6927 - val_accuracy: 0.5092\n",
      "Epoch 87/1000\n",
      "40901/40901 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5231 - val_loss: 0.6927 - val_accuracy: 0.5150\n",
      "Training with significance = 0.63, run 0\n",
      "Train on 40952 samples, validate on 10238 samples\n",
      "Epoch 1/1000\n",
      "40952/40952 [==============================] - 1s 28us/sample - loss: 0.6939 - accuracy: 0.5021 - val_loss: 0.6930 - val_accuracy: 0.5110\n",
      "Epoch 2/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6928 - accuracy: 0.5102 - val_loss: 0.6929 - val_accuracy: 0.5150\n",
      "Epoch 3/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6927 - accuracy: 0.5131 - val_loss: 0.6932 - val_accuracy: 0.5073\n",
      "Epoch 4/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6926 - accuracy: 0.5126 - val_loss: 0.6930 - val_accuracy: 0.5115\n",
      "Epoch 5/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6925 - accuracy: 0.5147 - val_loss: 0.6931 - val_accuracy: 0.5088\n",
      "Epoch 6/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5134 - val_loss: 0.6930 - val_accuracy: 0.5081\n",
      "Epoch 7/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6925 - accuracy: 0.5132 - val_loss: 0.6932 - val_accuracy: 0.5041\n",
      "Epoch 8/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5143 - val_loss: 0.6931 - val_accuracy: 0.5082\n",
      "Epoch 9/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5156 - val_loss: 0.6931 - val_accuracy: 0.5048\n",
      "Epoch 10/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5154 - val_loss: 0.6931 - val_accuracy: 0.5063\n",
      "Epoch 11/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5150 - val_loss: 0.6931 - val_accuracy: 0.5071\n",
      "Epoch 12/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5170 - val_loss: 0.6931 - val_accuracy: 0.5061\n",
      "Epoch 13/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5168 - val_loss: 0.6932 - val_accuracy: 0.5083\n",
      "Epoch 14/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40952/40952 [==============================] - 0s 12us/sample - loss: 0.6922 - accuracy: 0.5162 - val_loss: 0.6931 - val_accuracy: 0.5079\n",
      "Epoch 15/1000\n",
      "40952/40952 [==============================] - 1s 12us/sample - loss: 0.6922 - accuracy: 0.5169 - val_loss: 0.6931 - val_accuracy: 0.5080\n",
      "Epoch 16/1000\n",
      "40952/40952 [==============================] - 1s 12us/sample - loss: 0.6922 - accuracy: 0.5171 - val_loss: 0.6932 - val_accuracy: 0.5067\n",
      "Epoch 17/1000\n",
      "40952/40952 [==============================] - 0s 12us/sample - loss: 0.6921 - accuracy: 0.5179 - val_loss: 0.6932 - val_accuracy: 0.5092\n",
      "Epoch 18/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5168 - val_loss: 0.6931 - val_accuracy: 0.5079\n",
      "Epoch 19/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5154 - val_loss: 0.6932 - val_accuracy: 0.5067\n",
      "Epoch 20/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5160 - val_loss: 0.6932 - val_accuracy: 0.5096\n",
      "Epoch 21/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5158 - val_loss: 0.6931 - val_accuracy: 0.5078\n",
      "Epoch 22/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5159 - val_loss: 0.6931 - val_accuracy: 0.5077\n",
      "Epoch 23/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5180 - val_loss: 0.6932 - val_accuracy: 0.5056\n",
      "Epoch 24/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5171 - val_loss: 0.6932 - val_accuracy: 0.5107\n",
      "Epoch 25/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5165 - val_loss: 0.6932 - val_accuracy: 0.5084\n",
      "Epoch 26/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5166 - val_loss: 0.6932 - val_accuracy: 0.5099\n",
      "Epoch 27/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5162 - val_loss: 0.6932 - val_accuracy: 0.5095\n",
      "Epoch 28/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5165 - val_loss: 0.6932 - val_accuracy: 0.5095\n",
      "Epoch 29/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5164 - val_loss: 0.6932 - val_accuracy: 0.5080\n",
      "Epoch 30/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5183 - val_loss: 0.6931 - val_accuracy: 0.5101\n",
      "Epoch 31/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5169 - val_loss: 0.6931 - val_accuracy: 0.5097\n",
      "Epoch 32/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5175 - val_loss: 0.6932 - val_accuracy: 0.5103\n",
      "Training with significance = 0.63, run 1\n",
      "Train on 40952 samples, validate on 10238 samples\n",
      "Epoch 1/1000\n",
      "40952/40952 [==============================] - 1s 28us/sample - loss: 0.6939 - accuracy: 0.5054 - val_loss: 0.6931 - val_accuracy: 0.5022\n",
      "Epoch 2/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6928 - accuracy: 0.5124 - val_loss: 0.6925 - val_accuracy: 0.5110\n",
      "Epoch 3/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6925 - accuracy: 0.5162 - val_loss: 0.6924 - val_accuracy: 0.5112\n",
      "Epoch 4/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5188 - val_loss: 0.6923 - val_accuracy: 0.5105\n",
      "Epoch 5/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5155 - val_loss: 0.6927 - val_accuracy: 0.5117\n",
      "Epoch 6/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5182 - val_loss: 0.6927 - val_accuracy: 0.5104\n",
      "Epoch 7/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5182 - val_loss: 0.6925 - val_accuracy: 0.5085\n",
      "Epoch 8/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5194 - val_loss: 0.6930 - val_accuracy: 0.5092\n",
      "Epoch 9/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5202 - val_loss: 0.6924 - val_accuracy: 0.5081\n",
      "Epoch 10/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5182 - val_loss: 0.6932 - val_accuracy: 0.5094\n",
      "Epoch 11/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5185 - val_loss: 0.6930 - val_accuracy: 0.5121\n",
      "Epoch 12/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5199 - val_loss: 0.6927 - val_accuracy: 0.5078\n",
      "Epoch 13/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5198 - val_loss: 0.6926 - val_accuracy: 0.5112\n",
      "Epoch 14/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5194 - val_loss: 0.6925 - val_accuracy: 0.5090\n",
      "Epoch 15/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5191 - val_loss: 0.6928 - val_accuracy: 0.5103\n",
      "Epoch 16/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5201 - val_loss: 0.6928 - val_accuracy: 0.5098\n",
      "Epoch 17/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5215 - val_loss: 0.6931 - val_accuracy: 0.5129\n",
      "Epoch 18/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5208 - val_loss: 0.6930 - val_accuracy: 0.5102\n",
      "Epoch 19/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5213 - val_loss: 0.6927 - val_accuracy: 0.5105\n",
      "Epoch 20/1000\n",
      "40952/40952 [==============================] - 1s 12us/sample - loss: 0.6918 - accuracy: 0.5194 - val_loss: 0.6928 - val_accuracy: 0.5113\n",
      "Epoch 21/1000\n",
      "40952/40952 [==============================] - 1s 12us/sample - loss: 0.6918 - accuracy: 0.5212 - val_loss: 0.6925 - val_accuracy: 0.5101\n",
      "Epoch 22/1000\n",
      "40952/40952 [==============================] - 0s 12us/sample - loss: 0.6918 - accuracy: 0.5200 - val_loss: 0.6928 - val_accuracy: 0.5104\n",
      "Epoch 23/1000\n",
      "40952/40952 [==============================] - 0s 12us/sample - loss: 0.6917 - accuracy: 0.5215 - val_loss: 0.6924 - val_accuracy: 0.5115\n",
      "Epoch 24/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5209 - val_loss: 0.6924 - val_accuracy: 0.5064\n",
      "Epoch 25/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5206 - val_loss: 0.6931 - val_accuracy: 0.5114\n",
      "Epoch 26/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5211 - val_loss: 0.6927 - val_accuracy: 0.5113\n",
      "Epoch 27/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5231 - val_loss: 0.6931 - val_accuracy: 0.5099\n",
      "Epoch 28/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5211 - val_loss: 0.6926 - val_accuracy: 0.5105\n",
      "Epoch 29/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5217 - val_loss: 0.6927 - val_accuracy: 0.5105\n",
      "Epoch 30/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5215 - val_loss: 0.6927 - val_accuracy: 0.5102\n",
      "Epoch 31/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5206 - val_loss: 0.6928 - val_accuracy: 0.5129\n",
      "Epoch 32/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5224 - val_loss: 0.6928 - val_accuracy: 0.5112\n",
      "Epoch 33/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5213 - val_loss: 0.6925 - val_accuracy: 0.5093\n",
      "Epoch 34/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5211 - val_loss: 0.6927 - val_accuracy: 0.5122\n",
      "Training with significance = 0.63, run 2\n",
      "Train on 40952 samples, validate on 10238 samples\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40952/40952 [==============================] - 1s 35us/sample - loss: 0.6936 - accuracy: 0.5017 - val_loss: 0.6931 - val_accuracy: 0.5023\n",
      "Epoch 2/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6926 - accuracy: 0.5151 - val_loss: 0.6929 - val_accuracy: 0.5025\n",
      "Epoch 3/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6925 - accuracy: 0.5147 - val_loss: 0.6929 - val_accuracy: 0.5069\n",
      "Epoch 4/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5178 - val_loss: 0.6931 - val_accuracy: 0.5080\n",
      "Epoch 5/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5166 - val_loss: 0.6932 - val_accuracy: 0.5066\n",
      "Epoch 6/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5182 - val_loss: 0.6931 - val_accuracy: 0.5072\n",
      "Epoch 7/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5179 - val_loss: 0.6932 - val_accuracy: 0.5066\n",
      "Epoch 8/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5183 - val_loss: 0.6931 - val_accuracy: 0.5061\n",
      "Epoch 9/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5167 - val_loss: 0.6932 - val_accuracy: 0.5053\n",
      "Epoch 10/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5178 - val_loss: 0.6932 - val_accuracy: 0.5050\n",
      "Epoch 11/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5171 - val_loss: 0.6931 - val_accuracy: 0.5042\n",
      "Epoch 12/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5212 - val_loss: 0.6932 - val_accuracy: 0.5059\n",
      "Epoch 13/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5174 - val_loss: 0.6933 - val_accuracy: 0.5053\n",
      "Epoch 14/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5198 - val_loss: 0.6933 - val_accuracy: 0.5046\n",
      "Epoch 15/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5190 - val_loss: 0.6932 - val_accuracy: 0.5046\n",
      "Epoch 16/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5183 - val_loss: 0.6933 - val_accuracy: 0.5034\n",
      "Epoch 17/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5181 - val_loss: 0.6934 - val_accuracy: 0.5041\n",
      "Epoch 18/1000\n",
      "40952/40952 [==============================] - 1s 12us/sample - loss: 0.6919 - accuracy: 0.5203 - val_loss: 0.6933 - val_accuracy: 0.5053\n",
      "Epoch 19/1000\n",
      "40952/40952 [==============================] - 1s 12us/sample - loss: 0.6919 - accuracy: 0.5191 - val_loss: 0.6937 - val_accuracy: 0.5028\n",
      "Epoch 20/1000\n",
      "40952/40952 [==============================] - 1s 12us/sample - loss: 0.6921 - accuracy: 0.5199 - val_loss: 0.6935 - val_accuracy: 0.5034\n",
      "Epoch 21/1000\n",
      "40952/40952 [==============================] - 0s 12us/sample - loss: 0.6919 - accuracy: 0.5212 - val_loss: 0.6933 - val_accuracy: 0.5039\n",
      "Epoch 22/1000\n",
      "40952/40952 [==============================] - 1s 12us/sample - loss: 0.6920 - accuracy: 0.5191 - val_loss: 0.6934 - val_accuracy: 0.5043\n",
      "Epoch 23/1000\n",
      "40952/40952 [==============================] - 1s 12us/sample - loss: 0.6918 - accuracy: 0.5195 - val_loss: 0.6933 - val_accuracy: 0.5049\n",
      "Epoch 24/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5195 - val_loss: 0.6933 - val_accuracy: 0.5046\n",
      "Epoch 25/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5194 - val_loss: 0.6933 - val_accuracy: 0.5050\n",
      "Epoch 26/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5209 - val_loss: 0.6934 - val_accuracy: 0.5037\n",
      "Epoch 27/1000\n",
      "40952/40952 [==============================] - 1s 12us/sample - loss: 0.6918 - accuracy: 0.5183 - val_loss: 0.6935 - val_accuracy: 0.5053\n",
      "Epoch 28/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5201 - val_loss: 0.6932 - val_accuracy: 0.5054\n",
      "Epoch 29/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5192 - val_loss: 0.6935 - val_accuracy: 0.5057\n",
      "Epoch 30/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5202 - val_loss: 0.6933 - val_accuracy: 0.5088\n",
      "Epoch 31/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5210 - val_loss: 0.6932 - val_accuracy: 0.5072\n",
      "Epoch 32/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5215 - val_loss: 0.6933 - val_accuracy: 0.5067\n",
      "Training with significance = 0.63, run 3\n",
      "Train on 40952 samples, validate on 10238 samples\n",
      "Epoch 1/1000\n",
      "40952/40952 [==============================] - 1s 27us/sample - loss: 0.6940 - accuracy: 0.5050 - val_loss: 0.6932 - val_accuracy: 0.5071\n",
      "Epoch 2/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6927 - accuracy: 0.5122 - val_loss: 0.6930 - val_accuracy: 0.5090\n",
      "Epoch 3/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6925 - accuracy: 0.5137 - val_loss: 0.6930 - val_accuracy: 0.5097\n",
      "Epoch 4/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5155 - val_loss: 0.6930 - val_accuracy: 0.5113\n",
      "Epoch 5/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5166 - val_loss: 0.6931 - val_accuracy: 0.5107\n",
      "Epoch 6/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5161 - val_loss: 0.6930 - val_accuracy: 0.5145\n",
      "Epoch 7/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5185 - val_loss: 0.6928 - val_accuracy: 0.5161\n",
      "Epoch 8/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5155 - val_loss: 0.6929 - val_accuracy: 0.5132\n",
      "Epoch 9/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5171 - val_loss: 0.6929 - val_accuracy: 0.5133\n",
      "Epoch 10/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5158 - val_loss: 0.6931 - val_accuracy: 0.5101\n",
      "Epoch 11/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5166 - val_loss: 0.6930 - val_accuracy: 0.5137\n",
      "Epoch 12/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5177 - val_loss: 0.6932 - val_accuracy: 0.5138\n",
      "Epoch 13/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5179 - val_loss: 0.6931 - val_accuracy: 0.5132\n",
      "Epoch 14/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5158 - val_loss: 0.6934 - val_accuracy: 0.5133\n",
      "Epoch 15/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5186 - val_loss: 0.6930 - val_accuracy: 0.5131\n",
      "Epoch 16/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5188 - val_loss: 0.6928 - val_accuracy: 0.5135\n",
      "Epoch 17/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5189 - val_loss: 0.6929 - val_accuracy: 0.5140\n",
      "Epoch 18/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5179 - val_loss: 0.6930 - val_accuracy: 0.5132\n",
      "Epoch 19/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5178 - val_loss: 0.6929 - val_accuracy: 0.5131\n",
      "Epoch 20/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5189 - val_loss: 0.6929 - val_accuracy: 0.5143\n",
      "Epoch 21/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5184 - val_loss: 0.6930 - val_accuracy: 0.5127\n",
      "Epoch 22/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5178 - val_loss: 0.6931 - val_accuracy: 0.5115\n",
      "Epoch 23/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5181 - val_loss: 0.6932 - val_accuracy: 0.5138\n",
      "Epoch 24/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5199 - val_loss: 0.6929 - val_accuracy: 0.5132\n",
      "Epoch 25/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5187 - val_loss: 0.6931 - val_accuracy: 0.5148\n",
      "Epoch 26/1000\n",
      "40952/40952 [==============================] - 0s 12us/sample - loss: 0.6918 - accuracy: 0.5209 - val_loss: 0.6930 - val_accuracy: 0.5150\n",
      "Epoch 27/1000\n",
      "40952/40952 [==============================] - 1s 12us/sample - loss: 0.6917 - accuracy: 0.5182 - val_loss: 0.6930 - val_accuracy: 0.5162\n",
      "Epoch 28/1000\n",
      "40952/40952 [==============================] - 1s 12us/sample - loss: 0.6917 - accuracy: 0.5197 - val_loss: 0.6930 - val_accuracy: 0.5126\n",
      "Epoch 29/1000\n",
      "40952/40952 [==============================] - 0s 12us/sample - loss: 0.6917 - accuracy: 0.5182 - val_loss: 0.6929 - val_accuracy: 0.5177\n",
      "Epoch 30/1000\n",
      "40952/40952 [==============================] - 0s 12us/sample - loss: 0.6917 - accuracy: 0.5172 - val_loss: 0.6932 - val_accuracy: 0.5165\n",
      "Epoch 31/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5193 - val_loss: 0.6932 - val_accuracy: 0.5148\n",
      "Epoch 32/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5179 - val_loss: 0.6929 - val_accuracy: 0.5134\n",
      "Epoch 33/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5187 - val_loss: 0.6930 - val_accuracy: 0.5136\n",
      "Epoch 34/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5202 - val_loss: 0.6928 - val_accuracy: 0.5147\n",
      "Epoch 35/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5186 - val_loss: 0.6934 - val_accuracy: 0.5137\n",
      "Epoch 36/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5219 - val_loss: 0.6933 - val_accuracy: 0.5125\n",
      "Epoch 37/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5191 - val_loss: 0.6931 - val_accuracy: 0.5131\n",
      "Training with significance = 0.63, run 4\n",
      "Train on 40952 samples, validate on 10238 samples\n",
      "Epoch 1/1000\n",
      "40952/40952 [==============================] - 1s 37us/sample - loss: 0.6936 - accuracy: 0.5047 - val_loss: 0.6929 - val_accuracy: 0.5120\n",
      "Epoch 2/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6927 - accuracy: 0.5113 - val_loss: 0.6925 - val_accuracy: 0.5207\n",
      "Epoch 3/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6925 - accuracy: 0.5123 - val_loss: 0.6923 - val_accuracy: 0.5253\n",
      "Epoch 4/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6925 - accuracy: 0.5130 - val_loss: 0.6921 - val_accuracy: 0.5213\n",
      "Epoch 5/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5148 - val_loss: 0.6921 - val_accuracy: 0.5212\n",
      "Epoch 6/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5153 - val_loss: 0.6920 - val_accuracy: 0.5226\n",
      "Epoch 7/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5154 - val_loss: 0.6920 - val_accuracy: 0.5224\n",
      "Epoch 8/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5155 - val_loss: 0.6920 - val_accuracy: 0.5198\n",
      "Epoch 9/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5155 - val_loss: 0.6921 - val_accuracy: 0.5217\n",
      "Epoch 10/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5178 - val_loss: 0.6920 - val_accuracy: 0.5216\n",
      "Epoch 11/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5148 - val_loss: 0.6920 - val_accuracy: 0.5190\n",
      "Epoch 12/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5166 - val_loss: 0.6921 - val_accuracy: 0.5220\n",
      "Epoch 13/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5187 - val_loss: 0.6920 - val_accuracy: 0.5207\n",
      "Epoch 14/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5182 - val_loss: 0.6920 - val_accuracy: 0.5205\n",
      "Epoch 15/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5189 - val_loss: 0.6919 - val_accuracy: 0.5224\n",
      "Epoch 16/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5176 - val_loss: 0.6923 - val_accuracy: 0.5193\n",
      "Epoch 17/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5168 - val_loss: 0.6922 - val_accuracy: 0.5193\n",
      "Epoch 18/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5168 - val_loss: 0.6921 - val_accuracy: 0.5195\n",
      "Epoch 19/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5199 - val_loss: 0.6923 - val_accuracy: 0.5183\n",
      "Epoch 20/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5161 - val_loss: 0.6921 - val_accuracy: 0.5193\n",
      "Epoch 21/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5184 - val_loss: 0.6920 - val_accuracy: 0.5173\n",
      "Epoch 22/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5191 - val_loss: 0.6920 - val_accuracy: 0.5206\n",
      "Epoch 23/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5178 - val_loss: 0.6920 - val_accuracy: 0.5197\n",
      "Epoch 24/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5186 - val_loss: 0.6921 - val_accuracy: 0.5199\n",
      "Epoch 25/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5191 - val_loss: 0.6921 - val_accuracy: 0.5197\n",
      "Epoch 26/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5178 - val_loss: 0.6920 - val_accuracy: 0.5188\n",
      "Epoch 27/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5180 - val_loss: 0.6922 - val_accuracy: 0.5210\n",
      "Epoch 28/1000\n",
      "40952/40952 [==============================] - 1s 12us/sample - loss: 0.6917 - accuracy: 0.5196 - val_loss: 0.6920 - val_accuracy: 0.5198\n",
      "Epoch 29/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5186 - val_loss: 0.6921 - val_accuracy: 0.5200\n",
      "Epoch 30/1000\n",
      "40952/40952 [==============================] - 0s 12us/sample - loss: 0.6917 - accuracy: 0.5189 - val_loss: 0.6923 - val_accuracy: 0.5183\n",
      "Epoch 31/1000\n",
      "40952/40952 [==============================] - 1s 12us/sample - loss: 0.6917 - accuracy: 0.5189 - val_loss: 0.6921 - val_accuracy: 0.5181\n",
      "Epoch 32/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5196 - val_loss: 0.6921 - val_accuracy: 0.5200\n",
      "Epoch 33/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5184 - val_loss: 0.6921 - val_accuracy: 0.5183\n",
      "Epoch 34/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5199 - val_loss: 0.6921 - val_accuracy: 0.5193\n",
      "Epoch 35/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5182 - val_loss: 0.6921 - val_accuracy: 0.5203\n",
      "Epoch 36/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5177 - val_loss: 0.6923 - val_accuracy: 0.5207\n",
      "Epoch 37/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5191 - val_loss: 0.6921 - val_accuracy: 0.5199\n",
      "Epoch 38/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5188 - val_loss: 0.6922 - val_accuracy: 0.5199\n",
      "Epoch 39/1000\n",
      "40952/40952 [==============================] - 1s 14us/sample - loss: 0.6915 - accuracy: 0.5195 - val_loss: 0.6923 - val_accuracy: 0.5208\n",
      "Epoch 40/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5199 - val_loss: 0.6920 - val_accuracy: 0.5195\n",
      "Epoch 41/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5199 - val_loss: 0.6921 - val_accuracy: 0.5231\n",
      "Epoch 42/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5196 - val_loss: 0.6921 - val_accuracy: 0.5199\n",
      "Epoch 43/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5212 - val_loss: 0.6921 - val_accuracy: 0.5207\n",
      "Epoch 44/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5206 - val_loss: 0.6923 - val_accuracy: 0.5186\n",
      "Epoch 45/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5199 - val_loss: 0.6922 - val_accuracy: 0.5189\n",
      "Training with significance = 0.63, run 5\n",
      "Train on 40952 samples, validate on 10238 samples\n",
      "Epoch 1/1000\n",
      "40952/40952 [==============================] - 1s 29us/sample - loss: 0.6936 - accuracy: 0.5098 - val_loss: 0.6929 - val_accuracy: 0.5126\n",
      "Epoch 2/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6927 - accuracy: 0.5124 - val_loss: 0.6928 - val_accuracy: 0.5075\n",
      "Epoch 3/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6926 - accuracy: 0.5156 - val_loss: 0.6929 - val_accuracy: 0.5096\n",
      "Epoch 4/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5146 - val_loss: 0.6926 - val_accuracy: 0.5111\n",
      "Epoch 5/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5156 - val_loss: 0.6928 - val_accuracy: 0.5090\n",
      "Epoch 6/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5163 - val_loss: 0.6927 - val_accuracy: 0.5103\n",
      "Epoch 7/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5165 - val_loss: 0.6928 - val_accuracy: 0.5096\n",
      "Epoch 8/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5162 - val_loss: 0.6928 - val_accuracy: 0.5094\n",
      "Epoch 9/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5169 - val_loss: 0.6928 - val_accuracy: 0.5089\n",
      "Epoch 10/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5169 - val_loss: 0.6927 - val_accuracy: 0.5106\n",
      "Epoch 11/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5170 - val_loss: 0.6926 - val_accuracy: 0.5127\n",
      "Epoch 12/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5168 - val_loss: 0.6927 - val_accuracy: 0.5102\n",
      "Epoch 13/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5176 - val_loss: 0.6926 - val_accuracy: 0.5110\n",
      "Epoch 14/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5188 - val_loss: 0.6928 - val_accuracy: 0.5089\n",
      "Epoch 15/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5172 - val_loss: 0.6927 - val_accuracy: 0.5105\n",
      "Epoch 16/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5200 - val_loss: 0.6928 - val_accuracy: 0.5057\n",
      "Epoch 17/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5184 - val_loss: 0.6927 - val_accuracy: 0.5116\n",
      "Epoch 18/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5193 - val_loss: 0.6928 - val_accuracy: 0.5099\n",
      "Epoch 19/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5183 - val_loss: 0.6927 - val_accuracy: 0.5121\n",
      "Epoch 20/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5184 - val_loss: 0.6926 - val_accuracy: 0.5121\n",
      "Epoch 21/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5176 - val_loss: 0.6927 - val_accuracy: 0.5105\n",
      "Epoch 22/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5178 - val_loss: 0.6928 - val_accuracy: 0.5106\n",
      "Epoch 23/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5198 - val_loss: 0.6926 - val_accuracy: 0.5113\n",
      "Epoch 24/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5198 - val_loss: 0.6926 - val_accuracy: 0.5112\n",
      "Epoch 25/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5209 - val_loss: 0.6927 - val_accuracy: 0.5086\n",
      "Epoch 26/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5201 - val_loss: 0.6928 - val_accuracy: 0.5072\n",
      "Epoch 27/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5194 - val_loss: 0.6926 - val_accuracy: 0.5122\n",
      "Epoch 28/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5210 - val_loss: 0.6929 - val_accuracy: 0.5071\n",
      "Epoch 29/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5195 - val_loss: 0.6927 - val_accuracy: 0.5101\n",
      "Epoch 30/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5202 - val_loss: 0.6927 - val_accuracy: 0.5114\n",
      "Epoch 31/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5209 - val_loss: 0.6928 - val_accuracy: 0.5069\n",
      "Epoch 32/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5204 - val_loss: 0.6928 - val_accuracy: 0.5107\n",
      "Epoch 33/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5206 - val_loss: 0.6929 - val_accuracy: 0.5089\n",
      "Epoch 34/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5189 - val_loss: 0.6927 - val_accuracy: 0.5076\n",
      "Training with significance = 0.63, run 6\n",
      "Train on 40952 samples, validate on 10238 samples\n",
      "Epoch 1/1000\n",
      "40952/40952 [==============================] - 1s 36us/sample - loss: 0.6942 - accuracy: 0.5026 - val_loss: 0.6928 - val_accuracy: 0.5166\n",
      "Epoch 2/1000\n",
      "40952/40952 [==============================] - 1s 12us/sample - loss: 0.6928 - accuracy: 0.5088 - val_loss: 0.6931 - val_accuracy: 0.5060\n",
      "Epoch 3/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6927 - accuracy: 0.5130 - val_loss: 0.6927 - val_accuracy: 0.5123\n",
      "Epoch 4/1000\n",
      "40952/40952 [==============================] - 0s 12us/sample - loss: 0.6925 - accuracy: 0.5122 - val_loss: 0.6928 - val_accuracy: 0.5154\n",
      "Epoch 5/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5132 - val_loss: 0.6923 - val_accuracy: 0.5164\n",
      "Epoch 6/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6925 - accuracy: 0.5132 - val_loss: 0.6923 - val_accuracy: 0.5165\n",
      "Epoch 7/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5129 - val_loss: 0.6923 - val_accuracy: 0.5180\n",
      "Epoch 8/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5133 - val_loss: 0.6919 - val_accuracy: 0.5205\n",
      "Epoch 9/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5138 - val_loss: 0.6920 - val_accuracy: 0.5210\n",
      "Epoch 10/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5149 - val_loss: 0.6921 - val_accuracy: 0.5191\n",
      "Epoch 11/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5161 - val_loss: 0.6921 - val_accuracy: 0.5195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5157 - val_loss: 0.6920 - val_accuracy: 0.5213\n",
      "Epoch 13/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5168 - val_loss: 0.6927 - val_accuracy: 0.5060\n",
      "Epoch 14/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5152 - val_loss: 0.6922 - val_accuracy: 0.5197\n",
      "Epoch 15/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5151 - val_loss: 0.6923 - val_accuracy: 0.5188\n",
      "Epoch 16/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5152 - val_loss: 0.6920 - val_accuracy: 0.5229\n",
      "Epoch 17/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5173 - val_loss: 0.6922 - val_accuracy: 0.5173\n",
      "Epoch 18/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5158 - val_loss: 0.6922 - val_accuracy: 0.5203\n",
      "Epoch 19/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5151 - val_loss: 0.6921 - val_accuracy: 0.5161\n",
      "Epoch 20/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5173 - val_loss: 0.6923 - val_accuracy: 0.5164\n",
      "Epoch 21/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5171 - val_loss: 0.6924 - val_accuracy: 0.5136\n",
      "Epoch 22/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5157 - val_loss: 0.6921 - val_accuracy: 0.5191\n",
      "Epoch 23/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5170 - val_loss: 0.6921 - val_accuracy: 0.5215\n",
      "Epoch 24/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5182 - val_loss: 0.6920 - val_accuracy: 0.5208\n",
      "Epoch 25/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5173 - val_loss: 0.6920 - val_accuracy: 0.5214\n",
      "Epoch 26/1000\n",
      "40952/40952 [==============================] - 0s 12us/sample - loss: 0.6920 - accuracy: 0.5159 - val_loss: 0.6920 - val_accuracy: 0.5191\n",
      "Epoch 27/1000\n",
      "40952/40952 [==============================] - 0s 12us/sample - loss: 0.6920 - accuracy: 0.5174 - val_loss: 0.6922 - val_accuracy: 0.5189\n",
      "Epoch 28/1000\n",
      "40952/40952 [==============================] - 1s 12us/sample - loss: 0.6920 - accuracy: 0.5172 - val_loss: 0.6923 - val_accuracy: 0.5147\n",
      "Epoch 29/1000\n",
      "40952/40952 [==============================] - 1s 12us/sample - loss: 0.6920 - accuracy: 0.5186 - val_loss: 0.6923 - val_accuracy: 0.5151\n",
      "Epoch 30/1000\n",
      "40952/40952 [==============================] - 1s 12us/sample - loss: 0.6920 - accuracy: 0.5169 - val_loss: 0.6924 - val_accuracy: 0.5111\n",
      "Epoch 31/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5173 - val_loss: 0.6923 - val_accuracy: 0.5145\n",
      "Epoch 32/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5165 - val_loss: 0.6922 - val_accuracy: 0.5156\n",
      "Epoch 33/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5158 - val_loss: 0.6923 - val_accuracy: 0.5154\n",
      "Epoch 34/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5177 - val_loss: 0.6921 - val_accuracy: 0.5193\n",
      "Epoch 35/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5172 - val_loss: 0.6925 - val_accuracy: 0.5156\n",
      "Epoch 36/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5184 - val_loss: 0.6920 - val_accuracy: 0.5201\n",
      "Epoch 37/1000\n",
      "40952/40952 [==============================] - 1s 12us/sample - loss: 0.6920 - accuracy: 0.5182 - val_loss: 0.6923 - val_accuracy: 0.5154\n",
      "Epoch 38/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5167 - val_loss: 0.6924 - val_accuracy: 0.5179\n",
      "Training with significance = 0.63, run 7\n",
      "Train on 40952 samples, validate on 10238 samples\n",
      "Epoch 1/1000\n",
      "40952/40952 [==============================] - 1s 28us/sample - loss: 0.6930 - accuracy: 0.5074 - val_loss: 0.6934 - val_accuracy: 0.4966\n",
      "Epoch 2/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6925 - accuracy: 0.5119 - val_loss: 0.6928 - val_accuracy: 0.5099\n",
      "Epoch 3/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6925 - accuracy: 0.5121 - val_loss: 0.6929 - val_accuracy: 0.5116\n",
      "Epoch 4/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5133 - val_loss: 0.6924 - val_accuracy: 0.5088\n",
      "Epoch 5/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5126 - val_loss: 0.6923 - val_accuracy: 0.5169\n",
      "Epoch 6/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5133 - val_loss: 0.6924 - val_accuracy: 0.5128\n",
      "Epoch 7/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5129 - val_loss: 0.6923 - val_accuracy: 0.5180\n",
      "Epoch 8/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5142 - val_loss: 0.6923 - val_accuracy: 0.5141\n",
      "Epoch 9/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5136 - val_loss: 0.6922 - val_accuracy: 0.5178\n",
      "Epoch 10/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5139 - val_loss: 0.6924 - val_accuracy: 0.5138\n",
      "Epoch 11/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5132 - val_loss: 0.6923 - val_accuracy: 0.5171\n",
      "Epoch 12/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5151 - val_loss: 0.6922 - val_accuracy: 0.5151\n",
      "Epoch 13/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5149 - val_loss: 0.6924 - val_accuracy: 0.5139\n",
      "Epoch 14/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5159 - val_loss: 0.6923 - val_accuracy: 0.5163\n",
      "Epoch 15/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5151 - val_loss: 0.6922 - val_accuracy: 0.5166\n",
      "Epoch 16/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5149 - val_loss: 0.6924 - val_accuracy: 0.5147\n",
      "Epoch 17/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5155 - val_loss: 0.6924 - val_accuracy: 0.5145\n",
      "Epoch 18/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5160 - val_loss: 0.6923 - val_accuracy: 0.5172\n",
      "Epoch 19/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5145 - val_loss: 0.6924 - val_accuracy: 0.5134\n",
      "Epoch 20/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5159 - val_loss: 0.6923 - val_accuracy: 0.5165\n",
      "Epoch 21/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5137 - val_loss: 0.6923 - val_accuracy: 0.5181\n",
      "Epoch 22/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5177 - val_loss: 0.6924 - val_accuracy: 0.5181\n",
      "Epoch 23/1000\n",
      "40952/40952 [==============================] - 1s 12us/sample - loss: 0.6919 - accuracy: 0.5164 - val_loss: 0.6922 - val_accuracy: 0.5192\n",
      "Epoch 24/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5153 - val_loss: 0.6922 - val_accuracy: 0.5171\n",
      "Epoch 25/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5148 - val_loss: 0.6924 - val_accuracy: 0.5159\n",
      "Epoch 26/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5164 - val_loss: 0.6925 - val_accuracy: 0.5175\n",
      "Epoch 27/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5154 - val_loss: 0.6922 - val_accuracy: 0.5180\n",
      "Epoch 28/1000\n",
      "40952/40952 [==============================] - 1s 12us/sample - loss: 0.6919 - accuracy: 0.5153 - val_loss: 0.6923 - val_accuracy: 0.5165\n",
      "Epoch 29/1000\n",
      "40952/40952 [==============================] - 0s 12us/sample - loss: 0.6919 - accuracy: 0.5164 - val_loss: 0.6922 - val_accuracy: 0.5189\n",
      "Epoch 30/1000\n",
      "40952/40952 [==============================] - 1s 12us/sample - loss: 0.6919 - accuracy: 0.5170 - val_loss: 0.6926 - val_accuracy: 0.5115\n",
      "Epoch 31/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5173 - val_loss: 0.6924 - val_accuracy: 0.5205\n",
      "Epoch 32/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5162 - val_loss: 0.6924 - val_accuracy: 0.5118\n",
      "Epoch 33/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5181 - val_loss: 0.6922 - val_accuracy: 0.5156\n",
      "Epoch 34/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5176 - val_loss: 0.6922 - val_accuracy: 0.5177\n",
      "Epoch 35/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5157 - val_loss: 0.6923 - val_accuracy: 0.5153\n",
      "Epoch 36/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5176 - val_loss: 0.6922 - val_accuracy: 0.5173\n",
      "Epoch 37/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5150 - val_loss: 0.6923 - val_accuracy: 0.5154\n",
      "Epoch 38/1000\n",
      "40952/40952 [==============================] - 1s 14us/sample - loss: 0.6917 - accuracy: 0.5160 - val_loss: 0.6924 - val_accuracy: 0.5166\n",
      "Epoch 39/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5168 - val_loss: 0.6925 - val_accuracy: 0.5117\n",
      "Epoch 40/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5153 - val_loss: 0.6922 - val_accuracy: 0.5169\n",
      "Epoch 41/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5179 - val_loss: 0.6924 - val_accuracy: 0.5167\n",
      "Epoch 42/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5188 - val_loss: 0.6923 - val_accuracy: 0.5193\n",
      "Epoch 43/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5163 - val_loss: 0.6922 - val_accuracy: 0.5167\n",
      "Epoch 44/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5170 - val_loss: 0.6924 - val_accuracy: 0.5167\n",
      "Epoch 45/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5202 - val_loss: 0.6925 - val_accuracy: 0.5117\n",
      "Epoch 46/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5179 - val_loss: 0.6925 - val_accuracy: 0.5097\n",
      "Epoch 47/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5148 - val_loss: 0.6923 - val_accuracy: 0.5189\n",
      "Epoch 48/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5196 - val_loss: 0.6924 - val_accuracy: 0.5150\n",
      "Epoch 49/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5169 - val_loss: 0.6924 - val_accuracy: 0.5179\n",
      "Epoch 50/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5175 - val_loss: 0.6922 - val_accuracy: 0.5169\n",
      "Epoch 51/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5170 - val_loss: 0.6922 - val_accuracy: 0.5187\n",
      "Epoch 52/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5178 - val_loss: 0.6922 - val_accuracy: 0.5171\n",
      "Epoch 53/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5169 - val_loss: 0.6925 - val_accuracy: 0.5123\n",
      "Epoch 54/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5153 - val_loss: 0.6924 - val_accuracy: 0.5134\n",
      "Epoch 55/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5211 - val_loss: 0.6923 - val_accuracy: 0.5180\n",
      "Epoch 56/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5188 - val_loss: 0.6923 - val_accuracy: 0.5164\n",
      "Epoch 57/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5192 - val_loss: 0.6924 - val_accuracy: 0.5131\n",
      "Epoch 58/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5186 - val_loss: 0.6924 - val_accuracy: 0.5155\n",
      "Epoch 59/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5185 - val_loss: 0.6924 - val_accuracy: 0.5202\n",
      "Epoch 60/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5170 - val_loss: 0.6925 - val_accuracy: 0.5101\n",
      "Epoch 61/1000\n",
      "40952/40952 [==============================] - 1s 14us/sample - loss: 0.6916 - accuracy: 0.5180 - val_loss: 0.6924 - val_accuracy: 0.5194\n",
      "Epoch 62/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5188 - val_loss: 0.6924 - val_accuracy: 0.5137\n",
      "Epoch 63/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5200 - val_loss: 0.6925 - val_accuracy: 0.5109\n",
      "Training with significance = 0.63, run 8\n",
      "Train on 40952 samples, validate on 10238 samples\n",
      "Epoch 1/1000\n",
      "40952/40952 [==============================] - 1s 28us/sample - loss: 0.6941 - accuracy: 0.5068 - val_loss: 0.6937 - val_accuracy: 0.4979\n",
      "Epoch 2/1000\n",
      "40952/40952 [==============================] - 1s 14us/sample - loss: 0.6929 - accuracy: 0.5111 - val_loss: 0.6930 - val_accuracy: 0.5076\n",
      "Epoch 3/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6927 - accuracy: 0.5120 - val_loss: 0.6926 - val_accuracy: 0.5161\n",
      "Epoch 4/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6925 - accuracy: 0.5143 - val_loss: 0.6926 - val_accuracy: 0.5178\n",
      "Epoch 5/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5139 - val_loss: 0.6925 - val_accuracy: 0.5163\n",
      "Epoch 6/1000\n",
      "40952/40952 [==============================] - 1s 14us/sample - loss: 0.6923 - accuracy: 0.5166 - val_loss: 0.6925 - val_accuracy: 0.5155\n",
      "Epoch 7/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5154 - val_loss: 0.6926 - val_accuracy: 0.5158\n",
      "Epoch 8/1000\n",
      "40952/40952 [==============================] - 1s 12us/sample - loss: 0.6923 - accuracy: 0.5174 - val_loss: 0.6925 - val_accuracy: 0.5172\n",
      "Epoch 9/1000\n",
      "40952/40952 [==============================] - 1s 12us/sample - loss: 0.6921 - accuracy: 0.5158 - val_loss: 0.6925 - val_accuracy: 0.5165\n",
      "Epoch 10/1000\n",
      "40952/40952 [==============================] - 1s 12us/sample - loss: 0.6921 - accuracy: 0.5183 - val_loss: 0.6926 - val_accuracy: 0.5157\n",
      "Epoch 11/1000\n",
      "40952/40952 [==============================] - 1s 12us/sample - loss: 0.6921 - accuracy: 0.5190 - val_loss: 0.6925 - val_accuracy: 0.5147\n",
      "Epoch 12/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5183 - val_loss: 0.6925 - val_accuracy: 0.5159\n",
      "Epoch 13/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5166 - val_loss: 0.6925 - val_accuracy: 0.5162\n",
      "Epoch 14/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5180 - val_loss: 0.6925 - val_accuracy: 0.5170\n",
      "Epoch 15/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5185 - val_loss: 0.6925 - val_accuracy: 0.5164\n",
      "Epoch 16/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5172 - val_loss: 0.6925 - val_accuracy: 0.5146\n",
      "Epoch 17/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5194 - val_loss: 0.6925 - val_accuracy: 0.5167\n",
      "Epoch 18/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5174 - val_loss: 0.6925 - val_accuracy: 0.5160\n",
      "Epoch 19/1000\n",
      "40952/40952 [==============================] - 1s 12us/sample - loss: 0.6920 - accuracy: 0.5184 - val_loss: 0.6925 - val_accuracy: 0.5182\n",
      "Epoch 20/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5187 - val_loss: 0.6925 - val_accuracy: 0.5148\n",
      "Epoch 21/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5180 - val_loss: 0.6925 - val_accuracy: 0.5137\n",
      "Epoch 22/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5190 - val_loss: 0.6924 - val_accuracy: 0.5165\n",
      "Epoch 23/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5181 - val_loss: 0.6925 - val_accuracy: 0.5161\n",
      "Epoch 24/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5179 - val_loss: 0.6925 - val_accuracy: 0.5159\n",
      "Epoch 25/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5183 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 26/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5178 - val_loss: 0.6926 - val_accuracy: 0.5139\n",
      "Epoch 27/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5176 - val_loss: 0.6925 - val_accuracy: 0.5148\n",
      "Epoch 28/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5189 - val_loss: 0.6925 - val_accuracy: 0.5165\n",
      "Epoch 29/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5182 - val_loss: 0.6924 - val_accuracy: 0.5162\n",
      "Epoch 30/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5193 - val_loss: 0.6925 - val_accuracy: 0.5148\n",
      "Epoch 31/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5205 - val_loss: 0.6925 - val_accuracy: 0.5150\n",
      "Epoch 32/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5190 - val_loss: 0.6925 - val_accuracy: 0.5144\n",
      "Epoch 33/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5201 - val_loss: 0.6925 - val_accuracy: 0.5167\n",
      "Epoch 34/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5181 - val_loss: 0.6925 - val_accuracy: 0.5147\n",
      "Epoch 35/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5214 - val_loss: 0.6925 - val_accuracy: 0.5141\n",
      "Epoch 36/1000\n",
      "40952/40952 [==============================] - 1s 14us/sample - loss: 0.6916 - accuracy: 0.5211 - val_loss: 0.6925 - val_accuracy: 0.5192\n",
      "Epoch 37/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5202 - val_loss: 0.6925 - val_accuracy: 0.5157\n",
      "Epoch 38/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5203 - val_loss: 0.6925 - val_accuracy: 0.5144\n",
      "Epoch 39/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5213 - val_loss: 0.6925 - val_accuracy: 0.5154\n",
      "Epoch 40/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5197 - val_loss: 0.6925 - val_accuracy: 0.5127\n",
      "Epoch 41/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5191 - val_loss: 0.6926 - val_accuracy: 0.5129\n",
      "Epoch 42/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5196 - val_loss: 0.6925 - val_accuracy: 0.5151\n",
      "Epoch 43/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5205 - val_loss: 0.6925 - val_accuracy: 0.5166\n",
      "Epoch 44/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5215 - val_loss: 0.6925 - val_accuracy: 0.5164\n",
      "Epoch 45/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5214 - val_loss: 0.6925 - val_accuracy: 0.5153\n",
      "Epoch 46/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5214 - val_loss: 0.6925 - val_accuracy: 0.5136\n",
      "Epoch 47/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5193 - val_loss: 0.6925 - val_accuracy: 0.5155\n",
      "Epoch 48/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5212 - val_loss: 0.6925 - val_accuracy: 0.5151\n",
      "Epoch 49/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5207 - val_loss: 0.6925 - val_accuracy: 0.5151\n",
      "Epoch 50/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5227 - val_loss: 0.6925 - val_accuracy: 0.5163\n",
      "Epoch 51/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5209 - val_loss: 0.6925 - val_accuracy: 0.5138\n",
      "Epoch 52/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5207 - val_loss: 0.6925 - val_accuracy: 0.5151\n",
      "Training with significance = 0.63, run 9\n",
      "Train on 40952 samples, validate on 10238 samples\n",
      "Epoch 1/1000\n",
      "40952/40952 [==============================] - 1s 28us/sample - loss: 0.6930 - accuracy: 0.5069 - val_loss: 0.6942 - val_accuracy: 0.5025\n",
      "Epoch 2/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6926 - accuracy: 0.5104 - val_loss: 0.6931 - val_accuracy: 0.5115\n",
      "Epoch 3/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6925 - accuracy: 0.5133 - val_loss: 0.6929 - val_accuracy: 0.5161\n",
      "Epoch 4/1000\n",
      "40952/40952 [==============================] - 1s 14us/sample - loss: 0.6924 - accuracy: 0.5138 - val_loss: 0.6927 - val_accuracy: 0.5157\n",
      "Epoch 5/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5137 - val_loss: 0.6927 - val_accuracy: 0.5159\n",
      "Epoch 6/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5140 - val_loss: 0.6927 - val_accuracy: 0.5143\n",
      "Epoch 7/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5119 - val_loss: 0.6924 - val_accuracy: 0.5195\n",
      "Epoch 8/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5137 - val_loss: 0.6925 - val_accuracy: 0.5175\n",
      "Epoch 9/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5142 - val_loss: 0.6926 - val_accuracy: 0.5165\n",
      "Epoch 10/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5145 - val_loss: 0.6925 - val_accuracy: 0.5191\n",
      "Epoch 11/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5147 - val_loss: 0.6926 - val_accuracy: 0.5178\n",
      "Epoch 12/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5146 - val_loss: 0.6926 - val_accuracy: 0.5170\n",
      "Epoch 13/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5167 - val_loss: 0.6925 - val_accuracy: 0.5183\n",
      "Epoch 14/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5164 - val_loss: 0.6926 - val_accuracy: 0.5184\n",
      "Epoch 15/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5149 - val_loss: 0.6927 - val_accuracy: 0.5169\n",
      "Epoch 16/1000\n",
      "40952/40952 [==============================] - 1s 12us/sample - loss: 0.6920 - accuracy: 0.5161 - val_loss: 0.6924 - val_accuracy: 0.5181\n",
      "Epoch 17/1000\n",
      "40952/40952 [==============================] - 0s 12us/sample - loss: 0.6920 - accuracy: 0.5152 - val_loss: 0.6928 - val_accuracy: 0.5155\n",
      "Epoch 18/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40952/40952 [==============================] - 0s 12us/sample - loss: 0.6921 - accuracy: 0.5144 - val_loss: 0.6925 - val_accuracy: 0.5181\n",
      "Epoch 19/1000\n",
      "40952/40952 [==============================] - 0s 12us/sample - loss: 0.6920 - accuracy: 0.5164 - val_loss: 0.6927 - val_accuracy: 0.5163\n",
      "Epoch 20/1000\n",
      "40952/40952 [==============================] - 1s 12us/sample - loss: 0.6921 - accuracy: 0.5155 - val_loss: 0.6925 - val_accuracy: 0.5178\n",
      "Epoch 21/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5158 - val_loss: 0.6924 - val_accuracy: 0.5186\n",
      "Epoch 22/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5157 - val_loss: 0.6927 - val_accuracy: 0.5173\n",
      "Epoch 23/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5171 - val_loss: 0.6925 - val_accuracy: 0.5171\n",
      "Epoch 24/1000\n",
      "40952/40952 [==============================] - 1s 14us/sample - loss: 0.6920 - accuracy: 0.5181 - val_loss: 0.6926 - val_accuracy: 0.5156\n",
      "Epoch 25/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5172 - val_loss: 0.6927 - val_accuracy: 0.5194\n",
      "Epoch 26/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5181 - val_loss: 0.6926 - val_accuracy: 0.5182\n",
      "Epoch 27/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5168 - val_loss: 0.6927 - val_accuracy: 0.5126\n",
      "Epoch 28/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5169 - val_loss: 0.6925 - val_accuracy: 0.5195\n",
      "Epoch 29/1000\n",
      "40952/40952 [==============================] - 1s 14us/sample - loss: 0.6918 - accuracy: 0.5177 - val_loss: 0.6927 - val_accuracy: 0.5174\n",
      "Epoch 30/1000\n",
      "40952/40952 [==============================] - 1s 14us/sample - loss: 0.6919 - accuracy: 0.5177 - val_loss: 0.6927 - val_accuracy: 0.5150\n",
      "Epoch 31/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5177 - val_loss: 0.6925 - val_accuracy: 0.5178\n",
      "Epoch 32/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5160 - val_loss: 0.6927 - val_accuracy: 0.5171\n",
      "Epoch 33/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5176 - val_loss: 0.6925 - val_accuracy: 0.5161\n",
      "Epoch 34/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5158 - val_loss: 0.6927 - val_accuracy: 0.5184\n",
      "Epoch 35/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5179 - val_loss: 0.6925 - val_accuracy: 0.5160\n",
      "Epoch 36/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5193 - val_loss: 0.6925 - val_accuracy: 0.5152\n",
      "Epoch 37/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5161 - val_loss: 0.6925 - val_accuracy: 0.5189\n",
      "Epoch 38/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5154 - val_loss: 0.6928 - val_accuracy: 0.5189\n",
      "Epoch 39/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5189 - val_loss: 0.6926 - val_accuracy: 0.5176\n",
      "Epoch 40/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5170 - val_loss: 0.6926 - val_accuracy: 0.5165\n",
      "Epoch 41/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5171 - val_loss: 0.6925 - val_accuracy: 0.5169\n",
      "Epoch 42/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5172 - val_loss: 0.6927 - val_accuracy: 0.5189\n",
      "Epoch 43/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5202 - val_loss: 0.6927 - val_accuracy: 0.5189\n",
      "Epoch 44/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5178 - val_loss: 0.6925 - val_accuracy: 0.5167\n",
      "Epoch 45/1000\n",
      "40952/40952 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5178 - val_loss: 0.6927 - val_accuracy: 0.5189\n",
      "Epoch 46/1000\n",
      "40952/40952 [==============================] - 1s 14us/sample - loss: 0.6917 - accuracy: 0.5184 - val_loss: 0.6926 - val_accuracy: 0.5174\n",
      "Training with significance = 0.95, run 0\n",
      "Train on 41003 samples, validate on 10251 samples\n",
      "Epoch 1/1000\n",
      "41003/41003 [==============================] - 1s 28us/sample - loss: 0.6942 - accuracy: 0.5074 - val_loss: 0.6931 - val_accuracy: 0.5069\n",
      "Epoch 2/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6928 - accuracy: 0.5133 - val_loss: 0.6927 - val_accuracy: 0.5100\n",
      "Epoch 3/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6927 - accuracy: 0.5152 - val_loss: 0.6928 - val_accuracy: 0.5120\n",
      "Epoch 4/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6927 - accuracy: 0.5132 - val_loss: 0.6928 - val_accuracy: 0.5115\n",
      "Epoch 5/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6926 - accuracy: 0.5162 - val_loss: 0.6929 - val_accuracy: 0.5101\n",
      "Epoch 6/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6925 - accuracy: 0.5165 - val_loss: 0.6929 - val_accuracy: 0.5115\n",
      "Epoch 7/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6926 - accuracy: 0.5156 - val_loss: 0.6928 - val_accuracy: 0.5098\n",
      "Epoch 8/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6925 - accuracy: 0.5175 - val_loss: 0.6929 - val_accuracy: 0.5072\n",
      "Epoch 9/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5179 - val_loss: 0.6929 - val_accuracy: 0.5095\n",
      "Epoch 10/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5160 - val_loss: 0.6930 - val_accuracy: 0.5089\n",
      "Epoch 11/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5142 - val_loss: 0.6929 - val_accuracy: 0.5080\n",
      "Epoch 12/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5160 - val_loss: 0.6928 - val_accuracy: 0.5099\n",
      "Epoch 13/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5165 - val_loss: 0.6929 - val_accuracy: 0.5103\n",
      "Epoch 14/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5166 - val_loss: 0.6930 - val_accuracy: 0.5068\n",
      "Epoch 15/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5163 - val_loss: 0.6930 - val_accuracy: 0.5066\n",
      "Epoch 16/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5189 - val_loss: 0.6931 - val_accuracy: 0.5052\n",
      "Epoch 17/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5158 - val_loss: 0.6929 - val_accuracy: 0.5080\n",
      "Epoch 18/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5166 - val_loss: 0.6929 - val_accuracy: 0.5071\n",
      "Epoch 19/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5173 - val_loss: 0.6929 - val_accuracy: 0.5060\n",
      "Epoch 20/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5181 - val_loss: 0.6930 - val_accuracy: 0.5066\n",
      "Epoch 21/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5177 - val_loss: 0.6929 - val_accuracy: 0.5087\n",
      "Epoch 22/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5170 - val_loss: 0.6930 - val_accuracy: 0.5077\n",
      "Epoch 23/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5165 - val_loss: 0.6930 - val_accuracy: 0.5103\n",
      "Epoch 24/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5175 - val_loss: 0.6929 - val_accuracy: 0.5091\n",
      "Epoch 25/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5155 - val_loss: 0.6929 - val_accuracy: 0.5111\n",
      "Epoch 26/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5187 - val_loss: 0.6929 - val_accuracy: 0.5087\n",
      "Epoch 27/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5166 - val_loss: 0.6930 - val_accuracy: 0.5092\n",
      "Epoch 28/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5184 - val_loss: 0.6930 - val_accuracy: 0.5054\n",
      "Epoch 29/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5172 - val_loss: 0.6929 - val_accuracy: 0.5064\n",
      "Epoch 30/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5177 - val_loss: 0.6929 - val_accuracy: 0.5072\n",
      "Epoch 31/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5177 - val_loss: 0.6929 - val_accuracy: 0.5080\n",
      "Epoch 32/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5167 - val_loss: 0.6930 - val_accuracy: 0.5078\n",
      "Training with significance = 0.95, run 1\n",
      "Train on 41003 samples, validate on 10251 samples\n",
      "Epoch 1/1000\n",
      "41003/41003 [==============================] - 2s 38us/sample - loss: 0.6936 - accuracy: 0.5044 - val_loss: 0.6938 - val_accuracy: 0.5031\n",
      "Epoch 2/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6928 - accuracy: 0.5116 - val_loss: 0.6933 - val_accuracy: 0.5086\n",
      "Epoch 3/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6927 - accuracy: 0.5155 - val_loss: 0.6928 - val_accuracy: 0.5082\n",
      "Epoch 4/1000\n",
      "41003/41003 [==============================] - 1s 14us/sample - loss: 0.6924 - accuracy: 0.5153 - val_loss: 0.6927 - val_accuracy: 0.5093\n",
      "Epoch 5/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6925 - accuracy: 0.5135 - val_loss: 0.6924 - val_accuracy: 0.5175\n",
      "Epoch 6/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5163 - val_loss: 0.6924 - val_accuracy: 0.5168\n",
      "Epoch 7/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5173 - val_loss: 0.6925 - val_accuracy: 0.5156\n",
      "Epoch 8/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5161 - val_loss: 0.6923 - val_accuracy: 0.5136\n",
      "Epoch 9/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5179 - val_loss: 0.6925 - val_accuracy: 0.5165\n",
      "Epoch 10/1000\n",
      "41003/41003 [==============================] - 1s 14us/sample - loss: 0.6922 - accuracy: 0.5170 - val_loss: 0.6925 - val_accuracy: 0.5195\n",
      "Epoch 11/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5178 - val_loss: 0.6926 - val_accuracy: 0.5175\n",
      "Epoch 12/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5186 - val_loss: 0.6928 - val_accuracy: 0.5156\n",
      "Epoch 13/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5146 - val_loss: 0.6924 - val_accuracy: 0.5149\n",
      "Epoch 14/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5176 - val_loss: 0.6925 - val_accuracy: 0.5157\n",
      "Epoch 15/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5177 - val_loss: 0.6924 - val_accuracy: 0.5130\n",
      "Epoch 16/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5185 - val_loss: 0.6924 - val_accuracy: 0.5131\n",
      "Epoch 17/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5169 - val_loss: 0.6924 - val_accuracy: 0.5174\n",
      "Epoch 18/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5186 - val_loss: 0.6924 - val_accuracy: 0.5161\n",
      "Epoch 19/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5198 - val_loss: 0.6925 - val_accuracy: 0.5189\n",
      "Epoch 20/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5183 - val_loss: 0.6924 - val_accuracy: 0.5178\n",
      "Epoch 21/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5192 - val_loss: 0.6923 - val_accuracy: 0.5184\n",
      "Epoch 22/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5178 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 23/1000\n",
      "41003/41003 [==============================] - 1s 14us/sample - loss: 0.6919 - accuracy: 0.5181 - val_loss: 0.6925 - val_accuracy: 0.5156\n",
      "Epoch 24/1000\n",
      "41003/41003 [==============================] - 1s 14us/sample - loss: 0.6920 - accuracy: 0.5184 - val_loss: 0.6925 - val_accuracy: 0.5139\n",
      "Epoch 25/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5177 - val_loss: 0.6924 - val_accuracy: 0.5156\n",
      "Epoch 26/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5198 - val_loss: 0.6926 - val_accuracy: 0.5120\n",
      "Epoch 27/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5183 - val_loss: 0.6925 - val_accuracy: 0.5151\n",
      "Epoch 28/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5194 - val_loss: 0.6924 - val_accuracy: 0.5151\n",
      "Epoch 29/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5173 - val_loss: 0.6924 - val_accuracy: 0.5169\n",
      "Epoch 30/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5186 - val_loss: 0.6925 - val_accuracy: 0.5175\n",
      "Epoch 31/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5190 - val_loss: 0.6924 - val_accuracy: 0.5176\n",
      "Epoch 32/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5173 - val_loss: 0.6924 - val_accuracy: 0.5170\n",
      "Epoch 33/1000\n",
      "41003/41003 [==============================] - 1s 14us/sample - loss: 0.6918 - accuracy: 0.5193 - val_loss: 0.6927 - val_accuracy: 0.5192\n",
      "Epoch 34/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5166 - val_loss: 0.6927 - val_accuracy: 0.5154\n",
      "Epoch 35/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5163 - val_loss: 0.6924 - val_accuracy: 0.5168\n",
      "Epoch 36/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5189 - val_loss: 0.6924 - val_accuracy: 0.5188\n",
      "Epoch 37/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5184 - val_loss: 0.6924 - val_accuracy: 0.5176\n",
      "Epoch 38/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5183 - val_loss: 0.6924 - val_accuracy: 0.5184\n",
      "Epoch 39/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5190 - val_loss: 0.6923 - val_accuracy: 0.5213\n",
      "Epoch 40/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5184 - val_loss: 0.6923 - val_accuracy: 0.5185\n",
      "Epoch 41/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5189 - val_loss: 0.6924 - val_accuracy: 0.5172\n",
      "Epoch 42/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5194 - val_loss: 0.6925 - val_accuracy: 0.5177\n",
      "Epoch 43/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5192 - val_loss: 0.6926 - val_accuracy: 0.5197\n",
      "Epoch 44/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5188 - val_loss: 0.6925 - val_accuracy: 0.5175\n",
      "Epoch 45/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5181 - val_loss: 0.6925 - val_accuracy: 0.5168\n",
      "Epoch 46/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5177 - val_loss: 0.6925 - val_accuracy: 0.5187\n",
      "Epoch 47/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5179 - val_loss: 0.6926 - val_accuracy: 0.5199\n",
      "Epoch 48/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5174 - val_loss: 0.6926 - val_accuracy: 0.5188\n",
      "Epoch 49/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5193 - val_loss: 0.6925 - val_accuracy: 0.5172\n",
      "Epoch 50/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5185 - val_loss: 0.6924 - val_accuracy: 0.5174\n",
      "Epoch 51/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5162 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Training with significance = 0.95, run 2\n",
      "Train on 41003 samples, validate on 10251 samples\n",
      "Epoch 1/1000\n",
      "41003/41003 [==============================] - 1s 29us/sample - loss: 0.6937 - accuracy: 0.5079 - val_loss: 0.6935 - val_accuracy: 0.5007\n",
      "Epoch 2/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6927 - accuracy: 0.5134 - val_loss: 0.6939 - val_accuracy: 0.4993\n",
      "Epoch 3/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6925 - accuracy: 0.5152 - val_loss: 0.6935 - val_accuracy: 0.5078\n",
      "Epoch 4/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6926 - accuracy: 0.5150 - val_loss: 0.6936 - val_accuracy: 0.5088\n",
      "Epoch 5/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6925 - accuracy: 0.5143 - val_loss: 0.6935 - val_accuracy: 0.5099\n",
      "Epoch 6/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5162 - val_loss: 0.6934 - val_accuracy: 0.5089\n",
      "Epoch 7/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5154 - val_loss: 0.6936 - val_accuracy: 0.5092\n",
      "Epoch 8/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6926 - accuracy: 0.5154 - val_loss: 0.6934 - val_accuracy: 0.5078\n",
      "Epoch 9/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5160 - val_loss: 0.6933 - val_accuracy: 0.5035\n",
      "Epoch 10/1000\n",
      "41003/41003 [==============================] - 1s 14us/sample - loss: 0.6924 - accuracy: 0.5164 - val_loss: 0.6932 - val_accuracy: 0.5086\n",
      "Epoch 11/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5148 - val_loss: 0.6935 - val_accuracy: 0.5053\n",
      "Epoch 12/1000\n",
      "41003/41003 [==============================] - 1s 12us/sample - loss: 0.6922 - accuracy: 0.5172 - val_loss: 0.6933 - val_accuracy: 0.5050\n",
      "Epoch 13/1000\n",
      "41003/41003 [==============================] - 1s 12us/sample - loss: 0.6923 - accuracy: 0.5168 - val_loss: 0.6936 - val_accuracy: 0.5037\n",
      "Epoch 14/1000\n",
      "41003/41003 [==============================] - 0s 12us/sample - loss: 0.6923 - accuracy: 0.5178 - val_loss: 0.6933 - val_accuracy: 0.5040\n",
      "Epoch 15/1000\n",
      "41003/41003 [==============================] - 1s 12us/sample - loss: 0.6922 - accuracy: 0.5168 - val_loss: 0.6932 - val_accuracy: 0.5078\n",
      "Epoch 16/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5152 - val_loss: 0.6934 - val_accuracy: 0.5040\n",
      "Epoch 17/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5173 - val_loss: 0.6932 - val_accuracy: 0.5084\n",
      "Epoch 18/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5200 - val_loss: 0.6932 - val_accuracy: 0.5072\n",
      "Epoch 19/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5186 - val_loss: 0.6933 - val_accuracy: 0.5039\n",
      "Epoch 20/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5182 - val_loss: 0.6931 - val_accuracy: 0.5058\n",
      "Epoch 21/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5190 - val_loss: 0.6933 - val_accuracy: 0.5044\n",
      "Epoch 22/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5184 - val_loss: 0.6931 - val_accuracy: 0.5133\n",
      "Epoch 23/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5173 - val_loss: 0.6930 - val_accuracy: 0.5086\n",
      "Epoch 24/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5211 - val_loss: 0.6932 - val_accuracy: 0.5042\n",
      "Epoch 25/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5187 - val_loss: 0.6933 - val_accuracy: 0.5040\n",
      "Epoch 26/1000\n",
      "41003/41003 [==============================] - 1s 14us/sample - loss: 0.6921 - accuracy: 0.5180 - val_loss: 0.6932 - val_accuracy: 0.5051\n",
      "Epoch 27/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5198 - val_loss: 0.6931 - val_accuracy: 0.5066\n",
      "Epoch 28/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5183 - val_loss: 0.6932 - val_accuracy: 0.5039\n",
      "Epoch 29/1000\n",
      "41003/41003 [==============================] - 1s 14us/sample - loss: 0.6920 - accuracy: 0.5198 - val_loss: 0.6931 - val_accuracy: 0.5066\n",
      "Epoch 30/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5177 - val_loss: 0.6931 - val_accuracy: 0.5093\n",
      "Epoch 31/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5205 - val_loss: 0.6931 - val_accuracy: 0.5101\n",
      "Epoch 32/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5177 - val_loss: 0.6933 - val_accuracy: 0.5105\n",
      "Epoch 33/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5199 - val_loss: 0.6932 - val_accuracy: 0.5084\n",
      "Epoch 34/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5177 - val_loss: 0.6932 - val_accuracy: 0.5102\n",
      "Epoch 35/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5164 - val_loss: 0.6933 - val_accuracy: 0.5128\n",
      "Epoch 36/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5178 - val_loss: 0.6935 - val_accuracy: 0.5124\n",
      "Epoch 37/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5204 - val_loss: 0.6935 - val_accuracy: 0.5077\n",
      "Epoch 38/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5207 - val_loss: 0.6932 - val_accuracy: 0.5044\n",
      "Epoch 39/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5205 - val_loss: 0.6932 - val_accuracy: 0.5106\n",
      "Epoch 40/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5194 - val_loss: 0.6934 - val_accuracy: 0.5027\n",
      "Epoch 41/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5191 - val_loss: 0.6933 - val_accuracy: 0.5085\n",
      "Epoch 42/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5160 - val_loss: 0.6933 - val_accuracy: 0.5091\n",
      "Epoch 43/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5180 - val_loss: 0.6933 - val_accuracy: 0.5049\n",
      "Epoch 44/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5205 - val_loss: 0.6931 - val_accuracy: 0.5041\n",
      "Epoch 45/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5206 - val_loss: 0.6931 - val_accuracy: 0.5083\n",
      "Epoch 46/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5186 - val_loss: 0.6934 - val_accuracy: 0.5044\n",
      "Epoch 47/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5216 - val_loss: 0.6932 - val_accuracy: 0.5069\n",
      "Epoch 48/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5204 - val_loss: 0.6932 - val_accuracy: 0.5079\n",
      "Epoch 49/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5192 - val_loss: 0.6932 - val_accuracy: 0.5086\n",
      "Epoch 50/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5182 - val_loss: 0.6931 - val_accuracy: 0.5082\n",
      "Epoch 51/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5199 - val_loss: 0.6932 - val_accuracy: 0.5074\n",
      "Epoch 52/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5187 - val_loss: 0.6931 - val_accuracy: 0.5104\n",
      "Epoch 53/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5198 - val_loss: 0.6931 - val_accuracy: 0.5050\n",
      "Training with significance = 0.95, run 3\n",
      "Train on 41003 samples, validate on 10251 samples\n",
      "Epoch 1/1000\n",
      "41003/41003 [==============================] - 1s 27us/sample - loss: 0.6935 - accuracy: 0.5056 - val_loss: 0.6931 - val_accuracy: 0.5035\n",
      "Epoch 2/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6929 - accuracy: 0.5118 - val_loss: 0.6928 - val_accuracy: 0.5072\n",
      "Epoch 3/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6927 - accuracy: 0.5125 - val_loss: 0.6926 - val_accuracy: 0.5151\n",
      "Epoch 4/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6927 - accuracy: 0.5125 - val_loss: 0.6925 - val_accuracy: 0.5148\n",
      "Epoch 5/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6928 - accuracy: 0.5127 - val_loss: 0.6926 - val_accuracy: 0.5151\n",
      "Epoch 6/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6926 - accuracy: 0.5164 - val_loss: 0.6923 - val_accuracy: 0.5133\n",
      "Epoch 7/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6926 - accuracy: 0.5146 - val_loss: 0.6922 - val_accuracy: 0.5162\n",
      "Epoch 8/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6926 - accuracy: 0.5145 - val_loss: 0.6923 - val_accuracy: 0.5134\n",
      "Epoch 9/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5156 - val_loss: 0.6923 - val_accuracy: 0.5160\n",
      "Epoch 10/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6925 - accuracy: 0.5098 - val_loss: 0.6923 - val_accuracy: 0.5141\n",
      "Epoch 11/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6925 - accuracy: 0.5141 - val_loss: 0.6923 - val_accuracy: 0.5158\n",
      "Epoch 12/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5140 - val_loss: 0.6922 - val_accuracy: 0.5150\n",
      "Epoch 13/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5142 - val_loss: 0.6921 - val_accuracy: 0.5165\n",
      "Epoch 14/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5159 - val_loss: 0.6922 - val_accuracy: 0.5155\n",
      "Epoch 15/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5168 - val_loss: 0.6921 - val_accuracy: 0.5152\n",
      "Epoch 16/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5171 - val_loss: 0.6920 - val_accuracy: 0.5176\n",
      "Epoch 17/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5131 - val_loss: 0.6920 - val_accuracy: 0.5164\n",
      "Epoch 18/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5165 - val_loss: 0.6921 - val_accuracy: 0.5155\n",
      "Epoch 19/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5166 - val_loss: 0.6921 - val_accuracy: 0.5163\n",
      "Epoch 20/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5169 - val_loss: 0.6920 - val_accuracy: 0.5162\n",
      "Epoch 21/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5152 - val_loss: 0.6920 - val_accuracy: 0.5153\n",
      "Epoch 22/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5160 - val_loss: 0.6920 - val_accuracy: 0.5157\n",
      "Epoch 23/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5167 - val_loss: 0.6921 - val_accuracy: 0.5152\n",
      "Epoch 24/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5173 - val_loss: 0.6922 - val_accuracy: 0.5155\n",
      "Epoch 25/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5155 - val_loss: 0.6922 - val_accuracy: 0.5142\n",
      "Epoch 26/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5161 - val_loss: 0.6922 - val_accuracy: 0.5121\n",
      "Epoch 27/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5169 - val_loss: 0.6923 - val_accuracy: 0.5139\n",
      "Epoch 28/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5163 - val_loss: 0.6923 - val_accuracy: 0.5126\n",
      "Epoch 29/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5165 - val_loss: 0.6922 - val_accuracy: 0.5141\n",
      "Epoch 30/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5167 - val_loss: 0.6922 - val_accuracy: 0.5129\n",
      "Epoch 31/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5181 - val_loss: 0.6920 - val_accuracy: 0.5158\n",
      "Epoch 32/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5168 - val_loss: 0.6921 - val_accuracy: 0.5149\n",
      "Epoch 33/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5155 - val_loss: 0.6922 - val_accuracy: 0.5163\n",
      "Epoch 34/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5166 - val_loss: 0.6920 - val_accuracy: 0.5131\n",
      "Epoch 35/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5159 - val_loss: 0.6920 - val_accuracy: 0.5179\n",
      "Epoch 36/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5177 - val_loss: 0.6920 - val_accuracy: 0.5160\n",
      "Epoch 37/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5160 - val_loss: 0.6921 - val_accuracy: 0.5157\n",
      "Epoch 38/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5177 - val_loss: 0.6921 - val_accuracy: 0.5126\n",
      "Epoch 39/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5186 - val_loss: 0.6921 - val_accuracy: 0.5165\n",
      "Epoch 40/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5166 - val_loss: 0.6921 - val_accuracy: 0.5141\n",
      "Epoch 41/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5177 - val_loss: 0.6923 - val_accuracy: 0.5122\n",
      "Epoch 42/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5194 - val_loss: 0.6922 - val_accuracy: 0.5139\n",
      "Epoch 43/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5182 - val_loss: 0.6921 - val_accuracy: 0.5146\n",
      "Epoch 44/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5198 - val_loss: 0.6922 - val_accuracy: 0.5142\n",
      "Epoch 45/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5176 - val_loss: 0.6921 - val_accuracy: 0.5106\n",
      "Epoch 46/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5177 - val_loss: 0.6922 - val_accuracy: 0.5141\n",
      "Epoch 47/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5187 - val_loss: 0.6923 - val_accuracy: 0.5128\n",
      "Training with significance = 0.95, run 4\n",
      "Train on 41003 samples, validate on 10251 samples\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41003/41003 [==============================] - 1s 27us/sample - loss: 0.6939 - accuracy: 0.5037 - val_loss: 0.6948 - val_accuracy: 0.4907\n",
      "Epoch 2/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6927 - accuracy: 0.5098 - val_loss: 0.6933 - val_accuracy: 0.5010\n",
      "Epoch 3/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6926 - accuracy: 0.5110 - val_loss: 0.6932 - val_accuracy: 0.5055\n",
      "Epoch 4/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6926 - accuracy: 0.5102 - val_loss: 0.6929 - val_accuracy: 0.5131\n",
      "Epoch 5/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6926 - accuracy: 0.5067 - val_loss: 0.6927 - val_accuracy: 0.5117\n",
      "Epoch 6/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5093 - val_loss: 0.6927 - val_accuracy: 0.5130\n",
      "Epoch 7/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5117 - val_loss: 0.6927 - val_accuracy: 0.5167\n",
      "Epoch 8/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5129 - val_loss: 0.6925 - val_accuracy: 0.5176\n",
      "Epoch 9/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5164 - val_loss: 0.6925 - val_accuracy: 0.5175\n",
      "Epoch 10/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5122 - val_loss: 0.6926 - val_accuracy: 0.5159\n",
      "Epoch 11/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5156 - val_loss: 0.6925 - val_accuracy: 0.5164\n",
      "Epoch 12/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5149 - val_loss: 0.6925 - val_accuracy: 0.5167\n",
      "Epoch 13/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5158 - val_loss: 0.6924 - val_accuracy: 0.5164\n",
      "Epoch 14/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5173 - val_loss: 0.6924 - val_accuracy: 0.5211\n",
      "Epoch 15/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5166 - val_loss: 0.6924 - val_accuracy: 0.5214\n",
      "Epoch 16/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5172 - val_loss: 0.6923 - val_accuracy: 0.5217\n",
      "Epoch 17/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5151 - val_loss: 0.6924 - val_accuracy: 0.5172\n",
      "Epoch 18/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5171 - val_loss: 0.6923 - val_accuracy: 0.5233\n",
      "Epoch 19/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5154 - val_loss: 0.6923 - val_accuracy: 0.5192\n",
      "Epoch 20/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5173 - val_loss: 0.6922 - val_accuracy: 0.5190\n",
      "Epoch 21/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5146 - val_loss: 0.6923 - val_accuracy: 0.5230\n",
      "Epoch 22/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5149 - val_loss: 0.6924 - val_accuracy: 0.5170\n",
      "Epoch 23/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5137 - val_loss: 0.6923 - val_accuracy: 0.5217\n",
      "Epoch 24/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5154 - val_loss: 0.6924 - val_accuracy: 0.5207\n",
      "Epoch 25/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5152 - val_loss: 0.6924 - val_accuracy: 0.5198\n",
      "Epoch 26/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5162 - val_loss: 0.6925 - val_accuracy: 0.5190\n",
      "Epoch 27/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5151 - val_loss: 0.6924 - val_accuracy: 0.5191\n",
      "Epoch 28/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5156 - val_loss: 0.6926 - val_accuracy: 0.5150\n",
      "Epoch 29/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5152 - val_loss: 0.6925 - val_accuracy: 0.5198\n",
      "Epoch 30/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5167 - val_loss: 0.6925 - val_accuracy: 0.5198\n",
      "Epoch 31/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5171 - val_loss: 0.6925 - val_accuracy: 0.5185\n",
      "Epoch 32/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5181 - val_loss: 0.6926 - val_accuracy: 0.5181\n",
      "Epoch 33/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5158 - val_loss: 0.6924 - val_accuracy: 0.5193\n",
      "Epoch 34/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5178 - val_loss: 0.6923 - val_accuracy: 0.5212\n",
      "Epoch 35/1000\n",
      "41003/41003 [==============================] - 1s 14us/sample - loss: 0.6918 - accuracy: 0.5171 - val_loss: 0.6925 - val_accuracy: 0.5189\n",
      "Epoch 36/1000\n",
      "41003/41003 [==============================] - 1s 14us/sample - loss: 0.6918 - accuracy: 0.5177 - val_loss: 0.6924 - val_accuracy: 0.5218\n",
      "Epoch 37/1000\n",
      "41003/41003 [==============================] - 1s 14us/sample - loss: 0.6918 - accuracy: 0.5182 - val_loss: 0.6923 - val_accuracy: 0.5184\n",
      "Epoch 38/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5149 - val_loss: 0.6922 - val_accuracy: 0.5214\n",
      "Epoch 39/1000\n",
      "41003/41003 [==============================] - 1s 14us/sample - loss: 0.6918 - accuracy: 0.5176 - val_loss: 0.6922 - val_accuracy: 0.5236\n",
      "Epoch 40/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5161 - val_loss: 0.6924 - val_accuracy: 0.5214\n",
      "Epoch 41/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5185 - val_loss: 0.6924 - val_accuracy: 0.5196\n",
      "Epoch 42/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5167 - val_loss: 0.6923 - val_accuracy: 0.5239\n",
      "Epoch 43/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5176 - val_loss: 0.6924 - val_accuracy: 0.5204\n",
      "Epoch 44/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5170 - val_loss: 0.6925 - val_accuracy: 0.5212\n",
      "Epoch 45/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5163 - val_loss: 0.6925 - val_accuracy: 0.5217\n",
      "Epoch 46/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5173 - val_loss: 0.6924 - val_accuracy: 0.5216\n",
      "Epoch 47/1000\n",
      "41003/41003 [==============================] - 1s 12us/sample - loss: 0.6915 - accuracy: 0.5179 - val_loss: 0.6924 - val_accuracy: 0.5211\n",
      "Epoch 48/1000\n",
      "41003/41003 [==============================] - 1s 12us/sample - loss: 0.6918 - accuracy: 0.5185 - val_loss: 0.6923 - val_accuracy: 0.5204\n",
      "Epoch 49/1000\n",
      "41003/41003 [==============================] - 1s 12us/sample - loss: 0.6917 - accuracy: 0.5186 - val_loss: 0.6923 - val_accuracy: 0.5214\n",
      "Epoch 50/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5199 - val_loss: 0.6924 - val_accuracy: 0.5218\n",
      "Epoch 51/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5187 - val_loss: 0.6923 - val_accuracy: 0.5202\n",
      "Epoch 52/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5186 - val_loss: 0.6923 - val_accuracy: 0.5214\n",
      "Epoch 53/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5192 - val_loss: 0.6923 - val_accuracy: 0.5208\n",
      "Epoch 54/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5199 - val_loss: 0.6923 - val_accuracy: 0.5202\n",
      "Epoch 55/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5179 - val_loss: 0.6923 - val_accuracy: 0.5196\n",
      "Epoch 56/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5182 - val_loss: 0.6923 - val_accuracy: 0.5234\n",
      "Epoch 57/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5185 - val_loss: 0.6924 - val_accuracy: 0.5195\n",
      "Epoch 58/1000\n",
      "41003/41003 [==============================] - 1s 12us/sample - loss: 0.6917 - accuracy: 0.5197 - val_loss: 0.6923 - val_accuracy: 0.5200\n",
      "Epoch 59/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5203 - val_loss: 0.6923 - val_accuracy: 0.5223\n",
      "Epoch 60/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5194 - val_loss: 0.6925 - val_accuracy: 0.5213\n",
      "Epoch 61/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5200 - val_loss: 0.6922 - val_accuracy: 0.5224\n",
      "Epoch 62/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5205 - val_loss: 0.6923 - val_accuracy: 0.5207\n",
      "Epoch 63/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5192 - val_loss: 0.6923 - val_accuracy: 0.5210\n",
      "Epoch 64/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5189 - val_loss: 0.6923 - val_accuracy: 0.5213\n",
      "Epoch 65/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5166 - val_loss: 0.6923 - val_accuracy: 0.5222\n",
      "Epoch 66/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5197 - val_loss: 0.6923 - val_accuracy: 0.5213\n",
      "Epoch 67/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5193 - val_loss: 0.6922 - val_accuracy: 0.5219\n",
      "Epoch 68/1000\n",
      "41003/41003 [==============================] - 1s 14us/sample - loss: 0.6915 - accuracy: 0.5217 - val_loss: 0.6923 - val_accuracy: 0.5203\n",
      "Epoch 69/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5187 - val_loss: 0.6923 - val_accuracy: 0.5246\n",
      "Training with significance = 0.95, run 5\n",
      "Train on 41003 samples, validate on 10251 samples\n",
      "Epoch 1/1000\n",
      "41003/41003 [==============================] - 1s 28us/sample - loss: 0.6938 - accuracy: 0.5064 - val_loss: 0.6933 - val_accuracy: 0.5061\n",
      "Epoch 2/1000\n",
      "41003/41003 [==============================] - 1s 14us/sample - loss: 0.6927 - accuracy: 0.5141 - val_loss: 0.6926 - val_accuracy: 0.5103\n",
      "Epoch 3/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6927 - accuracy: 0.5116 - val_loss: 0.6922 - val_accuracy: 0.5197\n",
      "Epoch 4/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6926 - accuracy: 0.5115 - val_loss: 0.6919 - val_accuracy: 0.5201\n",
      "Epoch 5/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6926 - accuracy: 0.5124 - val_loss: 0.6920 - val_accuracy: 0.5213\n",
      "Epoch 6/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6926 - accuracy: 0.5140 - val_loss: 0.6922 - val_accuracy: 0.5187\n",
      "Epoch 7/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6925 - accuracy: 0.5144 - val_loss: 0.6918 - val_accuracy: 0.5180\n",
      "Epoch 8/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6925 - accuracy: 0.5136 - val_loss: 0.6919 - val_accuracy: 0.5185\n",
      "Epoch 9/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5136 - val_loss: 0.6918 - val_accuracy: 0.5202\n",
      "Epoch 10/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5141 - val_loss: 0.6920 - val_accuracy: 0.5196\n",
      "Epoch 11/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6925 - accuracy: 0.5111 - val_loss: 0.6918 - val_accuracy: 0.5199\n",
      "Epoch 12/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6925 - accuracy: 0.5138 - val_loss: 0.6919 - val_accuracy: 0.5205\n",
      "Epoch 13/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5128 - val_loss: 0.6920 - val_accuracy: 0.5209\n",
      "Epoch 14/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5115 - val_loss: 0.6919 - val_accuracy: 0.5203\n",
      "Epoch 15/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5149 - val_loss: 0.6919 - val_accuracy: 0.5199\n",
      "Epoch 16/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5147 - val_loss: 0.6919 - val_accuracy: 0.5212\n",
      "Epoch 17/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5155 - val_loss: 0.6920 - val_accuracy: 0.5185\n",
      "Epoch 18/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5133 - val_loss: 0.6918 - val_accuracy: 0.5217\n",
      "Epoch 19/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5133 - val_loss: 0.6918 - val_accuracy: 0.5229\n",
      "Epoch 20/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5156 - val_loss: 0.6918 - val_accuracy: 0.5227\n",
      "Epoch 21/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5132 - val_loss: 0.6919 - val_accuracy: 0.5199\n",
      "Epoch 22/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5151 - val_loss: 0.6920 - val_accuracy: 0.5198\n",
      "Epoch 23/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5143 - val_loss: 0.6919 - val_accuracy: 0.5204\n",
      "Epoch 24/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5159 - val_loss: 0.6919 - val_accuracy: 0.5216\n",
      "Epoch 25/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5157 - val_loss: 0.6919 - val_accuracy: 0.5225\n",
      "Epoch 26/1000\n",
      "41003/41003 [==============================] - 1s 14us/sample - loss: 0.6921 - accuracy: 0.5179 - val_loss: 0.6920 - val_accuracy: 0.5198\n",
      "Epoch 27/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5158 - val_loss: 0.6919 - val_accuracy: 0.5185\n",
      "Epoch 28/1000\n",
      "41003/41003 [==============================] - 1s 14us/sample - loss: 0.6922 - accuracy: 0.5170 - val_loss: 0.6919 - val_accuracy: 0.5169\n",
      "Epoch 29/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5145 - val_loss: 0.6918 - val_accuracy: 0.5207\n",
      "Epoch 30/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5172 - val_loss: 0.6920 - val_accuracy: 0.5209\n",
      "Epoch 31/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5163 - val_loss: 0.6920 - val_accuracy: 0.5210\n",
      "Epoch 32/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5147 - val_loss: 0.6920 - val_accuracy: 0.5194\n",
      "Epoch 33/1000\n",
      "41003/41003 [==============================] - 1s 12us/sample - loss: 0.6920 - accuracy: 0.5165 - val_loss: 0.6920 - val_accuracy: 0.5196\n",
      "Epoch 34/1000\n",
      "41003/41003 [==============================] - 0s 12us/sample - loss: 0.6920 - accuracy: 0.5169 - val_loss: 0.6919 - val_accuracy: 0.5174\n",
      "Epoch 35/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5169 - val_loss: 0.6920 - val_accuracy: 0.5157\n",
      "Epoch 36/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5156 - val_loss: 0.6920 - val_accuracy: 0.5188\n",
      "Epoch 37/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5161 - val_loss: 0.6919 - val_accuracy: 0.5150\n",
      "Epoch 38/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5177 - val_loss: 0.6918 - val_accuracy: 0.5156\n",
      "Epoch 39/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5153 - val_loss: 0.6919 - val_accuracy: 0.5125\n",
      "Training with significance = 0.95, run 6\n",
      "Train on 41003 samples, validate on 10251 samples\n",
      "Epoch 1/1000\n",
      "41003/41003 [==============================] - 2s 38us/sample - loss: 0.6933 - accuracy: 0.5078 - val_loss: 0.6948 - val_accuracy: 0.5028\n",
      "Epoch 2/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6927 - accuracy: 0.5131 - val_loss: 0.6932 - val_accuracy: 0.5110\n",
      "Epoch 3/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6925 - accuracy: 0.5144 - val_loss: 0.6931 - val_accuracy: 0.5099\n",
      "Epoch 4/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6925 - accuracy: 0.5126 - val_loss: 0.6929 - val_accuracy: 0.5117\n",
      "Epoch 5/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6925 - accuracy: 0.5144 - val_loss: 0.6929 - val_accuracy: 0.5080\n",
      "Epoch 6/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5142 - val_loss: 0.6930 - val_accuracy: 0.5111\n",
      "Epoch 7/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5168 - val_loss: 0.6929 - val_accuracy: 0.5069\n",
      "Epoch 8/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5176 - val_loss: 0.6928 - val_accuracy: 0.5116\n",
      "Epoch 9/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5164 - val_loss: 0.6928 - val_accuracy: 0.5086\n",
      "Epoch 10/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5168 - val_loss: 0.6929 - val_accuracy: 0.5089\n",
      "Epoch 11/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5185 - val_loss: 0.6930 - val_accuracy: 0.5090\n",
      "Epoch 12/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5166 - val_loss: 0.6929 - val_accuracy: 0.5098\n",
      "Epoch 13/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5145 - val_loss: 0.6928 - val_accuracy: 0.5074\n",
      "Epoch 14/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5168 - val_loss: 0.6929 - val_accuracy: 0.5098\n",
      "Epoch 15/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5157 - val_loss: 0.6927 - val_accuracy: 0.5126\n",
      "Epoch 16/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5190 - val_loss: 0.6928 - val_accuracy: 0.5085\n",
      "Epoch 17/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5169 - val_loss: 0.6930 - val_accuracy: 0.5080\n",
      "Epoch 18/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5152 - val_loss: 0.6929 - val_accuracy: 0.5088\n",
      "Epoch 19/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5156 - val_loss: 0.6927 - val_accuracy: 0.5129\n",
      "Epoch 20/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5178 - val_loss: 0.6929 - val_accuracy: 0.5112\n",
      "Epoch 21/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5184 - val_loss: 0.6930 - val_accuracy: 0.5092\n",
      "Epoch 22/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5172 - val_loss: 0.6931 - val_accuracy: 0.5115\n",
      "Epoch 23/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5163 - val_loss: 0.6931 - val_accuracy: 0.5109\n",
      "Epoch 24/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5171 - val_loss: 0.6932 - val_accuracy: 0.5098\n",
      "Epoch 25/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5182 - val_loss: 0.6931 - val_accuracy: 0.5091\n",
      "Epoch 26/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5165 - val_loss: 0.6929 - val_accuracy: 0.5092\n",
      "Epoch 27/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5169 - val_loss: 0.6931 - val_accuracy: 0.5090\n",
      "Epoch 28/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5161 - val_loss: 0.6929 - val_accuracy: 0.5086\n",
      "Epoch 29/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5160 - val_loss: 0.6930 - val_accuracy: 0.5130\n",
      "Epoch 30/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5154 - val_loss: 0.6932 - val_accuracy: 0.5106\n",
      "Epoch 31/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5176 - val_loss: 0.6929 - val_accuracy: 0.5117\n",
      "Epoch 32/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5174 - val_loss: 0.6929 - val_accuracy: 0.5093\n",
      "Epoch 33/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5175 - val_loss: 0.6929 - val_accuracy: 0.5133\n",
      "Epoch 34/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5166 - val_loss: 0.6928 - val_accuracy: 0.5121\n",
      "Epoch 35/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5176 - val_loss: 0.6928 - val_accuracy: 0.5126\n",
      "Epoch 36/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5170 - val_loss: 0.6927 - val_accuracy: 0.5140\n",
      "Epoch 37/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5157 - val_loss: 0.6929 - val_accuracy: 0.5089\n",
      "Epoch 38/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5180 - val_loss: 0.6928 - val_accuracy: 0.5116\n",
      "Epoch 39/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5174 - val_loss: 0.6927 - val_accuracy: 0.5115\n",
      "Epoch 40/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5185 - val_loss: 0.6928 - val_accuracy: 0.5108\n",
      "Epoch 41/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5182 - val_loss: 0.6929 - val_accuracy: 0.5090\n",
      "Epoch 42/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5190 - val_loss: 0.6929 - val_accuracy: 0.5126\n",
      "Epoch 43/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5172 - val_loss: 0.6930 - val_accuracy: 0.5090\n",
      "Epoch 44/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5181 - val_loss: 0.6931 - val_accuracy: 0.5048\n",
      "Epoch 45/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5180 - val_loss: 0.6931 - val_accuracy: 0.5056\n",
      "Epoch 46/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5181 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 47/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5182 - val_loss: 0.6929 - val_accuracy: 0.5088\n",
      "Epoch 48/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5174 - val_loss: 0.6928 - val_accuracy: 0.5117\n",
      "Epoch 49/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5185 - val_loss: 0.6930 - val_accuracy: 0.5074\n",
      "Epoch 50/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5200 - val_loss: 0.6929 - val_accuracy: 0.5070\n",
      "Epoch 51/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5175 - val_loss: 0.6929 - val_accuracy: 0.5095\n",
      "Epoch 52/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5198 - val_loss: 0.6930 - val_accuracy: 0.5068\n",
      "Epoch 53/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5188 - val_loss: 0.6930 - val_accuracy: 0.5067\n",
      "Epoch 54/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5190 - val_loss: 0.6930 - val_accuracy: 0.5069\n",
      "Epoch 55/1000\n",
      "41003/41003 [==============================] - 1s 14us/sample - loss: 0.6919 - accuracy: 0.5193 - val_loss: 0.6929 - val_accuracy: 0.5093\n",
      "Epoch 56/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5194 - val_loss: 0.6929 - val_accuracy: 0.5096\n",
      "Epoch 57/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5185 - val_loss: 0.6929 - val_accuracy: 0.5086\n",
      "Epoch 58/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5205 - val_loss: 0.6929 - val_accuracy: 0.5096\n",
      "Epoch 59/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5180 - val_loss: 0.6926 - val_accuracy: 0.5115\n",
      "Epoch 60/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5186 - val_loss: 0.6927 - val_accuracy: 0.5117\n",
      "Epoch 61/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5177 - val_loss: 0.6927 - val_accuracy: 0.5100\n",
      "Epoch 62/1000\n",
      "41003/41003 [==============================] - 1s 12us/sample - loss: 0.6917 - accuracy: 0.5199 - val_loss: 0.6927 - val_accuracy: 0.5116\n",
      "Epoch 63/1000\n",
      "41003/41003 [==============================] - 1s 12us/sample - loss: 0.6918 - accuracy: 0.5198 - val_loss: 0.6928 - val_accuracy: 0.5108\n",
      "Epoch 64/1000\n",
      "41003/41003 [==============================] - 1s 12us/sample - loss: 0.6918 - accuracy: 0.5180 - val_loss: 0.6928 - val_accuracy: 0.5120\n",
      "Epoch 65/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5189 - val_loss: 0.6926 - val_accuracy: 0.5116\n",
      "Epoch 66/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5155 - val_loss: 0.6928 - val_accuracy: 0.5132\n",
      "Epoch 67/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5166 - val_loss: 0.6927 - val_accuracy: 0.5087\n",
      "Epoch 68/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5182 - val_loss: 0.6927 - val_accuracy: 0.5097\n",
      "Epoch 69/1000\n",
      "41003/41003 [==============================] - 1s 14us/sample - loss: 0.6919 - accuracy: 0.5164 - val_loss: 0.6926 - val_accuracy: 0.5122\n",
      "Epoch 70/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5196 - val_loss: 0.6929 - val_accuracy: 0.5074\n",
      "Epoch 71/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5191 - val_loss: 0.6930 - val_accuracy: 0.5073\n",
      "Epoch 72/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5186 - val_loss: 0.6928 - val_accuracy: 0.5083\n",
      "Epoch 73/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5186 - val_loss: 0.6929 - val_accuracy: 0.5107\n",
      "Epoch 74/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5188 - val_loss: 0.6930 - val_accuracy: 0.5088\n",
      "Epoch 75/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5220 - val_loss: 0.6928 - val_accuracy: 0.5054\n",
      "Epoch 76/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5191 - val_loss: 0.6929 - val_accuracy: 0.5080\n",
      "Epoch 77/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5188 - val_loss: 0.6930 - val_accuracy: 0.5053\n",
      "Epoch 78/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5176 - val_loss: 0.6929 - val_accuracy: 0.5087\n",
      "Epoch 79/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5168 - val_loss: 0.6928 - val_accuracy: 0.5083\n",
      "Epoch 80/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5198 - val_loss: 0.6931 - val_accuracy: 0.5093\n",
      "Epoch 81/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5179 - val_loss: 0.6930 - val_accuracy: 0.5098\n",
      "Epoch 82/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5204 - val_loss: 0.6932 - val_accuracy: 0.5070\n",
      "Epoch 83/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5197 - val_loss: 0.6929 - val_accuracy: 0.5086\n",
      "Epoch 84/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5185 - val_loss: 0.6930 - val_accuracy: 0.5074\n",
      "Epoch 85/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5195 - val_loss: 0.6930 - val_accuracy: 0.5070\n",
      "Epoch 86/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5196 - val_loss: 0.6931 - val_accuracy: 0.5074\n",
      "Epoch 87/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5215 - val_loss: 0.6930 - val_accuracy: 0.5061\n",
      "Epoch 88/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5183 - val_loss: 0.6928 - val_accuracy: 0.5103\n",
      "Epoch 89/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5194 - val_loss: 0.6929 - val_accuracy: 0.5104\n",
      "Training with significance = 0.95, run 7\n",
      "Train on 41003 samples, validate on 10251 samples\n",
      "Epoch 1/1000\n",
      "41003/41003 [==============================] - 1s 28us/sample - loss: 0.6938 - accuracy: 0.5037 - val_loss: 0.6928 - val_accuracy: 0.5118\n",
      "Epoch 2/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6929 - accuracy: 0.5096 - val_loss: 0.6929 - val_accuracy: 0.5049\n",
      "Epoch 3/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6928 - accuracy: 0.5111 - val_loss: 0.6922 - val_accuracy: 0.5167\n",
      "Epoch 4/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6926 - accuracy: 0.5127 - val_loss: 0.6920 - val_accuracy: 0.5224\n",
      "Epoch 5/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6927 - accuracy: 0.5139 - val_loss: 0.6920 - val_accuracy: 0.5179\n",
      "Epoch 6/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6926 - accuracy: 0.5099 - val_loss: 0.6918 - val_accuracy: 0.5211\n",
      "Epoch 7/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6925 - accuracy: 0.5131 - val_loss: 0.6919 - val_accuracy: 0.5173\n",
      "Epoch 8/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6925 - accuracy: 0.5144 - val_loss: 0.6919 - val_accuracy: 0.5176\n",
      "Epoch 9/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6925 - accuracy: 0.5134 - val_loss: 0.6921 - val_accuracy: 0.5166\n",
      "Epoch 10/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6925 - accuracy: 0.5118 - val_loss: 0.6919 - val_accuracy: 0.5193\n",
      "Epoch 11/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6925 - accuracy: 0.5134 - val_loss: 0.6918 - val_accuracy: 0.5201\n",
      "Epoch 12/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6925 - accuracy: 0.5148 - val_loss: 0.6919 - val_accuracy: 0.5159\n",
      "Epoch 13/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5145 - val_loss: 0.6919 - val_accuracy: 0.5176\n",
      "Epoch 14/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5154 - val_loss: 0.6919 - val_accuracy: 0.5184\n",
      "Epoch 15/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5140 - val_loss: 0.6918 - val_accuracy: 0.5159\n",
      "Epoch 16/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5151 - val_loss: 0.6917 - val_accuracy: 0.5183\n",
      "Epoch 17/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5127 - val_loss: 0.6918 - val_accuracy: 0.5169\n",
      "Epoch 18/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5147 - val_loss: 0.6920 - val_accuracy: 0.5120\n",
      "Epoch 19/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5147 - val_loss: 0.6918 - val_accuracy: 0.5184\n",
      "Epoch 20/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5153 - val_loss: 0.6917 - val_accuracy: 0.5197\n",
      "Epoch 21/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5150 - val_loss: 0.6916 - val_accuracy: 0.5209\n",
      "Epoch 22/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5157 - val_loss: 0.6916 - val_accuracy: 0.5201\n",
      "Epoch 23/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5152 - val_loss: 0.6917 - val_accuracy: 0.5207\n",
      "Epoch 24/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5156 - val_loss: 0.6917 - val_accuracy: 0.5208\n",
      "Epoch 25/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5163 - val_loss: 0.6917 - val_accuracy: 0.5189\n",
      "Epoch 26/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5114 - val_loss: 0.6917 - val_accuracy: 0.5211\n",
      "Epoch 27/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5160 - val_loss: 0.6916 - val_accuracy: 0.5214\n",
      "Epoch 28/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5145 - val_loss: 0.6917 - val_accuracy: 0.5216\n",
      "Epoch 29/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5154 - val_loss: 0.6915 - val_accuracy: 0.5235\n",
      "Epoch 30/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5168 - val_loss: 0.6916 - val_accuracy: 0.5218\n",
      "Epoch 31/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5165 - val_loss: 0.6916 - val_accuracy: 0.5194\n",
      "Epoch 32/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5156 - val_loss: 0.6916 - val_accuracy: 0.5213\n",
      "Epoch 33/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5153 - val_loss: 0.6916 - val_accuracy: 0.5198\n",
      "Epoch 34/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5150 - val_loss: 0.6915 - val_accuracy: 0.5206\n",
      "Epoch 35/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5158 - val_loss: 0.6916 - val_accuracy: 0.5190\n",
      "Epoch 36/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5147 - val_loss: 0.6918 - val_accuracy: 0.5183\n",
      "Epoch 37/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5161 - val_loss: 0.6918 - val_accuracy: 0.5181\n",
      "Epoch 38/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5135 - val_loss: 0.6917 - val_accuracy: 0.5181\n",
      "Epoch 39/1000\n",
      "41003/41003 [==============================] - 0s 12us/sample - loss: 0.6921 - accuracy: 0.5163 - val_loss: 0.6916 - val_accuracy: 0.5199\n",
      "Epoch 40/1000\n",
      "41003/41003 [==============================] - 0s 12us/sample - loss: 0.6922 - accuracy: 0.5156 - val_loss: 0.6915 - val_accuracy: 0.5197\n",
      "Epoch 41/1000\n",
      "41003/41003 [==============================] - 1s 12us/sample - loss: 0.6921 - accuracy: 0.5160 - val_loss: 0.6917 - val_accuracy: 0.5189\n",
      "Epoch 42/1000\n",
      "41003/41003 [==============================] - 1s 12us/sample - loss: 0.6922 - accuracy: 0.5134 - val_loss: 0.6916 - val_accuracy: 0.5212\n",
      "Epoch 43/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5151 - val_loss: 0.6916 - val_accuracy: 0.5221\n",
      "Epoch 44/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5157 - val_loss: 0.6916 - val_accuracy: 0.5206\n",
      "Epoch 45/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5157 - val_loss: 0.6916 - val_accuracy: 0.5202\n",
      "Epoch 46/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5143 - val_loss: 0.6916 - val_accuracy: 0.5219\n",
      "Epoch 47/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5135 - val_loss: 0.6916 - val_accuracy: 0.5213\n",
      "Epoch 48/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5154 - val_loss: 0.6916 - val_accuracy: 0.5211\n",
      "Epoch 49/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5164 - val_loss: 0.6917 - val_accuracy: 0.5159\n",
      "Epoch 50/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5179 - val_loss: 0.6917 - val_accuracy: 0.5163\n",
      "Epoch 51/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5180 - val_loss: 0.6918 - val_accuracy: 0.5180\n",
      "Epoch 52/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5140 - val_loss: 0.6917 - val_accuracy: 0.5209\n",
      "Epoch 53/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5147 - val_loss: 0.6918 - val_accuracy: 0.5180\n",
      "Epoch 54/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5164 - val_loss: 0.6918 - val_accuracy: 0.5164\n",
      "Epoch 55/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5164 - val_loss: 0.6919 - val_accuracy: 0.5163\n",
      "Epoch 56/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5148 - val_loss: 0.6918 - val_accuracy: 0.5179\n",
      "Epoch 57/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5192 - val_loss: 0.6919 - val_accuracy: 0.5174\n",
      "Epoch 58/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5180 - val_loss: 0.6922 - val_accuracy: 0.5096\n",
      "Epoch 59/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5174 - val_loss: 0.6919 - val_accuracy: 0.5196\n",
      "Epoch 60/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5187 - val_loss: 0.6919 - val_accuracy: 0.5177\n",
      "Epoch 61/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5172 - val_loss: 0.6918 - val_accuracy: 0.5212\n",
      "Epoch 62/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5168 - val_loss: 0.6917 - val_accuracy: 0.5203\n",
      "Epoch 63/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5167 - val_loss: 0.6920 - val_accuracy: 0.5139\n",
      "Epoch 64/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5167 - val_loss: 0.6919 - val_accuracy: 0.5137\n",
      "Training with significance = 0.95, run 8\n",
      "Train on 41003 samples, validate on 10251 samples\n",
      "Epoch 1/1000\n",
      "41003/41003 [==============================] - 1s 29us/sample - loss: 0.6933 - accuracy: 0.5040 - val_loss: 0.6938 - val_accuracy: 0.5092\n",
      "Epoch 2/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6927 - accuracy: 0.5102 - val_loss: 0.6927 - val_accuracy: 0.5154\n",
      "Epoch 3/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6926 - accuracy: 0.5113 - val_loss: 0.6924 - val_accuracy: 0.5186\n",
      "Epoch 4/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6926 - accuracy: 0.5100 - val_loss: 0.6925 - val_accuracy: 0.5174\n",
      "Epoch 5/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6926 - accuracy: 0.5116 - val_loss: 0.6923 - val_accuracy: 0.5201\n",
      "Epoch 6/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6925 - accuracy: 0.5124 - val_loss: 0.6923 - val_accuracy: 0.5171\n",
      "Epoch 7/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5136 - val_loss: 0.6924 - val_accuracy: 0.5175\n",
      "Epoch 8/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6925 - accuracy: 0.5152 - val_loss: 0.6923 - val_accuracy: 0.5160\n",
      "Epoch 9/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6925 - accuracy: 0.5139 - val_loss: 0.6922 - val_accuracy: 0.5196\n",
      "Epoch 10/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5129 - val_loss: 0.6924 - val_accuracy: 0.5166\n",
      "Epoch 11/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5139 - val_loss: 0.6923 - val_accuracy: 0.5170\n",
      "Epoch 12/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5133 - val_loss: 0.6923 - val_accuracy: 0.5181\n",
      "Epoch 13/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5146 - val_loss: 0.6923 - val_accuracy: 0.5184\n",
      "Epoch 14/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5143 - val_loss: 0.6923 - val_accuracy: 0.5180\n",
      "Epoch 15/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5164 - val_loss: 0.6923 - val_accuracy: 0.5197\n",
      "Epoch 16/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5158 - val_loss: 0.6923 - val_accuracy: 0.5181\n",
      "Epoch 17/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5164 - val_loss: 0.6922 - val_accuracy: 0.5187\n",
      "Epoch 18/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5162 - val_loss: 0.6921 - val_accuracy: 0.5208\n",
      "Epoch 19/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5170 - val_loss: 0.6921 - val_accuracy: 0.5199\n",
      "Epoch 20/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5156 - val_loss: 0.6922 - val_accuracy: 0.5182\n",
      "Epoch 21/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5156 - val_loss: 0.6921 - val_accuracy: 0.5178\n",
      "Epoch 22/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5158 - val_loss: 0.6922 - val_accuracy: 0.5114\n",
      "Epoch 23/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5170 - val_loss: 0.6922 - val_accuracy: 0.5134\n",
      "Epoch 24/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5174 - val_loss: 0.6922 - val_accuracy: 0.5180\n",
      "Epoch 25/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5168 - val_loss: 0.6923 - val_accuracy: 0.5138\n",
      "Epoch 26/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5171 - val_loss: 0.6924 - val_accuracy: 0.5132\n",
      "Epoch 27/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5167 - val_loss: 0.6925 - val_accuracy: 0.5157\n",
      "Epoch 28/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5179 - val_loss: 0.6924 - val_accuracy: 0.5115\n",
      "Epoch 29/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5175 - val_loss: 0.6924 - val_accuracy: 0.5165\n",
      "Epoch 30/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5169 - val_loss: 0.6923 - val_accuracy: 0.5171\n",
      "Epoch 31/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5146 - val_loss: 0.6924 - val_accuracy: 0.5164\n",
      "Epoch 32/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5167 - val_loss: 0.6923 - val_accuracy: 0.5154\n",
      "Epoch 33/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5170 - val_loss: 0.6923 - val_accuracy: 0.5179\n",
      "Epoch 34/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5164 - val_loss: 0.6923 - val_accuracy: 0.5153\n",
      "Epoch 35/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5162 - val_loss: 0.6923 - val_accuracy: 0.5188\n",
      "Epoch 36/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5174 - val_loss: 0.6923 - val_accuracy: 0.5170\n",
      "Epoch 37/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5175 - val_loss: 0.6921 - val_accuracy: 0.5185\n",
      "Epoch 38/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5170 - val_loss: 0.6921 - val_accuracy: 0.5204\n",
      "Epoch 39/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5192 - val_loss: 0.6921 - val_accuracy: 0.5187\n",
      "Epoch 40/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5175 - val_loss: 0.6921 - val_accuracy: 0.5172\n",
      "Epoch 41/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5170 - val_loss: 0.6920 - val_accuracy: 0.5202\n",
      "Epoch 42/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5164 - val_loss: 0.6922 - val_accuracy: 0.5180\n",
      "Epoch 43/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5165 - val_loss: 0.6921 - val_accuracy: 0.5175\n",
      "Epoch 44/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5175 - val_loss: 0.6920 - val_accuracy: 0.5197\n",
      "Epoch 45/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5198 - val_loss: 0.6920 - val_accuracy: 0.5184\n",
      "Epoch 46/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5151 - val_loss: 0.6921 - val_accuracy: 0.5178\n",
      "Epoch 47/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5171 - val_loss: 0.6921 - val_accuracy: 0.5189\n",
      "Epoch 48/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5177 - val_loss: 0.6921 - val_accuracy: 0.5185\n",
      "Epoch 49/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5189 - val_loss: 0.6921 - val_accuracy: 0.5195\n",
      "Epoch 50/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5201 - val_loss: 0.6920 - val_accuracy: 0.5201\n",
      "Epoch 51/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5157 - val_loss: 0.6920 - val_accuracy: 0.5199\n",
      "Epoch 52/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5167 - val_loss: 0.6921 - val_accuracy: 0.5188\n",
      "Epoch 53/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5187 - val_loss: 0.6920 - val_accuracy: 0.5200\n",
      "Epoch 54/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5204 - val_loss: 0.6920 - val_accuracy: 0.5188\n",
      "Epoch 55/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5180 - val_loss: 0.6921 - val_accuracy: 0.5182\n",
      "Epoch 56/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5195 - val_loss: 0.6920 - val_accuracy: 0.5188\n",
      "Epoch 57/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5154 - val_loss: 0.6920 - val_accuracy: 0.5184\n",
      "Epoch 58/1000\n",
      "41003/41003 [==============================] - 1s 14us/sample - loss: 0.6919 - accuracy: 0.5173 - val_loss: 0.6921 - val_accuracy: 0.5181\n",
      "Epoch 59/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5187 - val_loss: 0.6921 - val_accuracy: 0.5181\n",
      "Epoch 60/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5187 - val_loss: 0.6920 - val_accuracy: 0.5185\n",
      "Epoch 61/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5182 - val_loss: 0.6921 - val_accuracy: 0.5203\n",
      "Epoch 62/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5176 - val_loss: 0.6921 - val_accuracy: 0.5186\n",
      "Epoch 63/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5202 - val_loss: 0.6921 - val_accuracy: 0.5198\n",
      "Epoch 64/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5194 - val_loss: 0.6922 - val_accuracy: 0.5155\n",
      "Epoch 65/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5201 - val_loss: 0.6921 - val_accuracy: 0.5185\n",
      "Epoch 66/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5183 - val_loss: 0.6921 - val_accuracy: 0.5184\n",
      "Epoch 67/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5192 - val_loss: 0.6921 - val_accuracy: 0.5175\n",
      "Epoch 68/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5195 - val_loss: 0.6920 - val_accuracy: 0.5184\n",
      "Epoch 69/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5185 - val_loss: 0.6921 - val_accuracy: 0.5185\n",
      "Epoch 70/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5195 - val_loss: 0.6921 - val_accuracy: 0.5147\n",
      "Epoch 71/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5206 - val_loss: 0.6921 - val_accuracy: 0.5168\n",
      "Epoch 72/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5205 - val_loss: 0.6921 - val_accuracy: 0.5200\n",
      "Epoch 73/1000\n",
      "41003/41003 [==============================] - 1s 14us/sample - loss: 0.6918 - accuracy: 0.5193 - val_loss: 0.6922 - val_accuracy: 0.5159\n",
      "Epoch 74/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5196 - val_loss: 0.6923 - val_accuracy: 0.5127\n",
      "Epoch 75/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5194 - val_loss: 0.6922 - val_accuracy: 0.5149\n",
      "Epoch 76/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5181 - val_loss: 0.6921 - val_accuracy: 0.5150\n",
      "Epoch 77/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5202 - val_loss: 0.6921 - val_accuracy: 0.5189\n",
      "Epoch 78/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5195 - val_loss: 0.6921 - val_accuracy: 0.5186\n",
      "Epoch 79/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5182 - val_loss: 0.6922 - val_accuracy: 0.5188\n",
      "Epoch 80/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5186 - val_loss: 0.6920 - val_accuracy: 0.5186\n",
      "Epoch 81/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5185 - val_loss: 0.6921 - val_accuracy: 0.5156\n",
      "Epoch 82/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5196 - val_loss: 0.6921 - val_accuracy: 0.5165\n",
      "Epoch 83/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5182 - val_loss: 0.6921 - val_accuracy: 0.5174\n",
      "Epoch 84/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5177 - val_loss: 0.6921 - val_accuracy: 0.5178\n",
      "Epoch 85/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5195 - val_loss: 0.6922 - val_accuracy: 0.5157\n",
      "Epoch 86/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5179 - val_loss: 0.6922 - val_accuracy: 0.5161\n",
      "Training with significance = 0.95, run 9\n",
      "Train on 41003 samples, validate on 10251 samples\n",
      "Epoch 1/1000\n",
      "41003/41003 [==============================] - 2s 41us/sample - loss: 0.6929 - accuracy: 0.5134 - val_loss: 0.6936 - val_accuracy: 0.5074\n",
      "Epoch 2/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6928 - accuracy: 0.5133 - val_loss: 0.6928 - val_accuracy: 0.5078\n",
      "Epoch 3/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6926 - accuracy: 0.5149 - val_loss: 0.6927 - val_accuracy: 0.5082\n",
      "Epoch 4/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5134 - val_loss: 0.6928 - val_accuracy: 0.5108\n",
      "Epoch 5/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6925 - accuracy: 0.5132 - val_loss: 0.6929 - val_accuracy: 0.5123\n",
      "Epoch 6/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5151 - val_loss: 0.6929 - val_accuracy: 0.5149\n",
      "Epoch 7/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5164 - val_loss: 0.6929 - val_accuracy: 0.5154\n",
      "Epoch 8/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5173 - val_loss: 0.6929 - val_accuracy: 0.5118\n",
      "Epoch 9/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5164 - val_loss: 0.6929 - val_accuracy: 0.5134\n",
      "Epoch 10/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5159 - val_loss: 0.6930 - val_accuracy: 0.5109\n",
      "Epoch 11/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5152 - val_loss: 0.6929 - val_accuracy: 0.5156\n",
      "Epoch 12/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5167 - val_loss: 0.6930 - val_accuracy: 0.5130\n",
      "Epoch 13/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5167 - val_loss: 0.6929 - val_accuracy: 0.5107\n",
      "Epoch 14/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5142 - val_loss: 0.6928 - val_accuracy: 0.5122\n",
      "Epoch 15/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5176 - val_loss: 0.6930 - val_accuracy: 0.5126\n",
      "Epoch 16/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5161 - val_loss: 0.6928 - val_accuracy: 0.5109\n",
      "Epoch 17/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5158 - val_loss: 0.6929 - val_accuracy: 0.5104\n",
      "Epoch 18/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5176 - val_loss: 0.6930 - val_accuracy: 0.5094\n",
      "Epoch 19/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5142 - val_loss: 0.6930 - val_accuracy: 0.5099\n",
      "Epoch 20/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5166 - val_loss: 0.6929 - val_accuracy: 0.5110\n",
      "Epoch 21/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5162 - val_loss: 0.6928 - val_accuracy: 0.5093\n",
      "Epoch 22/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5172 - val_loss: 0.6928 - val_accuracy: 0.5111\n",
      "Epoch 23/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5157 - val_loss: 0.6929 - val_accuracy: 0.5092\n",
      "Epoch 24/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5163 - val_loss: 0.6928 - val_accuracy: 0.5101\n",
      "Epoch 25/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5183 - val_loss: 0.6927 - val_accuracy: 0.5133\n",
      "Epoch 26/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5165 - val_loss: 0.6928 - val_accuracy: 0.5111\n",
      "Epoch 27/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41003/41003 [==============================] - 1s 14us/sample - loss: 0.6920 - accuracy: 0.5159 - val_loss: 0.6928 - val_accuracy: 0.5113\n",
      "Epoch 28/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5178 - val_loss: 0.6928 - val_accuracy: 0.5124\n",
      "Epoch 29/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5168 - val_loss: 0.6928 - val_accuracy: 0.5096\n",
      "Epoch 30/1000\n",
      "41003/41003 [==============================] - 1s 14us/sample - loss: 0.6921 - accuracy: 0.5185 - val_loss: 0.6929 - val_accuracy: 0.5113\n",
      "Epoch 31/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5191 - val_loss: 0.6929 - val_accuracy: 0.5116\n",
      "Epoch 32/1000\n",
      "41003/41003 [==============================] - 1s 14us/sample - loss: 0.6920 - accuracy: 0.5183 - val_loss: 0.6929 - val_accuracy: 0.5109\n",
      "Epoch 33/1000\n",
      "41003/41003 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5171 - val_loss: 0.6929 - val_accuracy: 0.5106\n",
      "Training with significance = 1.26, run 0\n",
      "Train on 41053 samples, validate on 10264 samples\n",
      "Epoch 1/1000\n",
      "41053/41053 [==============================] - 1s 29us/sample - loss: 0.6935 - accuracy: 0.5066 - val_loss: 0.6930 - val_accuracy: 0.5094\n",
      "Epoch 2/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6927 - accuracy: 0.5135 - val_loss: 0.6929 - val_accuracy: 0.5139\n",
      "Epoch 3/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6925 - accuracy: 0.5154 - val_loss: 0.6930 - val_accuracy: 0.5155\n",
      "Epoch 4/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6925 - accuracy: 0.5123 - val_loss: 0.6929 - val_accuracy: 0.5174\n",
      "Epoch 5/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5142 - val_loss: 0.6929 - val_accuracy: 0.5180\n",
      "Epoch 6/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5152 - val_loss: 0.6930 - val_accuracy: 0.5165\n",
      "Epoch 7/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5151 - val_loss: 0.6930 - val_accuracy: 0.5128\n",
      "Epoch 8/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5170 - val_loss: 0.6929 - val_accuracy: 0.5157\n",
      "Epoch 9/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5173 - val_loss: 0.6928 - val_accuracy: 0.5158\n",
      "Epoch 10/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5149 - val_loss: 0.6929 - val_accuracy: 0.5169\n",
      "Epoch 11/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5151 - val_loss: 0.6929 - val_accuracy: 0.5171\n",
      "Epoch 12/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5157 - val_loss: 0.6929 - val_accuracy: 0.5121\n",
      "Epoch 13/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5147 - val_loss: 0.6930 - val_accuracy: 0.5170\n",
      "Epoch 14/1000\n",
      "41053/41053 [==============================] - 1s 12us/sample - loss: 0.6920 - accuracy: 0.5178 - val_loss: 0.6932 - val_accuracy: 0.5121\n",
      "Epoch 15/1000\n",
      "41053/41053 [==============================] - 1s 12us/sample - loss: 0.6921 - accuracy: 0.5178 - val_loss: 0.6931 - val_accuracy: 0.5170\n",
      "Epoch 16/1000\n",
      "41053/41053 [==============================] - 0s 12us/sample - loss: 0.6920 - accuracy: 0.5175 - val_loss: 0.6930 - val_accuracy: 0.5148\n",
      "Epoch 17/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5191 - val_loss: 0.6931 - val_accuracy: 0.5186\n",
      "Epoch 18/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5156 - val_loss: 0.6930 - val_accuracy: 0.5161\n",
      "Epoch 19/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5162 - val_loss: 0.6930 - val_accuracy: 0.5177\n",
      "Epoch 20/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5168 - val_loss: 0.6930 - val_accuracy: 0.5178\n",
      "Epoch 21/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5178 - val_loss: 0.6930 - val_accuracy: 0.5167\n",
      "Epoch 22/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5181 - val_loss: 0.6931 - val_accuracy: 0.5125\n",
      "Epoch 23/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5173 - val_loss: 0.6931 - val_accuracy: 0.5080\n",
      "Epoch 24/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5174 - val_loss: 0.6931 - val_accuracy: 0.5150\n",
      "Epoch 25/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5176 - val_loss: 0.6932 - val_accuracy: 0.5140\n",
      "Epoch 26/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5177 - val_loss: 0.6932 - val_accuracy: 0.5175\n",
      "Epoch 27/1000\n",
      "41053/41053 [==============================] - 1s 14us/sample - loss: 0.6919 - accuracy: 0.5175 - val_loss: 0.6929 - val_accuracy: 0.5177\n",
      "Epoch 28/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5163 - val_loss: 0.6930 - val_accuracy: 0.5172\n",
      "Epoch 29/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5172 - val_loss: 0.6930 - val_accuracy: 0.5142\n",
      "Epoch 30/1000\n",
      "41053/41053 [==============================] - 1s 14us/sample - loss: 0.6918 - accuracy: 0.5192 - val_loss: 0.6928 - val_accuracy: 0.5174\n",
      "Epoch 31/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5187 - val_loss: 0.6932 - val_accuracy: 0.5136\n",
      "Epoch 32/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5195 - val_loss: 0.6931 - val_accuracy: 0.5128\n",
      "Epoch 33/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5187 - val_loss: 0.6930 - val_accuracy: 0.5146\n",
      "Epoch 34/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5185 - val_loss: 0.6931 - val_accuracy: 0.5161\n",
      "Epoch 35/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5197 - val_loss: 0.6930 - val_accuracy: 0.5166\n",
      "Epoch 36/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5176 - val_loss: 0.6931 - val_accuracy: 0.5145\n",
      "Epoch 37/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5185 - val_loss: 0.6930 - val_accuracy: 0.5153\n",
      "Epoch 38/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5168 - val_loss: 0.6932 - val_accuracy: 0.5134\n",
      "Epoch 39/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5192 - val_loss: 0.6933 - val_accuracy: 0.5146\n",
      "Epoch 40/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5203 - val_loss: 0.6933 - val_accuracy: 0.5157\n",
      "Epoch 41/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5177 - val_loss: 0.6931 - val_accuracy: 0.5157\n",
      "Epoch 42/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5186 - val_loss: 0.6931 - val_accuracy: 0.5143\n",
      "Epoch 43/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5186 - val_loss: 0.6930 - val_accuracy: 0.5170\n",
      "Epoch 44/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5181 - val_loss: 0.6932 - val_accuracy: 0.5134\n",
      "Epoch 45/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5188 - val_loss: 0.6930 - val_accuracy: 0.5116\n",
      "Epoch 46/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5192 - val_loss: 0.6933 - val_accuracy: 0.5070\n",
      "Epoch 47/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5197 - val_loss: 0.6931 - val_accuracy: 0.5159\n",
      "Epoch 48/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5204 - val_loss: 0.6931 - val_accuracy: 0.5159\n",
      "Epoch 49/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5196 - val_loss: 0.6931 - val_accuracy: 0.5162\n",
      "Epoch 50/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5191 - val_loss: 0.6931 - val_accuracy: 0.5160\n",
      "Epoch 51/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5191 - val_loss: 0.6932 - val_accuracy: 0.5115\n",
      "Epoch 52/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5193 - val_loss: 0.6932 - val_accuracy: 0.5123\n",
      "Epoch 53/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5211 - val_loss: 0.6932 - val_accuracy: 0.5106\n",
      "Epoch 54/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5197 - val_loss: 0.6932 - val_accuracy: 0.5145\n",
      "Epoch 55/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5204 - val_loss: 0.6934 - val_accuracy: 0.5062\n",
      "Epoch 56/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5205 - val_loss: 0.6934 - val_accuracy: 0.5116\n",
      "Epoch 57/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5196 - val_loss: 0.6933 - val_accuracy: 0.5095\n",
      "Epoch 58/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5194 - val_loss: 0.6932 - val_accuracy: 0.5112\n",
      "Epoch 59/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5181 - val_loss: 0.6931 - val_accuracy: 0.5149\n",
      "Epoch 60/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5210 - val_loss: 0.6932 - val_accuracy: 0.5095\n",
      "Training with significance = 1.26, run 1\n",
      "Train on 41053 samples, validate on 10264 samples\n",
      "Epoch 1/1000\n",
      "41053/41053 [==============================] - 1s 28us/sample - loss: 0.6932 - accuracy: 0.5072 - val_loss: 0.6942 - val_accuracy: 0.5040\n",
      "Epoch 2/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5162 - val_loss: 0.6925 - val_accuracy: 0.5173\n",
      "Epoch 3/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5160 - val_loss: 0.6920 - val_accuracy: 0.5207\n",
      "Epoch 4/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5162 - val_loss: 0.6919 - val_accuracy: 0.5198\n",
      "Epoch 5/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5148 - val_loss: 0.6918 - val_accuracy: 0.5213\n",
      "Epoch 6/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5166 - val_loss: 0.6919 - val_accuracy: 0.5195\n",
      "Epoch 7/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5171 - val_loss: 0.6919 - val_accuracy: 0.5196\n",
      "Epoch 8/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5177 - val_loss: 0.6920 - val_accuracy: 0.5154\n",
      "Epoch 9/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5160 - val_loss: 0.6920 - val_accuracy: 0.5181\n",
      "Epoch 10/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5168 - val_loss: 0.6919 - val_accuracy: 0.5180\n",
      "Epoch 11/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5203 - val_loss: 0.6920 - val_accuracy: 0.5162\n",
      "Epoch 12/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5181 - val_loss: 0.6919 - val_accuracy: 0.5164\n",
      "Epoch 13/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5182 - val_loss: 0.6920 - val_accuracy: 0.5183\n",
      "Epoch 14/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5180 - val_loss: 0.6919 - val_accuracy: 0.5176\n",
      "Epoch 15/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5170 - val_loss: 0.6919 - val_accuracy: 0.5185\n",
      "Epoch 16/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5179 - val_loss: 0.6919 - val_accuracy: 0.5212\n",
      "Epoch 17/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5166 - val_loss: 0.6920 - val_accuracy: 0.5201\n",
      "Epoch 18/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5175 - val_loss: 0.6920 - val_accuracy: 0.5172\n",
      "Epoch 19/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5189 - val_loss: 0.6920 - val_accuracy: 0.5208\n",
      "Epoch 20/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5170 - val_loss: 0.6919 - val_accuracy: 0.5197\n",
      "Epoch 21/1000\n",
      "41053/41053 [==============================] - 1s 12us/sample - loss: 0.6918 - accuracy: 0.5201 - val_loss: 0.6920 - val_accuracy: 0.5202\n",
      "Epoch 22/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5173 - val_loss: 0.6919 - val_accuracy: 0.5210\n",
      "Epoch 23/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5181 - val_loss: 0.6920 - val_accuracy: 0.5202\n",
      "Epoch 24/1000\n",
      "41053/41053 [==============================] - 1s 12us/sample - loss: 0.6918 - accuracy: 0.5164 - val_loss: 0.6921 - val_accuracy: 0.5175\n",
      "Epoch 25/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5205 - val_loss: 0.6919 - val_accuracy: 0.5213\n",
      "Epoch 26/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5179 - val_loss: 0.6920 - val_accuracy: 0.5182\n",
      "Epoch 27/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5176 - val_loss: 0.6919 - val_accuracy: 0.5188\n",
      "Epoch 28/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5187 - val_loss: 0.6921 - val_accuracy: 0.5185\n",
      "Epoch 29/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5192 - val_loss: 0.6921 - val_accuracy: 0.5182\n",
      "Epoch 30/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5176 - val_loss: 0.6919 - val_accuracy: 0.5202\n",
      "Epoch 31/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5194 - val_loss: 0.6919 - val_accuracy: 0.5199\n",
      "Epoch 32/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5185 - val_loss: 0.6920 - val_accuracy: 0.5205\n",
      "Epoch 33/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5187 - val_loss: 0.6920 - val_accuracy: 0.5178\n",
      "Epoch 34/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5166 - val_loss: 0.6920 - val_accuracy: 0.5198\n",
      "Epoch 35/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5199 - val_loss: 0.6922 - val_accuracy: 0.5203\n",
      "Training with significance = 1.26, run 2\n",
      "Train on 41053 samples, validate on 10264 samples\n",
      "Epoch 1/1000\n",
      "41053/41053 [==============================] - 1s 27us/sample - loss: 0.6939 - accuracy: 0.5080 - val_loss: 0.6944 - val_accuracy: 0.4936\n",
      "Epoch 2/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6929 - accuracy: 0.5123 - val_loss: 0.6931 - val_accuracy: 0.5045\n",
      "Epoch 3/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6928 - accuracy: 0.5133 - val_loss: 0.6928 - val_accuracy: 0.5081\n",
      "Epoch 4/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6926 - accuracy: 0.5157 - val_loss: 0.6925 - val_accuracy: 0.5144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6925 - accuracy: 0.5149 - val_loss: 0.6925 - val_accuracy: 0.5124\n",
      "Epoch 6/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6925 - accuracy: 0.5171 - val_loss: 0.6925 - val_accuracy: 0.5166\n",
      "Epoch 7/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6925 - accuracy: 0.5152 - val_loss: 0.6926 - val_accuracy: 0.5150\n",
      "Epoch 8/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5167 - val_loss: 0.6923 - val_accuracy: 0.5123\n",
      "Epoch 9/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5170 - val_loss: 0.6927 - val_accuracy: 0.5112\n",
      "Epoch 10/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5164 - val_loss: 0.6928 - val_accuracy: 0.5102\n",
      "Epoch 11/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5179 - val_loss: 0.6927 - val_accuracy: 0.5117\n",
      "Epoch 12/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5164 - val_loss: 0.6927 - val_accuracy: 0.5126\n",
      "Epoch 13/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5165 - val_loss: 0.6924 - val_accuracy: 0.5137\n",
      "Epoch 14/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5178 - val_loss: 0.6924 - val_accuracy: 0.5134\n",
      "Epoch 15/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5194 - val_loss: 0.6925 - val_accuracy: 0.5129\n",
      "Epoch 16/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5168 - val_loss: 0.6925 - val_accuracy: 0.5138\n",
      "Epoch 17/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5174 - val_loss: 0.6925 - val_accuracy: 0.5133\n",
      "Epoch 18/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5187 - val_loss: 0.6924 - val_accuracy: 0.5115\n",
      "Epoch 19/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5178 - val_loss: 0.6924 - val_accuracy: 0.5141\n",
      "Epoch 20/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5167 - val_loss: 0.6924 - val_accuracy: 0.5134\n",
      "Epoch 21/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5176 - val_loss: 0.6924 - val_accuracy: 0.5129\n",
      "Epoch 22/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5171 - val_loss: 0.6925 - val_accuracy: 0.5132\n",
      "Epoch 23/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5206 - val_loss: 0.6930 - val_accuracy: 0.5091\n",
      "Epoch 24/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5161 - val_loss: 0.6924 - val_accuracy: 0.5112\n",
      "Epoch 25/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5188 - val_loss: 0.6922 - val_accuracy: 0.5127\n",
      "Epoch 26/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5184 - val_loss: 0.6924 - val_accuracy: 0.5138\n",
      "Epoch 27/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5186 - val_loss: 0.6925 - val_accuracy: 0.5132\n",
      "Epoch 28/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5168 - val_loss: 0.6926 - val_accuracy: 0.5120\n",
      "Epoch 29/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5189 - val_loss: 0.6926 - val_accuracy: 0.5119\n",
      "Epoch 30/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5182 - val_loss: 0.6924 - val_accuracy: 0.5139\n",
      "Epoch 31/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5191 - val_loss: 0.6923 - val_accuracy: 0.5136\n",
      "Epoch 32/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5185 - val_loss: 0.6924 - val_accuracy: 0.5147\n",
      "Epoch 33/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5191 - val_loss: 0.6927 - val_accuracy: 0.5110\n",
      "Epoch 34/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5189 - val_loss: 0.6923 - val_accuracy: 0.5149\n",
      "Epoch 35/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5182 - val_loss: 0.6926 - val_accuracy: 0.5086\n",
      "Epoch 36/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5167 - val_loss: 0.6925 - val_accuracy: 0.5123\n",
      "Epoch 37/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5188 - val_loss: 0.6923 - val_accuracy: 0.5136\n",
      "Epoch 38/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5178 - val_loss: 0.6924 - val_accuracy: 0.5125\n",
      "Epoch 39/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5186 - val_loss: 0.6925 - val_accuracy: 0.5105\n",
      "Epoch 40/1000\n",
      "41053/41053 [==============================] - 1s 12us/sample - loss: 0.6919 - accuracy: 0.5198 - val_loss: 0.6924 - val_accuracy: 0.5131\n",
      "Epoch 41/1000\n",
      "41053/41053 [==============================] - 1s 12us/sample - loss: 0.6919 - accuracy: 0.5202 - val_loss: 0.6923 - val_accuracy: 0.5117\n",
      "Epoch 42/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5194 - val_loss: 0.6925 - val_accuracy: 0.5125\n",
      "Epoch 43/1000\n",
      "41053/41053 [==============================] - 1s 12us/sample - loss: 0.6919 - accuracy: 0.5197 - val_loss: 0.6926 - val_accuracy: 0.5113\n",
      "Epoch 44/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5192 - val_loss: 0.6924 - val_accuracy: 0.5114\n",
      "Epoch 45/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5195 - val_loss: 0.6922 - val_accuracy: 0.5147\n",
      "Epoch 46/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5208 - val_loss: 0.6923 - val_accuracy: 0.5166\n",
      "Epoch 47/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5184 - val_loss: 0.6923 - val_accuracy: 0.5146\n",
      "Epoch 48/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5204 - val_loss: 0.6924 - val_accuracy: 0.5133\n",
      "Epoch 49/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5216 - val_loss: 0.6926 - val_accuracy: 0.5116\n",
      "Epoch 50/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5210 - val_loss: 0.6923 - val_accuracy: 0.5138\n",
      "Epoch 51/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5211 - val_loss: 0.6924 - val_accuracy: 0.5133\n",
      "Epoch 52/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5200 - val_loss: 0.6924 - val_accuracy: 0.5127\n",
      "Epoch 53/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5214 - val_loss: 0.6924 - val_accuracy: 0.5123\n",
      "Epoch 54/1000\n",
      "41053/41053 [==============================] - 1s 14us/sample - loss: 0.6917 - accuracy: 0.5197 - val_loss: 0.6923 - val_accuracy: 0.5137\n",
      "Epoch 55/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5200 - val_loss: 0.6925 - val_accuracy: 0.5132\n",
      "Training with significance = 1.26, run 3\n",
      "Train on 41053 samples, validate on 10264 samples\n",
      "Epoch 1/1000\n",
      "41053/41053 [==============================] - 1s 28us/sample - loss: 0.6932 - accuracy: 0.5126 - val_loss: 0.6943 - val_accuracy: 0.4963\n",
      "Epoch 2/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6927 - accuracy: 0.5136 - val_loss: 0.6936 - val_accuracy: 0.5021\n",
      "Epoch 3/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5133 - val_loss: 0.6932 - val_accuracy: 0.5086\n",
      "Epoch 4/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5156 - val_loss: 0.6932 - val_accuracy: 0.5083\n",
      "Epoch 5/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5159 - val_loss: 0.6932 - val_accuracy: 0.5117\n",
      "Epoch 6/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5153 - val_loss: 0.6930 - val_accuracy: 0.5079\n",
      "Epoch 7/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5165 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 8/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5159 - val_loss: 0.6930 - val_accuracy: 0.5105\n",
      "Epoch 9/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5150 - val_loss: 0.6930 - val_accuracy: 0.5103\n",
      "Epoch 10/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5181 - val_loss: 0.6929 - val_accuracy: 0.5106\n",
      "Epoch 11/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5153 - val_loss: 0.6929 - val_accuracy: 0.5101\n",
      "Epoch 12/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5172 - val_loss: 0.6929 - val_accuracy: 0.5100\n",
      "Epoch 13/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5174 - val_loss: 0.6931 - val_accuracy: 0.5106\n",
      "Epoch 14/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5189 - val_loss: 0.6930 - val_accuracy: 0.5082\n",
      "Epoch 15/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5181 - val_loss: 0.6929 - val_accuracy: 0.5120\n",
      "Epoch 16/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5171 - val_loss: 0.6929 - val_accuracy: 0.5140\n",
      "Epoch 17/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5169 - val_loss: 0.6929 - val_accuracy: 0.5109\n",
      "Epoch 18/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5185 - val_loss: 0.6928 - val_accuracy: 0.5091\n",
      "Epoch 19/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5173 - val_loss: 0.6931 - val_accuracy: 0.5095\n",
      "Epoch 20/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5182 - val_loss: 0.6929 - val_accuracy: 0.5111\n",
      "Epoch 21/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5185 - val_loss: 0.6930 - val_accuracy: 0.5098\n",
      "Epoch 22/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5193 - val_loss: 0.6930 - val_accuracy: 0.5130\n",
      "Epoch 23/1000\n",
      "41053/41053 [==============================] - 1s 14us/sample - loss: 0.6917 - accuracy: 0.5169 - val_loss: 0.6929 - val_accuracy: 0.5140\n",
      "Epoch 24/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5180 - val_loss: 0.6930 - val_accuracy: 0.5124\n",
      "Epoch 25/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5174 - val_loss: 0.6929 - val_accuracy: 0.5138\n",
      "Epoch 26/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5184 - val_loss: 0.6929 - val_accuracy: 0.5128\n",
      "Epoch 27/1000\n",
      "41053/41053 [==============================] - 1s 12us/sample - loss: 0.6917 - accuracy: 0.5176 - val_loss: 0.6929 - val_accuracy: 0.5118\n",
      "Epoch 28/1000\n",
      "41053/41053 [==============================] - 1s 12us/sample - loss: 0.6917 - accuracy: 0.5183 - val_loss: 0.6931 - val_accuracy: 0.5112\n",
      "Epoch 29/1000\n",
      "41053/41053 [==============================] - 1s 12us/sample - loss: 0.6917 - accuracy: 0.5180 - val_loss: 0.6930 - val_accuracy: 0.5131\n",
      "Epoch 30/1000\n",
      "41053/41053 [==============================] - 1s 12us/sample - loss: 0.6916 - accuracy: 0.5192 - val_loss: 0.6929 - val_accuracy: 0.5139\n",
      "Epoch 31/1000\n",
      "41053/41053 [==============================] - 1s 12us/sample - loss: 0.6916 - accuracy: 0.5197 - val_loss: 0.6930 - val_accuracy: 0.5111\n",
      "Epoch 32/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5200 - val_loss: 0.6928 - val_accuracy: 0.5147\n",
      "Epoch 33/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5187 - val_loss: 0.6929 - val_accuracy: 0.5128\n",
      "Epoch 34/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5191 - val_loss: 0.6929 - val_accuracy: 0.5120\n",
      "Epoch 35/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5180 - val_loss: 0.6928 - val_accuracy: 0.5139\n",
      "Epoch 36/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5189 - val_loss: 0.6929 - val_accuracy: 0.5120\n",
      "Epoch 37/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5195 - val_loss: 0.6929 - val_accuracy: 0.5125\n",
      "Epoch 38/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5192 - val_loss: 0.6928 - val_accuracy: 0.5126\n",
      "Epoch 39/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5195 - val_loss: 0.6930 - val_accuracy: 0.5110\n",
      "Epoch 40/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5177 - val_loss: 0.6930 - val_accuracy: 0.5131\n",
      "Epoch 41/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5189 - val_loss: 0.6928 - val_accuracy: 0.5128\n",
      "Epoch 42/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5182 - val_loss: 0.6929 - val_accuracy: 0.5122\n",
      "Epoch 43/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5181 - val_loss: 0.6928 - val_accuracy: 0.5124\n",
      "Epoch 44/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5218 - val_loss: 0.6930 - val_accuracy: 0.5146\n",
      "Epoch 45/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5195 - val_loss: 0.6929 - val_accuracy: 0.5118\n",
      "Epoch 46/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5198 - val_loss: 0.6931 - val_accuracy: 0.5091\n",
      "Epoch 47/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5208 - val_loss: 0.6930 - val_accuracy: 0.5101\n",
      "Epoch 48/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5206 - val_loss: 0.6929 - val_accuracy: 0.5108\n",
      "Epoch 49/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5184 - val_loss: 0.6930 - val_accuracy: 0.5127\n",
      "Epoch 50/1000\n",
      "41053/41053 [==============================] - 1s 14us/sample - loss: 0.6914 - accuracy: 0.5208 - val_loss: 0.6933 - val_accuracy: 0.5120\n",
      "Epoch 51/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5200 - val_loss: 0.6930 - val_accuracy: 0.5123\n",
      "Epoch 52/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5208 - val_loss: 0.6930 - val_accuracy: 0.5111\n",
      "Epoch 53/1000\n",
      "41053/41053 [==============================] - 1s 14us/sample - loss: 0.6914 - accuracy: 0.5215 - val_loss: 0.6930 - val_accuracy: 0.5116\n",
      "Epoch 54/1000\n",
      "41053/41053 [==============================] - 1s 14us/sample - loss: 0.6915 - accuracy: 0.5185 - val_loss: 0.6929 - val_accuracy: 0.5111\n",
      "Epoch 55/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5198 - val_loss: 0.6929 - val_accuracy: 0.5132\n",
      "Epoch 56/1000\n",
      "41053/41053 [==============================] - 1s 14us/sample - loss: 0.6914 - accuracy: 0.5204 - val_loss: 0.6930 - val_accuracy: 0.5107\n",
      "Epoch 57/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41053/41053 [==============================] - 1s 14us/sample - loss: 0.6914 - accuracy: 0.5201 - val_loss: 0.6930 - val_accuracy: 0.5120\n",
      "Epoch 58/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5204 - val_loss: 0.6929 - val_accuracy: 0.5113\n",
      "Epoch 59/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5220 - val_loss: 0.6930 - val_accuracy: 0.5106\n",
      "Epoch 60/1000\n",
      "41053/41053 [==============================] - 1s 14us/sample - loss: 0.6914 - accuracy: 0.5200 - val_loss: 0.6930 - val_accuracy: 0.5110\n",
      "Epoch 61/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5209 - val_loss: 0.6930 - val_accuracy: 0.5107\n",
      "Epoch 62/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5212 - val_loss: 0.6930 - val_accuracy: 0.5120\n",
      "Epoch 63/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5199 - val_loss: 0.6931 - val_accuracy: 0.5124\n",
      "Epoch 64/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5206 - val_loss: 0.6930 - val_accuracy: 0.5105\n",
      "Epoch 65/1000\n",
      "41053/41053 [==============================] - 1s 12us/sample - loss: 0.6913 - accuracy: 0.5206 - val_loss: 0.6931 - val_accuracy: 0.5096\n",
      "Epoch 66/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5206 - val_loss: 0.6931 - val_accuracy: 0.5108\n",
      "Epoch 67/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5208 - val_loss: 0.6930 - val_accuracy: 0.5109\n",
      "Epoch 68/1000\n",
      "41053/41053 [==============================] - 1s 14us/sample - loss: 0.6914 - accuracy: 0.5205 - val_loss: 0.6932 - val_accuracy: 0.5088\n",
      "Training with significance = 1.26, run 4\n",
      "Train on 41053 samples, validate on 10264 samples\n",
      "Epoch 1/1000\n",
      "41053/41053 [==============================] - 1s 28us/sample - loss: 0.6931 - accuracy: 0.5075 - val_loss: 0.6970 - val_accuracy: 0.4921\n",
      "Epoch 2/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5129 - val_loss: 0.6935 - val_accuracy: 0.5083\n",
      "Epoch 3/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5142 - val_loss: 0.6931 - val_accuracy: 0.5098\n",
      "Epoch 4/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5141 - val_loss: 0.6933 - val_accuracy: 0.5092\n",
      "Epoch 5/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5176 - val_loss: 0.6931 - val_accuracy: 0.5062\n",
      "Epoch 6/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5169 - val_loss: 0.6932 - val_accuracy: 0.5066\n",
      "Epoch 7/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5170 - val_loss: 0.6931 - val_accuracy: 0.5057\n",
      "Epoch 8/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5157 - val_loss: 0.6933 - val_accuracy: 0.5049\n",
      "Epoch 9/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5178 - val_loss: 0.6929 - val_accuracy: 0.5067\n",
      "Epoch 10/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5176 - val_loss: 0.6929 - val_accuracy: 0.5083\n",
      "Epoch 11/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5199 - val_loss: 0.6928 - val_accuracy: 0.5094\n",
      "Epoch 12/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5194 - val_loss: 0.6928 - val_accuracy: 0.5111\n",
      "Epoch 13/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5192 - val_loss: 0.6930 - val_accuracy: 0.5060\n",
      "Epoch 14/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5191 - val_loss: 0.6930 - val_accuracy: 0.5085\n",
      "Epoch 15/1000\n",
      "41053/41053 [==============================] - 1s 12us/sample - loss: 0.6915 - accuracy: 0.5195 - val_loss: 0.6930 - val_accuracy: 0.5076\n",
      "Epoch 16/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5208 - val_loss: 0.6929 - val_accuracy: 0.5075\n",
      "Epoch 17/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5204 - val_loss: 0.6931 - val_accuracy: 0.5072\n",
      "Epoch 18/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5193 - val_loss: 0.6928 - val_accuracy: 0.5102\n",
      "Epoch 19/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5193 - val_loss: 0.6928 - val_accuracy: 0.5095\n",
      "Epoch 20/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5184 - val_loss: 0.6929 - val_accuracy: 0.5082\n",
      "Epoch 21/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5202 - val_loss: 0.6930 - val_accuracy: 0.5080\n",
      "Epoch 22/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5189 - val_loss: 0.6929 - val_accuracy: 0.5090\n",
      "Epoch 23/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5196 - val_loss: 0.6931 - val_accuracy: 0.5080\n",
      "Epoch 24/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5208 - val_loss: 0.6930 - val_accuracy: 0.5075\n",
      "Epoch 25/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5190 - val_loss: 0.6931 - val_accuracy: 0.5065\n",
      "Epoch 26/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5211 - val_loss: 0.6930 - val_accuracy: 0.5054\n",
      "Epoch 27/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5187 - val_loss: 0.6927 - val_accuracy: 0.5116\n",
      "Epoch 28/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5206 - val_loss: 0.6931 - val_accuracy: 0.5089\n",
      "Epoch 29/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5189 - val_loss: 0.6929 - val_accuracy: 0.5113\n",
      "Epoch 30/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5195 - val_loss: 0.6931 - val_accuracy: 0.5089\n",
      "Epoch 31/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5203 - val_loss: 0.6931 - val_accuracy: 0.5077\n",
      "Epoch 32/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5223 - val_loss: 0.6928 - val_accuracy: 0.5149\n",
      "Epoch 33/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5221 - val_loss: 0.6931 - val_accuracy: 0.5104\n",
      "Epoch 34/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5213 - val_loss: 0.6933 - val_accuracy: 0.5058\n",
      "Epoch 35/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5184 - val_loss: 0.6929 - val_accuracy: 0.5126\n",
      "Epoch 36/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5217 - val_loss: 0.6929 - val_accuracy: 0.5090\n",
      "Epoch 37/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5219 - val_loss: 0.6933 - val_accuracy: 0.5046\n",
      "Epoch 38/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5212 - val_loss: 0.6931 - val_accuracy: 0.5099\n",
      "Epoch 39/1000\n",
      "41053/41053 [==============================] - 1s 12us/sample - loss: 0.6913 - accuracy: 0.5215 - val_loss: 0.6928 - val_accuracy: 0.5166\n",
      "Epoch 40/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5220 - val_loss: 0.6932 - val_accuracy: 0.5048\n",
      "Epoch 41/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5214 - val_loss: 0.6933 - val_accuracy: 0.5090\n",
      "Epoch 42/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5226 - val_loss: 0.6931 - val_accuracy: 0.5069\n",
      "Epoch 43/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5203 - val_loss: 0.6931 - val_accuracy: 0.5095\n",
      "Epoch 44/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5213 - val_loss: 0.6931 - val_accuracy: 0.5076\n",
      "Epoch 45/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5207 - val_loss: 0.6931 - val_accuracy: 0.5070\n",
      "Epoch 46/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5214 - val_loss: 0.6930 - val_accuracy: 0.5091\n",
      "Epoch 47/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5214 - val_loss: 0.6933 - val_accuracy: 0.5101\n",
      "Epoch 48/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5219 - val_loss: 0.6930 - val_accuracy: 0.5103\n",
      "Epoch 49/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5221 - val_loss: 0.6933 - val_accuracy: 0.5087\n",
      "Epoch 50/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5207 - val_loss: 0.6930 - val_accuracy: 0.5078\n",
      "Epoch 51/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5220 - val_loss: 0.6932 - val_accuracy: 0.5091\n",
      "Epoch 52/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5211 - val_loss: 0.6931 - val_accuracy: 0.5102\n",
      "Epoch 53/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5219 - val_loss: 0.6933 - val_accuracy: 0.5095\n",
      "Epoch 54/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5234 - val_loss: 0.6930 - val_accuracy: 0.5140\n",
      "Epoch 55/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5217 - val_loss: 0.6929 - val_accuracy: 0.5115\n",
      "Epoch 56/1000\n",
      "41053/41053 [==============================] - 1s 12us/sample - loss: 0.6911 - accuracy: 0.5229 - val_loss: 0.6930 - val_accuracy: 0.5098\n",
      "Epoch 57/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5224 - val_loss: 0.6932 - val_accuracy: 0.5079\n",
      "Training with significance = 1.26, run 5\n",
      "Train on 41053 samples, validate on 10264 samples\n",
      "Epoch 1/1000\n",
      "41053/41053 [==============================] - 1s 28us/sample - loss: 0.6932 - accuracy: 0.5079 - val_loss: 0.6938 - val_accuracy: 0.4977\n",
      "Epoch 2/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6927 - accuracy: 0.5098 - val_loss: 0.6931 - val_accuracy: 0.5139\n",
      "Epoch 3/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6925 - accuracy: 0.5133 - val_loss: 0.6926 - val_accuracy: 0.5114\n",
      "Epoch 4/1000\n",
      "41053/41053 [==============================] - 1s 14us/sample - loss: 0.6924 - accuracy: 0.5129 - val_loss: 0.6925 - val_accuracy: 0.5103\n",
      "Epoch 5/1000\n",
      "41053/41053 [==============================] - 1s 14us/sample - loss: 0.6924 - accuracy: 0.5110 - val_loss: 0.6924 - val_accuracy: 0.5121\n",
      "Epoch 6/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5148 - val_loss: 0.6923 - val_accuracy: 0.5169\n",
      "Epoch 7/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5132 - val_loss: 0.6923 - val_accuracy: 0.5182\n",
      "Epoch 8/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5138 - val_loss: 0.6924 - val_accuracy: 0.5145\n",
      "Epoch 9/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5142 - val_loss: 0.6922 - val_accuracy: 0.5125\n",
      "Epoch 10/1000\n",
      "41053/41053 [==============================] - 1s 14us/sample - loss: 0.6922 - accuracy: 0.5141 - val_loss: 0.6922 - val_accuracy: 0.5168\n",
      "Epoch 11/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5154 - val_loss: 0.6922 - val_accuracy: 0.5143\n",
      "Epoch 12/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5173 - val_loss: 0.6923 - val_accuracy: 0.5167\n",
      "Epoch 13/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5144 - val_loss: 0.6922 - val_accuracy: 0.5149\n",
      "Epoch 14/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5171 - val_loss: 0.6923 - val_accuracy: 0.5139\n",
      "Epoch 15/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5152 - val_loss: 0.6921 - val_accuracy: 0.5196\n",
      "Epoch 16/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5163 - val_loss: 0.6922 - val_accuracy: 0.5167\n",
      "Epoch 17/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5154 - val_loss: 0.6921 - val_accuracy: 0.5180\n",
      "Epoch 18/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5156 - val_loss: 0.6921 - val_accuracy: 0.5149\n",
      "Epoch 19/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5157 - val_loss: 0.6923 - val_accuracy: 0.5124\n",
      "Epoch 20/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5168 - val_loss: 0.6922 - val_accuracy: 0.5136\n",
      "Epoch 21/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5161 - val_loss: 0.6921 - val_accuracy: 0.5153\n",
      "Epoch 22/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5155 - val_loss: 0.6920 - val_accuracy: 0.5165\n",
      "Epoch 23/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5166 - val_loss: 0.6920 - val_accuracy: 0.5140\n",
      "Epoch 24/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5177 - val_loss: 0.6920 - val_accuracy: 0.5135\n",
      "Epoch 25/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5166 - val_loss: 0.6921 - val_accuracy: 0.5132\n",
      "Epoch 26/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5163 - val_loss: 0.6921 - val_accuracy: 0.5127\n",
      "Epoch 27/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5145 - val_loss: 0.6920 - val_accuracy: 0.5147\n",
      "Epoch 28/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5177 - val_loss: 0.6923 - val_accuracy: 0.5119\n",
      "Epoch 29/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5171 - val_loss: 0.6923 - val_accuracy: 0.5092\n",
      "Epoch 30/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5170 - val_loss: 0.6921 - val_accuracy: 0.5157\n",
      "Epoch 31/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5187 - val_loss: 0.6920 - val_accuracy: 0.5158\n",
      "Epoch 32/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5158 - val_loss: 0.6920 - val_accuracy: 0.5168\n",
      "Epoch 33/1000\n",
      "41053/41053 [==============================] - 1s 14us/sample - loss: 0.6919 - accuracy: 0.5167 - val_loss: 0.6920 - val_accuracy: 0.5146\n",
      "Epoch 34/1000\n",
      "41053/41053 [==============================] - 1s 14us/sample - loss: 0.6919 - accuracy: 0.5172 - val_loss: 0.6920 - val_accuracy: 0.5166\n",
      "Epoch 35/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5175 - val_loss: 0.6920 - val_accuracy: 0.5140\n",
      "Epoch 36/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5174 - val_loss: 0.6920 - val_accuracy: 0.5157\n",
      "Epoch 37/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5173 - val_loss: 0.6920 - val_accuracy: 0.5164\n",
      "Epoch 38/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5177 - val_loss: 0.6919 - val_accuracy: 0.5170\n",
      "Epoch 39/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5167 - val_loss: 0.6921 - val_accuracy: 0.5173\n",
      "Epoch 40/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5182 - val_loss: 0.6921 - val_accuracy: 0.5167\n",
      "Epoch 41/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5172 - val_loss: 0.6922 - val_accuracy: 0.5123\n",
      "Epoch 42/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5169 - val_loss: 0.6919 - val_accuracy: 0.5156\n",
      "Epoch 43/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5174 - val_loss: 0.6919 - val_accuracy: 0.5184\n",
      "Epoch 44/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5172 - val_loss: 0.6919 - val_accuracy: 0.5183\n",
      "Epoch 45/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5171 - val_loss: 0.6921 - val_accuracy: 0.5130\n",
      "Epoch 46/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5189 - val_loss: 0.6922 - val_accuracy: 0.5148\n",
      "Epoch 47/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5184 - val_loss: 0.6920 - val_accuracy: 0.5172\n",
      "Epoch 48/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5174 - val_loss: 0.6919 - val_accuracy: 0.5172\n",
      "Epoch 49/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5190 - val_loss: 0.6919 - val_accuracy: 0.5166\n",
      "Epoch 50/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5165 - val_loss: 0.6919 - val_accuracy: 0.5162\n",
      "Epoch 51/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5168 - val_loss: 0.6918 - val_accuracy: 0.5162\n",
      "Epoch 52/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5199 - val_loss: 0.6918 - val_accuracy: 0.5158\n",
      "Epoch 53/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5188 - val_loss: 0.6919 - val_accuracy: 0.5173\n",
      "Epoch 54/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5211 - val_loss: 0.6919 - val_accuracy: 0.5159\n",
      "Epoch 55/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5193 - val_loss: 0.6919 - val_accuracy: 0.5114\n",
      "Epoch 56/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5181 - val_loss: 0.6920 - val_accuracy: 0.5172\n",
      "Epoch 57/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5190 - val_loss: 0.6920 - val_accuracy: 0.5148\n",
      "Epoch 58/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5171 - val_loss: 0.6919 - val_accuracy: 0.5180\n",
      "Epoch 59/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5184 - val_loss: 0.6920 - val_accuracy: 0.5133\n",
      "Epoch 60/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5210 - val_loss: 0.6920 - val_accuracy: 0.5198\n",
      "Epoch 61/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5182 - val_loss: 0.6918 - val_accuracy: 0.5173\n",
      "Epoch 62/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5184 - val_loss: 0.6919 - val_accuracy: 0.5165\n",
      "Epoch 63/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5186 - val_loss: 0.6919 - val_accuracy: 0.5170\n",
      "Epoch 64/1000\n",
      "41053/41053 [==============================] - 1s 14us/sample - loss: 0.6915 - accuracy: 0.5224 - val_loss: 0.6920 - val_accuracy: 0.5133\n",
      "Epoch 65/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5195 - val_loss: 0.6918 - val_accuracy: 0.5223\n",
      "Epoch 66/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5192 - val_loss: 0.6918 - val_accuracy: 0.5198\n",
      "Epoch 67/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5173 - val_loss: 0.6919 - val_accuracy: 0.5169\n",
      "Epoch 68/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5190 - val_loss: 0.6920 - val_accuracy: 0.5147\n",
      "Epoch 69/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5176 - val_loss: 0.6918 - val_accuracy: 0.5172\n",
      "Epoch 70/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5202 - val_loss: 0.6920 - val_accuracy: 0.5113\n",
      "Epoch 71/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5196 - val_loss: 0.6917 - val_accuracy: 0.5221\n",
      "Epoch 72/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5180 - val_loss: 0.6918 - val_accuracy: 0.5180\n",
      "Epoch 73/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5188 - val_loss: 0.6919 - val_accuracy: 0.5190\n",
      "Epoch 74/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5200 - val_loss: 0.6917 - val_accuracy: 0.5197\n",
      "Epoch 75/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5209 - val_loss: 0.6920 - val_accuracy: 0.5147\n",
      "Epoch 76/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5172 - val_loss: 0.6919 - val_accuracy: 0.5124\n",
      "Epoch 77/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5186 - val_loss: 0.6919 - val_accuracy: 0.5138\n",
      "Epoch 78/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5206 - val_loss: 0.6918 - val_accuracy: 0.5150\n",
      "Epoch 79/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5204 - val_loss: 0.6919 - val_accuracy: 0.5122\n",
      "Epoch 80/1000\n",
      "41053/41053 [==============================] - 1s 14us/sample - loss: 0.6915 - accuracy: 0.5185 - val_loss: 0.6919 - val_accuracy: 0.5164\n",
      "Epoch 81/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5190 - val_loss: 0.6919 - val_accuracy: 0.5168\n",
      "Epoch 82/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5187 - val_loss: 0.6921 - val_accuracy: 0.5149\n",
      "Epoch 83/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5199 - val_loss: 0.6919 - val_accuracy: 0.5191\n",
      "Epoch 84/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5189 - val_loss: 0.6918 - val_accuracy: 0.5177\n",
      "Epoch 85/1000\n",
      "41053/41053 [==============================] - 1s 14us/sample - loss: 0.6915 - accuracy: 0.5204 - val_loss: 0.6918 - val_accuracy: 0.5162\n",
      "Epoch 86/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5188 - val_loss: 0.6918 - val_accuracy: 0.5212\n",
      "Epoch 87/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5204 - val_loss: 0.6919 - val_accuracy: 0.5145\n",
      "Epoch 88/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5204 - val_loss: 0.6918 - val_accuracy: 0.5196\n",
      "Epoch 89/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5193 - val_loss: 0.6918 - val_accuracy: 0.5194\n",
      "Epoch 90/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5195 - val_loss: 0.6919 - val_accuracy: 0.5134\n",
      "Epoch 91/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5184 - val_loss: 0.6918 - val_accuracy: 0.5158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92/1000\n",
      "41053/41053 [==============================] - 1s 12us/sample - loss: 0.6914 - accuracy: 0.5221 - val_loss: 0.6917 - val_accuracy: 0.5210\n",
      "Epoch 93/1000\n",
      "41053/41053 [==============================] - 1s 12us/sample - loss: 0.6914 - accuracy: 0.5204 - val_loss: 0.6918 - val_accuracy: 0.5186\n",
      "Epoch 94/1000\n",
      "41053/41053 [==============================] - 1s 12us/sample - loss: 0.6914 - accuracy: 0.5202 - val_loss: 0.6918 - val_accuracy: 0.5199\n",
      "Epoch 95/1000\n",
      "41053/41053 [==============================] - 1s 12us/sample - loss: 0.6913 - accuracy: 0.5207 - val_loss: 0.6920 - val_accuracy: 0.5118\n",
      "Epoch 96/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5197 - val_loss: 0.6917 - val_accuracy: 0.5157\n",
      "Epoch 97/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5203 - val_loss: 0.6918 - val_accuracy: 0.5155\n",
      "Epoch 98/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5216 - val_loss: 0.6919 - val_accuracy: 0.5125\n",
      "Epoch 99/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5189 - val_loss: 0.6918 - val_accuracy: 0.5127\n",
      "Epoch 100/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5197 - val_loss: 0.6919 - val_accuracy: 0.5095\n",
      "Epoch 101/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5193 - val_loss: 0.6918 - val_accuracy: 0.5165\n",
      "Epoch 102/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5187 - val_loss: 0.6917 - val_accuracy: 0.5138\n",
      "Epoch 103/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5193 - val_loss: 0.6917 - val_accuracy: 0.5171\n",
      "Epoch 104/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5210 - val_loss: 0.6920 - val_accuracy: 0.5109\n",
      "Epoch 105/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5199 - val_loss: 0.6917 - val_accuracy: 0.5153\n",
      "Epoch 106/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5196 - val_loss: 0.6917 - val_accuracy: 0.5170\n",
      "Epoch 107/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5214 - val_loss: 0.6917 - val_accuracy: 0.5147\n",
      "Epoch 108/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5204 - val_loss: 0.6919 - val_accuracy: 0.5149\n",
      "Epoch 109/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5220 - val_loss: 0.6917 - val_accuracy: 0.5182\n",
      "Epoch 110/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5211 - val_loss: 0.6918 - val_accuracy: 0.5127\n",
      "Epoch 111/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5194 - val_loss: 0.6918 - val_accuracy: 0.5131\n",
      "Epoch 112/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5210 - val_loss: 0.6918 - val_accuracy: 0.5133\n",
      "Epoch 113/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5211 - val_loss: 0.6919 - val_accuracy: 0.5170\n",
      "Epoch 114/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5192 - val_loss: 0.6918 - val_accuracy: 0.5114\n",
      "Epoch 115/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5208 - val_loss: 0.6918 - val_accuracy: 0.5138\n",
      "Epoch 116/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5200 - val_loss: 0.6918 - val_accuracy: 0.5199\n",
      "Epoch 117/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5226 - val_loss: 0.6917 - val_accuracy: 0.5197\n",
      "Epoch 118/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5218 - val_loss: 0.6920 - val_accuracy: 0.5184\n",
      "Epoch 119/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5206 - val_loss: 0.6919 - val_accuracy: 0.5167\n",
      "Epoch 120/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5209 - val_loss: 0.6919 - val_accuracy: 0.5163\n",
      "Epoch 121/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5198 - val_loss: 0.6920 - val_accuracy: 0.5140\n",
      "Epoch 122/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5200 - val_loss: 0.6921 - val_accuracy: 0.5149\n",
      "Epoch 123/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5228 - val_loss: 0.6918 - val_accuracy: 0.5189\n",
      "Epoch 124/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5197 - val_loss: 0.6919 - val_accuracy: 0.5106\n",
      "Epoch 125/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5229 - val_loss: 0.6920 - val_accuracy: 0.5170\n",
      "Epoch 126/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5202 - val_loss: 0.6920 - val_accuracy: 0.5076\n",
      "Epoch 127/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5226 - val_loss: 0.6918 - val_accuracy: 0.5157\n",
      "Epoch 128/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5214 - val_loss: 0.6918 - val_accuracy: 0.5167\n",
      "Epoch 129/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5211 - val_loss: 0.6918 - val_accuracy: 0.5111\n",
      "Epoch 130/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5211 - val_loss: 0.6918 - val_accuracy: 0.5170\n",
      "Epoch 131/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5207 - val_loss: 0.6917 - val_accuracy: 0.5190\n",
      "Epoch 132/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5196 - val_loss: 0.6918 - val_accuracy: 0.5092\n",
      "Epoch 133/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5219 - val_loss: 0.6919 - val_accuracy: 0.5131\n",
      "Epoch 134/1000\n",
      "41053/41053 [==============================] - 1s 12us/sample - loss: 0.6912 - accuracy: 0.5218 - val_loss: 0.6919 - val_accuracy: 0.5186\n",
      "Epoch 135/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5205 - val_loss: 0.6917 - val_accuracy: 0.5220\n",
      "Epoch 136/1000\n",
      "41053/41053 [==============================] - 1s 12us/sample - loss: 0.6912 - accuracy: 0.5234 - val_loss: 0.6919 - val_accuracy: 0.5128\n",
      "Epoch 137/1000\n",
      "41053/41053 [==============================] - 0s 12us/sample - loss: 0.6911 - accuracy: 0.5207 - val_loss: 0.6919 - val_accuracy: 0.5128\n",
      "Epoch 138/1000\n",
      "41053/41053 [==============================] - 1s 12us/sample - loss: 0.6911 - accuracy: 0.5209 - val_loss: 0.6920 - val_accuracy: 0.5139\n",
      "Epoch 139/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5215 - val_loss: 0.6917 - val_accuracy: 0.5213\n",
      "Epoch 140/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5236 - val_loss: 0.6917 - val_accuracy: 0.5130\n",
      "Epoch 141/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5249 - val_loss: 0.6919 - val_accuracy: 0.5107\n",
      "Epoch 142/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5229 - val_loss: 0.6920 - val_accuracy: 0.5090\n",
      "Epoch 143/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5231 - val_loss: 0.6922 - val_accuracy: 0.5097\n",
      "Epoch 144/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5214 - val_loss: 0.6917 - val_accuracy: 0.5179\n",
      "Epoch 145/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5203 - val_loss: 0.6918 - val_accuracy: 0.5141\n",
      "Epoch 146/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5230 - val_loss: 0.6918 - val_accuracy: 0.5217\n",
      "Epoch 147/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5227 - val_loss: 0.6918 - val_accuracy: 0.5139\n",
      "Epoch 148/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5212 - val_loss: 0.6918 - val_accuracy: 0.5154\n",
      "Epoch 149/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5213 - val_loss: 0.6917 - val_accuracy: 0.5176\n",
      "Epoch 150/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5222 - val_loss: 0.6918 - val_accuracy: 0.5165\n",
      "Epoch 151/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5220 - val_loss: 0.6918 - val_accuracy: 0.5111\n",
      "Epoch 152/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5222 - val_loss: 0.6918 - val_accuracy: 0.5169\n",
      "Epoch 153/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5160\n",
      "Epoch 154/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5239 - val_loss: 0.6918 - val_accuracy: 0.5219\n",
      "Epoch 155/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5220 - val_loss: 0.6917 - val_accuracy: 0.5201\n",
      "Epoch 156/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5214 - val_loss: 0.6918 - val_accuracy: 0.5185\n",
      "Epoch 157/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5241 - val_loss: 0.6918 - val_accuracy: 0.5172\n",
      "Epoch 158/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5199 - val_loss: 0.6919 - val_accuracy: 0.5140\n",
      "Epoch 159/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5216 - val_loss: 0.6919 - val_accuracy: 0.5161\n",
      "Epoch 160/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5201 - val_loss: 0.6917 - val_accuracy: 0.5210\n",
      "Epoch 161/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5220 - val_loss: 0.6919 - val_accuracy: 0.5152\n",
      "Epoch 162/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5248 - val_loss: 0.6920 - val_accuracy: 0.5156\n",
      "Epoch 163/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5254 - val_loss: 0.6921 - val_accuracy: 0.5146\n",
      "Epoch 164/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5217 - val_loss: 0.6919 - val_accuracy: 0.5120\n",
      "Epoch 165/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5224 - val_loss: 0.6919 - val_accuracy: 0.5108\n",
      "Epoch 166/1000\n",
      "41053/41053 [==============================] - 1s 14us/sample - loss: 0.6910 - accuracy: 0.5219 - val_loss: 0.6918 - val_accuracy: 0.5141\n",
      "Epoch 167/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5211 - val_loss: 0.6917 - val_accuracy: 0.5186\n",
      "Epoch 168/1000\n",
      "41053/41053 [==============================] - 1s 14us/sample - loss: 0.6909 - accuracy: 0.5227 - val_loss: 0.6918 - val_accuracy: 0.5180\n",
      "Epoch 169/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5218 - val_loss: 0.6917 - val_accuracy: 0.5179\n",
      "Epoch 170/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5233 - val_loss: 0.6919 - val_accuracy: 0.5144\n",
      "Epoch 171/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5225 - val_loss: 0.6918 - val_accuracy: 0.5183\n",
      "Epoch 172/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5246 - val_loss: 0.6919 - val_accuracy: 0.5169\n",
      "Epoch 173/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5196 - val_loss: 0.6918 - val_accuracy: 0.5175\n",
      "Epoch 174/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5205 - val_loss: 0.6919 - val_accuracy: 0.5180\n",
      "Epoch 175/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5115\n",
      "Epoch 176/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5237 - val_loss: 0.6918 - val_accuracy: 0.5137\n",
      "Epoch 177/1000\n",
      "41053/41053 [==============================] - 1s 12us/sample - loss: 0.6909 - accuracy: 0.5232 - val_loss: 0.6917 - val_accuracy: 0.5176\n",
      "Epoch 178/1000\n",
      "41053/41053 [==============================] - 1s 12us/sample - loss: 0.6909 - accuracy: 0.5245 - val_loss: 0.6918 - val_accuracy: 0.5168\n",
      "Epoch 179/1000\n",
      "41053/41053 [==============================] - 1s 12us/sample - loss: 0.6908 - accuracy: 0.5240 - val_loss: 0.6917 - val_accuracy: 0.5219\n",
      "Training with significance = 1.26, run 6\n",
      "Train on 41053 samples, validate on 10264 samples\n",
      "Epoch 1/1000\n",
      "41053/41053 [==============================] - 2s 42us/sample - loss: 0.6943 - accuracy: 0.5049 - val_loss: 0.6930 - val_accuracy: 0.5088\n",
      "Epoch 2/1000\n",
      "41053/41053 [==============================] - 1s 14us/sample - loss: 0.6925 - accuracy: 0.5154 - val_loss: 0.6927 - val_accuracy: 0.5095\n",
      "Epoch 3/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5157 - val_loss: 0.6928 - val_accuracy: 0.5077\n",
      "Epoch 4/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5175 - val_loss: 0.6927 - val_accuracy: 0.5087\n",
      "Epoch 5/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5168 - val_loss: 0.6928 - val_accuracy: 0.5094\n",
      "Epoch 6/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5154 - val_loss: 0.6927 - val_accuracy: 0.5154\n",
      "Epoch 7/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5167 - val_loss: 0.6927 - val_accuracy: 0.5164\n",
      "Epoch 8/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5156 - val_loss: 0.6928 - val_accuracy: 0.5124\n",
      "Epoch 9/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5171 - val_loss: 0.6928 - val_accuracy: 0.5133\n",
      "Epoch 10/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5176 - val_loss: 0.6927 - val_accuracy: 0.5150\n",
      "Epoch 11/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5176 - val_loss: 0.6929 - val_accuracy: 0.5110\n",
      "Epoch 12/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5173 - val_loss: 0.6929 - val_accuracy: 0.5107\n",
      "Epoch 13/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5176 - val_loss: 0.6927 - val_accuracy: 0.5169\n",
      "Epoch 14/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5186 - val_loss: 0.6927 - val_accuracy: 0.5142\n",
      "Epoch 15/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5183 - val_loss: 0.6927 - val_accuracy: 0.5151\n",
      "Epoch 16/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5185 - val_loss: 0.6929 - val_accuracy: 0.5137\n",
      "Epoch 17/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5164 - val_loss: 0.6929 - val_accuracy: 0.5133\n",
      "Epoch 18/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5194 - val_loss: 0.6928 - val_accuracy: 0.5140\n",
      "Epoch 19/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5191 - val_loss: 0.6928 - val_accuracy: 0.5146\n",
      "Epoch 20/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5192 - val_loss: 0.6928 - val_accuracy: 0.5143\n",
      "Epoch 21/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5193 - val_loss: 0.6928 - val_accuracy: 0.5147\n",
      "Epoch 22/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5174 - val_loss: 0.6927 - val_accuracy: 0.5159\n",
      "Epoch 23/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5173 - val_loss: 0.6928 - val_accuracy: 0.5154\n",
      "Epoch 24/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5195 - val_loss: 0.6928 - val_accuracy: 0.5134\n",
      "Epoch 25/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5188 - val_loss: 0.6928 - val_accuracy: 0.5146\n",
      "Epoch 26/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5205 - val_loss: 0.6929 - val_accuracy: 0.5117\n",
      "Epoch 27/1000\n",
      "41053/41053 [==============================] - 1s 14us/sample - loss: 0.6917 - accuracy: 0.5178 - val_loss: 0.6929 - val_accuracy: 0.5107\n",
      "Epoch 28/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5188 - val_loss: 0.6928 - val_accuracy: 0.5165\n",
      "Epoch 29/1000\n",
      "41053/41053 [==============================] - 1s 14us/sample - loss: 0.6916 - accuracy: 0.5192 - val_loss: 0.6929 - val_accuracy: 0.5157\n",
      "Epoch 30/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5187 - val_loss: 0.6928 - val_accuracy: 0.5137\n",
      "Epoch 31/1000\n",
      "41053/41053 [==============================] - 1s 14us/sample - loss: 0.6917 - accuracy: 0.5182 - val_loss: 0.6928 - val_accuracy: 0.5133\n",
      "Epoch 32/1000\n",
      "41053/41053 [==============================] - 1s 14us/sample - loss: 0.6916 - accuracy: 0.5202 - val_loss: 0.6928 - val_accuracy: 0.5131\n",
      "Epoch 33/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5180 - val_loss: 0.6929 - val_accuracy: 0.5142\n",
      "Epoch 34/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5187 - val_loss: 0.6929 - val_accuracy: 0.5152\n",
      "Epoch 35/1000\n",
      "41053/41053 [==============================] - 1s 12us/sample - loss: 0.6917 - accuracy: 0.5195 - val_loss: 0.6928 - val_accuracy: 0.5132\n",
      "Epoch 36/1000\n",
      "41053/41053 [==============================] - 1s 12us/sample - loss: 0.6917 - accuracy: 0.5197 - val_loss: 0.6929 - val_accuracy: 0.5129\n",
      "Epoch 37/1000\n",
      "41053/41053 [==============================] - 1s 12us/sample - loss: 0.6918 - accuracy: 0.5178 - val_loss: 0.6929 - val_accuracy: 0.5130\n",
      "Epoch 38/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5192 - val_loss: 0.6929 - val_accuracy: 0.5139\n",
      "Epoch 39/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5188 - val_loss: 0.6931 - val_accuracy: 0.5112\n",
      "Epoch 40/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5182 - val_loss: 0.6930 - val_accuracy: 0.5099\n",
      "Epoch 41/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5195 - val_loss: 0.6930 - val_accuracy: 0.5114\n",
      "Epoch 42/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5199 - val_loss: 0.6929 - val_accuracy: 0.5132\n",
      "Epoch 43/1000\n",
      "41053/41053 [==============================] - 1s 14us/sample - loss: 0.6915 - accuracy: 0.5191 - val_loss: 0.6928 - val_accuracy: 0.5135\n",
      "Epoch 44/1000\n",
      "41053/41053 [==============================] - 1s 14us/sample - loss: 0.6915 - accuracy: 0.5197 - val_loss: 0.6928 - val_accuracy: 0.5086\n",
      "Epoch 45/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5196 - val_loss: 0.6929 - val_accuracy: 0.5150\n",
      "Epoch 46/1000\n",
      "41053/41053 [==============================] - 1s 14us/sample - loss: 0.6916 - accuracy: 0.5172 - val_loss: 0.6929 - val_accuracy: 0.5145\n",
      "Epoch 47/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5207 - val_loss: 0.6928 - val_accuracy: 0.5140\n",
      "Epoch 48/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5201 - val_loss: 0.6929 - val_accuracy: 0.5134\n",
      "Epoch 49/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5203 - val_loss: 0.6931 - val_accuracy: 0.5100\n",
      "Epoch 50/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5204 - val_loss: 0.6928 - val_accuracy: 0.5120\n",
      "Epoch 51/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5201 - val_loss: 0.6929 - val_accuracy: 0.5122\n",
      "Epoch 52/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5199 - val_loss: 0.6929 - val_accuracy: 0.5138\n",
      "Training with significance = 1.26, run 7\n",
      "Train on 41053 samples, validate on 10264 samples\n",
      "Epoch 1/1000\n",
      "41053/41053 [==============================] - 1s 28us/sample - loss: 0.6940 - accuracy: 0.5024 - val_loss: 0.6933 - val_accuracy: 0.5074\n",
      "Epoch 2/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6926 - accuracy: 0.5117 - val_loss: 0.6926 - val_accuracy: 0.5120\n",
      "Epoch 3/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6925 - accuracy: 0.5127 - val_loss: 0.6924 - val_accuracy: 0.5147\n",
      "Epoch 4/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6925 - accuracy: 0.5137 - val_loss: 0.6924 - val_accuracy: 0.5171\n",
      "Epoch 5/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5145 - val_loss: 0.6926 - val_accuracy: 0.5176\n",
      "Epoch 6/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5150 - val_loss: 0.6925 - val_accuracy: 0.5142\n",
      "Epoch 7/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5140 - val_loss: 0.6926 - val_accuracy: 0.5039\n",
      "Epoch 8/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5162 - val_loss: 0.6925 - val_accuracy: 0.5133\n",
      "Epoch 9/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5163 - val_loss: 0.6929 - val_accuracy: 0.5158\n",
      "Epoch 10/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5149 - val_loss: 0.6928 - val_accuracy: 0.5111\n",
      "Epoch 11/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5175 - val_loss: 0.6930 - val_accuracy: 0.5152\n",
      "Epoch 12/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5150 - val_loss: 0.6929 - val_accuracy: 0.5135\n",
      "Epoch 13/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5161 - val_loss: 0.6927 - val_accuracy: 0.5136\n",
      "Epoch 14/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5152 - val_loss: 0.6928 - val_accuracy: 0.5164\n",
      "Epoch 15/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5169 - val_loss: 0.6928 - val_accuracy: 0.5163\n",
      "Epoch 16/1000\n",
      "41053/41053 [==============================] - 1s 14us/sample - loss: 0.6919 - accuracy: 0.5156 - val_loss: 0.6926 - val_accuracy: 0.5152\n",
      "Epoch 17/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5179 - val_loss: 0.6927 - val_accuracy: 0.5091\n",
      "Epoch 18/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5187 - val_loss: 0.6926 - val_accuracy: 0.5143\n",
      "Epoch 19/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5170 - val_loss: 0.6926 - val_accuracy: 0.5147\n",
      "Epoch 20/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5177 - val_loss: 0.6928 - val_accuracy: 0.5123\n",
      "Epoch 21/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5156 - val_loss: 0.6925 - val_accuracy: 0.5157\n",
      "Epoch 22/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5164 - val_loss: 0.6927 - val_accuracy: 0.5149\n",
      "Epoch 23/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5192 - val_loss: 0.6928 - val_accuracy: 0.5116\n",
      "Epoch 24/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5194 - val_loss: 0.6927 - val_accuracy: 0.5115\n",
      "Epoch 25/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5159 - val_loss: 0.6925 - val_accuracy: 0.5157\n",
      "Epoch 26/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5188 - val_loss: 0.6927 - val_accuracy: 0.5149\n",
      "Epoch 27/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5169 - val_loss: 0.6927 - val_accuracy: 0.5172\n",
      "Epoch 28/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5161 - val_loss: 0.6926 - val_accuracy: 0.5145\n",
      "Epoch 29/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5188 - val_loss: 0.6926 - val_accuracy: 0.5135\n",
      "Epoch 30/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5202 - val_loss: 0.6926 - val_accuracy: 0.5132\n",
      "Epoch 31/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5200 - val_loss: 0.6926 - val_accuracy: 0.5122\n",
      "Epoch 32/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5175 - val_loss: 0.6927 - val_accuracy: 0.5170\n",
      "Epoch 33/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5180 - val_loss: 0.6928 - val_accuracy: 0.5103\n",
      "Epoch 34/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5191 - val_loss: 0.6929 - val_accuracy: 0.5147\n",
      "Training with significance = 1.26, run 8\n",
      "Train on 41053 samples, validate on 10264 samples\n",
      "Epoch 1/1000\n",
      "41053/41053 [==============================] - 1s 28us/sample - loss: 0.6943 - accuracy: 0.5018 - val_loss: 0.6939 - val_accuracy: 0.5041\n",
      "Epoch 2/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6928 - accuracy: 0.5101 - val_loss: 0.6930 - val_accuracy: 0.5224\n",
      "Epoch 3/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6926 - accuracy: 0.5119 - val_loss: 0.6926 - val_accuracy: 0.5203\n",
      "Epoch 4/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5122 - val_loss: 0.6925 - val_accuracy: 0.5204\n",
      "Epoch 5/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5132 - val_loss: 0.6925 - val_accuracy: 0.5177\n",
      "Epoch 6/1000\n",
      "41053/41053 [==============================] - 1s 14us/sample - loss: 0.6924 - accuracy: 0.5130 - val_loss: 0.6925 - val_accuracy: 0.5200\n",
      "Epoch 7/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5142 - val_loss: 0.6924 - val_accuracy: 0.5168\n",
      "Epoch 8/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5157 - val_loss: 0.6923 - val_accuracy: 0.5195\n",
      "Epoch 9/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5142 - val_loss: 0.6923 - val_accuracy: 0.5211\n",
      "Epoch 10/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5151 - val_loss: 0.6923 - val_accuracy: 0.5210\n",
      "Epoch 11/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5155 - val_loss: 0.6923 - val_accuracy: 0.5212\n",
      "Epoch 12/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5155 - val_loss: 0.6924 - val_accuracy: 0.5202\n",
      "Epoch 13/1000\n",
      "41053/41053 [==============================] - 1s 12us/sample - loss: 0.6921 - accuracy: 0.5164 - val_loss: 0.6923 - val_accuracy: 0.5201\n",
      "Epoch 14/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5155 - val_loss: 0.6922 - val_accuracy: 0.5216\n",
      "Epoch 15/1000\n",
      "41053/41053 [==============================] - 0s 12us/sample - loss: 0.6922 - accuracy: 0.5152 - val_loss: 0.6922 - val_accuracy: 0.5217\n",
      "Epoch 16/1000\n",
      "41053/41053 [==============================] - 0s 12us/sample - loss: 0.6921 - accuracy: 0.5151 - val_loss: 0.6924 - val_accuracy: 0.5207\n",
      "Epoch 17/1000\n",
      "41053/41053 [==============================] - 0s 12us/sample - loss: 0.6921 - accuracy: 0.5185 - val_loss: 0.6923 - val_accuracy: 0.5212\n",
      "Epoch 18/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5155 - val_loss: 0.6922 - val_accuracy: 0.5214\n",
      "Epoch 19/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5187 - val_loss: 0.6922 - val_accuracy: 0.5224\n",
      "Epoch 20/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5175 - val_loss: 0.6922 - val_accuracy: 0.5201\n",
      "Epoch 21/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5169 - val_loss: 0.6922 - val_accuracy: 0.5199\n",
      "Epoch 22/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5182 - val_loss: 0.6922 - val_accuracy: 0.5186\n",
      "Epoch 23/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5188 - val_loss: 0.6921 - val_accuracy: 0.5201\n",
      "Epoch 24/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5179 - val_loss: 0.6921 - val_accuracy: 0.5224\n",
      "Epoch 25/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5176 - val_loss: 0.6922 - val_accuracy: 0.5207\n",
      "Epoch 26/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5190 - val_loss: 0.6922 - val_accuracy: 0.5219\n",
      "Epoch 27/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5170 - val_loss: 0.6923 - val_accuracy: 0.5189\n",
      "Epoch 28/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5178 - val_loss: 0.6923 - val_accuracy: 0.5195\n",
      "Epoch 29/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5186 - val_loss: 0.6922 - val_accuracy: 0.5206\n",
      "Epoch 30/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5173 - val_loss: 0.6923 - val_accuracy: 0.5185\n",
      "Epoch 31/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5180 - val_loss: 0.6922 - val_accuracy: 0.5190\n",
      "Epoch 32/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5216 - val_loss: 0.6922 - val_accuracy: 0.5214\n",
      "Epoch 33/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5187 - val_loss: 0.6922 - val_accuracy: 0.5197\n",
      "Epoch 34/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5189 - val_loss: 0.6922 - val_accuracy: 0.5222\n",
      "Epoch 35/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5195 - val_loss: 0.6922 - val_accuracy: 0.5179\n",
      "Epoch 36/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5189 - val_loss: 0.6922 - val_accuracy: 0.5181\n",
      "Epoch 37/1000\n",
      "41053/41053 [==============================] - 1s 14us/sample - loss: 0.6918 - accuracy: 0.5183 - val_loss: 0.6923 - val_accuracy: 0.5188\n",
      "Epoch 38/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5173 - val_loss: 0.6922 - val_accuracy: 0.5175\n",
      "Epoch 39/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5193 - val_loss: 0.6922 - val_accuracy: 0.5228\n",
      "Epoch 40/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5201 - val_loss: 0.6922 - val_accuracy: 0.5185\n",
      "Epoch 41/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5199 - val_loss: 0.6923 - val_accuracy: 0.5189\n",
      "Epoch 42/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5179 - val_loss: 0.6922 - val_accuracy: 0.5208\n",
      "Epoch 43/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5197 - val_loss: 0.6921 - val_accuracy: 0.5192\n",
      "Epoch 44/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5215 - val_loss: 0.6922 - val_accuracy: 0.5205\n",
      "Epoch 45/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5209 - val_loss: 0.6922 - val_accuracy: 0.5195\n",
      "Epoch 46/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5191 - val_loss: 0.6922 - val_accuracy: 0.5184\n",
      "Epoch 47/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5223 - val_loss: 0.6921 - val_accuracy: 0.5177\n",
      "Epoch 48/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5199 - val_loss: 0.6922 - val_accuracy: 0.5186\n",
      "Epoch 49/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5205 - val_loss: 0.6924 - val_accuracy: 0.5173\n",
      "Epoch 50/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5224 - val_loss: 0.6922 - val_accuracy: 0.5181\n",
      "Epoch 51/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5212 - val_loss: 0.6924 - val_accuracy: 0.5192\n",
      "Epoch 52/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5215 - val_loss: 0.6923 - val_accuracy: 0.5183\n",
      "Epoch 53/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5230 - val_loss: 0.6923 - val_accuracy: 0.5176\n",
      "Epoch 54/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5214 - val_loss: 0.6924 - val_accuracy: 0.5202\n",
      "Training with significance = 1.26, run 9\n",
      "Train on 41053 samples, validate on 10264 samples\n",
      "Epoch 1/1000\n",
      "41053/41053 [==============================] - 1s 28us/sample - loss: 0.6934 - accuracy: 0.5027 - val_loss: 0.6930 - val_accuracy: 0.5013\n",
      "Epoch 2/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6928 - accuracy: 0.5100 - val_loss: 0.6927 - val_accuracy: 0.5140\n",
      "Epoch 3/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6926 - accuracy: 0.5131 - val_loss: 0.6925 - val_accuracy: 0.5163\n",
      "Epoch 4/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6926 - accuracy: 0.5126 - val_loss: 0.6925 - val_accuracy: 0.5168\n",
      "Epoch 5/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6925 - accuracy: 0.5136 - val_loss: 0.6924 - val_accuracy: 0.5165\n",
      "Epoch 6/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5138 - val_loss: 0.6925 - val_accuracy: 0.5178\n",
      "Epoch 7/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5132 - val_loss: 0.6925 - val_accuracy: 0.5171\n",
      "Epoch 8/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5150 - val_loss: 0.6924 - val_accuracy: 0.5177\n",
      "Epoch 9/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5142 - val_loss: 0.6925 - val_accuracy: 0.5170\n",
      "Epoch 10/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5145 - val_loss: 0.6924 - val_accuracy: 0.5184\n",
      "Epoch 11/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5152 - val_loss: 0.6924 - val_accuracy: 0.5194\n",
      "Epoch 12/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5150 - val_loss: 0.6924 - val_accuracy: 0.5189\n",
      "Epoch 13/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5151 - val_loss: 0.6924 - val_accuracy: 0.5187\n",
      "Epoch 14/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5165 - val_loss: 0.6926 - val_accuracy: 0.5175\n",
      "Epoch 15/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5142 - val_loss: 0.6924 - val_accuracy: 0.5178\n",
      "Epoch 16/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5150 - val_loss: 0.6926 - val_accuracy: 0.5163\n",
      "Epoch 17/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5159 - val_loss: 0.6924 - val_accuracy: 0.5178\n",
      "Epoch 18/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5153 - val_loss: 0.6924 - val_accuracy: 0.5186\n",
      "Epoch 19/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5170 - val_loss: 0.6923 - val_accuracy: 0.5202\n",
      "Epoch 20/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5171 - val_loss: 0.6925 - val_accuracy: 0.5177\n",
      "Epoch 21/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5154 - val_loss: 0.6924 - val_accuracy: 0.5187\n",
      "Epoch 22/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5168 - val_loss: 0.6923 - val_accuracy: 0.5203\n",
      "Epoch 23/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5165 - val_loss: 0.6923 - val_accuracy: 0.5190\n",
      "Epoch 24/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5162 - val_loss: 0.6923 - val_accuracy: 0.5141\n",
      "Epoch 25/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5168 - val_loss: 0.6925 - val_accuracy: 0.5168\n",
      "Epoch 26/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5166 - val_loss: 0.6923 - val_accuracy: 0.5170\n",
      "Epoch 27/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5174 - val_loss: 0.6925 - val_accuracy: 0.5152\n",
      "Epoch 28/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5166 - val_loss: 0.6923 - val_accuracy: 0.5183\n",
      "Epoch 29/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5160 - val_loss: 0.6923 - val_accuracy: 0.5200\n",
      "Epoch 30/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5189 - val_loss: 0.6923 - val_accuracy: 0.5194\n",
      "Epoch 31/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5172 - val_loss: 0.6924 - val_accuracy: 0.5162\n",
      "Epoch 32/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5184 - val_loss: 0.6925 - val_accuracy: 0.5148\n",
      "Epoch 33/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5174 - val_loss: 0.6924 - val_accuracy: 0.5164\n",
      "Epoch 34/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5168 - val_loss: 0.6923 - val_accuracy: 0.5215\n",
      "Epoch 35/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5169 - val_loss: 0.6923 - val_accuracy: 0.5172\n",
      "Epoch 36/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5182 - val_loss: 0.6923 - val_accuracy: 0.5193\n",
      "Epoch 37/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5194 - val_loss: 0.6925 - val_accuracy: 0.5147\n",
      "Epoch 38/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5185 - val_loss: 0.6923 - val_accuracy: 0.5198\n",
      "Epoch 39/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5188 - val_loss: 0.6924 - val_accuracy: 0.5164\n",
      "Epoch 40/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5174 - val_loss: 0.6923 - val_accuracy: 0.5178\n",
      "Epoch 41/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5179 - val_loss: 0.6923 - val_accuracy: 0.5183\n",
      "Epoch 42/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5207 - val_loss: 0.6923 - val_accuracy: 0.5188\n",
      "Epoch 43/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5188 - val_loss: 0.6923 - val_accuracy: 0.5164\n",
      "Epoch 44/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5185 - val_loss: 0.6924 - val_accuracy: 0.5173\n",
      "Epoch 45/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5190 - val_loss: 0.6924 - val_accuracy: 0.5177\n",
      "Epoch 46/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5207 - val_loss: 0.6924 - val_accuracy: 0.5184\n",
      "Epoch 47/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5199 - val_loss: 0.6924 - val_accuracy: 0.5194\n",
      "Epoch 48/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5187 - val_loss: 0.6924 - val_accuracy: 0.5191\n",
      "Epoch 49/1000\n",
      "41053/41053 [==============================] - 1s 12us/sample - loss: 0.6916 - accuracy: 0.5190 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 50/1000\n",
      "41053/41053 [==============================] - 1s 12us/sample - loss: 0.6918 - accuracy: 0.5191 - val_loss: 0.6923 - val_accuracy: 0.5166\n",
      "Epoch 51/1000\n",
      "41053/41053 [==============================] - 1s 12us/sample - loss: 0.6917 - accuracy: 0.5189 - val_loss: 0.6924 - val_accuracy: 0.5179\n",
      "Epoch 52/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5199 - val_loss: 0.6924 - val_accuracy: 0.5178\n",
      "Epoch 53/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5197 - val_loss: 0.6925 - val_accuracy: 0.5153\n",
      "Epoch 54/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5170 - val_loss: 0.6923 - val_accuracy: 0.5176\n",
      "Epoch 55/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5189 - val_loss: 0.6923 - val_accuracy: 0.5169\n",
      "Epoch 56/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5191 - val_loss: 0.6923 - val_accuracy: 0.5174\n",
      "Epoch 57/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5195 - val_loss: 0.6925 - val_accuracy: 0.5174\n",
      "Epoch 58/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5180 - val_loss: 0.6926 - val_accuracy: 0.5183\n",
      "Epoch 59/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5200 - val_loss: 0.6926 - val_accuracy: 0.5157\n",
      "Epoch 60/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5201 - val_loss: 0.6925 - val_accuracy: 0.5150\n",
      "Epoch 61/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5193 - val_loss: 0.6925 - val_accuracy: 0.5154\n",
      "Epoch 62/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5206 - val_loss: 0.6924 - val_accuracy: 0.5126\n",
      "Epoch 63/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5205 - val_loss: 0.6923 - val_accuracy: 0.5158\n",
      "Epoch 64/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5186 - val_loss: 0.6924 - val_accuracy: 0.5148\n",
      "Epoch 65/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5195 - val_loss: 0.6925 - val_accuracy: 0.5166\n",
      "Epoch 66/1000\n",
      "41053/41053 [==============================] - 1s 14us/sample - loss: 0.6916 - accuracy: 0.5195 - val_loss: 0.6924 - val_accuracy: 0.5153\n",
      "Epoch 67/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5188 - val_loss: 0.6924 - val_accuracy: 0.5170\n",
      "Epoch 68/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5201 - val_loss: 0.6924 - val_accuracy: 0.5147\n",
      "Epoch 69/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5202 - val_loss: 0.6924 - val_accuracy: 0.5159\n",
      "Epoch 70/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5196 - val_loss: 0.6924 - val_accuracy: 0.5137\n",
      "Epoch 71/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5221 - val_loss: 0.6926 - val_accuracy: 0.5150\n",
      "Epoch 72/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5189 - val_loss: 0.6925 - val_accuracy: 0.5170\n",
      "Epoch 73/1000\n",
      "41053/41053 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5229 - val_loss: 0.6925 - val_accuracy: 0.5174\n",
      "Training with significance = 1.58, run 0\n",
      "Train on 41104 samples, validate on 10276 samples\n",
      "Epoch 1/1000\n",
      "41104/41104 [==============================] - 1s 28us/sample - loss: 0.6941 - accuracy: 0.5062 - val_loss: 0.6946 - val_accuracy: 0.4981\n",
      "Epoch 2/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6929 - accuracy: 0.5106 - val_loss: 0.6929 - val_accuracy: 0.5139\n",
      "Epoch 3/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6927 - accuracy: 0.5120 - val_loss: 0.6930 - val_accuracy: 0.5150\n",
      "Epoch 4/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6926 - accuracy: 0.5136 - val_loss: 0.6928 - val_accuracy: 0.5151\n",
      "Epoch 5/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6926 - accuracy: 0.5131 - val_loss: 0.6928 - val_accuracy: 0.5131\n",
      "Epoch 6/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5127 - val_loss: 0.6928 - val_accuracy: 0.5163\n",
      "Epoch 7/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5147 - val_loss: 0.6927 - val_accuracy: 0.5131\n",
      "Epoch 8/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5147 - val_loss: 0.6927 - val_accuracy: 0.5085\n",
      "Epoch 9/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5165 - val_loss: 0.6928 - val_accuracy: 0.5117\n",
      "Epoch 10/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5157 - val_loss: 0.6927 - val_accuracy: 0.5095\n",
      "Epoch 11/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5153 - val_loss: 0.6927 - val_accuracy: 0.5148\n",
      "Epoch 12/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5177 - val_loss: 0.6927 - val_accuracy: 0.5142\n",
      "Epoch 13/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5160 - val_loss: 0.6927 - val_accuracy: 0.5134\n",
      "Epoch 14/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5171 - val_loss: 0.6927 - val_accuracy: 0.5124\n",
      "Epoch 15/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5192 - val_loss: 0.6927 - val_accuracy: 0.5110\n",
      "Epoch 16/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5167 - val_loss: 0.6927 - val_accuracy: 0.5133\n",
      "Epoch 17/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5164 - val_loss: 0.6928 - val_accuracy: 0.5131\n",
      "Epoch 18/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5179 - val_loss: 0.6928 - val_accuracy: 0.5112\n",
      "Epoch 19/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5188 - val_loss: 0.6928 - val_accuracy: 0.5127\n",
      "Epoch 20/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5175 - val_loss: 0.6928 - val_accuracy: 0.5083\n",
      "Epoch 21/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5171 - val_loss: 0.6927 - val_accuracy: 0.5144\n",
      "Epoch 22/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5187 - val_loss: 0.6928 - val_accuracy: 0.5130\n",
      "Epoch 23/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5173 - val_loss: 0.6928 - val_accuracy: 0.5100\n",
      "Epoch 24/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5169 - val_loss: 0.6927 - val_accuracy: 0.5114\n",
      "Epoch 25/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5175 - val_loss: 0.6928 - val_accuracy: 0.5103\n",
      "Epoch 26/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5194 - val_loss: 0.6927 - val_accuracy: 0.5129\n",
      "Epoch 27/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5175 - val_loss: 0.6928 - val_accuracy: 0.5107\n",
      "Epoch 28/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5179 - val_loss: 0.6927 - val_accuracy: 0.5087\n",
      "Epoch 29/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5183 - val_loss: 0.6927 - val_accuracy: 0.5090\n",
      "Epoch 30/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5181 - val_loss: 0.6928 - val_accuracy: 0.5072\n",
      "Epoch 31/1000\n",
      "41104/41104 [==============================] - 1s 12us/sample - loss: 0.6917 - accuracy: 0.5196 - val_loss: 0.6929 - val_accuracy: 0.5108\n",
      "Epoch 32/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5183 - val_loss: 0.6929 - val_accuracy: 0.5086\n",
      "Epoch 33/1000\n",
      "41104/41104 [==============================] - 0s 12us/sample - loss: 0.6918 - accuracy: 0.5180 - val_loss: 0.6928 - val_accuracy: 0.5094\n",
      "Epoch 34/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5181 - val_loss: 0.6929 - val_accuracy: 0.5091\n",
      "Epoch 35/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5199 - val_loss: 0.6929 - val_accuracy: 0.5131\n",
      "Epoch 36/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5191 - val_loss: 0.6928 - val_accuracy: 0.5114\n",
      "Epoch 37/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5185 - val_loss: 0.6928 - val_accuracy: 0.5100\n",
      "Epoch 38/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5173 - val_loss: 0.6928 - val_accuracy: 0.5092\n",
      "Epoch 39/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5200 - val_loss: 0.6927 - val_accuracy: 0.5095\n",
      "Epoch 40/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5197 - val_loss: 0.6930 - val_accuracy: 0.5073\n",
      "Epoch 41/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5207 - val_loss: 0.6928 - val_accuracy: 0.5123\n",
      "Epoch 42/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5184 - val_loss: 0.6928 - val_accuracy: 0.5098\n",
      "Epoch 43/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5180 - val_loss: 0.6928 - val_accuracy: 0.5102\n",
      "Epoch 44/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5170 - val_loss: 0.6928 - val_accuracy: 0.5125\n",
      "Epoch 45/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5194 - val_loss: 0.6928 - val_accuracy: 0.5065\n",
      "Epoch 46/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5208 - val_loss: 0.6928 - val_accuracy: 0.5081\n",
      "Training with significance = 1.58, run 1\n",
      "Train on 41104 samples, validate on 10276 samples\n",
      "Epoch 1/1000\n",
      "41104/41104 [==============================] - 1s 27us/sample - loss: 0.6939 - accuracy: 0.5060 - val_loss: 0.6926 - val_accuracy: 0.5094\n",
      "Epoch 2/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6926 - accuracy: 0.5131 - val_loss: 0.6923 - val_accuracy: 0.5146\n",
      "Epoch 3/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5170 - val_loss: 0.6921 - val_accuracy: 0.5161\n",
      "Epoch 4/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5164 - val_loss: 0.6920 - val_accuracy: 0.5182\n",
      "Epoch 5/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5178 - val_loss: 0.6919 - val_accuracy: 0.5133\n",
      "Epoch 6/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5189 - val_loss: 0.6920 - val_accuracy: 0.5153\n",
      "Epoch 7/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5196 - val_loss: 0.6920 - val_accuracy: 0.5132\n",
      "Epoch 8/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5172 - val_loss: 0.6919 - val_accuracy: 0.5160\n",
      "Epoch 9/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5176 - val_loss: 0.6921 - val_accuracy: 0.5137\n",
      "Epoch 10/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5186 - val_loss: 0.6919 - val_accuracy: 0.5154\n",
      "Epoch 11/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5199 - val_loss: 0.6920 - val_accuracy: 0.5148\n",
      "Epoch 12/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5224 - val_loss: 0.6920 - val_accuracy: 0.5153\n",
      "Epoch 13/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5205 - val_loss: 0.6920 - val_accuracy: 0.5168\n",
      "Epoch 14/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5185 - val_loss: 0.6920 - val_accuracy: 0.5137\n",
      "Epoch 15/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5210 - val_loss: 0.6921 - val_accuracy: 0.5144\n",
      "Epoch 16/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5189 - val_loss: 0.6920 - val_accuracy: 0.5162\n",
      "Epoch 17/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5191 - val_loss: 0.6919 - val_accuracy: 0.5121\n",
      "Epoch 18/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5200 - val_loss: 0.6919 - val_accuracy: 0.5114\n",
      "Epoch 19/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5201 - val_loss: 0.6920 - val_accuracy: 0.5139\n",
      "Epoch 20/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5229 - val_loss: 0.6920 - val_accuracy: 0.5154\n",
      "Epoch 21/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5191 - val_loss: 0.6919 - val_accuracy: 0.5150\n",
      "Epoch 22/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5240 - val_loss: 0.6921 - val_accuracy: 0.5153\n",
      "Epoch 23/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5223 - val_loss: 0.6920 - val_accuracy: 0.5165\n",
      "Epoch 24/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5214 - val_loss: 0.6921 - val_accuracy: 0.5124\n",
      "Epoch 25/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5226 - val_loss: 0.6919 - val_accuracy: 0.5176\n",
      "Epoch 26/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5209 - val_loss: 0.6920 - val_accuracy: 0.5157\n",
      "Epoch 27/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5215 - val_loss: 0.6920 - val_accuracy: 0.5136\n",
      "Epoch 28/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5222 - val_loss: 0.6919 - val_accuracy: 0.5149\n",
      "Epoch 29/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5223 - val_loss: 0.6919 - val_accuracy: 0.5112\n",
      "Epoch 30/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5216 - val_loss: 0.6920 - val_accuracy: 0.5144\n",
      "Epoch 31/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5236 - val_loss: 0.6919 - val_accuracy: 0.5170\n",
      "Epoch 32/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5218 - val_loss: 0.6922 - val_accuracy: 0.5110\n",
      "Epoch 33/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5224 - val_loss: 0.6920 - val_accuracy: 0.5157\n",
      "Epoch 34/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5248 - val_loss: 0.6920 - val_accuracy: 0.5143\n",
      "Epoch 35/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5223 - val_loss: 0.6920 - val_accuracy: 0.5116\n",
      "Epoch 36/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5217 - val_loss: 0.6921 - val_accuracy: 0.5143\n",
      "Epoch 37/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5214 - val_loss: 0.6921 - val_accuracy: 0.5112\n",
      "Epoch 38/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5233 - val_loss: 0.6919 - val_accuracy: 0.5157\n",
      "Training with significance = 1.58, run 2\n",
      "Train on 41104 samples, validate on 10276 samples\n",
      "Epoch 1/1000\n",
      "41104/41104 [==============================] - 1s 27us/sample - loss: 0.6938 - accuracy: 0.5004 - val_loss: 0.6930 - val_accuracy: 0.5038\n",
      "Epoch 2/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6930 - accuracy: 0.5091 - val_loss: 0.6927 - val_accuracy: 0.5093\n",
      "Epoch 3/1000\n",
      "41104/41104 [==============================] - 1s 12us/sample - loss: 0.6928 - accuracy: 0.5102 - val_loss: 0.6923 - val_accuracy: 0.5147\n",
      "Epoch 4/1000\n",
      "41104/41104 [==============================] - 1s 12us/sample - loss: 0.6927 - accuracy: 0.5121 - val_loss: 0.6922 - val_accuracy: 0.5182\n",
      "Epoch 5/1000\n",
      "41104/41104 [==============================] - 0s 12us/sample - loss: 0.6926 - accuracy: 0.5149 - val_loss: 0.6921 - val_accuracy: 0.5226\n",
      "Epoch 6/1000\n",
      "41104/41104 [==============================] - 1s 12us/sample - loss: 0.6925 - accuracy: 0.5148 - val_loss: 0.6921 - val_accuracy: 0.5203\n",
      "Epoch 7/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6925 - accuracy: 0.5132 - val_loss: 0.6920 - val_accuracy: 0.5214\n",
      "Epoch 8/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6925 - accuracy: 0.5137 - val_loss: 0.6921 - val_accuracy: 0.5242\n",
      "Epoch 9/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5133 - val_loss: 0.6919 - val_accuracy: 0.5188\n",
      "Epoch 10/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5154 - val_loss: 0.6919 - val_accuracy: 0.5197\n",
      "Epoch 11/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5151 - val_loss: 0.6919 - val_accuracy: 0.5206\n",
      "Epoch 12/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5163 - val_loss: 0.6920 - val_accuracy: 0.5208\n",
      "Epoch 13/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5156 - val_loss: 0.6920 - val_accuracy: 0.5179\n",
      "Epoch 14/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5158 - val_loss: 0.6920 - val_accuracy: 0.5222\n",
      "Epoch 15/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5172 - val_loss: 0.6919 - val_accuracy: 0.5199\n",
      "Epoch 16/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5180 - val_loss: 0.6919 - val_accuracy: 0.5193\n",
      "Epoch 17/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5168 - val_loss: 0.6919 - val_accuracy: 0.5213\n",
      "Epoch 18/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5163 - val_loss: 0.6918 - val_accuracy: 0.5196\n",
      "Epoch 19/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5171 - val_loss: 0.6919 - val_accuracy: 0.5202\n",
      "Epoch 20/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5183 - val_loss: 0.6918 - val_accuracy: 0.5212\n",
      "Epoch 21/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5162 - val_loss: 0.6919 - val_accuracy: 0.5189\n",
      "Epoch 22/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5170 - val_loss: 0.6919 - val_accuracy: 0.5183\n",
      "Epoch 23/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5169 - val_loss: 0.6918 - val_accuracy: 0.5212\n",
      "Epoch 24/1000\n",
      "41104/41104 [==============================] - 1s 12us/sample - loss: 0.6921 - accuracy: 0.5164 - val_loss: 0.6919 - val_accuracy: 0.5189\n",
      "Epoch 25/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5182 - val_loss: 0.6919 - val_accuracy: 0.5218\n",
      "Epoch 26/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5158 - val_loss: 0.6918 - val_accuracy: 0.5176\n",
      "Epoch 27/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5176 - val_loss: 0.6918 - val_accuracy: 0.5189\n",
      "Epoch 28/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5198 - val_loss: 0.6918 - val_accuracy: 0.5188\n",
      "Epoch 29/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5200 - val_loss: 0.6918 - val_accuracy: 0.5192\n",
      "Epoch 30/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5193 - val_loss: 0.6919 - val_accuracy: 0.5196\n",
      "Epoch 31/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5176 - val_loss: 0.6918 - val_accuracy: 0.5204\n",
      "Epoch 32/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5209 - val_loss: 0.6918 - val_accuracy: 0.5212\n",
      "Epoch 33/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5184 - val_loss: 0.6919 - val_accuracy: 0.5173\n",
      "Epoch 34/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5202 - val_loss: 0.6918 - val_accuracy: 0.5195\n",
      "Epoch 35/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5181 - val_loss: 0.6917 - val_accuracy: 0.5199\n",
      "Epoch 36/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5188 - val_loss: 0.6918 - val_accuracy: 0.5186\n",
      "Epoch 37/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5183 - val_loss: 0.6918 - val_accuracy: 0.5178\n",
      "Epoch 38/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5182 - val_loss: 0.6918 - val_accuracy: 0.5174\n",
      "Epoch 39/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5193 - val_loss: 0.6918 - val_accuracy: 0.5197\n",
      "Epoch 40/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5198 - val_loss: 0.6918 - val_accuracy: 0.5199\n",
      "Epoch 41/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5190 - val_loss: 0.6919 - val_accuracy: 0.5188\n",
      "Epoch 42/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5219 - val_loss: 0.6922 - val_accuracy: 0.5162\n",
      "Epoch 43/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5202 - val_loss: 0.6918 - val_accuracy: 0.5208\n",
      "Epoch 44/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5181 - val_loss: 0.6919 - val_accuracy: 0.5194\n",
      "Epoch 45/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5186 - val_loss: 0.6918 - val_accuracy: 0.5186\n",
      "Epoch 46/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5189 - val_loss: 0.6917 - val_accuracy: 0.5209\n",
      "Epoch 47/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5196 - val_loss: 0.6919 - val_accuracy: 0.5194\n",
      "Epoch 48/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5197 - val_loss: 0.6919 - val_accuracy: 0.5225\n",
      "Epoch 49/1000\n",
      "41104/41104 [==============================] - 1s 12us/sample - loss: 0.6918 - accuracy: 0.5208 - val_loss: 0.6919 - val_accuracy: 0.5207\n",
      "Epoch 50/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5178 - val_loss: 0.6918 - val_accuracy: 0.5211\n",
      "Epoch 51/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5189 - val_loss: 0.6919 - val_accuracy: 0.5192\n",
      "Epoch 52/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5190 - val_loss: 0.6919 - val_accuracy: 0.5189\n",
      "Epoch 53/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5210 - val_loss: 0.6918 - val_accuracy: 0.5185\n",
      "Epoch 54/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5190 - val_loss: 0.6919 - val_accuracy: 0.5207\n",
      "Epoch 55/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5206 - val_loss: 0.6918 - val_accuracy: 0.5183\n",
      "Epoch 56/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5208 - val_loss: 0.6919 - val_accuracy: 0.5195\n",
      "Epoch 57/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5212 - val_loss: 0.6920 - val_accuracy: 0.5188\n",
      "Epoch 58/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5215 - val_loss: 0.6919 - val_accuracy: 0.5188\n",
      "Epoch 59/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5212 - val_loss: 0.6920 - val_accuracy: 0.5191\n",
      "Epoch 60/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5199 - val_loss: 0.6919 - val_accuracy: 0.5198\n",
      "Epoch 61/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5208 - val_loss: 0.6919 - val_accuracy: 0.5225\n",
      "Epoch 62/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5206 - val_loss: 0.6918 - val_accuracy: 0.5187\n",
      "Epoch 63/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5202 - val_loss: 0.6918 - val_accuracy: 0.5179\n",
      "Epoch 64/1000\n",
      "41104/41104 [==============================] - 1s 12us/sample - loss: 0.6917 - accuracy: 0.5189 - val_loss: 0.6919 - val_accuracy: 0.5206\n",
      "Epoch 65/1000\n",
      "41104/41104 [==============================] - 1s 12us/sample - loss: 0.6917 - accuracy: 0.5200 - val_loss: 0.6920 - val_accuracy: 0.5176\n",
      "Epoch 66/1000\n",
      "41104/41104 [==============================] - 0s 12us/sample - loss: 0.6917 - accuracy: 0.5215 - val_loss: 0.6918 - val_accuracy: 0.5196\n",
      "Epoch 67/1000\n",
      "41104/41104 [==============================] - 1s 12us/sample - loss: 0.6917 - accuracy: 0.5209 - val_loss: 0.6919 - val_accuracy: 0.5191\n",
      "Epoch 68/1000\n",
      "41104/41104 [==============================] - 1s 12us/sample - loss: 0.6918 - accuracy: 0.5211 - val_loss: 0.6920 - val_accuracy: 0.5157\n",
      "Epoch 69/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5208 - val_loss: 0.6919 - val_accuracy: 0.5180\n",
      "Epoch 70/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5203 - val_loss: 0.6919 - val_accuracy: 0.5163\n",
      "Epoch 71/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5191 - val_loss: 0.6919 - val_accuracy: 0.5185\n",
      "Epoch 72/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5194 - val_loss: 0.6919 - val_accuracy: 0.5205\n",
      "Epoch 73/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5201 - val_loss: 0.6919 - val_accuracy: 0.5172\n",
      "Epoch 74/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5209 - val_loss: 0.6919 - val_accuracy: 0.5184\n",
      "Epoch 75/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5197 - val_loss: 0.6919 - val_accuracy: 0.5188\n",
      "Epoch 76/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5198 - val_loss: 0.6919 - val_accuracy: 0.5182\n",
      "Training with significance = 1.58, run 3\n",
      "Train on 41104 samples, validate on 10276 samples\n",
      "Epoch 1/1000\n",
      "41104/41104 [==============================] - 2s 43us/sample - loss: 0.6936 - accuracy: 0.5013 - val_loss: 0.6950 - val_accuracy: 0.5006\n",
      "Epoch 2/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6928 - accuracy: 0.5109 - val_loss: 0.6931 - val_accuracy: 0.5079\n",
      "Epoch 3/1000\n",
      "41104/41104 [==============================] - 1s 14us/sample - loss: 0.6926 - accuracy: 0.5130 - val_loss: 0.6927 - val_accuracy: 0.5175\n",
      "Epoch 4/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6926 - accuracy: 0.5129 - val_loss: 0.6924 - val_accuracy: 0.5177\n",
      "Epoch 5/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5144 - val_loss: 0.6921 - val_accuracy: 0.5218\n",
      "Epoch 6/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5143 - val_loss: 0.6918 - val_accuracy: 0.5245\n",
      "Epoch 7/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5114 - val_loss: 0.6918 - val_accuracy: 0.5233\n",
      "Epoch 8/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5149 - val_loss: 0.6919 - val_accuracy: 0.5183\n",
      "Epoch 9/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5131 - val_loss: 0.6921 - val_accuracy: 0.5248\n",
      "Epoch 10/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5153 - val_loss: 0.6920 - val_accuracy: 0.5215\n",
      "Epoch 11/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5133 - val_loss: 0.6920 - val_accuracy: 0.5216\n",
      "Epoch 12/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5154 - val_loss: 0.6920 - val_accuracy: 0.5260\n",
      "Epoch 13/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5149 - val_loss: 0.6924 - val_accuracy: 0.5221\n",
      "Epoch 14/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5148 - val_loss: 0.6918 - val_accuracy: 0.5206\n",
      "Epoch 15/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5177 - val_loss: 0.6919 - val_accuracy: 0.5241\n",
      "Epoch 16/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5170 - val_loss: 0.6918 - val_accuracy: 0.5233\n",
      "Epoch 17/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5144 - val_loss: 0.6922 - val_accuracy: 0.5201\n",
      "Epoch 18/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5182 - val_loss: 0.6920 - val_accuracy: 0.5219\n",
      "Epoch 19/1000\n",
      "41104/41104 [==============================] - 1s 14us/sample - loss: 0.6919 - accuracy: 0.5167 - val_loss: 0.6917 - val_accuracy: 0.5230\n",
      "Epoch 20/1000\n",
      "41104/41104 [==============================] - 1s 14us/sample - loss: 0.6919 - accuracy: 0.5166 - val_loss: 0.6919 - val_accuracy: 0.5217\n",
      "Epoch 21/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5171 - val_loss: 0.6919 - val_accuracy: 0.5203\n",
      "Epoch 22/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5181 - val_loss: 0.6919 - val_accuracy: 0.5223\n",
      "Epoch 23/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5159 - val_loss: 0.6919 - val_accuracy: 0.5249\n",
      "Epoch 24/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5178 - val_loss: 0.6921 - val_accuracy: 0.5230\n",
      "Epoch 25/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5176 - val_loss: 0.6923 - val_accuracy: 0.5194\n",
      "Epoch 26/1000\n",
      "41104/41104 [==============================] - 0s 12us/sample - loss: 0.6918 - accuracy: 0.5196 - val_loss: 0.6923 - val_accuracy: 0.5187\n",
      "Epoch 27/1000\n",
      "41104/41104 [==============================] - 1s 12us/sample - loss: 0.6918 - accuracy: 0.5171 - val_loss: 0.6922 - val_accuracy: 0.5236\n",
      "Epoch 28/1000\n",
      "41104/41104 [==============================] - 0s 12us/sample - loss: 0.6918 - accuracy: 0.5162 - val_loss: 0.6920 - val_accuracy: 0.5230\n",
      "Epoch 29/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5184 - val_loss: 0.6922 - val_accuracy: 0.5263\n",
      "Epoch 30/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5185 - val_loss: 0.6919 - val_accuracy: 0.5224\n",
      "Epoch 31/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5179 - val_loss: 0.6918 - val_accuracy: 0.5256\n",
      "Epoch 32/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5194 - val_loss: 0.6919 - val_accuracy: 0.5224\n",
      "Epoch 33/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5188 - val_loss: 0.6924 - val_accuracy: 0.5169\n",
      "Epoch 34/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5190 - val_loss: 0.6920 - val_accuracy: 0.5208\n",
      "Epoch 35/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5196 - val_loss: 0.6918 - val_accuracy: 0.5243\n",
      "Epoch 36/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5181 - val_loss: 0.6923 - val_accuracy: 0.5173\n",
      "Epoch 37/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5199 - val_loss: 0.6922 - val_accuracy: 0.5213\n",
      "Epoch 38/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5198 - val_loss: 0.6921 - val_accuracy: 0.5238\n",
      "Epoch 39/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5182 - val_loss: 0.6921 - val_accuracy: 0.5225\n",
      "Epoch 40/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5195 - val_loss: 0.6920 - val_accuracy: 0.5234\n",
      "Epoch 41/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5180 - val_loss: 0.6921 - val_accuracy: 0.5219\n",
      "Epoch 42/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5198 - val_loss: 0.6920 - val_accuracy: 0.5230\n",
      "Epoch 43/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5199 - val_loss: 0.6919 - val_accuracy: 0.5244\n",
      "Epoch 44/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5203 - val_loss: 0.6920 - val_accuracy: 0.5204\n",
      "Epoch 45/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5174 - val_loss: 0.6922 - val_accuracy: 0.5199\n",
      "Epoch 46/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5196 - val_loss: 0.6921 - val_accuracy: 0.5203\n",
      "Epoch 47/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5192 - val_loss: 0.6923 - val_accuracy: 0.5204\n",
      "Epoch 48/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5201 - val_loss: 0.6924 - val_accuracy: 0.5216\n",
      "Epoch 49/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5204 - val_loss: 0.6920 - val_accuracy: 0.5235\n",
      "Training with significance = 1.58, run 4\n",
      "Train on 41104 samples, validate on 10276 samples\n",
      "Epoch 1/1000\n",
      "41104/41104 [==============================] - 1s 28us/sample - loss: 0.6931 - accuracy: 0.5118 - val_loss: 0.6933 - val_accuracy: 0.4983\n",
      "Epoch 2/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5144 - val_loss: 0.6926 - val_accuracy: 0.5114\n",
      "Epoch 3/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5168 - val_loss: 0.6923 - val_accuracy: 0.5153\n",
      "Epoch 4/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5143 - val_loss: 0.6922 - val_accuracy: 0.5138\n",
      "Epoch 5/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5166 - val_loss: 0.6921 - val_accuracy: 0.5159\n",
      "Epoch 6/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5148 - val_loss: 0.6924 - val_accuracy: 0.5167\n",
      "Epoch 7/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5179 - val_loss: 0.6922 - val_accuracy: 0.5170\n",
      "Epoch 8/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5174 - val_loss: 0.6924 - val_accuracy: 0.5172\n",
      "Epoch 9/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5183 - val_loss: 0.6922 - val_accuracy: 0.5160\n",
      "Epoch 10/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5183 - val_loss: 0.6923 - val_accuracy: 0.5155\n",
      "Epoch 11/1000\n",
      "41104/41104 [==============================] - 1s 12us/sample - loss: 0.6918 - accuracy: 0.5177 - val_loss: 0.6923 - val_accuracy: 0.5160\n",
      "Epoch 12/1000\n",
      "41104/41104 [==============================] - 1s 12us/sample - loss: 0.6917 - accuracy: 0.5186 - val_loss: 0.6924 - val_accuracy: 0.5149\n",
      "Epoch 13/1000\n",
      "41104/41104 [==============================] - 1s 12us/sample - loss: 0.6917 - accuracy: 0.5197 - val_loss: 0.6926 - val_accuracy: 0.5140\n",
      "Epoch 14/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5200 - val_loss: 0.6926 - val_accuracy: 0.5144\n",
      "Epoch 15/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5214 - val_loss: 0.6921 - val_accuracy: 0.5143\n",
      "Epoch 16/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5173 - val_loss: 0.6923 - val_accuracy: 0.5170\n",
      "Epoch 17/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5208 - val_loss: 0.6922 - val_accuracy: 0.5182\n",
      "Epoch 18/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5214 - val_loss: 0.6924 - val_accuracy: 0.5151\n",
      "Epoch 19/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5195 - val_loss: 0.6925 - val_accuracy: 0.5146\n",
      "Epoch 20/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5215 - val_loss: 0.6922 - val_accuracy: 0.5130\n",
      "Epoch 21/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5220 - val_loss: 0.6923 - val_accuracy: 0.5154\n",
      "Epoch 22/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5221 - val_loss: 0.6922 - val_accuracy: 0.5158\n",
      "Epoch 23/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5204 - val_loss: 0.6923 - val_accuracy: 0.5164\n",
      "Epoch 24/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5211 - val_loss: 0.6925 - val_accuracy: 0.5161\n",
      "Epoch 25/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5204 - val_loss: 0.6921 - val_accuracy: 0.5143\n",
      "Epoch 26/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5212 - val_loss: 0.6923 - val_accuracy: 0.5167\n",
      "Epoch 27/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5211 - val_loss: 0.6924 - val_accuracy: 0.5157\n",
      "Epoch 28/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5218 - val_loss: 0.6921 - val_accuracy: 0.5166\n",
      "Epoch 29/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5216 - val_loss: 0.6924 - val_accuracy: 0.5138\n",
      "Epoch 30/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5218 - val_loss: 0.6925 - val_accuracy: 0.5157\n",
      "Epoch 31/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5222 - val_loss: 0.6927 - val_accuracy: 0.5135\n",
      "Epoch 32/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5214 - val_loss: 0.6927 - val_accuracy: 0.5149\n",
      "Epoch 33/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5215 - val_loss: 0.6924 - val_accuracy: 0.5129\n",
      "Epoch 34/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5226 - val_loss: 0.6924 - val_accuracy: 0.5136\n",
      "Epoch 35/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5225 - val_loss: 0.6922 - val_accuracy: 0.5175\n",
      "Epoch 36/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5211 - val_loss: 0.6924 - val_accuracy: 0.5057\n",
      "Epoch 37/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5206 - val_loss: 0.6924 - val_accuracy: 0.5146\n",
      "Epoch 38/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5227 - val_loss: 0.6923 - val_accuracy: 0.5144\n",
      "Epoch 39/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5233 - val_loss: 0.6923 - val_accuracy: 0.5150\n",
      "Epoch 40/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5192 - val_loss: 0.6924 - val_accuracy: 0.5156\n",
      "Epoch 41/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5200 - val_loss: 0.6926 - val_accuracy: 0.5157\n",
      "Epoch 42/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5218 - val_loss: 0.6921 - val_accuracy: 0.5163\n",
      "Epoch 43/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5227 - val_loss: 0.6923 - val_accuracy: 0.5147\n",
      "Epoch 44/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5222 - val_loss: 0.6924 - val_accuracy: 0.5168\n",
      "Epoch 45/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5224 - val_loss: 0.6922 - val_accuracy: 0.5162\n",
      "Epoch 46/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5224 - val_loss: 0.6923 - val_accuracy: 0.5148\n",
      "Epoch 47/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5234 - val_loss: 0.6923 - val_accuracy: 0.5155\n",
      "Epoch 48/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5215 - val_loss: 0.6925 - val_accuracy: 0.5121\n",
      "Epoch 49/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5207 - val_loss: 0.6923 - val_accuracy: 0.5127\n",
      "Epoch 50/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5231 - val_loss: 0.6924 - val_accuracy: 0.5139\n",
      "Epoch 51/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5231 - val_loss: 0.6926 - val_accuracy: 0.5086\n",
      "Epoch 52/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5225 - val_loss: 0.6923 - val_accuracy: 0.5111\n",
      "Epoch 53/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5236 - val_loss: 0.6928 - val_accuracy: 0.5169\n",
      "Epoch 54/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5235 - val_loss: 0.6923 - val_accuracy: 0.5132\n",
      "Epoch 55/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5227 - val_loss: 0.6926 - val_accuracy: 0.5134\n",
      "Epoch 56/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5236 - val_loss: 0.6923 - val_accuracy: 0.5116\n",
      "Epoch 57/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5251 - val_loss: 0.6921 - val_accuracy: 0.5147\n",
      "Epoch 58/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5221 - val_loss: 0.6927 - val_accuracy: 0.5105\n",
      "Training with significance = 1.58, run 5\n",
      "Train on 41104 samples, validate on 10276 samples\n",
      "Epoch 1/1000\n",
      "41104/41104 [==============================] - 1s 29us/sample - loss: 0.6946 - accuracy: 0.5052 - val_loss: 0.6939 - val_accuracy: 0.5045\n",
      "Epoch 2/1000\n",
      "41104/41104 [==============================] - 1s 14us/sample - loss: 0.6923 - accuracy: 0.5159 - val_loss: 0.6933 - val_accuracy: 0.5027\n",
      "Epoch 3/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5144 - val_loss: 0.6935 - val_accuracy: 0.5005\n",
      "Epoch 4/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5170 - val_loss: 0.6933 - val_accuracy: 0.5070\n",
      "Epoch 5/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5157 - val_loss: 0.6932 - val_accuracy: 0.5129\n",
      "Epoch 6/1000\n",
      "41104/41104 [==============================] - 1s 14us/sample - loss: 0.6919 - accuracy: 0.5167 - val_loss: 0.6930 - val_accuracy: 0.5058\n",
      "Epoch 7/1000\n",
      "41104/41104 [==============================] - 1s 14us/sample - loss: 0.6919 - accuracy: 0.5158 - val_loss: 0.6932 - val_accuracy: 0.5081\n",
      "Epoch 8/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5176 - val_loss: 0.6931 - val_accuracy: 0.5118\n",
      "Epoch 9/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5163 - val_loss: 0.6931 - val_accuracy: 0.5106\n",
      "Epoch 10/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5171 - val_loss: 0.6935 - val_accuracy: 0.5097\n",
      "Epoch 11/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5177 - val_loss: 0.6932 - val_accuracy: 0.5082\n",
      "Epoch 12/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5155 - val_loss: 0.6931 - val_accuracy: 0.5084\n",
      "Epoch 13/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5173 - val_loss: 0.6930 - val_accuracy: 0.5125\n",
      "Epoch 14/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5170 - val_loss: 0.6930 - val_accuracy: 0.5139\n",
      "Epoch 15/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5196 - val_loss: 0.6930 - val_accuracy: 0.5133\n",
      "Epoch 16/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41104/41104 [==============================] - 1s 14us/sample - loss: 0.6916 - accuracy: 0.5189 - val_loss: 0.6932 - val_accuracy: 0.5101\n",
      "Epoch 17/1000\n",
      "41104/41104 [==============================] - 1s 14us/sample - loss: 0.6916 - accuracy: 0.5173 - val_loss: 0.6932 - val_accuracy: 0.5096\n",
      "Epoch 18/1000\n",
      "41104/41104 [==============================] - 1s 14us/sample - loss: 0.6916 - accuracy: 0.5191 - val_loss: 0.6929 - val_accuracy: 0.5128\n",
      "Epoch 19/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5192 - val_loss: 0.6933 - val_accuracy: 0.5077\n",
      "Epoch 20/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5190 - val_loss: 0.6930 - val_accuracy: 0.5092\n",
      "Epoch 21/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5188 - val_loss: 0.6931 - val_accuracy: 0.5097\n",
      "Epoch 22/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5189 - val_loss: 0.6934 - val_accuracy: 0.5085\n",
      "Epoch 23/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5193 - val_loss: 0.6931 - val_accuracy: 0.5091\n",
      "Epoch 24/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5205 - val_loss: 0.6936 - val_accuracy: 0.5073\n",
      "Epoch 25/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5209 - val_loss: 0.6932 - val_accuracy: 0.5099\n",
      "Epoch 26/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5193 - val_loss: 0.6933 - val_accuracy: 0.5093\n",
      "Epoch 27/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5211 - val_loss: 0.6931 - val_accuracy: 0.5134\n",
      "Epoch 28/1000\n",
      "41104/41104 [==============================] - 1s 14us/sample - loss: 0.6914 - accuracy: 0.5194 - val_loss: 0.6933 - val_accuracy: 0.5119\n",
      "Epoch 29/1000\n",
      "41104/41104 [==============================] - 1s 14us/sample - loss: 0.6914 - accuracy: 0.5214 - val_loss: 0.6935 - val_accuracy: 0.5071\n",
      "Epoch 30/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5213 - val_loss: 0.6932 - val_accuracy: 0.5110\n",
      "Epoch 31/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5213 - val_loss: 0.6936 - val_accuracy: 0.5114\n",
      "Epoch 32/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5225 - val_loss: 0.6933 - val_accuracy: 0.5048\n",
      "Epoch 33/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5197 - val_loss: 0.6936 - val_accuracy: 0.5068\n",
      "Epoch 34/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5200 - val_loss: 0.6931 - val_accuracy: 0.5117\n",
      "Epoch 35/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5211 - val_loss: 0.6933 - val_accuracy: 0.5109\n",
      "Epoch 36/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5204 - val_loss: 0.6934 - val_accuracy: 0.5061\n",
      "Epoch 37/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5201 - val_loss: 0.6934 - val_accuracy: 0.5099\n",
      "Epoch 38/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5213 - val_loss: 0.6932 - val_accuracy: 0.5107\n",
      "Epoch 39/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5201 - val_loss: 0.6932 - val_accuracy: 0.5116\n",
      "Epoch 40/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5186 - val_loss: 0.6931 - val_accuracy: 0.5126\n",
      "Epoch 41/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5214 - val_loss: 0.6933 - val_accuracy: 0.5065\n",
      "Epoch 42/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5221 - val_loss: 0.6934 - val_accuracy: 0.5108\n",
      "Epoch 43/1000\n",
      "41104/41104 [==============================] - 1s 12us/sample - loss: 0.6913 - accuracy: 0.5197 - val_loss: 0.6937 - val_accuracy: 0.5084\n",
      "Epoch 44/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5233 - val_loss: 0.6933 - val_accuracy: 0.5095\n",
      "Epoch 45/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5209 - val_loss: 0.6936 - val_accuracy: 0.5066\n",
      "Epoch 46/1000\n",
      "41104/41104 [==============================] - 1s 12us/sample - loss: 0.6912 - accuracy: 0.5222 - val_loss: 0.6932 - val_accuracy: 0.5121\n",
      "Epoch 47/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5222 - val_loss: 0.6934 - val_accuracy: 0.5089\n",
      "Epoch 48/1000\n",
      "41104/41104 [==============================] - 1s 14us/sample - loss: 0.6912 - accuracy: 0.5215 - val_loss: 0.6934 - val_accuracy: 0.5090\n",
      "Training with significance = 1.58, run 6\n",
      "Train on 41104 samples, validate on 10276 samples\n",
      "Epoch 1/1000\n",
      "41104/41104 [==============================] - 1s 28us/sample - loss: 0.6935 - accuracy: 0.5048 - val_loss: 0.6931 - val_accuracy: 0.5050\n",
      "Epoch 2/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6929 - accuracy: 0.5127 - val_loss: 0.6926 - val_accuracy: 0.5120\n",
      "Epoch 3/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6927 - accuracy: 0.5144 - val_loss: 0.6923 - val_accuracy: 0.5142\n",
      "Epoch 4/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6926 - accuracy: 0.5130 - val_loss: 0.6921 - val_accuracy: 0.5202\n",
      "Epoch 5/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6925 - accuracy: 0.5138 - val_loss: 0.6921 - val_accuracy: 0.5217\n",
      "Epoch 6/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5153 - val_loss: 0.6921 - val_accuracy: 0.5192\n",
      "Epoch 7/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5157 - val_loss: 0.6920 - val_accuracy: 0.5213\n",
      "Epoch 8/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5170 - val_loss: 0.6921 - val_accuracy: 0.5220\n",
      "Epoch 9/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5162 - val_loss: 0.6920 - val_accuracy: 0.5230\n",
      "Epoch 10/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5172 - val_loss: 0.6920 - val_accuracy: 0.5208\n",
      "Epoch 11/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5183 - val_loss: 0.6920 - val_accuracy: 0.5202\n",
      "Epoch 12/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5197 - val_loss: 0.6921 - val_accuracy: 0.5180\n",
      "Epoch 13/1000\n",
      "41104/41104 [==============================] - 1s 14us/sample - loss: 0.6921 - accuracy: 0.5145 - val_loss: 0.6919 - val_accuracy: 0.5210\n",
      "Epoch 14/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5163 - val_loss: 0.6921 - val_accuracy: 0.5180\n",
      "Epoch 15/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5186 - val_loss: 0.6921 - val_accuracy: 0.5205\n",
      "Epoch 16/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5187 - val_loss: 0.6921 - val_accuracy: 0.5186\n",
      "Epoch 17/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5190 - val_loss: 0.6919 - val_accuracy: 0.5211\n",
      "Epoch 18/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5184 - val_loss: 0.6919 - val_accuracy: 0.5221\n",
      "Epoch 19/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5184 - val_loss: 0.6919 - val_accuracy: 0.5218\n",
      "Epoch 20/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5174 - val_loss: 0.6919 - val_accuracy: 0.5221\n",
      "Epoch 21/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5200 - val_loss: 0.6919 - val_accuracy: 0.5212\n",
      "Epoch 22/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5175 - val_loss: 0.6919 - val_accuracy: 0.5220\n",
      "Epoch 23/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5183 - val_loss: 0.6919 - val_accuracy: 0.5212\n",
      "Epoch 24/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5176 - val_loss: 0.6919 - val_accuracy: 0.5165\n",
      "Epoch 25/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5193 - val_loss: 0.6918 - val_accuracy: 0.5196\n",
      "Epoch 26/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5196 - val_loss: 0.6919 - val_accuracy: 0.5206\n",
      "Epoch 27/1000\n",
      "41104/41104 [==============================] - 1s 14us/sample - loss: 0.6918 - accuracy: 0.5204 - val_loss: 0.6917 - val_accuracy: 0.5196\n",
      "Epoch 28/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5181 - val_loss: 0.6919 - val_accuracy: 0.5200\n",
      "Epoch 29/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5173 - val_loss: 0.6918 - val_accuracy: 0.5215\n",
      "Epoch 30/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5185 - val_loss: 0.6919 - val_accuracy: 0.5201\n",
      "Epoch 31/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5187 - val_loss: 0.6919 - val_accuracy: 0.5207\n",
      "Epoch 32/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5193 - val_loss: 0.6919 - val_accuracy: 0.5196\n",
      "Epoch 33/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5193 - val_loss: 0.6918 - val_accuracy: 0.5205\n",
      "Epoch 34/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5198 - val_loss: 0.6918 - val_accuracy: 0.5216\n",
      "Epoch 35/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5204 - val_loss: 0.6918 - val_accuracy: 0.5196\n",
      "Epoch 36/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5170 - val_loss: 0.6919 - val_accuracy: 0.5202\n",
      "Epoch 37/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5208 - val_loss: 0.6918 - val_accuracy: 0.5205\n",
      "Epoch 38/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5200 - val_loss: 0.6918 - val_accuracy: 0.5188\n",
      "Epoch 39/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5196 - val_loss: 0.6919 - val_accuracy: 0.5213\n",
      "Epoch 40/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5187 - val_loss: 0.6918 - val_accuracy: 0.5179\n",
      "Epoch 41/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5205 - val_loss: 0.6918 - val_accuracy: 0.5163\n",
      "Epoch 42/1000\n",
      "41104/41104 [==============================] - 0s 12us/sample - loss: 0.6918 - accuracy: 0.5188 - val_loss: 0.6919 - val_accuracy: 0.5207\n",
      "Epoch 43/1000\n",
      "41104/41104 [==============================] - 1s 12us/sample - loss: 0.6918 - accuracy: 0.5197 - val_loss: 0.6919 - val_accuracy: 0.5153\n",
      "Epoch 44/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5193 - val_loss: 0.6919 - val_accuracy: 0.5184\n",
      "Epoch 45/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5170 - val_loss: 0.6919 - val_accuracy: 0.5194\n",
      "Epoch 46/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5219 - val_loss: 0.6920 - val_accuracy: 0.5180\n",
      "Epoch 47/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5207 - val_loss: 0.6919 - val_accuracy: 0.5183\n",
      "Epoch 48/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5225 - val_loss: 0.6918 - val_accuracy: 0.5166\n",
      "Epoch 49/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5201 - val_loss: 0.6918 - val_accuracy: 0.5191\n",
      "Epoch 50/1000\n",
      "41104/41104 [==============================] - 1s 14us/sample - loss: 0.6916 - accuracy: 0.5214 - val_loss: 0.6919 - val_accuracy: 0.5177\n",
      "Epoch 51/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5185 - val_loss: 0.6919 - val_accuracy: 0.5191\n",
      "Epoch 52/1000\n",
      "41104/41104 [==============================] - 1s 14us/sample - loss: 0.6918 - accuracy: 0.5205 - val_loss: 0.6919 - val_accuracy: 0.5199\n",
      "Epoch 53/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5198 - val_loss: 0.6918 - val_accuracy: 0.5209\n",
      "Epoch 54/1000\n",
      "41104/41104 [==============================] - 1s 14us/sample - loss: 0.6917 - accuracy: 0.5211 - val_loss: 0.6919 - val_accuracy: 0.5192\n",
      "Epoch 55/1000\n",
      "41104/41104 [==============================] - 1s 14us/sample - loss: 0.6918 - accuracy: 0.5199 - val_loss: 0.6919 - val_accuracy: 0.5207\n",
      "Epoch 56/1000\n",
      "41104/41104 [==============================] - 1s 14us/sample - loss: 0.6916 - accuracy: 0.5223 - val_loss: 0.6919 - val_accuracy: 0.5168\n",
      "Epoch 57/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5206 - val_loss: 0.6918 - val_accuracy: 0.5175\n",
      "Training with significance = 1.58, run 7\n",
      "Train on 41104 samples, validate on 10276 samples\n",
      "Epoch 1/1000\n",
      "41104/41104 [==============================] - 1s 27us/sample - loss: 0.6932 - accuracy: 0.5074 - val_loss: 0.6943 - val_accuracy: 0.4906\n",
      "Epoch 2/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6928 - accuracy: 0.5095 - val_loss: 0.6931 - val_accuracy: 0.5070\n",
      "Epoch 3/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6925 - accuracy: 0.5139 - val_loss: 0.6929 - val_accuracy: 0.5059\n",
      "Epoch 4/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5141 - val_loss: 0.6926 - val_accuracy: 0.5141\n",
      "Epoch 5/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5144 - val_loss: 0.6924 - val_accuracy: 0.5133\n",
      "Epoch 6/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5150 - val_loss: 0.6922 - val_accuracy: 0.5190\n",
      "Epoch 7/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5153 - val_loss: 0.6921 - val_accuracy: 0.5191\n",
      "Epoch 8/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5152 - val_loss: 0.6923 - val_accuracy: 0.5122\n",
      "Epoch 9/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5129 - val_loss: 0.6922 - val_accuracy: 0.5181\n",
      "Epoch 10/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5160 - val_loss: 0.6921 - val_accuracy: 0.5174\n",
      "Epoch 11/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5167 - val_loss: 0.6922 - val_accuracy: 0.5159\n",
      "Epoch 12/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5159 - val_loss: 0.6922 - val_accuracy: 0.5186\n",
      "Epoch 13/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5165 - val_loss: 0.6922 - val_accuracy: 0.5172\n",
      "Epoch 14/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5143 - val_loss: 0.6921 - val_accuracy: 0.5181\n",
      "Epoch 15/1000\n",
      "41104/41104 [==============================] - 1s 12us/sample - loss: 0.6919 - accuracy: 0.5155 - val_loss: 0.6924 - val_accuracy: 0.5156\n",
      "Epoch 16/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5164 - val_loss: 0.6924 - val_accuracy: 0.5156\n",
      "Epoch 17/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5161 - val_loss: 0.6922 - val_accuracy: 0.5169\n",
      "Epoch 18/1000\n",
      "41104/41104 [==============================] - 1s 12us/sample - loss: 0.6918 - accuracy: 0.5184 - val_loss: 0.6921 - val_accuracy: 0.5174\n",
      "Epoch 19/1000\n",
      "41104/41104 [==============================] - 0s 12us/sample - loss: 0.6919 - accuracy: 0.5172 - val_loss: 0.6921 - val_accuracy: 0.5178\n",
      "Epoch 20/1000\n",
      "41104/41104 [==============================] - 0s 12us/sample - loss: 0.6918 - accuracy: 0.5170 - val_loss: 0.6921 - val_accuracy: 0.5133\n",
      "Epoch 21/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5172 - val_loss: 0.6924 - val_accuracy: 0.5111\n",
      "Epoch 22/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5170 - val_loss: 0.6923 - val_accuracy: 0.5144\n",
      "Epoch 23/1000\n",
      "41104/41104 [==============================] - 1s 14us/sample - loss: 0.6918 - accuracy: 0.5176 - val_loss: 0.6921 - val_accuracy: 0.5167\n",
      "Epoch 24/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5174 - val_loss: 0.6922 - val_accuracy: 0.5168\n",
      "Epoch 25/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5175 - val_loss: 0.6920 - val_accuracy: 0.5199\n",
      "Epoch 26/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5183 - val_loss: 0.6922 - val_accuracy: 0.5172\n",
      "Epoch 27/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5176 - val_loss: 0.6920 - val_accuracy: 0.5194\n",
      "Epoch 28/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5177 - val_loss: 0.6922 - val_accuracy: 0.5134\n",
      "Epoch 29/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5175 - val_loss: 0.6922 - val_accuracy: 0.5134\n",
      "Epoch 30/1000\n",
      "41104/41104 [==============================] - 1s 14us/sample - loss: 0.6917 - accuracy: 0.5174 - val_loss: 0.6920 - val_accuracy: 0.5210\n",
      "Epoch 31/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5184 - val_loss: 0.6922 - val_accuracy: 0.5137\n",
      "Epoch 32/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5182 - val_loss: 0.6923 - val_accuracy: 0.5125\n",
      "Epoch 33/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5194 - val_loss: 0.6922 - val_accuracy: 0.5175\n",
      "Epoch 34/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5183 - val_loss: 0.6923 - val_accuracy: 0.5120\n",
      "Epoch 35/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5183 - val_loss: 0.6921 - val_accuracy: 0.5186\n",
      "Epoch 36/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5194 - val_loss: 0.6922 - val_accuracy: 0.5170\n",
      "Epoch 37/1000\n",
      "41104/41104 [==============================] - 1s 14us/sample - loss: 0.6916 - accuracy: 0.5199 - val_loss: 0.6921 - val_accuracy: 0.5165\n",
      "Epoch 38/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5195 - val_loss: 0.6924 - val_accuracy: 0.5110\n",
      "Epoch 39/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5188 - val_loss: 0.6922 - val_accuracy: 0.5163\n",
      "Epoch 40/1000\n",
      "41104/41104 [==============================] - 1s 12us/sample - loss: 0.6916 - accuracy: 0.5203 - val_loss: 0.6921 - val_accuracy: 0.5159\n",
      "Epoch 41/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5181 - val_loss: 0.6922 - val_accuracy: 0.5130\n",
      "Epoch 42/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5194 - val_loss: 0.6925 - val_accuracy: 0.5151\n",
      "Epoch 43/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5175 - val_loss: 0.6922 - val_accuracy: 0.5118\n",
      "Epoch 44/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5197 - val_loss: 0.6921 - val_accuracy: 0.5172\n",
      "Epoch 45/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5187 - val_loss: 0.6923 - val_accuracy: 0.5146\n",
      "Epoch 46/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5189 - val_loss: 0.6923 - val_accuracy: 0.5136\n",
      "Epoch 47/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5167 - val_loss: 0.6922 - val_accuracy: 0.5160\n",
      "Epoch 48/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5218 - val_loss: 0.6924 - val_accuracy: 0.5109\n",
      "Epoch 49/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5188 - val_loss: 0.6921 - val_accuracy: 0.5171\n",
      "Epoch 50/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5186 - val_loss: 0.6925 - val_accuracy: 0.5123\n",
      "Epoch 51/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5192 - val_loss: 0.6923 - val_accuracy: 0.5156\n",
      "Epoch 52/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5171 - val_loss: 0.6924 - val_accuracy: 0.5125\n",
      "Epoch 53/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5199 - val_loss: 0.6924 - val_accuracy: 0.5144\n",
      "Epoch 54/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5195 - val_loss: 0.6921 - val_accuracy: 0.5159\n",
      "Epoch 55/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5212 - val_loss: 0.6924 - val_accuracy: 0.5137\n",
      "Training with significance = 1.58, run 8\n",
      "Train on 41104 samples, validate on 10276 samples\n",
      "Epoch 1/1000\n",
      "41104/41104 [==============================] - 1s 28us/sample - loss: 0.6932 - accuracy: 0.5081 - val_loss: 0.6936 - val_accuracy: 0.4987\n",
      "Epoch 2/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6925 - accuracy: 0.5139 - val_loss: 0.6935 - val_accuracy: 0.5097\n",
      "Epoch 3/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5156 - val_loss: 0.6929 - val_accuracy: 0.5105\n",
      "Epoch 4/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5145 - val_loss: 0.6932 - val_accuracy: 0.5129\n",
      "Epoch 5/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5151 - val_loss: 0.6930 - val_accuracy: 0.5101\n",
      "Epoch 6/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5158 - val_loss: 0.6926 - val_accuracy: 0.5127\n",
      "Epoch 7/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5178 - val_loss: 0.6928 - val_accuracy: 0.5116\n",
      "Epoch 8/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5170 - val_loss: 0.6927 - val_accuracy: 0.5091\n",
      "Epoch 9/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5170 - val_loss: 0.6925 - val_accuracy: 0.5135\n",
      "Epoch 10/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5165 - val_loss: 0.6923 - val_accuracy: 0.5159\n",
      "Epoch 11/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5168 - val_loss: 0.6924 - val_accuracy: 0.5134\n",
      "Epoch 12/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5172 - val_loss: 0.6926 - val_accuracy: 0.5109\n",
      "Epoch 13/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5190 - val_loss: 0.6925 - val_accuracy: 0.5122\n",
      "Epoch 14/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5170 - val_loss: 0.6924 - val_accuracy: 0.5130\n",
      "Epoch 15/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5178 - val_loss: 0.6925 - val_accuracy: 0.5111\n",
      "Epoch 16/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5177 - val_loss: 0.6925 - val_accuracy: 0.5126\n",
      "Epoch 17/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5176 - val_loss: 0.6925 - val_accuracy: 0.5129\n",
      "Epoch 18/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5196 - val_loss: 0.6930 - val_accuracy: 0.5068\n",
      "Epoch 19/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5178 - val_loss: 0.6924 - val_accuracy: 0.5115\n",
      "Epoch 20/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5177 - val_loss: 0.6923 - val_accuracy: 0.5164\n",
      "Epoch 21/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5196 - val_loss: 0.6924 - val_accuracy: 0.5143\n",
      "Epoch 22/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5193 - val_loss: 0.6923 - val_accuracy: 0.5117\n",
      "Epoch 23/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5186 - val_loss: 0.6926 - val_accuracy: 0.5125\n",
      "Epoch 24/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5193 - val_loss: 0.6922 - val_accuracy: 0.5135\n",
      "Epoch 25/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5190 - val_loss: 0.6927 - val_accuracy: 0.5094\n",
      "Epoch 26/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5193 - val_loss: 0.6926 - val_accuracy: 0.5101\n",
      "Epoch 27/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5184 - val_loss: 0.6923 - val_accuracy: 0.5124\n",
      "Epoch 28/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5204 - val_loss: 0.6926 - val_accuracy: 0.5094\n",
      "Epoch 29/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5195 - val_loss: 0.6923 - val_accuracy: 0.5125\n",
      "Epoch 30/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5199 - val_loss: 0.6927 - val_accuracy: 0.5082\n",
      "Epoch 31/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5197 - val_loss: 0.6925 - val_accuracy: 0.5119\n",
      "Epoch 32/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5184 - val_loss: 0.6923 - val_accuracy: 0.5168\n",
      "Epoch 33/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5203 - val_loss: 0.6924 - val_accuracy: 0.5122\n",
      "Epoch 34/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5217 - val_loss: 0.6924 - val_accuracy: 0.5113\n",
      "Epoch 35/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5201 - val_loss: 0.6923 - val_accuracy: 0.5154\n",
      "Epoch 36/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5180 - val_loss: 0.6922 - val_accuracy: 0.5143\n",
      "Epoch 37/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5205 - val_loss: 0.6924 - val_accuracy: 0.5130\n",
      "Epoch 38/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5200 - val_loss: 0.6925 - val_accuracy: 0.5110\n",
      "Epoch 39/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5203 - val_loss: 0.6925 - val_accuracy: 0.5118\n",
      "Epoch 40/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5205 - val_loss: 0.6924 - val_accuracy: 0.5126\n",
      "Epoch 41/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5213 - val_loss: 0.6922 - val_accuracy: 0.5149\n",
      "Epoch 42/1000\n",
      "41104/41104 [==============================] - 1s 12us/sample - loss: 0.6915 - accuracy: 0.5209 - val_loss: 0.6926 - val_accuracy: 0.5095\n",
      "Epoch 43/1000\n",
      "41104/41104 [==============================] - 1s 12us/sample - loss: 0.6915 - accuracy: 0.5191 - val_loss: 0.6923 - val_accuracy: 0.5160\n",
      "Epoch 44/1000\n",
      "41104/41104 [==============================] - 0s 12us/sample - loss: 0.6915 - accuracy: 0.5225 - val_loss: 0.6922 - val_accuracy: 0.5165\n",
      "Epoch 45/1000\n",
      "41104/41104 [==============================] - 1s 12us/sample - loss: 0.6915 - accuracy: 0.5211 - val_loss: 0.6928 - val_accuracy: 0.5098\n",
      "Epoch 46/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5195 - val_loss: 0.6923 - val_accuracy: 0.5146\n",
      "Epoch 47/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5218 - val_loss: 0.6926 - val_accuracy: 0.5094\n",
      "Epoch 48/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5223 - val_loss: 0.6927 - val_accuracy: 0.5088\n",
      "Epoch 49/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5201 - val_loss: 0.6924 - val_accuracy: 0.5127\n",
      "Epoch 50/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5193 - val_loss: 0.6923 - val_accuracy: 0.5146\n",
      "Epoch 51/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5227 - val_loss: 0.6923 - val_accuracy: 0.5136\n",
      "Epoch 52/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5203 - val_loss: 0.6923 - val_accuracy: 0.5135\n",
      "Epoch 53/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5213 - val_loss: 0.6925 - val_accuracy: 0.5112\n",
      "Epoch 54/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5214 - val_loss: 0.6923 - val_accuracy: 0.5147\n",
      "Epoch 55/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5219 - val_loss: 0.6924 - val_accuracy: 0.5134\n",
      "Epoch 56/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5212 - val_loss: 0.6925 - val_accuracy: 0.5094\n",
      "Epoch 57/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5221 - val_loss: 0.6923 - val_accuracy: 0.5164\n",
      "Epoch 58/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5200 - val_loss: 0.6924 - val_accuracy: 0.5097\n",
      "Epoch 59/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5211 - val_loss: 0.6925 - val_accuracy: 0.5096\n",
      "Epoch 60/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5210 - val_loss: 0.6923 - val_accuracy: 0.5163\n",
      "Epoch 61/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5211 - val_loss: 0.6923 - val_accuracy: 0.5147\n",
      "Epoch 62/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5203 - val_loss: 0.6923 - val_accuracy: 0.5138\n",
      "Epoch 63/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5217 - val_loss: 0.6925 - val_accuracy: 0.5127\n",
      "Epoch 64/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5226 - val_loss: 0.6923 - val_accuracy: 0.5145\n",
      "Epoch 65/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5221 - val_loss: 0.6922 - val_accuracy: 0.5151\n",
      "Epoch 66/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5233 - val_loss: 0.6922 - val_accuracy: 0.5163\n",
      "Epoch 67/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5212 - val_loss: 0.6922 - val_accuracy: 0.5156\n",
      "Epoch 68/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5233 - val_loss: 0.6922 - val_accuracy: 0.5150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5216 - val_loss: 0.6921 - val_accuracy: 0.5156\n",
      "Epoch 70/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5220 - val_loss: 0.6925 - val_accuracy: 0.5111\n",
      "Epoch 71/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5235 - val_loss: 0.6925 - val_accuracy: 0.5123\n",
      "Epoch 72/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5229 - val_loss: 0.6925 - val_accuracy: 0.5136\n",
      "Epoch 73/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5221 - val_loss: 0.6921 - val_accuracy: 0.5160\n",
      "Epoch 74/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5220 - val_loss: 0.6922 - val_accuracy: 0.5146\n",
      "Epoch 75/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5228 - val_loss: 0.6923 - val_accuracy: 0.5153\n",
      "Epoch 76/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5230 - val_loss: 0.6924 - val_accuracy: 0.5125\n",
      "Epoch 77/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5229 - val_loss: 0.6921 - val_accuracy: 0.5151\n",
      "Epoch 78/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5208 - val_loss: 0.6921 - val_accuracy: 0.5150\n",
      "Epoch 79/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5209 - val_loss: 0.6922 - val_accuracy: 0.5147\n",
      "Epoch 80/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5217 - val_loss: 0.6922 - val_accuracy: 0.5178\n",
      "Epoch 81/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5231 - val_loss: 0.6925 - val_accuracy: 0.5109\n",
      "Epoch 82/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5228 - val_loss: 0.6926 - val_accuracy: 0.5107\n",
      "Epoch 83/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5239 - val_loss: 0.6922 - val_accuracy: 0.5139\n",
      "Epoch 84/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5219 - val_loss: 0.6924 - val_accuracy: 0.5132\n",
      "Epoch 85/1000\n",
      "41104/41104 [==============================] - 1s 14us/sample - loss: 0.6911 - accuracy: 0.5233 - val_loss: 0.6924 - val_accuracy: 0.5118\n",
      "Epoch 86/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5211 - val_loss: 0.6921 - val_accuracy: 0.5140\n",
      "Epoch 87/1000\n",
      "41104/41104 [==============================] - 1s 14us/sample - loss: 0.6912 - accuracy: 0.5226 - val_loss: 0.6923 - val_accuracy: 0.5144\n",
      "Epoch 88/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5215 - val_loss: 0.6923 - val_accuracy: 0.5130\n",
      "Epoch 89/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5241 - val_loss: 0.6925 - val_accuracy: 0.5106\n",
      "Epoch 90/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5231 - val_loss: 0.6921 - val_accuracy: 0.5154\n",
      "Epoch 91/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5230 - val_loss: 0.6925 - val_accuracy: 0.5128\n",
      "Epoch 92/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5233 - val_loss: 0.6927 - val_accuracy: 0.5106\n",
      "Epoch 93/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5245 - val_loss: 0.6926 - val_accuracy: 0.5093\n",
      "Epoch 94/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5225 - val_loss: 0.6926 - val_accuracy: 0.5097\n",
      "Epoch 95/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5206 - val_loss: 0.6925 - val_accuracy: 0.5098\n",
      "Epoch 96/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5233 - val_loss: 0.6927 - val_accuracy: 0.5114\n",
      "Epoch 97/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5243 - val_loss: 0.6923 - val_accuracy: 0.5122\n",
      "Epoch 98/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5217 - val_loss: 0.6923 - val_accuracy: 0.5118\n",
      "Epoch 99/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5237 - val_loss: 0.6926 - val_accuracy: 0.5137\n",
      "Epoch 100/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5236 - val_loss: 0.6923 - val_accuracy: 0.5151\n",
      "Epoch 101/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5265 - val_loss: 0.6923 - val_accuracy: 0.5118\n",
      "Epoch 102/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5237 - val_loss: 0.6924 - val_accuracy: 0.5112\n",
      "Epoch 103/1000\n",
      "41104/41104 [==============================] - 0s 12us/sample - loss: 0.6910 - accuracy: 0.5227 - val_loss: 0.6924 - val_accuracy: 0.5108\n",
      "Epoch 104/1000\n",
      "41104/41104 [==============================] - 0s 12us/sample - loss: 0.6910 - accuracy: 0.5221 - val_loss: 0.6927 - val_accuracy: 0.5097\n",
      "Epoch 105/1000\n",
      "41104/41104 [==============================] - 1s 12us/sample - loss: 0.6911 - accuracy: 0.5252 - val_loss: 0.6924 - val_accuracy: 0.5115\n",
      "Epoch 106/1000\n",
      "41104/41104 [==============================] - 1s 12us/sample - loss: 0.6911 - accuracy: 0.5232 - val_loss: 0.6924 - val_accuracy: 0.5122\n",
      "Epoch 107/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5236 - val_loss: 0.6928 - val_accuracy: 0.5114\n",
      "Training with significance = 1.58, run 9\n",
      "Train on 41104 samples, validate on 10276 samples\n",
      "Epoch 1/1000\n",
      "41104/41104 [==============================] - 1s 28us/sample - loss: 0.6942 - accuracy: 0.5049 - val_loss: 0.6932 - val_accuracy: 0.5073\n",
      "Epoch 2/1000\n",
      "41104/41104 [==============================] - 1s 14us/sample - loss: 0.6925 - accuracy: 0.5147 - val_loss: 0.6931 - val_accuracy: 0.5075\n",
      "Epoch 3/1000\n",
      "41104/41104 [==============================] - 1s 14us/sample - loss: 0.6923 - accuracy: 0.5158 - val_loss: 0.6930 - val_accuracy: 0.5128\n",
      "Epoch 4/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5141 - val_loss: 0.6930 - val_accuracy: 0.5121\n",
      "Epoch 5/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5164 - val_loss: 0.6930 - val_accuracy: 0.5133\n",
      "Epoch 6/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5145 - val_loss: 0.6930 - val_accuracy: 0.5076\n",
      "Epoch 7/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5160 - val_loss: 0.6931 - val_accuracy: 0.5108\n",
      "Epoch 8/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5170 - val_loss: 0.6931 - val_accuracy: 0.5123\n",
      "Epoch 9/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5173 - val_loss: 0.6933 - val_accuracy: 0.5091\n",
      "Epoch 10/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5155 - val_loss: 0.6931 - val_accuracy: 0.5105\n",
      "Epoch 11/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5172 - val_loss: 0.6931 - val_accuracy: 0.5102\n",
      "Epoch 12/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5156 - val_loss: 0.6931 - val_accuracy: 0.5081\n",
      "Epoch 13/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5180 - val_loss: 0.6931 - val_accuracy: 0.5106\n",
      "Epoch 14/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5174 - val_loss: 0.6931 - val_accuracy: 0.5087\n",
      "Epoch 15/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5178 - val_loss: 0.6931 - val_accuracy: 0.5094\n",
      "Epoch 16/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5190 - val_loss: 0.6930 - val_accuracy: 0.5117\n",
      "Epoch 17/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5194 - val_loss: 0.6930 - val_accuracy: 0.5097\n",
      "Epoch 18/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5193 - val_loss: 0.6931 - val_accuracy: 0.5105\n",
      "Epoch 19/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5184 - val_loss: 0.6932 - val_accuracy: 0.5077\n",
      "Epoch 20/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5182 - val_loss: 0.6931 - val_accuracy: 0.5089\n",
      "Epoch 21/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5189 - val_loss: 0.6932 - val_accuracy: 0.5098\n",
      "Epoch 22/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5204 - val_loss: 0.6931 - val_accuracy: 0.5116\n",
      "Epoch 23/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5213 - val_loss: 0.6931 - val_accuracy: 0.5104\n",
      "Epoch 24/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5189 - val_loss: 0.6931 - val_accuracy: 0.5093\n",
      "Epoch 25/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5181 - val_loss: 0.6931 - val_accuracy: 0.5109\n",
      "Epoch 26/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5186 - val_loss: 0.6932 - val_accuracy: 0.5072\n",
      "Epoch 27/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5192 - val_loss: 0.6931 - val_accuracy: 0.5091\n",
      "Epoch 28/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5214 - val_loss: 0.6933 - val_accuracy: 0.5118\n",
      "Epoch 29/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5190 - val_loss: 0.6931 - val_accuracy: 0.5066\n",
      "Epoch 30/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5198 - val_loss: 0.6932 - val_accuracy: 0.5066\n",
      "Epoch 31/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5207 - val_loss: 0.6935 - val_accuracy: 0.5099\n",
      "Epoch 32/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5180 - val_loss: 0.6931 - val_accuracy: 0.5114\n",
      "Epoch 33/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5205 - val_loss: 0.6932 - val_accuracy: 0.5081\n",
      "Epoch 34/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5201 - val_loss: 0.6931 - val_accuracy: 0.5090\n",
      "Epoch 35/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5190 - val_loss: 0.6933 - val_accuracy: 0.5067\n",
      "Epoch 36/1000\n",
      "41104/41104 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5204 - val_loss: 0.6935 - val_accuracy: 0.5059\n",
      "Training with significance = 1.89, run 0\n",
      "Train on 41154 samples, validate on 10289 samples\n",
      "Epoch 1/1000\n",
      "41154/41154 [==============================] - 1s 27us/sample - loss: 0.6950 - accuracy: 0.5048 - val_loss: 0.6929 - val_accuracy: 0.5039\n",
      "Epoch 2/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6928 - accuracy: 0.5097 - val_loss: 0.6928 - val_accuracy: 0.5079\n",
      "Epoch 3/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6927 - accuracy: 0.5100 - val_loss: 0.6926 - val_accuracy: 0.5162\n",
      "Epoch 4/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6926 - accuracy: 0.5125 - val_loss: 0.6926 - val_accuracy: 0.5150\n",
      "Epoch 5/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5158 - val_loss: 0.6926 - val_accuracy: 0.5129\n",
      "Epoch 6/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5134 - val_loss: 0.6927 - val_accuracy: 0.5123\n",
      "Epoch 7/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5124 - val_loss: 0.6928 - val_accuracy: 0.5036\n",
      "Epoch 8/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5145 - val_loss: 0.6927 - val_accuracy: 0.5128\n",
      "Epoch 9/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5161 - val_loss: 0.6928 - val_accuracy: 0.5120\n",
      "Epoch 10/1000\n",
      "41154/41154 [==============================] - 1s 12us/sample - loss: 0.6923 - accuracy: 0.5175 - val_loss: 0.6926 - val_accuracy: 0.5124\n",
      "Epoch 11/1000\n",
      "41154/41154 [==============================] - 1s 12us/sample - loss: 0.6922 - accuracy: 0.5180 - val_loss: 0.6926 - val_accuracy: 0.5114\n",
      "Epoch 12/1000\n",
      "41154/41154 [==============================] - 1s 12us/sample - loss: 0.6922 - accuracy: 0.5168 - val_loss: 0.6925 - val_accuracy: 0.5121\n",
      "Epoch 13/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5162 - val_loss: 0.6927 - val_accuracy: 0.5140\n",
      "Epoch 14/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5165 - val_loss: 0.6928 - val_accuracy: 0.5129\n",
      "Epoch 15/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5187 - val_loss: 0.6927 - val_accuracy: 0.5124\n",
      "Epoch 16/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5170 - val_loss: 0.6925 - val_accuracy: 0.5125\n",
      "Epoch 17/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5170 - val_loss: 0.6926 - val_accuracy: 0.5135\n",
      "Epoch 18/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5196 - val_loss: 0.6925 - val_accuracy: 0.5160\n",
      "Epoch 19/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5186 - val_loss: 0.6925 - val_accuracy: 0.5146\n",
      "Epoch 20/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5184 - val_loss: 0.6924 - val_accuracy: 0.5167\n",
      "Epoch 21/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5191 - val_loss: 0.6925 - val_accuracy: 0.5164\n",
      "Epoch 22/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5191 - val_loss: 0.6926 - val_accuracy: 0.5154\n",
      "Epoch 23/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5188 - val_loss: 0.6925 - val_accuracy: 0.5155\n",
      "Epoch 24/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5192 - val_loss: 0.6925 - val_accuracy: 0.5161\n",
      "Epoch 25/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5180 - val_loss: 0.6926 - val_accuracy: 0.5157\n",
      "Epoch 26/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5188 - val_loss: 0.6925 - val_accuracy: 0.5151\n",
      "Epoch 27/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5205 - val_loss: 0.6924 - val_accuracy: 0.5151\n",
      "Epoch 28/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5195 - val_loss: 0.6926 - val_accuracy: 0.5114\n",
      "Epoch 29/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5196 - val_loss: 0.6925 - val_accuracy: 0.5166\n",
      "Epoch 30/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5205 - val_loss: 0.6925 - val_accuracy: 0.5175\n",
      "Epoch 31/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5194 - val_loss: 0.6924 - val_accuracy: 0.5157\n",
      "Epoch 32/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5196 - val_loss: 0.6925 - val_accuracy: 0.5159\n",
      "Epoch 33/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5195 - val_loss: 0.6925 - val_accuracy: 0.5135\n",
      "Epoch 34/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5197 - val_loss: 0.6926 - val_accuracy: 0.5135\n",
      "Epoch 35/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5209 - val_loss: 0.6926 - val_accuracy: 0.5120\n",
      "Epoch 36/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5192 - val_loss: 0.6924 - val_accuracy: 0.5152\n",
      "Epoch 37/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5216 - val_loss: 0.6925 - val_accuracy: 0.5149\n",
      "Epoch 38/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5212 - val_loss: 0.6926 - val_accuracy: 0.5144\n",
      "Epoch 39/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5208 - val_loss: 0.6924 - val_accuracy: 0.5159\n",
      "Epoch 40/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5201 - val_loss: 0.6924 - val_accuracy: 0.5163\n",
      "Epoch 41/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5199 - val_loss: 0.6926 - val_accuracy: 0.5133\n",
      "Epoch 42/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5194 - val_loss: 0.6924 - val_accuracy: 0.5162\n",
      "Epoch 43/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5191 - val_loss: 0.6924 - val_accuracy: 0.5169\n",
      "Epoch 44/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5171 - val_loss: 0.6924 - val_accuracy: 0.5172\n",
      "Epoch 45/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5194 - val_loss: 0.6925 - val_accuracy: 0.5136\n",
      "Epoch 46/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5215 - val_loss: 0.6925 - val_accuracy: 0.5138\n",
      "Epoch 47/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5199 - val_loss: 0.6925 - val_accuracy: 0.5143\n",
      "Epoch 48/1000\n",
      "41154/41154 [==============================] - 1s 12us/sample - loss: 0.6917 - accuracy: 0.5205 - val_loss: 0.6924 - val_accuracy: 0.5177\n",
      "Epoch 49/1000\n",
      "41154/41154 [==============================] - 0s 12us/sample - loss: 0.6916 - accuracy: 0.5211 - val_loss: 0.6923 - val_accuracy: 0.5148\n",
      "Epoch 50/1000\n",
      "41154/41154 [==============================] - 1s 12us/sample - loss: 0.6918 - accuracy: 0.5187 - val_loss: 0.6923 - val_accuracy: 0.5164\n",
      "Epoch 51/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5213 - val_loss: 0.6925 - val_accuracy: 0.5165\n",
      "Epoch 52/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5206 - val_loss: 0.6925 - val_accuracy: 0.5168\n",
      "Epoch 53/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5199 - val_loss: 0.6924 - val_accuracy: 0.5138\n",
      "Epoch 54/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5224 - val_loss: 0.6924 - val_accuracy: 0.5146\n",
      "Epoch 55/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5199 - val_loss: 0.6924 - val_accuracy: 0.5163\n",
      "Epoch 56/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5198 - val_loss: 0.6924 - val_accuracy: 0.5164\n",
      "Epoch 57/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5209 - val_loss: 0.6925 - val_accuracy: 0.5168\n",
      "Epoch 58/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5211 - val_loss: 0.6923 - val_accuracy: 0.5170\n",
      "Epoch 59/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5209 - val_loss: 0.6923 - val_accuracy: 0.5146\n",
      "Epoch 60/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5217 - val_loss: 0.6924 - val_accuracy: 0.5153\n",
      "Epoch 61/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5197 - val_loss: 0.6924 - val_accuracy: 0.5157\n",
      "Epoch 62/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5210 - val_loss: 0.6924 - val_accuracy: 0.5173\n",
      "Epoch 63/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5199 - val_loss: 0.6923 - val_accuracy: 0.5158\n",
      "Epoch 64/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5213 - val_loss: 0.6926 - val_accuracy: 0.5143\n",
      "Epoch 65/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5208 - val_loss: 0.6924 - val_accuracy: 0.5144\n",
      "Epoch 66/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5208 - val_loss: 0.6925 - val_accuracy: 0.5176\n",
      "Epoch 67/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5194 - val_loss: 0.6924 - val_accuracy: 0.5152\n",
      "Epoch 68/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5200 - val_loss: 0.6923 - val_accuracy: 0.5175\n",
      "Epoch 69/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5219 - val_loss: 0.6923 - val_accuracy: 0.5168\n",
      "Epoch 70/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5207 - val_loss: 0.6924 - val_accuracy: 0.5173\n",
      "Epoch 71/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5218 - val_loss: 0.6924 - val_accuracy: 0.5150\n",
      "Epoch 72/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5226 - val_loss: 0.6923 - val_accuracy: 0.5149\n",
      "Epoch 73/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5194 - val_loss: 0.6923 - val_accuracy: 0.5161\n",
      "Epoch 74/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5215 - val_loss: 0.6923 - val_accuracy: 0.5151\n",
      "Epoch 75/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5232 - val_loss: 0.6924 - val_accuracy: 0.5165\n",
      "Epoch 76/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5208 - val_loss: 0.6924 - val_accuracy: 0.5161\n",
      "Epoch 77/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5198 - val_loss: 0.6927 - val_accuracy: 0.5145\n",
      "Epoch 78/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5213 - val_loss: 0.6923 - val_accuracy: 0.5151\n",
      "Epoch 79/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5210 - val_loss: 0.6925 - val_accuracy: 0.5144\n",
      "Epoch 80/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5212 - val_loss: 0.6923 - val_accuracy: 0.5182\n",
      "Epoch 81/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5189 - val_loss: 0.6924 - val_accuracy: 0.5166\n",
      "Epoch 82/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5210 - val_loss: 0.6925 - val_accuracy: 0.5153\n",
      "Epoch 83/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5205 - val_loss: 0.6922 - val_accuracy: 0.5151\n",
      "Epoch 84/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5201 - val_loss: 0.6922 - val_accuracy: 0.5171\n",
      "Epoch 85/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5205 - val_loss: 0.6923 - val_accuracy: 0.5177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5212 - val_loss: 0.6924 - val_accuracy: 0.5150\n",
      "Epoch 87/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5210 - val_loss: 0.6923 - val_accuracy: 0.5159\n",
      "Epoch 88/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5222 - val_loss: 0.6922 - val_accuracy: 0.5142\n",
      "Epoch 89/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5218 - val_loss: 0.6923 - val_accuracy: 0.5162\n",
      "Epoch 90/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5212 - val_loss: 0.6922 - val_accuracy: 0.5175\n",
      "Epoch 91/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5226 - val_loss: 0.6922 - val_accuracy: 0.5171\n",
      "Epoch 92/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5212 - val_loss: 0.6924 - val_accuracy: 0.5142\n",
      "Epoch 93/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5210 - val_loss: 0.6923 - val_accuracy: 0.5141\n",
      "Epoch 94/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5211 - val_loss: 0.6922 - val_accuracy: 0.5184\n",
      "Epoch 95/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5232 - val_loss: 0.6922 - val_accuracy: 0.5169\n",
      "Epoch 96/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5232 - val_loss: 0.6924 - val_accuracy: 0.5173\n",
      "Epoch 97/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5203 - val_loss: 0.6924 - val_accuracy: 0.5136\n",
      "Epoch 98/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5223 - val_loss: 0.6923 - val_accuracy: 0.5171\n",
      "Epoch 99/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5214 - val_loss: 0.6923 - val_accuracy: 0.5166\n",
      "Epoch 100/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5208 - val_loss: 0.6923 - val_accuracy: 0.5163\n",
      "Epoch 101/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5191 - val_loss: 0.6923 - val_accuracy: 0.5185\n",
      "Epoch 102/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5219 - val_loss: 0.6923 - val_accuracy: 0.5163\n",
      "Epoch 103/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5217 - val_loss: 0.6923 - val_accuracy: 0.5151\n",
      "Epoch 104/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5230 - val_loss: 0.6925 - val_accuracy: 0.5131\n",
      "Epoch 105/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5205 - val_loss: 0.6923 - val_accuracy: 0.5155\n",
      "Epoch 106/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5219 - val_loss: 0.6922 - val_accuracy: 0.5168\n",
      "Epoch 107/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5221 - val_loss: 0.6926 - val_accuracy: 0.5113\n",
      "Epoch 108/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5192 - val_loss: 0.6922 - val_accuracy: 0.5139\n",
      "Epoch 109/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5226 - val_loss: 0.6923 - val_accuracy: 0.5140\n",
      "Epoch 110/1000\n",
      "41154/41154 [==============================] - 1s 12us/sample - loss: 0.6912 - accuracy: 0.5216 - val_loss: 0.6923 - val_accuracy: 0.5173\n",
      "Epoch 111/1000\n",
      "41154/41154 [==============================] - 1s 12us/sample - loss: 0.6913 - accuracy: 0.5224 - val_loss: 0.6923 - val_accuracy: 0.5170\n",
      "Epoch 112/1000\n",
      "41154/41154 [==============================] - 1s 12us/sample - loss: 0.6912 - accuracy: 0.5220 - val_loss: 0.6923 - val_accuracy: 0.5149\n",
      "Epoch 113/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5230 - val_loss: 0.6924 - val_accuracy: 0.5189\n",
      "Epoch 114/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5217 - val_loss: 0.6922 - val_accuracy: 0.5166\n",
      "Epoch 115/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5217 - val_loss: 0.6922 - val_accuracy: 0.5191\n",
      "Epoch 116/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5230 - val_loss: 0.6924 - val_accuracy: 0.5166\n",
      "Epoch 117/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5212 - val_loss: 0.6923 - val_accuracy: 0.5131\n",
      "Epoch 118/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5230 - val_loss: 0.6924 - val_accuracy: 0.5171\n",
      "Epoch 119/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5201 - val_loss: 0.6924 - val_accuracy: 0.5152\n",
      "Epoch 120/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5216 - val_loss: 0.6923 - val_accuracy: 0.5154\n",
      "Epoch 121/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5228 - val_loss: 0.6923 - val_accuracy: 0.5165\n",
      "Epoch 122/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5215 - val_loss: 0.6922 - val_accuracy: 0.5191\n",
      "Epoch 123/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5241 - val_loss: 0.6922 - val_accuracy: 0.5168\n",
      "Epoch 124/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5231 - val_loss: 0.6925 - val_accuracy: 0.5154\n",
      "Epoch 125/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5198 - val_loss: 0.6923 - val_accuracy: 0.5168\n",
      "Epoch 126/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5220 - val_loss: 0.6922 - val_accuracy: 0.5158\n",
      "Epoch 127/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5236 - val_loss: 0.6924 - val_accuracy: 0.5169\n",
      "Epoch 128/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5218 - val_loss: 0.6923 - val_accuracy: 0.5181\n",
      "Epoch 129/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5224 - val_loss: 0.6924 - val_accuracy: 0.5164\n",
      "Epoch 130/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5237 - val_loss: 0.6923 - val_accuracy: 0.5162\n",
      "Epoch 131/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5217 - val_loss: 0.6924 - val_accuracy: 0.5171\n",
      "Epoch 132/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5223 - val_loss: 0.6922 - val_accuracy: 0.5163\n",
      "Epoch 133/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5226 - val_loss: 0.6923 - val_accuracy: 0.5203\n",
      "Epoch 134/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5215 - val_loss: 0.6923 - val_accuracy: 0.5152\n",
      "Epoch 135/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5217 - val_loss: 0.6922 - val_accuracy: 0.5161\n",
      "Epoch 136/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5221 - val_loss: 0.6924 - val_accuracy: 0.5163\n",
      "Epoch 137/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5226 - val_loss: 0.6923 - val_accuracy: 0.5174\n",
      "Epoch 138/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5217 - val_loss: 0.6924 - val_accuracy: 0.5152\n",
      "Epoch 139/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5213 - val_loss: 0.6925 - val_accuracy: 0.5117\n",
      "Epoch 140/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5225 - val_loss: 0.6924 - val_accuracy: 0.5173\n",
      "Epoch 141/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5220 - val_loss: 0.6923 - val_accuracy: 0.5150\n",
      "Epoch 142/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5233 - val_loss: 0.6922 - val_accuracy: 0.5151\n",
      "Epoch 143/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5232 - val_loss: 0.6922 - val_accuracy: 0.5175\n",
      "Epoch 144/1000\n",
      "41154/41154 [==============================] - 1s 14us/sample - loss: 0.6910 - accuracy: 0.5247 - val_loss: 0.6923 - val_accuracy: 0.5181\n",
      "Epoch 145/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5225 - val_loss: 0.6922 - val_accuracy: 0.5150\n",
      "Epoch 146/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5231 - val_loss: 0.6924 - val_accuracy: 0.5153\n",
      "Epoch 147/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5236 - val_loss: 0.6922 - val_accuracy: 0.5177\n",
      "Epoch 148/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5213 - val_loss: 0.6923 - val_accuracy: 0.5159\n",
      "Epoch 149/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5239 - val_loss: 0.6925 - val_accuracy: 0.5169\n",
      "Epoch 150/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5234 - val_loss: 0.6922 - val_accuracy: 0.5169\n",
      "Epoch 151/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5226 - val_loss: 0.6923 - val_accuracy: 0.5170\n",
      "Epoch 152/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5231 - val_loss: 0.6923 - val_accuracy: 0.5174\n",
      "Epoch 153/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5225 - val_loss: 0.6923 - val_accuracy: 0.5169\n",
      "Epoch 154/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5218 - val_loss: 0.6922 - val_accuracy: 0.5173\n",
      "Epoch 155/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5226 - val_loss: 0.6922 - val_accuracy: 0.5150\n",
      "Epoch 156/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5217 - val_loss: 0.6922 - val_accuracy: 0.5169\n",
      "Training with significance = 1.89, run 1\n",
      "Train on 41154 samples, validate on 10289 samples\n",
      "Epoch 1/1000\n",
      "41154/41154 [==============================] - 1s 27us/sample - loss: 0.6948 - accuracy: 0.4970 - val_loss: 0.6931 - val_accuracy: 0.5006\n",
      "Epoch 2/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6927 - accuracy: 0.5135 - val_loss: 0.6934 - val_accuracy: 0.5104\n",
      "Epoch 3/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5159 - val_loss: 0.6932 - val_accuracy: 0.5042\n",
      "Epoch 4/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5164 - val_loss: 0.6928 - val_accuracy: 0.5107\n",
      "Epoch 5/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5164 - val_loss: 0.6925 - val_accuracy: 0.5154\n",
      "Epoch 6/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5166 - val_loss: 0.6925 - val_accuracy: 0.5163\n",
      "Epoch 7/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5182 - val_loss: 0.6924 - val_accuracy: 0.5190\n",
      "Epoch 8/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5167 - val_loss: 0.6923 - val_accuracy: 0.5196\n",
      "Epoch 9/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5171 - val_loss: 0.6923 - val_accuracy: 0.5200\n",
      "Epoch 10/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5193 - val_loss: 0.6925 - val_accuracy: 0.5153\n",
      "Epoch 11/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5189 - val_loss: 0.6924 - val_accuracy: 0.5189\n",
      "Epoch 12/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5189 - val_loss: 0.6923 - val_accuracy: 0.5166\n",
      "Epoch 13/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5184 - val_loss: 0.6923 - val_accuracy: 0.5176\n",
      "Epoch 14/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5179 - val_loss: 0.6922 - val_accuracy: 0.5190\n",
      "Epoch 15/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5194 - val_loss: 0.6923 - val_accuracy: 0.5156\n",
      "Epoch 16/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5193 - val_loss: 0.6923 - val_accuracy: 0.5147\n",
      "Epoch 17/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5202 - val_loss: 0.6922 - val_accuracy: 0.5158\n",
      "Epoch 18/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5197 - val_loss: 0.6922 - val_accuracy: 0.5171\n",
      "Epoch 19/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5186 - val_loss: 0.6921 - val_accuracy: 0.5168\n",
      "Epoch 20/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5186 - val_loss: 0.6920 - val_accuracy: 0.5206\n",
      "Epoch 21/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5195 - val_loss: 0.6921 - val_accuracy: 0.5171\n",
      "Epoch 22/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5201 - val_loss: 0.6924 - val_accuracy: 0.5152\n",
      "Epoch 23/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5192 - val_loss: 0.6921 - val_accuracy: 0.5181\n",
      "Epoch 24/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5184 - val_loss: 0.6922 - val_accuracy: 0.5154\n",
      "Epoch 25/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5204 - val_loss: 0.6922 - val_accuracy: 0.5159\n",
      "Epoch 26/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5197 - val_loss: 0.6921 - val_accuracy: 0.5196\n",
      "Epoch 27/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5206 - val_loss: 0.6924 - val_accuracy: 0.5152\n",
      "Epoch 28/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5202 - val_loss: 0.6921 - val_accuracy: 0.5147\n",
      "Epoch 29/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5184 - val_loss: 0.6922 - val_accuracy: 0.5140\n",
      "Epoch 30/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5205 - val_loss: 0.6921 - val_accuracy: 0.5184\n",
      "Epoch 31/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5179 - val_loss: 0.6920 - val_accuracy: 0.5167\n",
      "Epoch 32/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5205 - val_loss: 0.6923 - val_accuracy: 0.5140\n",
      "Epoch 33/1000\n",
      "41154/41154 [==============================] - 1s 12us/sample - loss: 0.6915 - accuracy: 0.5210 - val_loss: 0.6921 - val_accuracy: 0.5145\n",
      "Epoch 34/1000\n",
      "41154/41154 [==============================] - 1s 12us/sample - loss: 0.6914 - accuracy: 0.5211 - val_loss: 0.6923 - val_accuracy: 0.5165\n",
      "Epoch 35/1000\n",
      "41154/41154 [==============================] - 1s 12us/sample - loss: 0.6915 - accuracy: 0.5201 - val_loss: 0.6922 - val_accuracy: 0.5141\n",
      "Epoch 36/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41154/41154 [==============================] - 1s 12us/sample - loss: 0.6915 - accuracy: 0.5200 - val_loss: 0.6922 - val_accuracy: 0.5192\n",
      "Epoch 37/1000\n",
      "41154/41154 [==============================] - 1s 12us/sample - loss: 0.6915 - accuracy: 0.5195 - val_loss: 0.6924 - val_accuracy: 0.5162\n",
      "Epoch 38/1000\n",
      "41154/41154 [==============================] - 1s 12us/sample - loss: 0.6915 - accuracy: 0.5217 - val_loss: 0.6923 - val_accuracy: 0.5157\n",
      "Epoch 39/1000\n",
      "41154/41154 [==============================] - 1s 12us/sample - loss: 0.6913 - accuracy: 0.5198 - val_loss: 0.6921 - val_accuracy: 0.5185\n",
      "Epoch 40/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5225 - val_loss: 0.6922 - val_accuracy: 0.5175\n",
      "Epoch 41/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5201 - val_loss: 0.6922 - val_accuracy: 0.5160\n",
      "Epoch 42/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5215 - val_loss: 0.6922 - val_accuracy: 0.5155\n",
      "Epoch 43/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5214 - val_loss: 0.6921 - val_accuracy: 0.5172\n",
      "Epoch 44/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5216 - val_loss: 0.6921 - val_accuracy: 0.5165\n",
      "Epoch 45/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5233 - val_loss: 0.6924 - val_accuracy: 0.5117\n",
      "Epoch 46/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5222 - val_loss: 0.6922 - val_accuracy: 0.5138\n",
      "Epoch 47/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5211 - val_loss: 0.6921 - val_accuracy: 0.5148\n",
      "Epoch 48/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5213 - val_loss: 0.6922 - val_accuracy: 0.5147\n",
      "Epoch 49/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5215 - val_loss: 0.6923 - val_accuracy: 0.5162\n",
      "Epoch 50/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5230 - val_loss: 0.6922 - val_accuracy: 0.5189\n",
      "Training with significance = 1.89, run 2\n",
      "Train on 41154 samples, validate on 10289 samples\n",
      "Epoch 1/1000\n",
      "41154/41154 [==============================] - 2s 45us/sample - loss: 0.6940 - accuracy: 0.5057 - val_loss: 0.6929 - val_accuracy: 0.5085\n",
      "Epoch 2/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6926 - accuracy: 0.5123 - val_loss: 0.6927 - val_accuracy: 0.5114\n",
      "Epoch 3/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5165 - val_loss: 0.6924 - val_accuracy: 0.5141\n",
      "Epoch 4/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5168 - val_loss: 0.6923 - val_accuracy: 0.5134\n",
      "Epoch 5/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5167 - val_loss: 0.6922 - val_accuracy: 0.5144\n",
      "Epoch 6/1000\n",
      "41154/41154 [==============================] - 1s 12us/sample - loss: 0.6923 - accuracy: 0.5168 - val_loss: 0.6921 - val_accuracy: 0.5175\n",
      "Epoch 7/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5177 - val_loss: 0.6921 - val_accuracy: 0.5176\n",
      "Epoch 8/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5175 - val_loss: 0.6921 - val_accuracy: 0.5150\n",
      "Epoch 9/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5178 - val_loss: 0.6922 - val_accuracy: 0.5147\n",
      "Epoch 10/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5163 - val_loss: 0.6922 - val_accuracy: 0.5160\n",
      "Epoch 11/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5177 - val_loss: 0.6922 - val_accuracy: 0.5196\n",
      "Epoch 12/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5174 - val_loss: 0.6921 - val_accuracy: 0.5166\n",
      "Epoch 13/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5170 - val_loss: 0.6921 - val_accuracy: 0.5169\n",
      "Epoch 14/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5173 - val_loss: 0.6921 - val_accuracy: 0.5159\n",
      "Epoch 15/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5188 - val_loss: 0.6921 - val_accuracy: 0.5160\n",
      "Epoch 16/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5172 - val_loss: 0.6921 - val_accuracy: 0.5163\n",
      "Epoch 17/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5161 - val_loss: 0.6922 - val_accuracy: 0.5156\n",
      "Epoch 18/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5188 - val_loss: 0.6921 - val_accuracy: 0.5164\n",
      "Epoch 19/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5193 - val_loss: 0.6922 - val_accuracy: 0.5171\n",
      "Epoch 20/1000\n",
      "41154/41154 [==============================] - 1s 12us/sample - loss: 0.6919 - accuracy: 0.5185 - val_loss: 0.6921 - val_accuracy: 0.5185\n",
      "Epoch 21/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5201 - val_loss: 0.6921 - val_accuracy: 0.5147\n",
      "Epoch 22/1000\n",
      "41154/41154 [==============================] - 1s 12us/sample - loss: 0.6918 - accuracy: 0.5188 - val_loss: 0.6921 - val_accuracy: 0.5147\n",
      "Epoch 23/1000\n",
      "41154/41154 [==============================] - 1s 12us/sample - loss: 0.6918 - accuracy: 0.5200 - val_loss: 0.6922 - val_accuracy: 0.5177\n",
      "Epoch 24/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5196 - val_loss: 0.6922 - val_accuracy: 0.5165\n",
      "Epoch 25/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5186 - val_loss: 0.6921 - val_accuracy: 0.5153\n",
      "Epoch 26/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5199 - val_loss: 0.6921 - val_accuracy: 0.5166\n",
      "Epoch 27/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5199 - val_loss: 0.6921 - val_accuracy: 0.5171\n",
      "Epoch 28/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5195 - val_loss: 0.6923 - val_accuracy: 0.5175\n",
      "Epoch 29/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5203 - val_loss: 0.6922 - val_accuracy: 0.5122\n",
      "Epoch 30/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5199 - val_loss: 0.6922 - val_accuracy: 0.5141\n",
      "Epoch 31/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5199 - val_loss: 0.6923 - val_accuracy: 0.5156\n",
      "Epoch 32/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5187 - val_loss: 0.6922 - val_accuracy: 0.5151\n",
      "Epoch 33/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5193 - val_loss: 0.6922 - val_accuracy: 0.5163\n",
      "Epoch 34/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5211 - val_loss: 0.6922 - val_accuracy: 0.5163\n",
      "Epoch 35/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5198 - val_loss: 0.6922 - val_accuracy: 0.5170\n",
      "Epoch 36/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5229 - val_loss: 0.6922 - val_accuracy: 0.5148\n",
      "Epoch 37/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5193 - val_loss: 0.6923 - val_accuracy: 0.5163\n",
      "Epoch 38/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5205 - val_loss: 0.6921 - val_accuracy: 0.5175\n",
      "Epoch 39/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5215 - val_loss: 0.6922 - val_accuracy: 0.5138\n",
      "Epoch 40/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5199 - val_loss: 0.6922 - val_accuracy: 0.5141\n",
      "Epoch 41/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5196 - val_loss: 0.6922 - val_accuracy: 0.5149\n",
      "Epoch 42/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5224 - val_loss: 0.6922 - val_accuracy: 0.5150\n",
      "Epoch 43/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5205 - val_loss: 0.6921 - val_accuracy: 0.5168\n",
      "Epoch 44/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5210 - val_loss: 0.6922 - val_accuracy: 0.5167\n",
      "Epoch 45/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5221 - val_loss: 0.6922 - val_accuracy: 0.5150\n",
      "Epoch 46/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5199 - val_loss: 0.6924 - val_accuracy: 0.5165\n",
      "Epoch 47/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5209 - val_loss: 0.6922 - val_accuracy: 0.5158\n",
      "Epoch 48/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5211 - val_loss: 0.6922 - val_accuracy: 0.5171\n",
      "Epoch 49/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5198 - val_loss: 0.6921 - val_accuracy: 0.5152\n",
      "Epoch 50/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5207 - val_loss: 0.6921 - val_accuracy: 0.5154\n",
      "Epoch 51/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5208 - val_loss: 0.6922 - val_accuracy: 0.5144\n",
      "Training with significance = 1.89, run 3\n",
      "Train on 41154 samples, validate on 10289 samples\n",
      "Epoch 1/1000\n",
      "41154/41154 [==============================] - 1s 28us/sample - loss: 0.6937 - accuracy: 0.5027 - val_loss: 0.6941 - val_accuracy: 0.5011\n",
      "Epoch 2/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6929 - accuracy: 0.5108 - val_loss: 0.6929 - val_accuracy: 0.5099\n",
      "Epoch 3/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6927 - accuracy: 0.5113 - val_loss: 0.6926 - val_accuracy: 0.5212\n",
      "Epoch 4/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6926 - accuracy: 0.5115 - val_loss: 0.6924 - val_accuracy: 0.5195\n",
      "Epoch 5/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6925 - accuracy: 0.5129 - val_loss: 0.6924 - val_accuracy: 0.5217\n",
      "Epoch 6/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5142 - val_loss: 0.6923 - val_accuracy: 0.5194\n",
      "Epoch 7/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5135 - val_loss: 0.6924 - val_accuracy: 0.5205\n",
      "Epoch 8/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5137 - val_loss: 0.6922 - val_accuracy: 0.5212\n",
      "Epoch 9/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5150 - val_loss: 0.6923 - val_accuracy: 0.5190\n",
      "Epoch 10/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5158 - val_loss: 0.6922 - val_accuracy: 0.5203\n",
      "Epoch 11/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5156 - val_loss: 0.6923 - val_accuracy: 0.5189\n",
      "Epoch 12/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5140 - val_loss: 0.6923 - val_accuracy: 0.5201\n",
      "Epoch 13/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5167 - val_loss: 0.6923 - val_accuracy: 0.5181\n",
      "Epoch 14/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5156 - val_loss: 0.6922 - val_accuracy: 0.5188\n",
      "Epoch 15/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5154 - val_loss: 0.6924 - val_accuracy: 0.5196\n",
      "Epoch 16/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5172 - val_loss: 0.6922 - val_accuracy: 0.5197\n",
      "Epoch 17/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5157 - val_loss: 0.6922 - val_accuracy: 0.5186\n",
      "Epoch 18/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5150 - val_loss: 0.6922 - val_accuracy: 0.5165\n",
      "Epoch 19/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5168 - val_loss: 0.6922 - val_accuracy: 0.5190\n",
      "Epoch 20/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5156 - val_loss: 0.6922 - val_accuracy: 0.5187\n",
      "Epoch 21/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5158 - val_loss: 0.6923 - val_accuracy: 0.5181\n",
      "Epoch 22/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5182 - val_loss: 0.6922 - val_accuracy: 0.5159\n",
      "Epoch 23/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5171 - val_loss: 0.6923 - val_accuracy: 0.5184\n",
      "Epoch 24/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5180 - val_loss: 0.6922 - val_accuracy: 0.5186\n",
      "Epoch 25/1000\n",
      "41154/41154 [==============================] - 1s 14us/sample - loss: 0.6918 - accuracy: 0.5170 - val_loss: 0.6923 - val_accuracy: 0.5167\n",
      "Epoch 26/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5189 - val_loss: 0.6923 - val_accuracy: 0.5175\n",
      "Epoch 27/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5193 - val_loss: 0.6922 - val_accuracy: 0.5182\n",
      "Epoch 28/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5193 - val_loss: 0.6921 - val_accuracy: 0.5195\n",
      "Epoch 29/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5174 - val_loss: 0.6921 - val_accuracy: 0.5155\n",
      "Epoch 30/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5173 - val_loss: 0.6922 - val_accuracy: 0.5184\n",
      "Epoch 31/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5179 - val_loss: 0.6921 - val_accuracy: 0.5171\n",
      "Epoch 32/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5172 - val_loss: 0.6923 - val_accuracy: 0.5189\n",
      "Epoch 33/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5187 - val_loss: 0.6923 - val_accuracy: 0.5181\n",
      "Epoch 34/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5168 - val_loss: 0.6922 - val_accuracy: 0.5177\n",
      "Epoch 35/1000\n",
      "41154/41154 [==============================] - 1s 12us/sample - loss: 0.6918 - accuracy: 0.5182 - val_loss: 0.6922 - val_accuracy: 0.5187\n",
      "Epoch 36/1000\n",
      "41154/41154 [==============================] - 1s 12us/sample - loss: 0.6917 - accuracy: 0.5165 - val_loss: 0.6921 - val_accuracy: 0.5188\n",
      "Epoch 37/1000\n",
      "41154/41154 [==============================] - 1s 12us/sample - loss: 0.6916 - accuracy: 0.5185 - val_loss: 0.6923 - val_accuracy: 0.5179\n",
      "Epoch 38/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5194 - val_loss: 0.6922 - val_accuracy: 0.5142\n",
      "Epoch 39/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5177 - val_loss: 0.6922 - val_accuracy: 0.5182\n",
      "Epoch 40/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5211 - val_loss: 0.6923 - val_accuracy: 0.5184\n",
      "Epoch 41/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5174 - val_loss: 0.6922 - val_accuracy: 0.5198\n",
      "Epoch 42/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5176 - val_loss: 0.6923 - val_accuracy: 0.5173\n",
      "Epoch 43/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5182 - val_loss: 0.6922 - val_accuracy: 0.5192\n",
      "Epoch 44/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5182 - val_loss: 0.6923 - val_accuracy: 0.5177\n",
      "Epoch 45/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5174 - val_loss: 0.6923 - val_accuracy: 0.5167\n",
      "Epoch 46/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5191 - val_loss: 0.6923 - val_accuracy: 0.5200\n",
      "Epoch 47/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5181 - val_loss: 0.6923 - val_accuracy: 0.5183\n",
      "Epoch 48/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5193 - val_loss: 0.6925 - val_accuracy: 0.5166\n",
      "Epoch 49/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5190 - val_loss: 0.6924 - val_accuracy: 0.5162\n",
      "Epoch 50/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5189 - val_loss: 0.6923 - val_accuracy: 0.5170\n",
      "Epoch 51/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5167 - val_loss: 0.6923 - val_accuracy: 0.5166\n",
      "Epoch 52/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5160 - val_loss: 0.6924 - val_accuracy: 0.5170\n",
      "Epoch 53/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5194 - val_loss: 0.6924 - val_accuracy: 0.5180\n",
      "Epoch 54/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5178 - val_loss: 0.6924 - val_accuracy: 0.5172\n",
      "Epoch 55/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5191 - val_loss: 0.6923 - val_accuracy: 0.5163\n",
      "Epoch 56/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5207 - val_loss: 0.6925 - val_accuracy: 0.5169\n",
      "Epoch 57/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5193 - val_loss: 0.6926 - val_accuracy: 0.5155\n",
      "Epoch 58/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5193 - val_loss: 0.6923 - val_accuracy: 0.5170\n",
      "Epoch 59/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5199 - val_loss: 0.6923 - val_accuracy: 0.5173\n",
      "Training with significance = 1.89, run 4\n",
      "Train on 41154 samples, validate on 10289 samples\n",
      "Epoch 1/1000\n",
      "41154/41154 [==============================] - 1s 28us/sample - loss: 0.6936 - accuracy: 0.5047 - val_loss: 0.6934 - val_accuracy: 0.5002\n",
      "Epoch 2/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6925 - accuracy: 0.5125 - val_loss: 0.6931 - val_accuracy: 0.5136\n",
      "Epoch 3/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5147 - val_loss: 0.6924 - val_accuracy: 0.5146\n",
      "Epoch 4/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5152 - val_loss: 0.6923 - val_accuracy: 0.5158\n",
      "Epoch 5/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5153 - val_loss: 0.6923 - val_accuracy: 0.5141\n",
      "Epoch 6/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5177 - val_loss: 0.6923 - val_accuracy: 0.5147\n",
      "Epoch 7/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5174 - val_loss: 0.6924 - val_accuracy: 0.5117\n",
      "Epoch 8/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5156 - val_loss: 0.6924 - val_accuracy: 0.5117\n",
      "Epoch 9/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5180 - val_loss: 0.6924 - val_accuracy: 0.5113\n",
      "Epoch 10/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5188 - val_loss: 0.6925 - val_accuracy: 0.5127\n",
      "Epoch 11/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5183 - val_loss: 0.6925 - val_accuracy: 0.5143\n",
      "Epoch 12/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5189 - val_loss: 0.6924 - val_accuracy: 0.5132\n",
      "Epoch 13/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5183 - val_loss: 0.6924 - val_accuracy: 0.5140\n",
      "Epoch 14/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5175 - val_loss: 0.6923 - val_accuracy: 0.5105\n",
      "Epoch 15/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5177 - val_loss: 0.6924 - val_accuracy: 0.5117\n",
      "Epoch 16/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5179 - val_loss: 0.6923 - val_accuracy: 0.5125\n",
      "Epoch 17/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5208 - val_loss: 0.6925 - val_accuracy: 0.5118\n",
      "Epoch 18/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5196 - val_loss: 0.6924 - val_accuracy: 0.5130\n",
      "Epoch 19/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5198 - val_loss: 0.6923 - val_accuracy: 0.5114\n",
      "Epoch 20/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5218 - val_loss: 0.6924 - val_accuracy: 0.5150\n",
      "Epoch 21/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5209 - val_loss: 0.6924 - val_accuracy: 0.5138\n",
      "Epoch 22/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5193 - val_loss: 0.6925 - val_accuracy: 0.5097\n",
      "Epoch 23/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5216 - val_loss: 0.6923 - val_accuracy: 0.5110\n",
      "Epoch 24/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5195 - val_loss: 0.6924 - val_accuracy: 0.5136\n",
      "Epoch 25/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5208 - val_loss: 0.6925 - val_accuracy: 0.5141\n",
      "Epoch 26/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5199 - val_loss: 0.6925 - val_accuracy: 0.5108\n",
      "Epoch 27/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5216 - val_loss: 0.6926 - val_accuracy: 0.5130\n",
      "Epoch 28/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5220 - val_loss: 0.6924 - val_accuracy: 0.5138\n",
      "Epoch 29/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5204 - val_loss: 0.6924 - val_accuracy: 0.5132\n",
      "Epoch 30/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5206 - val_loss: 0.6924 - val_accuracy: 0.5113\n",
      "Epoch 31/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5207 - val_loss: 0.6924 - val_accuracy: 0.5104\n",
      "Epoch 32/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5201 - val_loss: 0.6924 - val_accuracy: 0.5122\n",
      "Epoch 33/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5209 - val_loss: 0.6925 - val_accuracy: 0.5120\n",
      "Epoch 34/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5208 - val_loss: 0.6924 - val_accuracy: 0.5137\n",
      "Epoch 35/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5222 - val_loss: 0.6923 - val_accuracy: 0.5125\n",
      "Training with significance = 1.89, run 5\n",
      "Train on 41154 samples, validate on 10289 samples\n",
      "Epoch 1/1000\n",
      "41154/41154 [==============================] - 1s 27us/sample - loss: 0.6928 - accuracy: 0.5114 - val_loss: 0.6946 - val_accuracy: 0.5019\n",
      "Epoch 2/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5152 - val_loss: 0.6936 - val_accuracy: 0.5090\n",
      "Epoch 3/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5166 - val_loss: 0.6932 - val_accuracy: 0.5080\n",
      "Epoch 4/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5169 - val_loss: 0.6928 - val_accuracy: 0.5073\n",
      "Epoch 5/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5165 - val_loss: 0.6928 - val_accuracy: 0.5096\n",
      "Epoch 6/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5168 - val_loss: 0.6928 - val_accuracy: 0.5094\n",
      "Epoch 7/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5171 - val_loss: 0.6927 - val_accuracy: 0.5084\n",
      "Epoch 8/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5179 - val_loss: 0.6927 - val_accuracy: 0.5113\n",
      "Epoch 9/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5174 - val_loss: 0.6926 - val_accuracy: 0.5090\n",
      "Epoch 10/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5171 - val_loss: 0.6929 - val_accuracy: 0.5110\n",
      "Epoch 11/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5176 - val_loss: 0.6928 - val_accuracy: 0.5112\n",
      "Epoch 12/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5174 - val_loss: 0.6927 - val_accuracy: 0.5097\n",
      "Epoch 13/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5155 - val_loss: 0.6925 - val_accuracy: 0.5135\n",
      "Epoch 14/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5187 - val_loss: 0.6926 - val_accuracy: 0.5087\n",
      "Epoch 15/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5182 - val_loss: 0.6927 - val_accuracy: 0.5125\n",
      "Epoch 16/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5202 - val_loss: 0.6926 - val_accuracy: 0.5085\n",
      "Epoch 17/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5194 - val_loss: 0.6926 - val_accuracy: 0.5086\n",
      "Epoch 18/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5180 - val_loss: 0.6927 - val_accuracy: 0.5091\n",
      "Epoch 19/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5195 - val_loss: 0.6926 - val_accuracy: 0.5048\n",
      "Epoch 20/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5195 - val_loss: 0.6926 - val_accuracy: 0.5077\n",
      "Epoch 21/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5210 - val_loss: 0.6928 - val_accuracy: 0.5104\n",
      "Epoch 22/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5200 - val_loss: 0.6927 - val_accuracy: 0.5069\n",
      "Epoch 23/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5199 - val_loss: 0.6927 - val_accuracy: 0.5068\n",
      "Epoch 24/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5199 - val_loss: 0.6926 - val_accuracy: 0.5109\n",
      "Epoch 25/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5213 - val_loss: 0.6927 - val_accuracy: 0.5099\n",
      "Epoch 26/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5207 - val_loss: 0.6927 - val_accuracy: 0.5069\n",
      "Epoch 27/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5223 - val_loss: 0.6927 - val_accuracy: 0.5080\n",
      "Epoch 28/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5199 - val_loss: 0.6926 - val_accuracy: 0.5124\n",
      "Epoch 29/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5218 - val_loss: 0.6928 - val_accuracy: 0.5055\n",
      "Epoch 30/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5214 - val_loss: 0.6927 - val_accuracy: 0.5076\n",
      "Epoch 31/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5200 - val_loss: 0.6928 - val_accuracy: 0.5078\n",
      "Epoch 32/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5214 - val_loss: 0.6928 - val_accuracy: 0.5062\n",
      "Epoch 33/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5221 - val_loss: 0.6928 - val_accuracy: 0.5118\n",
      "Epoch 34/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5202 - val_loss: 0.6930 - val_accuracy: 0.5076\n",
      "Epoch 35/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5197 - val_loss: 0.6927 - val_accuracy: 0.5101\n",
      "Epoch 36/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5228 - val_loss: 0.6927 - val_accuracy: 0.5072\n",
      "Epoch 37/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5225 - val_loss: 0.6929 - val_accuracy: 0.5074\n",
      "Epoch 38/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5209 - val_loss: 0.6928 - val_accuracy: 0.5078\n",
      "Epoch 39/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5190 - val_loss: 0.6928 - val_accuracy: 0.5122\n",
      "Epoch 40/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5204 - val_loss: 0.6929 - val_accuracy: 0.5125\n",
      "Epoch 41/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5191 - val_loss: 0.6927 - val_accuracy: 0.5081\n",
      "Epoch 42/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5206 - val_loss: 0.6929 - val_accuracy: 0.5098\n",
      "Epoch 43/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5217 - val_loss: 0.6927 - val_accuracy: 0.5133\n",
      "Training with significance = 1.89, run 6\n",
      "Train on 41154 samples, validate on 10289 samples\n",
      "Epoch 1/1000\n",
      "41154/41154 [==============================] - 1s 27us/sample - loss: 0.6934 - accuracy: 0.5086 - val_loss: 0.6939 - val_accuracy: 0.4971\n",
      "Epoch 2/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6927 - accuracy: 0.5122 - val_loss: 0.6927 - val_accuracy: 0.5121\n",
      "Epoch 3/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6925 - accuracy: 0.5139 - val_loss: 0.6925 - val_accuracy: 0.5135\n",
      "Epoch 4/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5130 - val_loss: 0.6924 - val_accuracy: 0.5149\n",
      "Epoch 5/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5127 - val_loss: 0.6925 - val_accuracy: 0.5167\n",
      "Epoch 6/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5158 - val_loss: 0.6926 - val_accuracy: 0.5166\n",
      "Epoch 7/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5164 - val_loss: 0.6924 - val_accuracy: 0.5141\n",
      "Epoch 8/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5150 - val_loss: 0.6925 - val_accuracy: 0.5138\n",
      "Epoch 9/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5173 - val_loss: 0.6924 - val_accuracy: 0.5150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5158 - val_loss: 0.6923 - val_accuracy: 0.5163\n",
      "Epoch 11/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5162 - val_loss: 0.6924 - val_accuracy: 0.5175\n",
      "Epoch 12/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5148 - val_loss: 0.6925 - val_accuracy: 0.5162\n",
      "Epoch 13/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5168 - val_loss: 0.6923 - val_accuracy: 0.5163\n",
      "Epoch 14/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5181 - val_loss: 0.6924 - val_accuracy: 0.5153\n",
      "Epoch 15/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5170 - val_loss: 0.6923 - val_accuracy: 0.5152\n",
      "Epoch 16/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5168 - val_loss: 0.6923 - val_accuracy: 0.5179\n",
      "Epoch 17/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5161 - val_loss: 0.6923 - val_accuracy: 0.5175\n",
      "Epoch 18/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5152 - val_loss: 0.6923 - val_accuracy: 0.5150\n",
      "Epoch 19/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5156 - val_loss: 0.6923 - val_accuracy: 0.5171\n",
      "Epoch 20/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5176 - val_loss: 0.6924 - val_accuracy: 0.5167\n",
      "Epoch 21/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5181 - val_loss: 0.6923 - val_accuracy: 0.5173\n",
      "Epoch 22/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5189 - val_loss: 0.6923 - val_accuracy: 0.5167\n",
      "Epoch 23/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5160 - val_loss: 0.6923 - val_accuracy: 0.5169\n",
      "Epoch 24/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5167 - val_loss: 0.6922 - val_accuracy: 0.5186\n",
      "Epoch 25/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5183 - val_loss: 0.6923 - val_accuracy: 0.5153\n",
      "Epoch 26/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5165 - val_loss: 0.6922 - val_accuracy: 0.5162\n",
      "Epoch 27/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5176 - val_loss: 0.6924 - val_accuracy: 0.5146\n",
      "Epoch 28/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5189 - val_loss: 0.6923 - val_accuracy: 0.5161\n",
      "Epoch 29/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5170 - val_loss: 0.6923 - val_accuracy: 0.5144\n",
      "Epoch 30/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5166 - val_loss: 0.6923 - val_accuracy: 0.5171\n",
      "Epoch 31/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5171 - val_loss: 0.6922 - val_accuracy: 0.5148\n",
      "Epoch 32/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5176 - val_loss: 0.6923 - val_accuracy: 0.5157\n",
      "Epoch 33/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5177 - val_loss: 0.6923 - val_accuracy: 0.5144\n",
      "Epoch 34/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5175 - val_loss: 0.6924 - val_accuracy: 0.5160\n",
      "Epoch 35/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5182 - val_loss: 0.6922 - val_accuracy: 0.5155\n",
      "Epoch 36/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5180 - val_loss: 0.6922 - val_accuracy: 0.5171\n",
      "Epoch 37/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5165 - val_loss: 0.6922 - val_accuracy: 0.5179\n",
      "Epoch 38/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5182 - val_loss: 0.6923 - val_accuracy: 0.5158\n",
      "Epoch 39/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5203 - val_loss: 0.6923 - val_accuracy: 0.5163\n",
      "Epoch 40/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5174 - val_loss: 0.6923 - val_accuracy: 0.5145\n",
      "Epoch 41/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5187 - val_loss: 0.6922 - val_accuracy: 0.5145\n",
      "Epoch 42/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5192 - val_loss: 0.6922 - val_accuracy: 0.5154\n",
      "Epoch 43/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5190 - val_loss: 0.6924 - val_accuracy: 0.5173\n",
      "Epoch 44/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5174 - val_loss: 0.6922 - val_accuracy: 0.5164\n",
      "Epoch 45/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5183 - val_loss: 0.6923 - val_accuracy: 0.5149\n",
      "Epoch 46/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5185 - val_loss: 0.6923 - val_accuracy: 0.5147\n",
      "Epoch 47/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5192 - val_loss: 0.6923 - val_accuracy: 0.5140\n",
      "Epoch 48/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5204 - val_loss: 0.6923 - val_accuracy: 0.5130\n",
      "Epoch 49/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5195 - val_loss: 0.6924 - val_accuracy: 0.5154\n",
      "Epoch 50/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5186 - val_loss: 0.6925 - val_accuracy: 0.5147\n",
      "Epoch 51/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5179 - val_loss: 0.6923 - val_accuracy: 0.5161\n",
      "Epoch 52/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5201 - val_loss: 0.6922 - val_accuracy: 0.5132\n",
      "Epoch 53/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5197 - val_loss: 0.6923 - val_accuracy: 0.5181\n",
      "Epoch 54/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5201 - val_loss: 0.6922 - val_accuracy: 0.5167\n",
      "Epoch 55/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5189 - val_loss: 0.6923 - val_accuracy: 0.5162\n",
      "Epoch 56/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5198 - val_loss: 0.6924 - val_accuracy: 0.5164\n",
      "Epoch 57/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5183 - val_loss: 0.6924 - val_accuracy: 0.5142\n",
      "Epoch 58/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5187 - val_loss: 0.6923 - val_accuracy: 0.5150\n",
      "Epoch 59/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5176 - val_loss: 0.6922 - val_accuracy: 0.5137\n",
      "Epoch 60/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5199 - val_loss: 0.6923 - val_accuracy: 0.5153\n",
      "Epoch 61/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5181 - val_loss: 0.6923 - val_accuracy: 0.5174\n",
      "Epoch 62/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5192 - val_loss: 0.6924 - val_accuracy: 0.5138\n",
      "Epoch 63/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5196 - val_loss: 0.6926 - val_accuracy: 0.5156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5194 - val_loss: 0.6923 - val_accuracy: 0.5163\n",
      "Epoch 65/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5190 - val_loss: 0.6923 - val_accuracy: 0.5108\n",
      "Training with significance = 1.89, run 7\n",
      "Train on 41154 samples, validate on 10289 samples\n",
      "Epoch 1/1000\n",
      "41154/41154 [==============================] - 2s 44us/sample - loss: 0.6930 - accuracy: 0.5095 - val_loss: 0.6936 - val_accuracy: 0.5059\n",
      "Epoch 2/1000\n",
      "41154/41154 [==============================] - 1s 12us/sample - loss: 0.6925 - accuracy: 0.5113 - val_loss: 0.6928 - val_accuracy: 0.5059\n",
      "Epoch 3/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5143 - val_loss: 0.6922 - val_accuracy: 0.5217\n",
      "Epoch 4/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5140 - val_loss: 0.6923 - val_accuracy: 0.5165\n",
      "Epoch 5/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5143 - val_loss: 0.6921 - val_accuracy: 0.5219\n",
      "Epoch 6/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5147 - val_loss: 0.6920 - val_accuracy: 0.5195\n",
      "Epoch 7/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5155 - val_loss: 0.6920 - val_accuracy: 0.5215\n",
      "Epoch 8/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5142 - val_loss: 0.6921 - val_accuracy: 0.5217\n",
      "Epoch 9/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5143 - val_loss: 0.6919 - val_accuracy: 0.5225\n",
      "Epoch 10/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5172 - val_loss: 0.6919 - val_accuracy: 0.5254\n",
      "Epoch 11/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5155 - val_loss: 0.6919 - val_accuracy: 0.5257\n",
      "Epoch 12/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5146 - val_loss: 0.6919 - val_accuracy: 0.5241\n",
      "Epoch 13/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5152 - val_loss: 0.6919 - val_accuracy: 0.5212\n",
      "Epoch 14/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5179 - val_loss: 0.6919 - val_accuracy: 0.5230\n",
      "Epoch 15/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5169 - val_loss: 0.6918 - val_accuracy: 0.5213\n",
      "Epoch 16/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5167 - val_loss: 0.6920 - val_accuracy: 0.5200\n",
      "Epoch 17/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5168 - val_loss: 0.6919 - val_accuracy: 0.5223\n",
      "Epoch 18/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5165 - val_loss: 0.6919 - val_accuracy: 0.5242\n",
      "Epoch 19/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5187 - val_loss: 0.6919 - val_accuracy: 0.5220\n",
      "Epoch 20/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5172 - val_loss: 0.6918 - val_accuracy: 0.5216\n",
      "Epoch 21/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5174 - val_loss: 0.6918 - val_accuracy: 0.5221\n",
      "Epoch 22/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5183 - val_loss: 0.6918 - val_accuracy: 0.5231\n",
      "Epoch 23/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5181 - val_loss: 0.6919 - val_accuracy: 0.5180\n",
      "Epoch 24/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5176 - val_loss: 0.6920 - val_accuracy: 0.5203\n",
      "Epoch 25/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5170 - val_loss: 0.6919 - val_accuracy: 0.5205\n",
      "Epoch 26/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5179 - val_loss: 0.6920 - val_accuracy: 0.5221\n",
      "Epoch 27/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5182 - val_loss: 0.6920 - val_accuracy: 0.5199\n",
      "Epoch 28/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5174 - val_loss: 0.6919 - val_accuracy: 0.5220\n",
      "Epoch 29/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5181 - val_loss: 0.6920 - val_accuracy: 0.5182\n",
      "Epoch 30/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5194 - val_loss: 0.6919 - val_accuracy: 0.5213\n",
      "Epoch 31/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5178 - val_loss: 0.6920 - val_accuracy: 0.5221\n",
      "Epoch 32/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5194 - val_loss: 0.6919 - val_accuracy: 0.5193\n",
      "Epoch 33/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5199 - val_loss: 0.6920 - val_accuracy: 0.5200\n",
      "Epoch 34/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5165 - val_loss: 0.6919 - val_accuracy: 0.5179\n",
      "Epoch 35/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5216 - val_loss: 0.6919 - val_accuracy: 0.5156\n",
      "Epoch 36/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5176 - val_loss: 0.6919 - val_accuracy: 0.5220\n",
      "Epoch 37/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5191 - val_loss: 0.6919 - val_accuracy: 0.5215\n",
      "Epoch 38/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5186 - val_loss: 0.6920 - val_accuracy: 0.5150\n",
      "Epoch 39/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5193 - val_loss: 0.6919 - val_accuracy: 0.5179\n",
      "Epoch 40/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5199 - val_loss: 0.6919 - val_accuracy: 0.5226\n",
      "Epoch 41/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5183 - val_loss: 0.6918 - val_accuracy: 0.5198\n",
      "Epoch 42/1000\n",
      "41154/41154 [==============================] - 0s 12us/sample - loss: 0.6916 - accuracy: 0.5182 - val_loss: 0.6920 - val_accuracy: 0.5173\n",
      "Epoch 43/1000\n",
      "41154/41154 [==============================] - 0s 12us/sample - loss: 0.6916 - accuracy: 0.5209 - val_loss: 0.6920 - val_accuracy: 0.5181\n",
      "Epoch 44/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5192 - val_loss: 0.6919 - val_accuracy: 0.5209\n",
      "Epoch 45/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5186 - val_loss: 0.6920 - val_accuracy: 0.5178\n",
      "Epoch 46/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5168 - val_loss: 0.6919 - val_accuracy: 0.5198\n",
      "Epoch 47/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5176 - val_loss: 0.6919 - val_accuracy: 0.5208\n",
      "Epoch 48/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5195 - val_loss: 0.6919 - val_accuracy: 0.5205\n",
      "Epoch 49/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5197 - val_loss: 0.6919 - val_accuracy: 0.5199\n",
      "Epoch 50/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5200 - val_loss: 0.6920 - val_accuracy: 0.5217\n",
      "Epoch 51/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5197 - val_loss: 0.6920 - val_accuracy: 0.5194\n",
      "Epoch 52/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5193 - val_loss: 0.6919 - val_accuracy: 0.5184\n",
      "Epoch 53/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5191 - val_loss: 0.6919 - val_accuracy: 0.5224\n",
      "Epoch 54/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5183 - val_loss: 0.6919 - val_accuracy: 0.5188\n",
      "Epoch 55/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5204 - val_loss: 0.6920 - val_accuracy: 0.5197\n",
      "Epoch 56/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5199 - val_loss: 0.6920 - val_accuracy: 0.5154\n",
      "Epoch 57/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5196 - val_loss: 0.6919 - val_accuracy: 0.5208\n",
      "Epoch 58/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5200 - val_loss: 0.6920 - val_accuracy: 0.5140\n",
      "Epoch 59/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5200 - val_loss: 0.6919 - val_accuracy: 0.5149\n",
      "Epoch 60/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5204 - val_loss: 0.6919 - val_accuracy: 0.5186\n",
      "Epoch 61/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5225 - val_loss: 0.6923 - val_accuracy: 0.5135\n",
      "Epoch 62/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5215 - val_loss: 0.6920 - val_accuracy: 0.5195\n",
      "Epoch 63/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5214 - val_loss: 0.6919 - val_accuracy: 0.5167\n",
      "Epoch 64/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5226 - val_loss: 0.6920 - val_accuracy: 0.5199\n",
      "Epoch 65/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5195 - val_loss: 0.6920 - val_accuracy: 0.5133\n",
      "Epoch 66/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5199 - val_loss: 0.6920 - val_accuracy: 0.5100\n",
      "Epoch 67/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5217 - val_loss: 0.6920 - val_accuracy: 0.5208\n",
      "Epoch 68/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5206 - val_loss: 0.6919 - val_accuracy: 0.5216\n",
      "Epoch 69/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5206 - val_loss: 0.6920 - val_accuracy: 0.5152\n",
      "Epoch 70/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5227 - val_loss: 0.6920 - val_accuracy: 0.5165\n",
      "Epoch 71/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5209 - val_loss: 0.6919 - val_accuracy: 0.5184\n",
      "Training with significance = 1.89, run 8\n",
      "Train on 41154 samples, validate on 10289 samples\n",
      "Epoch 1/1000\n",
      "41154/41154 [==============================] - 1s 28us/sample - loss: 0.6943 - accuracy: 0.5026 - val_loss: 0.6936 - val_accuracy: 0.5184\n",
      "Epoch 2/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6929 - accuracy: 0.5107 - val_loss: 0.6933 - val_accuracy: 0.5057\n",
      "Epoch 3/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6926 - accuracy: 0.5121 - val_loss: 0.6930 - val_accuracy: 0.5140\n",
      "Epoch 4/1000\n",
      "41154/41154 [==============================] - 1s 14us/sample - loss: 0.6924 - accuracy: 0.5157 - val_loss: 0.6926 - val_accuracy: 0.5166\n",
      "Epoch 5/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5147 - val_loss: 0.6923 - val_accuracy: 0.5173\n",
      "Epoch 6/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5149 - val_loss: 0.6920 - val_accuracy: 0.5244\n",
      "Epoch 7/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5146 - val_loss: 0.6921 - val_accuracy: 0.5222\n",
      "Epoch 8/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5166 - val_loss: 0.6921 - val_accuracy: 0.5218\n",
      "Epoch 9/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5166 - val_loss: 0.6920 - val_accuracy: 0.5223\n",
      "Epoch 10/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5150 - val_loss: 0.6921 - val_accuracy: 0.5203\n",
      "Epoch 11/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5171 - val_loss: 0.6922 - val_accuracy: 0.5148\n",
      "Epoch 12/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5157 - val_loss: 0.6921 - val_accuracy: 0.5187\n",
      "Epoch 13/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5186 - val_loss: 0.6920 - val_accuracy: 0.5195\n",
      "Epoch 14/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5177 - val_loss: 0.6922 - val_accuracy: 0.5200\n",
      "Epoch 15/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5147 - val_loss: 0.6920 - val_accuracy: 0.5234\n",
      "Epoch 16/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5194 - val_loss: 0.6921 - val_accuracy: 0.5196\n",
      "Epoch 17/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5186 - val_loss: 0.6920 - val_accuracy: 0.5223\n",
      "Epoch 18/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5176 - val_loss: 0.6918 - val_accuracy: 0.5235\n",
      "Epoch 19/1000\n",
      "41154/41154 [==============================] - 1s 12us/sample - loss: 0.6919 - accuracy: 0.5173 - val_loss: 0.6919 - val_accuracy: 0.5238\n",
      "Epoch 20/1000\n",
      "41154/41154 [==============================] - 1s 12us/sample - loss: 0.6917 - accuracy: 0.5183 - val_loss: 0.6920 - val_accuracy: 0.5220\n",
      "Epoch 21/1000\n",
      "41154/41154 [==============================] - 1s 12us/sample - loss: 0.6917 - accuracy: 0.5190 - val_loss: 0.6921 - val_accuracy: 0.5178\n",
      "Epoch 22/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5166 - val_loss: 0.6920 - val_accuracy: 0.5179\n",
      "Epoch 23/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5184 - val_loss: 0.6920 - val_accuracy: 0.5200\n",
      "Epoch 24/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5173 - val_loss: 0.6919 - val_accuracy: 0.5216\n",
      "Epoch 25/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5191 - val_loss: 0.6920 - val_accuracy: 0.5209\n",
      "Epoch 26/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5179 - val_loss: 0.6921 - val_accuracy: 0.5215\n",
      "Epoch 27/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5172 - val_loss: 0.6920 - val_accuracy: 0.5173\n",
      "Epoch 28/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5195 - val_loss: 0.6921 - val_accuracy: 0.5163\n",
      "Epoch 29/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5180 - val_loss: 0.6920 - val_accuracy: 0.5185\n",
      "Epoch 30/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5199 - val_loss: 0.6922 - val_accuracy: 0.5167\n",
      "Epoch 31/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5191 - val_loss: 0.6922 - val_accuracy: 0.5168\n",
      "Epoch 32/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5182 - val_loss: 0.6919 - val_accuracy: 0.5175\n",
      "Epoch 33/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5166 - val_loss: 0.6920 - val_accuracy: 0.5162\n",
      "Epoch 34/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5173 - val_loss: 0.6922 - val_accuracy: 0.5163\n",
      "Epoch 35/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5186 - val_loss: 0.6921 - val_accuracy: 0.5157\n",
      "Epoch 36/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5196 - val_loss: 0.6921 - val_accuracy: 0.5175\n",
      "Epoch 37/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5196 - val_loss: 0.6920 - val_accuracy: 0.5188\n",
      "Epoch 38/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5189 - val_loss: 0.6921 - val_accuracy: 0.5173\n",
      "Epoch 39/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5202 - val_loss: 0.6920 - val_accuracy: 0.5196\n",
      "Epoch 40/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5209 - val_loss: 0.6923 - val_accuracy: 0.5155\n",
      "Epoch 41/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5196 - val_loss: 0.6920 - val_accuracy: 0.5167\n",
      "Epoch 42/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5184 - val_loss: 0.6921 - val_accuracy: 0.5130\n",
      "Epoch 43/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5199 - val_loss: 0.6922 - val_accuracy: 0.5160\n",
      "Epoch 44/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5185 - val_loss: 0.6921 - val_accuracy: 0.5154\n",
      "Epoch 45/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5197 - val_loss: 0.6924 - val_accuracy: 0.5128\n",
      "Epoch 46/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5194 - val_loss: 0.6921 - val_accuracy: 0.5161\n",
      "Epoch 47/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5190 - val_loss: 0.6920 - val_accuracy: 0.5207\n",
      "Epoch 48/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5196 - val_loss: 0.6921 - val_accuracy: 0.5174\n",
      "Training with significance = 1.89, run 9\n",
      "Train on 41154 samples, validate on 10289 samples\n",
      "Epoch 1/1000\n",
      "41154/41154 [==============================] - 1s 27us/sample - loss: 0.6934 - accuracy: 0.5076 - val_loss: 0.6947 - val_accuracy: 0.4941\n",
      "Epoch 2/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6926 - accuracy: 0.5114 - val_loss: 0.6933 - val_accuracy: 0.5017\n",
      "Epoch 3/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5147 - val_loss: 0.6927 - val_accuracy: 0.5107\n",
      "Epoch 4/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5159 - val_loss: 0.6923 - val_accuracy: 0.5202\n",
      "Epoch 5/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5157 - val_loss: 0.6923 - val_accuracy: 0.5217\n",
      "Epoch 6/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5148 - val_loss: 0.6922 - val_accuracy: 0.5197\n",
      "Epoch 7/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5147 - val_loss: 0.6923 - val_accuracy: 0.5179\n",
      "Epoch 8/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5159 - val_loss: 0.6923 - val_accuracy: 0.5191\n",
      "Epoch 9/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5149 - val_loss: 0.6923 - val_accuracy: 0.5189\n",
      "Epoch 10/1000\n",
      "41154/41154 [==============================] - 1s 12us/sample - loss: 0.6921 - accuracy: 0.5168 - val_loss: 0.6922 - val_accuracy: 0.5204\n",
      "Epoch 11/1000\n",
      "41154/41154 [==============================] - 1s 12us/sample - loss: 0.6920 - accuracy: 0.5173 - val_loss: 0.6923 - val_accuracy: 0.5195\n",
      "Epoch 12/1000\n",
      "41154/41154 [==============================] - 1s 12us/sample - loss: 0.6921 - accuracy: 0.5162 - val_loss: 0.6922 - val_accuracy: 0.5177\n",
      "Epoch 13/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5164 - val_loss: 0.6922 - val_accuracy: 0.5177\n",
      "Epoch 14/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5158 - val_loss: 0.6922 - val_accuracy: 0.5176\n",
      "Epoch 15/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5170 - val_loss: 0.6922 - val_accuracy: 0.5166\n",
      "Epoch 16/1000\n",
      "41154/41154 [==============================] - 1s 12us/sample - loss: 0.6920 - accuracy: 0.5158 - val_loss: 0.6922 - val_accuracy: 0.5173\n",
      "Epoch 17/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5176 - val_loss: 0.6922 - val_accuracy: 0.5190\n",
      "Epoch 18/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5181 - val_loss: 0.6923 - val_accuracy: 0.5204\n",
      "Epoch 19/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5181 - val_loss: 0.6921 - val_accuracy: 0.5177\n",
      "Epoch 20/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5177 - val_loss: 0.6921 - val_accuracy: 0.5181\n",
      "Epoch 21/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5193 - val_loss: 0.6922 - val_accuracy: 0.5185\n",
      "Epoch 22/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5171 - val_loss: 0.6922 - val_accuracy: 0.5178\n",
      "Epoch 23/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5165 - val_loss: 0.6923 - val_accuracy: 0.5175\n",
      "Epoch 24/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5170 - val_loss: 0.6924 - val_accuracy: 0.5148\n",
      "Epoch 25/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5177 - val_loss: 0.6922 - val_accuracy: 0.5191\n",
      "Epoch 26/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5165 - val_loss: 0.6923 - val_accuracy: 0.5169\n",
      "Epoch 27/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5182 - val_loss: 0.6922 - val_accuracy: 0.5183\n",
      "Epoch 28/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5169 - val_loss: 0.6923 - val_accuracy: 0.5204\n",
      "Epoch 29/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5182 - val_loss: 0.6924 - val_accuracy: 0.5191\n",
      "Epoch 30/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5180 - val_loss: 0.6922 - val_accuracy: 0.5187\n",
      "Epoch 31/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5188 - val_loss: 0.6922 - val_accuracy: 0.5177\n",
      "Epoch 32/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5197 - val_loss: 0.6922 - val_accuracy: 0.5173\n",
      "Epoch 33/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5165 - val_loss: 0.6922 - val_accuracy: 0.5163\n",
      "Epoch 34/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5187 - val_loss: 0.6922 - val_accuracy: 0.5163\n",
      "Epoch 35/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5191 - val_loss: 0.6922 - val_accuracy: 0.5159\n",
      "Epoch 36/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5188 - val_loss: 0.6924 - val_accuracy: 0.5160\n",
      "Epoch 37/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5183 - val_loss: 0.6924 - val_accuracy: 0.5176\n",
      "Epoch 38/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5192 - val_loss: 0.6923 - val_accuracy: 0.5187\n",
      "Epoch 39/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5219 - val_loss: 0.6923 - val_accuracy: 0.5187\n",
      "Epoch 40/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5179 - val_loss: 0.6923 - val_accuracy: 0.5155\n",
      "Epoch 41/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5187 - val_loss: 0.6923 - val_accuracy: 0.5168\n",
      "Epoch 42/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5194 - val_loss: 0.6922 - val_accuracy: 0.5164\n",
      "Epoch 43/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5191 - val_loss: 0.6922 - val_accuracy: 0.5169\n",
      "Epoch 44/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5198 - val_loss: 0.6923 - val_accuracy: 0.5184\n",
      "Epoch 45/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5195 - val_loss: 0.6923 - val_accuracy: 0.5173\n",
      "Epoch 46/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5205 - val_loss: 0.6922 - val_accuracy: 0.5181\n",
      "Epoch 47/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5195 - val_loss: 0.6923 - val_accuracy: 0.5183\n",
      "Epoch 48/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5192 - val_loss: 0.6923 - val_accuracy: 0.5187\n",
      "Epoch 49/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5185 - val_loss: 0.6923 - val_accuracy: 0.5196\n",
      "Epoch 50/1000\n",
      "41154/41154 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5211 - val_loss: 0.6923 - val_accuracy: 0.5172\n",
      "Training with significance = 2.21, run 0\n",
      "Train on 41204 samples, validate on 10302 samples\n",
      "Epoch 1/1000\n",
      "41204/41204 [==============================] - 1s 26us/sample - loss: 0.6933 - accuracy: 0.5085 - val_loss: 0.6956 - val_accuracy: 0.4898\n",
      "Epoch 2/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6928 - accuracy: 0.5119 - val_loss: 0.6931 - val_accuracy: 0.5053\n",
      "Epoch 3/1000\n",
      "41204/41204 [==============================] - 1s 12us/sample - loss: 0.6926 - accuracy: 0.5136 - val_loss: 0.6932 - val_accuracy: 0.5077\n",
      "Epoch 4/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6925 - accuracy: 0.5132 - val_loss: 0.6929 - val_accuracy: 0.5113\n",
      "Epoch 5/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5149 - val_loss: 0.6927 - val_accuracy: 0.5132\n",
      "Epoch 6/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5132 - val_loss: 0.6933 - val_accuracy: 0.5065\n",
      "Epoch 7/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5148 - val_loss: 0.6926 - val_accuracy: 0.5122\n",
      "Epoch 8/1000\n",
      "41204/41204 [==============================] - 1s 14us/sample - loss: 0.6921 - accuracy: 0.5160 - val_loss: 0.6925 - val_accuracy: 0.5120\n",
      "Epoch 9/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5166 - val_loss: 0.6928 - val_accuracy: 0.5104\n",
      "Epoch 10/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5158 - val_loss: 0.6924 - val_accuracy: 0.5118\n",
      "Epoch 11/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5161 - val_loss: 0.6926 - val_accuracy: 0.5125\n",
      "Epoch 12/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5166 - val_loss: 0.6925 - val_accuracy: 0.5125\n",
      "Epoch 13/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5166 - val_loss: 0.6926 - val_accuracy: 0.5120\n",
      "Epoch 14/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5157 - val_loss: 0.6926 - val_accuracy: 0.5106\n",
      "Epoch 15/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5166 - val_loss: 0.6925 - val_accuracy: 0.5121\n",
      "Epoch 16/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5170 - val_loss: 0.6925 - val_accuracy: 0.5159\n",
      "Epoch 17/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5165 - val_loss: 0.6925 - val_accuracy: 0.5139\n",
      "Epoch 18/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5176 - val_loss: 0.6925 - val_accuracy: 0.5140\n",
      "Epoch 19/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5175 - val_loss: 0.6924 - val_accuracy: 0.5123\n",
      "Epoch 20/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5177 - val_loss: 0.6929 - val_accuracy: 0.5099\n",
      "Epoch 21/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5172 - val_loss: 0.6924 - val_accuracy: 0.5136\n",
      "Epoch 22/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5185 - val_loss: 0.6927 - val_accuracy: 0.5093\n",
      "Epoch 23/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5170 - val_loss: 0.6925 - val_accuracy: 0.5129\n",
      "Epoch 24/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5177 - val_loss: 0.6926 - val_accuracy: 0.5119\n",
      "Epoch 25/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5170 - val_loss: 0.6924 - val_accuracy: 0.5141\n",
      "Epoch 26/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5180 - val_loss: 0.6924 - val_accuracy: 0.5131\n",
      "Epoch 27/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5183 - val_loss: 0.6926 - val_accuracy: 0.5131\n",
      "Epoch 28/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5170 - val_loss: 0.6924 - val_accuracy: 0.5155\n",
      "Epoch 29/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5195 - val_loss: 0.6926 - val_accuracy: 0.5095\n",
      "Epoch 30/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5186 - val_loss: 0.6927 - val_accuracy: 0.5112\n",
      "Epoch 31/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5185 - val_loss: 0.6929 - val_accuracy: 0.5083\n",
      "Epoch 32/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5184 - val_loss: 0.6924 - val_accuracy: 0.5154\n",
      "Epoch 33/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5182 - val_loss: 0.6927 - val_accuracy: 0.5088\n",
      "Epoch 34/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5184 - val_loss: 0.6924 - val_accuracy: 0.5153\n",
      "Epoch 35/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5205 - val_loss: 0.6925 - val_accuracy: 0.5152\n",
      "Epoch 36/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5195 - val_loss: 0.6925 - val_accuracy: 0.5115\n",
      "Epoch 37/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5183 - val_loss: 0.6927 - val_accuracy: 0.5095\n",
      "Epoch 38/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5186 - val_loss: 0.6929 - val_accuracy: 0.5094\n",
      "Epoch 39/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5198 - val_loss: 0.6927 - val_accuracy: 0.5090\n",
      "Epoch 40/1000\n",
      "41204/41204 [==============================] - 1s 12us/sample - loss: 0.6916 - accuracy: 0.5189 - val_loss: 0.6928 - val_accuracy: 0.5080\n",
      "Training with significance = 2.21, run 1\n",
      "Train on 41204 samples, validate on 10302 samples\n",
      "Epoch 1/1000\n",
      "41204/41204 [==============================] - 1s 26us/sample - loss: 0.6926 - accuracy: 0.5148 - val_loss: 0.6946 - val_accuracy: 0.5025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5169 - val_loss: 0.6930 - val_accuracy: 0.5121\n",
      "Epoch 3/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5155 - val_loss: 0.6927 - val_accuracy: 0.5165\n",
      "Epoch 4/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5169 - val_loss: 0.6925 - val_accuracy: 0.5155\n",
      "Epoch 5/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5181 - val_loss: 0.6925 - val_accuracy: 0.5132\n",
      "Epoch 6/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5182 - val_loss: 0.6926 - val_accuracy: 0.5133\n",
      "Epoch 7/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5195 - val_loss: 0.6928 - val_accuracy: 0.5130\n",
      "Epoch 8/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5180 - val_loss: 0.6925 - val_accuracy: 0.5142\n",
      "Epoch 9/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5179 - val_loss: 0.6925 - val_accuracy: 0.5131\n",
      "Epoch 10/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5191 - val_loss: 0.6925 - val_accuracy: 0.5144\n",
      "Epoch 11/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5182 - val_loss: 0.6925 - val_accuracy: 0.5159\n",
      "Epoch 12/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5184 - val_loss: 0.6925 - val_accuracy: 0.5154\n",
      "Epoch 13/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5193 - val_loss: 0.6924 - val_accuracy: 0.5145\n",
      "Epoch 14/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5214 - val_loss: 0.6924 - val_accuracy: 0.5142\n",
      "Epoch 15/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5179 - val_loss: 0.6923 - val_accuracy: 0.5160\n",
      "Epoch 16/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5202 - val_loss: 0.6924 - val_accuracy: 0.5157\n",
      "Epoch 17/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5200 - val_loss: 0.6925 - val_accuracy: 0.5144\n",
      "Epoch 18/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5170 - val_loss: 0.6925 - val_accuracy: 0.5147\n",
      "Epoch 19/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5208 - val_loss: 0.6924 - val_accuracy: 0.5164\n",
      "Epoch 20/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5197 - val_loss: 0.6927 - val_accuracy: 0.5138\n",
      "Epoch 21/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5189 - val_loss: 0.6926 - val_accuracy: 0.5123\n",
      "Epoch 22/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5196 - val_loss: 0.6925 - val_accuracy: 0.5149\n",
      "Epoch 23/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5188 - val_loss: 0.6924 - val_accuracy: 0.5135\n",
      "Epoch 24/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5219 - val_loss: 0.6925 - val_accuracy: 0.5145\n",
      "Epoch 25/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5221 - val_loss: 0.6925 - val_accuracy: 0.5149\n",
      "Epoch 26/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5193 - val_loss: 0.6924 - val_accuracy: 0.5168\n",
      "Epoch 27/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5207 - val_loss: 0.6925 - val_accuracy: 0.5165\n",
      "Epoch 28/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5200 - val_loss: 0.6924 - val_accuracy: 0.5171\n",
      "Epoch 29/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5206 - val_loss: 0.6925 - val_accuracy: 0.5140\n",
      "Epoch 30/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5218 - val_loss: 0.6925 - val_accuracy: 0.5146\n",
      "Epoch 31/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5204 - val_loss: 0.6924 - val_accuracy: 0.5146\n",
      "Epoch 32/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5213 - val_loss: 0.6924 - val_accuracy: 0.5152\n",
      "Epoch 33/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5202 - val_loss: 0.6925 - val_accuracy: 0.5130\n",
      "Epoch 34/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5207 - val_loss: 0.6927 - val_accuracy: 0.5130\n",
      "Epoch 35/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5201 - val_loss: 0.6925 - val_accuracy: 0.5147\n",
      "Epoch 36/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5226 - val_loss: 0.6925 - val_accuracy: 0.5160\n",
      "Epoch 37/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5218 - val_loss: 0.6926 - val_accuracy: 0.5182\n",
      "Epoch 38/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5206 - val_loss: 0.6926 - val_accuracy: 0.5117\n",
      "Epoch 39/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5220 - val_loss: 0.6925 - val_accuracy: 0.5168\n",
      "Epoch 40/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5205 - val_loss: 0.6926 - val_accuracy: 0.5149\n",
      "Epoch 41/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5228 - val_loss: 0.6925 - val_accuracy: 0.5166\n",
      "Epoch 42/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5219 - val_loss: 0.6925 - val_accuracy: 0.5118\n",
      "Epoch 43/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5202 - val_loss: 0.6925 - val_accuracy: 0.5174\n",
      "Epoch 44/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5226 - val_loss: 0.6926 - val_accuracy: 0.5113\n",
      "Epoch 45/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5230 - val_loss: 0.6926 - val_accuracy: 0.5137\n",
      "Training with significance = 2.21, run 2\n",
      "Train on 41204 samples, validate on 10302 samples\n",
      "Epoch 1/1000\n",
      "41204/41204 [==============================] - 2s 50us/sample - loss: 0.6940 - accuracy: 0.5084 - val_loss: 0.6928 - val_accuracy: 0.5098\n",
      "Epoch 2/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6928 - accuracy: 0.5139 - val_loss: 0.6927 - val_accuracy: 0.5108\n",
      "Epoch 3/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6926 - accuracy: 0.5159 - val_loss: 0.6928 - val_accuracy: 0.5078\n",
      "Epoch 4/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6925 - accuracy: 0.5163 - val_loss: 0.6926 - val_accuracy: 0.5116\n",
      "Epoch 5/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5169 - val_loss: 0.6926 - val_accuracy: 0.5117\n",
      "Epoch 6/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5171 - val_loss: 0.6925 - val_accuracy: 0.5090\n",
      "Epoch 7/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5166 - val_loss: 0.6925 - val_accuracy: 0.5116\n",
      "Epoch 8/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5170 - val_loss: 0.6925 - val_accuracy: 0.5124\n",
      "Epoch 9/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5181 - val_loss: 0.6925 - val_accuracy: 0.5095\n",
      "Epoch 10/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5184 - val_loss: 0.6927 - val_accuracy: 0.5102\n",
      "Epoch 11/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5200 - val_loss: 0.6925 - val_accuracy: 0.5074\n",
      "Epoch 12/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5187 - val_loss: 0.6924 - val_accuracy: 0.5049\n",
      "Epoch 13/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5185 - val_loss: 0.6926 - val_accuracy: 0.5090\n",
      "Epoch 14/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5180 - val_loss: 0.6927 - val_accuracy: 0.5116\n",
      "Epoch 15/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5189 - val_loss: 0.6926 - val_accuracy: 0.5098\n",
      "Epoch 16/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5203 - val_loss: 0.6925 - val_accuracy: 0.5113\n",
      "Epoch 17/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5211 - val_loss: 0.6927 - val_accuracy: 0.5097\n",
      "Epoch 18/1000\n",
      "41204/41204 [==============================] - 1s 12us/sample - loss: 0.6918 - accuracy: 0.5206 - val_loss: 0.6928 - val_accuracy: 0.5105\n",
      "Epoch 19/1000\n",
      "41204/41204 [==============================] - 1s 12us/sample - loss: 0.6919 - accuracy: 0.5213 - val_loss: 0.6930 - val_accuracy: 0.5089\n",
      "Epoch 20/1000\n",
      "41204/41204 [==============================] - 0s 12us/sample - loss: 0.6918 - accuracy: 0.5187 - val_loss: 0.6928 - val_accuracy: 0.5086\n",
      "Epoch 21/1000\n",
      "41204/41204 [==============================] - 1s 12us/sample - loss: 0.6918 - accuracy: 0.5210 - val_loss: 0.6928 - val_accuracy: 0.5090\n",
      "Epoch 22/1000\n",
      "41204/41204 [==============================] - 1s 12us/sample - loss: 0.6917 - accuracy: 0.5227 - val_loss: 0.6927 - val_accuracy: 0.5117\n",
      "Epoch 23/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5197 - val_loss: 0.6926 - val_accuracy: 0.5097\n",
      "Epoch 24/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5191 - val_loss: 0.6927 - val_accuracy: 0.5111\n",
      "Epoch 25/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5197 - val_loss: 0.6926 - val_accuracy: 0.5125\n",
      "Epoch 26/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5199 - val_loss: 0.6927 - val_accuracy: 0.5116\n",
      "Epoch 27/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5205 - val_loss: 0.6931 - val_accuracy: 0.5094\n",
      "Epoch 28/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5212 - val_loss: 0.6928 - val_accuracy: 0.5116\n",
      "Epoch 29/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5220 - val_loss: 0.6928 - val_accuracy: 0.5087\n",
      "Epoch 30/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5215 - val_loss: 0.6928 - val_accuracy: 0.5105\n",
      "Epoch 31/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5214 - val_loss: 0.6931 - val_accuracy: 0.5093\n",
      "Epoch 32/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5210 - val_loss: 0.6928 - val_accuracy: 0.5116\n",
      "Epoch 33/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5205 - val_loss: 0.6927 - val_accuracy: 0.5105\n",
      "Epoch 34/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5222 - val_loss: 0.6928 - val_accuracy: 0.5077\n",
      "Epoch 35/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5229 - val_loss: 0.6928 - val_accuracy: 0.5096\n",
      "Epoch 36/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5199 - val_loss: 0.6928 - val_accuracy: 0.5083\n",
      "Epoch 37/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5208 - val_loss: 0.6929 - val_accuracy: 0.5108\n",
      "Epoch 38/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5210 - val_loss: 0.6928 - val_accuracy: 0.5084\n",
      "Epoch 39/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5222 - val_loss: 0.6929 - val_accuracy: 0.5097\n",
      "Epoch 40/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5225 - val_loss: 0.6927 - val_accuracy: 0.5108\n",
      "Epoch 41/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5219 - val_loss: 0.6927 - val_accuracy: 0.5094\n",
      "Epoch 42/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5223 - val_loss: 0.6931 - val_accuracy: 0.5095\n",
      "Training with significance = 2.21, run 3\n",
      "Train on 41204 samples, validate on 10302 samples\n",
      "Epoch 1/1000\n",
      "41204/41204 [==============================] - 1s 27us/sample - loss: 0.6941 - accuracy: 0.5053 - val_loss: 0.6932 - val_accuracy: 0.5033\n",
      "Epoch 2/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6929 - accuracy: 0.5110 - val_loss: 0.6928 - val_accuracy: 0.5070\n",
      "Epoch 3/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6927 - accuracy: 0.5125 - val_loss: 0.6925 - val_accuracy: 0.5138\n",
      "Epoch 4/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6926 - accuracy: 0.5147 - val_loss: 0.6925 - val_accuracy: 0.5140\n",
      "Epoch 5/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5142 - val_loss: 0.6923 - val_accuracy: 0.5191\n",
      "Epoch 6/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5140 - val_loss: 0.6918 - val_accuracy: 0.5206\n",
      "Epoch 7/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5142 - val_loss: 0.6920 - val_accuracy: 0.5199\n",
      "Epoch 8/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5136 - val_loss: 0.6921 - val_accuracy: 0.5189\n",
      "Epoch 9/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5164 - val_loss: 0.6918 - val_accuracy: 0.5201\n",
      "Epoch 10/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5160 - val_loss: 0.6920 - val_accuracy: 0.5196\n",
      "Epoch 11/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5153 - val_loss: 0.6918 - val_accuracy: 0.5203\n",
      "Epoch 12/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5147 - val_loss: 0.6921 - val_accuracy: 0.5197\n",
      "Epoch 13/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5162 - val_loss: 0.6918 - val_accuracy: 0.5214\n",
      "Epoch 14/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5156 - val_loss: 0.6919 - val_accuracy: 0.5193\n",
      "Epoch 15/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5165 - val_loss: 0.6920 - val_accuracy: 0.5182\n",
      "Epoch 16/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5156 - val_loss: 0.6919 - val_accuracy: 0.5180\n",
      "Epoch 17/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5158 - val_loss: 0.6918 - val_accuracy: 0.5198\n",
      "Epoch 18/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5165 - val_loss: 0.6920 - val_accuracy: 0.5184\n",
      "Epoch 19/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5174 - val_loss: 0.6920 - val_accuracy: 0.5188\n",
      "Epoch 20/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5172 - val_loss: 0.6920 - val_accuracy: 0.5177\n",
      "Epoch 21/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5168 - val_loss: 0.6920 - val_accuracy: 0.5197\n",
      "Epoch 22/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5167 - val_loss: 0.6919 - val_accuracy: 0.5187\n",
      "Epoch 23/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5161 - val_loss: 0.6921 - val_accuracy: 0.5179\n",
      "Epoch 24/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5173 - val_loss: 0.6922 - val_accuracy: 0.5201\n",
      "Epoch 25/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5161 - val_loss: 0.6920 - val_accuracy: 0.5179\n",
      "Epoch 26/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5163 - val_loss: 0.6920 - val_accuracy: 0.5178\n",
      "Epoch 27/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5179 - val_loss: 0.6921 - val_accuracy: 0.5174\n",
      "Epoch 28/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5178 - val_loss: 0.6920 - val_accuracy: 0.5184\n",
      "Epoch 29/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5166 - val_loss: 0.6921 - val_accuracy: 0.5170\n",
      "Epoch 30/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5177 - val_loss: 0.6922 - val_accuracy: 0.5148\n",
      "Epoch 31/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5171 - val_loss: 0.6922 - val_accuracy: 0.5206\n",
      "Epoch 32/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5196 - val_loss: 0.6922 - val_accuracy: 0.5173\n",
      "Epoch 33/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5182 - val_loss: 0.6920 - val_accuracy: 0.5206\n",
      "Epoch 34/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5186 - val_loss: 0.6921 - val_accuracy: 0.5182\n",
      "Epoch 35/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5190 - val_loss: 0.6920 - val_accuracy: 0.5199\n",
      "Epoch 36/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5181 - val_loss: 0.6921 - val_accuracy: 0.5188\n",
      "Epoch 37/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5192 - val_loss: 0.6922 - val_accuracy: 0.5171\n",
      "Epoch 38/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5183 - val_loss: 0.6923 - val_accuracy: 0.5182\n",
      "Epoch 39/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5183 - val_loss: 0.6923 - val_accuracy: 0.5189\n",
      "Epoch 40/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5197 - val_loss: 0.6922 - val_accuracy: 0.5195\n",
      "Epoch 41/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5186 - val_loss: 0.6919 - val_accuracy: 0.5213\n",
      "Epoch 42/1000\n",
      "41204/41204 [==============================] - 0s 12us/sample - loss: 0.6916 - accuracy: 0.5171 - val_loss: 0.6920 - val_accuracy: 0.5214\n",
      "Epoch 43/1000\n",
      "41204/41204 [==============================] - 1s 12us/sample - loss: 0.6914 - accuracy: 0.5177 - val_loss: 0.6920 - val_accuracy: 0.5195\n",
      "Training with significance = 2.21, run 4\n",
      "Train on 41204 samples, validate on 10302 samples\n",
      "Epoch 1/1000\n",
      "41204/41204 [==============================] - 1s 28us/sample - loss: 0.6931 - accuracy: 0.5121 - val_loss: 0.6934 - val_accuracy: 0.5091\n",
      "Epoch 2/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5151 - val_loss: 0.6926 - val_accuracy: 0.5119\n",
      "Epoch 3/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5137 - val_loss: 0.6926 - val_accuracy: 0.5116\n",
      "Epoch 4/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5166 - val_loss: 0.6923 - val_accuracy: 0.5174\n",
      "Epoch 5/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5178 - val_loss: 0.6923 - val_accuracy: 0.5182\n",
      "Epoch 6/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5174 - val_loss: 0.6923 - val_accuracy: 0.5187\n",
      "Epoch 7/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5175 - val_loss: 0.6922 - val_accuracy: 0.5173\n",
      "Epoch 8/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5173 - val_loss: 0.6922 - val_accuracy: 0.5185\n",
      "Epoch 9/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5191 - val_loss: 0.6922 - val_accuracy: 0.5183\n",
      "Epoch 10/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5190 - val_loss: 0.6923 - val_accuracy: 0.5185\n",
      "Epoch 11/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5187 - val_loss: 0.6922 - val_accuracy: 0.5176\n",
      "Epoch 12/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5166 - val_loss: 0.6922 - val_accuracy: 0.5193\n",
      "Epoch 13/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5195 - val_loss: 0.6924 - val_accuracy: 0.5115\n",
      "Epoch 14/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5206 - val_loss: 0.6921 - val_accuracy: 0.5189\n",
      "Epoch 15/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5188 - val_loss: 0.6922 - val_accuracy: 0.5182\n",
      "Epoch 16/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5177 - val_loss: 0.6923 - val_accuracy: 0.5158\n",
      "Epoch 17/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5193 - val_loss: 0.6922 - val_accuracy: 0.5184\n",
      "Epoch 18/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5220 - val_loss: 0.6921 - val_accuracy: 0.5187\n",
      "Epoch 19/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5191 - val_loss: 0.6922 - val_accuracy: 0.5143\n",
      "Epoch 20/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5208 - val_loss: 0.6921 - val_accuracy: 0.5178\n",
      "Epoch 21/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5192 - val_loss: 0.6921 - val_accuracy: 0.5177\n",
      "Epoch 22/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5207 - val_loss: 0.6920 - val_accuracy: 0.5176\n",
      "Epoch 23/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5193 - val_loss: 0.6920 - val_accuracy: 0.5197\n",
      "Epoch 24/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5205 - val_loss: 0.6921 - val_accuracy: 0.5136\n",
      "Epoch 25/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5208 - val_loss: 0.6923 - val_accuracy: 0.5178\n",
      "Epoch 26/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5192 - val_loss: 0.6920 - val_accuracy: 0.5190\n",
      "Epoch 27/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5196 - val_loss: 0.6921 - val_accuracy: 0.5124\n",
      "Epoch 28/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5211 - val_loss: 0.6921 - val_accuracy: 0.5153\n",
      "Epoch 29/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5198 - val_loss: 0.6920 - val_accuracy: 0.5201\n",
      "Epoch 30/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5201 - val_loss: 0.6921 - val_accuracy: 0.5131\n",
      "Epoch 31/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5196 - val_loss: 0.6921 - val_accuracy: 0.5166\n",
      "Epoch 32/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5207 - val_loss: 0.6920 - val_accuracy: 0.5186\n",
      "Epoch 33/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5208 - val_loss: 0.6920 - val_accuracy: 0.5178\n",
      "Epoch 34/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5208 - val_loss: 0.6920 - val_accuracy: 0.5190\n",
      "Epoch 35/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5217 - val_loss: 0.6919 - val_accuracy: 0.5175\n",
      "Epoch 36/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5198 - val_loss: 0.6921 - val_accuracy: 0.5182\n",
      "Epoch 37/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5195 - val_loss: 0.6920 - val_accuracy: 0.5206\n",
      "Epoch 38/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5221 - val_loss: 0.6921 - val_accuracy: 0.5149\n",
      "Epoch 39/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5189 - val_loss: 0.6922 - val_accuracy: 0.5163\n",
      "Epoch 40/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5207 - val_loss: 0.6920 - val_accuracy: 0.5201\n",
      "Epoch 41/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5193 - val_loss: 0.6920 - val_accuracy: 0.5182\n",
      "Epoch 42/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5219 - val_loss: 0.6920 - val_accuracy: 0.5189\n",
      "Epoch 43/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5212 - val_loss: 0.6922 - val_accuracy: 0.5146\n",
      "Epoch 44/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5210 - val_loss: 0.6921 - val_accuracy: 0.5159\n",
      "Epoch 45/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5213 - val_loss: 0.6921 - val_accuracy: 0.5183\n",
      "Epoch 46/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5228 - val_loss: 0.6920 - val_accuracy: 0.5188\n",
      "Epoch 47/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5242 - val_loss: 0.6920 - val_accuracy: 0.5186\n",
      "Epoch 48/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5210 - val_loss: 0.6922 - val_accuracy: 0.5170\n",
      "Epoch 49/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5214 - val_loss: 0.6920 - val_accuracy: 0.5170\n",
      "Epoch 50/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5206 - val_loss: 0.6919 - val_accuracy: 0.5182\n",
      "Epoch 51/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5207 - val_loss: 0.6920 - val_accuracy: 0.5184\n",
      "Epoch 52/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5225 - val_loss: 0.6920 - val_accuracy: 0.5190\n",
      "Epoch 53/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5216 - val_loss: 0.6920 - val_accuracy: 0.5195\n",
      "Epoch 54/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5218 - val_loss: 0.6921 - val_accuracy: 0.5186\n",
      "Epoch 55/1000\n",
      "41204/41204 [==============================] - 1s 12us/sample - loss: 0.6911 - accuracy: 0.5213 - val_loss: 0.6920 - val_accuracy: 0.5162\n",
      "Epoch 56/1000\n",
      "41204/41204 [==============================] - 1s 12us/sample - loss: 0.6909 - accuracy: 0.5215 - val_loss: 0.6921 - val_accuracy: 0.5165\n",
      "Epoch 57/1000\n",
      "41204/41204 [==============================] - 1s 12us/sample - loss: 0.6910 - accuracy: 0.5231 - val_loss: 0.6920 - val_accuracy: 0.5169\n",
      "Epoch 58/1000\n",
      "41204/41204 [==============================] - 1s 12us/sample - loss: 0.6908 - accuracy: 0.5202 - val_loss: 0.6921 - val_accuracy: 0.5168\n",
      "Epoch 59/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5215 - val_loss: 0.6921 - val_accuracy: 0.5157\n",
      "Epoch 60/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5237 - val_loss: 0.6920 - val_accuracy: 0.5191\n",
      "Epoch 61/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5227 - val_loss: 0.6922 - val_accuracy: 0.5176\n",
      "Epoch 62/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5233 - val_loss: 0.6920 - val_accuracy: 0.5176\n",
      "Epoch 63/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5225 - val_loss: 0.6921 - val_accuracy: 0.5176\n",
      "Epoch 64/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5218 - val_loss: 0.6919 - val_accuracy: 0.5193\n",
      "Epoch 65/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5218 - val_loss: 0.6920 - val_accuracy: 0.5189\n",
      "Epoch 66/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5245 - val_loss: 0.6920 - val_accuracy: 0.5190\n",
      "Epoch 67/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5226 - val_loss: 0.6920 - val_accuracy: 0.5172\n",
      "Epoch 68/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5221 - val_loss: 0.6922 - val_accuracy: 0.5152\n",
      "Epoch 69/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5229 - val_loss: 0.6923 - val_accuracy: 0.5125\n",
      "Epoch 70/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5221 - val_loss: 0.6920 - val_accuracy: 0.5167\n",
      "Epoch 71/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5235 - val_loss: 0.6919 - val_accuracy: 0.5179\n",
      "Epoch 72/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5237 - val_loss: 0.6920 - val_accuracy: 0.5160\n",
      "Epoch 73/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5215 - val_loss: 0.6920 - val_accuracy: 0.5177\n",
      "Epoch 74/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5243 - val_loss: 0.6919 - val_accuracy: 0.5178\n",
      "Epoch 75/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5231 - val_loss: 0.6921 - val_accuracy: 0.5176\n",
      "Epoch 76/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5241 - val_loss: 0.6919 - val_accuracy: 0.5188\n",
      "Epoch 77/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5236 - val_loss: 0.6920 - val_accuracy: 0.5168\n",
      "Epoch 78/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5260 - val_loss: 0.6919 - val_accuracy: 0.5181\n",
      "Epoch 79/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5224 - val_loss: 0.6919 - val_accuracy: 0.5166\n",
      "Epoch 80/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5234 - val_loss: 0.6919 - val_accuracy: 0.5200\n",
      "Epoch 81/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5223 - val_loss: 0.6920 - val_accuracy: 0.5174\n",
      "Epoch 82/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5237 - val_loss: 0.6921 - val_accuracy: 0.5184\n",
      "Epoch 83/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5223 - val_loss: 0.6920 - val_accuracy: 0.5168\n",
      "Epoch 84/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5222 - val_loss: 0.6920 - val_accuracy: 0.5182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5217 - val_loss: 0.6920 - val_accuracy: 0.5180\n",
      "Epoch 86/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5242 - val_loss: 0.6921 - val_accuracy: 0.5174\n",
      "Epoch 87/1000\n",
      "41204/41204 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5236 - val_loss: 0.6920 - val_accuracy: 0.5178\n",
      "Epoch 88/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5236 - val_loss: 0.6920 - val_accuracy: 0.5175\n",
      "Epoch 89/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5238 - val_loss: 0.6920 - val_accuracy: 0.5184\n",
      "Epoch 90/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5257 - val_loss: 0.6920 - val_accuracy: 0.5177\n",
      "Epoch 91/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5225 - val_loss: 0.6922 - val_accuracy: 0.5146\n",
      "Epoch 92/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5231 - val_loss: 0.6920 - val_accuracy: 0.5196\n",
      "Epoch 93/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5251 - val_loss: 0.6923 - val_accuracy: 0.5136\n",
      "Epoch 94/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5257 - val_loss: 0.6920 - val_accuracy: 0.5200\n",
      "Epoch 95/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5256 - val_loss: 0.6923 - val_accuracy: 0.5159\n",
      "Epoch 96/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5266 - val_loss: 0.6921 - val_accuracy: 0.5187\n",
      "Epoch 97/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5243 - val_loss: 0.6921 - val_accuracy: 0.5164\n",
      "Epoch 98/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5249 - val_loss: 0.6921 - val_accuracy: 0.5208\n",
      "Epoch 99/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5228 - val_loss: 0.6921 - val_accuracy: 0.5171\n",
      "Epoch 100/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5247 - val_loss: 0.6920 - val_accuracy: 0.5181\n",
      "Epoch 101/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5237 - val_loss: 0.6921 - val_accuracy: 0.5150\n",
      "Training with significance = 2.21, run 5\n",
      "Train on 41204 samples, validate on 10302 samples\n",
      "Epoch 1/1000\n",
      "41204/41204 [==============================] - 1s 28us/sample - loss: 0.6938 - accuracy: 0.5079 - val_loss: 0.6940 - val_accuracy: 0.4989\n",
      "Epoch 2/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6926 - accuracy: 0.5140 - val_loss: 0.6933 - val_accuracy: 0.5094\n",
      "Epoch 3/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5155 - val_loss: 0.6927 - val_accuracy: 0.5094\n",
      "Epoch 4/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5157 - val_loss: 0.6925 - val_accuracy: 0.5117\n",
      "Epoch 5/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5145 - val_loss: 0.6923 - val_accuracy: 0.5142\n",
      "Epoch 6/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5166 - val_loss: 0.6924 - val_accuracy: 0.5123\n",
      "Epoch 7/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5152 - val_loss: 0.6924 - val_accuracy: 0.5133\n",
      "Epoch 8/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5156 - val_loss: 0.6924 - val_accuracy: 0.5146\n",
      "Epoch 9/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5181 - val_loss: 0.6924 - val_accuracy: 0.5139\n",
      "Epoch 10/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5166 - val_loss: 0.6923 - val_accuracy: 0.5154\n",
      "Epoch 11/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5187 - val_loss: 0.6922 - val_accuracy: 0.5172\n",
      "Epoch 12/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5169 - val_loss: 0.6924 - val_accuracy: 0.5181\n",
      "Epoch 13/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5191 - val_loss: 0.6923 - val_accuracy: 0.5153\n",
      "Epoch 14/1000\n",
      "41204/41204 [==============================] - 1s 12us/sample - loss: 0.6918 - accuracy: 0.5181 - val_loss: 0.6923 - val_accuracy: 0.5157\n",
      "Epoch 15/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5176 - val_loss: 0.6923 - val_accuracy: 0.5161\n",
      "Epoch 16/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5172 - val_loss: 0.6923 - val_accuracy: 0.5157\n",
      "Epoch 17/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5176 - val_loss: 0.6923 - val_accuracy: 0.5159\n",
      "Epoch 18/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5184 - val_loss: 0.6923 - val_accuracy: 0.5154\n",
      "Epoch 19/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5185 - val_loss: 0.6923 - val_accuracy: 0.5164\n",
      "Epoch 20/1000\n",
      "41204/41204 [==============================] - 0s 12us/sample - loss: 0.6916 - accuracy: 0.5189 - val_loss: 0.6923 - val_accuracy: 0.5151\n",
      "Epoch 21/1000\n",
      "41204/41204 [==============================] - 1s 12us/sample - loss: 0.6916 - accuracy: 0.5192 - val_loss: 0.6923 - val_accuracy: 0.5152\n",
      "Epoch 22/1000\n",
      "41204/41204 [==============================] - 1s 12us/sample - loss: 0.6917 - accuracy: 0.5179 - val_loss: 0.6922 - val_accuracy: 0.5148\n",
      "Epoch 23/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5190 - val_loss: 0.6923 - val_accuracy: 0.5162\n",
      "Epoch 24/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5196 - val_loss: 0.6922 - val_accuracy: 0.5161\n",
      "Epoch 25/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5185 - val_loss: 0.6926 - val_accuracy: 0.5157\n",
      "Epoch 26/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5185 - val_loss: 0.6922 - val_accuracy: 0.5157\n",
      "Epoch 27/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5218 - val_loss: 0.6922 - val_accuracy: 0.5155\n",
      "Epoch 28/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5187 - val_loss: 0.6924 - val_accuracy: 0.5168\n",
      "Epoch 29/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5198 - val_loss: 0.6923 - val_accuracy: 0.5157\n",
      "Epoch 30/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5192 - val_loss: 0.6921 - val_accuracy: 0.5165\n",
      "Epoch 31/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5214 - val_loss: 0.6922 - val_accuracy: 0.5139\n",
      "Epoch 32/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5200 - val_loss: 0.6922 - val_accuracy: 0.5173\n",
      "Epoch 33/1000\n",
      "41204/41204 [==============================] - 1s 12us/sample - loss: 0.6914 - accuracy: 0.5215 - val_loss: 0.6923 - val_accuracy: 0.5154\n",
      "Epoch 34/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5206 - val_loss: 0.6925 - val_accuracy: 0.5193\n",
      "Epoch 35/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5188 - val_loss: 0.6922 - val_accuracy: 0.5183\n",
      "Epoch 36/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5221 - val_loss: 0.6921 - val_accuracy: 0.5166\n",
      "Epoch 37/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5210 - val_loss: 0.6922 - val_accuracy: 0.5173\n",
      "Epoch 38/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5212 - val_loss: 0.6923 - val_accuracy: 0.5182\n",
      "Epoch 39/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5210 - val_loss: 0.6923 - val_accuracy: 0.5151\n",
      "Epoch 40/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5213 - val_loss: 0.6922 - val_accuracy: 0.5140\n",
      "Epoch 41/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5221 - val_loss: 0.6924 - val_accuracy: 0.5175\n",
      "Epoch 42/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5200 - val_loss: 0.6927 - val_accuracy: 0.5162\n",
      "Epoch 43/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5204 - val_loss: 0.6921 - val_accuracy: 0.5171\n",
      "Epoch 44/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5220 - val_loss: 0.6922 - val_accuracy: 0.5144\n",
      "Epoch 45/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5212 - val_loss: 0.6924 - val_accuracy: 0.5189\n",
      "Epoch 46/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5213 - val_loss: 0.6924 - val_accuracy: 0.5163\n",
      "Epoch 47/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5213 - val_loss: 0.6924 - val_accuracy: 0.5156\n",
      "Epoch 48/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5222 - val_loss: 0.6922 - val_accuracy: 0.5186\n",
      "Epoch 49/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5197 - val_loss: 0.6924 - val_accuracy: 0.5157\n",
      "Epoch 50/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5187 - val_loss: 0.6922 - val_accuracy: 0.5141\n",
      "Epoch 51/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5218 - val_loss: 0.6921 - val_accuracy: 0.5167\n",
      "Epoch 52/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5199 - val_loss: 0.6924 - val_accuracy: 0.5170\n",
      "Epoch 53/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5239 - val_loss: 0.6922 - val_accuracy: 0.5149\n",
      "Epoch 54/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5217 - val_loss: 0.6923 - val_accuracy: 0.5154\n",
      "Epoch 55/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5217 - val_loss: 0.6924 - val_accuracy: 0.5159\n",
      "Epoch 56/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5206 - val_loss: 0.6923 - val_accuracy: 0.5152\n",
      "Epoch 57/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5220 - val_loss: 0.6923 - val_accuracy: 0.5144\n",
      "Epoch 58/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5223 - val_loss: 0.6922 - val_accuracy: 0.5160\n",
      "Epoch 59/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5224 - val_loss: 0.6923 - val_accuracy: 0.5159\n",
      "Epoch 60/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5217 - val_loss: 0.6924 - val_accuracy: 0.5173\n",
      "Epoch 61/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5214 - val_loss: 0.6922 - val_accuracy: 0.5173\n",
      "Epoch 62/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5227 - val_loss: 0.6923 - val_accuracy: 0.5167\n",
      "Epoch 63/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5214 - val_loss: 0.6922 - val_accuracy: 0.5162\n",
      "Epoch 64/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5234 - val_loss: 0.6922 - val_accuracy: 0.5129\n",
      "Epoch 65/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5215 - val_loss: 0.6925 - val_accuracy: 0.5157\n",
      "Epoch 66/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5235 - val_loss: 0.6923 - val_accuracy: 0.5134\n",
      "Training with significance = 2.21, run 6\n",
      "Train on 41204 samples, validate on 10302 samples\n",
      "Epoch 1/1000\n",
      "41204/41204 [==============================] - 1s 27us/sample - loss: 0.6943 - accuracy: 0.5002 - val_loss: 0.6930 - val_accuracy: 0.5110\n",
      "Epoch 2/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6926 - accuracy: 0.5138 - val_loss: 0.6927 - val_accuracy: 0.5115\n",
      "Epoch 3/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6925 - accuracy: 0.5143 - val_loss: 0.6924 - val_accuracy: 0.5178\n",
      "Epoch 4/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5137 - val_loss: 0.6923 - val_accuracy: 0.5165\n",
      "Epoch 5/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5160 - val_loss: 0.6924 - val_accuracy: 0.5167\n",
      "Epoch 6/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5155 - val_loss: 0.6923 - val_accuracy: 0.5184\n",
      "Epoch 7/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5158 - val_loss: 0.6924 - val_accuracy: 0.5178\n",
      "Epoch 8/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5177 - val_loss: 0.6924 - val_accuracy: 0.5168\n",
      "Epoch 9/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5171 - val_loss: 0.6922 - val_accuracy: 0.5167\n",
      "Epoch 10/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5193 - val_loss: 0.6922 - val_accuracy: 0.5154\n",
      "Epoch 11/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5176 - val_loss: 0.6921 - val_accuracy: 0.5180\n",
      "Epoch 12/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5186 - val_loss: 0.6922 - val_accuracy: 0.5141\n",
      "Epoch 13/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5195 - val_loss: 0.6923 - val_accuracy: 0.5141\n",
      "Epoch 14/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5199 - val_loss: 0.6922 - val_accuracy: 0.5141\n",
      "Epoch 15/1000\n",
      "41204/41204 [==============================] - 1s 12us/sample - loss: 0.6918 - accuracy: 0.5167 - val_loss: 0.6922 - val_accuracy: 0.5137\n",
      "Epoch 16/1000\n",
      "41204/41204 [==============================] - 1s 12us/sample - loss: 0.6918 - accuracy: 0.5183 - val_loss: 0.6921 - val_accuracy: 0.5145\n",
      "Epoch 17/1000\n",
      "41204/41204 [==============================] - 0s 12us/sample - loss: 0.6917 - accuracy: 0.5177 - val_loss: 0.6921 - val_accuracy: 0.5182\n",
      "Epoch 18/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5188 - val_loss: 0.6923 - val_accuracy: 0.5182\n",
      "Epoch 19/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5183 - val_loss: 0.6921 - val_accuracy: 0.5170\n",
      "Epoch 20/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5193 - val_loss: 0.6921 - val_accuracy: 0.5182\n",
      "Epoch 21/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5185 - val_loss: 0.6922 - val_accuracy: 0.5193\n",
      "Epoch 22/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5180 - val_loss: 0.6921 - val_accuracy: 0.5187\n",
      "Epoch 23/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5182 - val_loss: 0.6922 - val_accuracy: 0.5173\n",
      "Epoch 24/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5199 - val_loss: 0.6922 - val_accuracy: 0.5174\n",
      "Epoch 25/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5187 - val_loss: 0.6922 - val_accuracy: 0.5172\n",
      "Epoch 26/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5182 - val_loss: 0.6921 - val_accuracy: 0.5171\n",
      "Epoch 27/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5190 - val_loss: 0.6922 - val_accuracy: 0.5140\n",
      "Epoch 28/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5171 - val_loss: 0.6921 - val_accuracy: 0.5175\n",
      "Epoch 29/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5191 - val_loss: 0.6922 - val_accuracy: 0.5156\n",
      "Epoch 30/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5194 - val_loss: 0.6923 - val_accuracy: 0.5163\n",
      "Epoch 31/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5194 - val_loss: 0.6923 - val_accuracy: 0.5197\n",
      "Epoch 32/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5174 - val_loss: 0.6922 - val_accuracy: 0.5100\n",
      "Epoch 33/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5207 - val_loss: 0.6922 - val_accuracy: 0.5184\n",
      "Epoch 34/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5199 - val_loss: 0.6922 - val_accuracy: 0.5144\n",
      "Epoch 35/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5202 - val_loss: 0.6923 - val_accuracy: 0.5176\n",
      "Epoch 36/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5203 - val_loss: 0.6922 - val_accuracy: 0.5152\n",
      "Epoch 37/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5199 - val_loss: 0.6922 - val_accuracy: 0.5159\n",
      "Epoch 38/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5196 - val_loss: 0.6921 - val_accuracy: 0.5164\n",
      "Epoch 39/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5196 - val_loss: 0.6924 - val_accuracy: 0.5182\n",
      "Epoch 40/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5202 - val_loss: 0.6922 - val_accuracy: 0.5147\n",
      "Epoch 41/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5202 - val_loss: 0.6924 - val_accuracy: 0.5168\n",
      "Epoch 42/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5228 - val_loss: 0.6922 - val_accuracy: 0.5160\n",
      "Epoch 43/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5195 - val_loss: 0.6922 - val_accuracy: 0.5183\n",
      "Epoch 44/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5200 - val_loss: 0.6922 - val_accuracy: 0.5155\n",
      "Epoch 45/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5212 - val_loss: 0.6922 - val_accuracy: 0.5145\n",
      "Epoch 46/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5207 - val_loss: 0.6921 - val_accuracy: 0.5176\n",
      "Epoch 47/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5199 - val_loss: 0.6922 - val_accuracy: 0.5157\n",
      "Epoch 48/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5210 - val_loss: 0.6923 - val_accuracy: 0.5183\n",
      "Epoch 49/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5201 - val_loss: 0.6923 - val_accuracy: 0.5097\n",
      "Epoch 50/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5215 - val_loss: 0.6923 - val_accuracy: 0.5123\n",
      "Epoch 51/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5218 - val_loss: 0.6921 - val_accuracy: 0.5138\n",
      "Epoch 52/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5223 - val_loss: 0.6923 - val_accuracy: 0.5212\n",
      "Epoch 53/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5223 - val_loss: 0.6923 - val_accuracy: 0.5154\n",
      "Epoch 54/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5196 - val_loss: 0.6924 - val_accuracy: 0.5175\n",
      "Epoch 55/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5233 - val_loss: 0.6923 - val_accuracy: 0.5177\n",
      "Epoch 56/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5200 - val_loss: 0.6921 - val_accuracy: 0.5164\n",
      "Epoch 57/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5211 - val_loss: 0.6923 - val_accuracy: 0.5182\n",
      "Epoch 58/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5217 - val_loss: 0.6923 - val_accuracy: 0.5170\n",
      "Epoch 59/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5209 - val_loss: 0.6922 - val_accuracy: 0.5152\n",
      "Epoch 60/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5206 - val_loss: 0.6924 - val_accuracy: 0.5153\n",
      "Epoch 61/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5221 - val_loss: 0.6922 - val_accuracy: 0.5150\n",
      "Epoch 62/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5211 - val_loss: 0.6921 - val_accuracy: 0.5157\n",
      "Epoch 63/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5214 - val_loss: 0.6923 - val_accuracy: 0.5187\n",
      "Epoch 64/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5206 - val_loss: 0.6922 - val_accuracy: 0.5138\n",
      "Epoch 65/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5221 - val_loss: 0.6923 - val_accuracy: 0.5150\n",
      "Epoch 66/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5230 - val_loss: 0.6921 - val_accuracy: 0.5148\n",
      "Epoch 67/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5205 - val_loss: 0.6923 - val_accuracy: 0.5142\n",
      "Epoch 68/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5238 - val_loss: 0.6926 - val_accuracy: 0.5142\n",
      "Epoch 69/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5230 - val_loss: 0.6923 - val_accuracy: 0.5179\n",
      "Epoch 70/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5217 - val_loss: 0.6922 - val_accuracy: 0.5108\n",
      "Epoch 71/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5227 - val_loss: 0.6924 - val_accuracy: 0.5107\n",
      "Epoch 72/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5221 - val_loss: 0.6922 - val_accuracy: 0.5161\n",
      "Epoch 73/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5220 - val_loss: 0.6922 - val_accuracy: 0.5141\n",
      "Epoch 74/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5232 - val_loss: 0.6922 - val_accuracy: 0.5123\n",
      "Epoch 75/1000\n",
      "41204/41204 [==============================] - 1s 12us/sample - loss: 0.6912 - accuracy: 0.5218 - val_loss: 0.6923 - val_accuracy: 0.5156\n",
      "Epoch 76/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5207 - val_loss: 0.6922 - val_accuracy: 0.5126\n",
      "Epoch 77/1000\n",
      "41204/41204 [==============================] - 1s 12us/sample - loss: 0.6911 - accuracy: 0.5200 - val_loss: 0.6922 - val_accuracy: 0.5190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/1000\n",
      "41204/41204 [==============================] - 1s 12us/sample - loss: 0.6911 - accuracy: 0.5211 - val_loss: 0.6922 - val_accuracy: 0.5109\n",
      "Epoch 79/1000\n",
      "41204/41204 [==============================] - 0s 12us/sample - loss: 0.6911 - accuracy: 0.5218 - val_loss: 0.6921 - val_accuracy: 0.5135\n",
      "Epoch 80/1000\n",
      "41204/41204 [==============================] - 1s 12us/sample - loss: 0.6910 - accuracy: 0.5234 - val_loss: 0.6922 - val_accuracy: 0.5124\n",
      "Epoch 81/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5212 - val_loss: 0.6922 - val_accuracy: 0.5184\n",
      "Epoch 82/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5241 - val_loss: 0.6922 - val_accuracy: 0.5173\n",
      "Epoch 83/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5227 - val_loss: 0.6923 - val_accuracy: 0.5125\n",
      "Epoch 84/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5219 - val_loss: 0.6923 - val_accuracy: 0.5129\n",
      "Epoch 85/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5225 - val_loss: 0.6923 - val_accuracy: 0.5145\n",
      "Epoch 86/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5231 - val_loss: 0.6924 - val_accuracy: 0.5106\n",
      "Training with significance = 2.21, run 7\n",
      "Train on 41204 samples, validate on 10302 samples\n",
      "Epoch 1/1000\n",
      "41204/41204 [==============================] - 1s 27us/sample - loss: 0.6928 - accuracy: 0.5088 - val_loss: 0.6946 - val_accuracy: 0.5041\n",
      "Epoch 2/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5156 - val_loss: 0.6934 - val_accuracy: 0.5120\n",
      "Epoch 3/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5157 - val_loss: 0.6927 - val_accuracy: 0.5120\n",
      "Epoch 4/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5152 - val_loss: 0.6924 - val_accuracy: 0.5132\n",
      "Epoch 5/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5168 - val_loss: 0.6923 - val_accuracy: 0.5141\n",
      "Epoch 6/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5165 - val_loss: 0.6923 - val_accuracy: 0.5156\n",
      "Epoch 7/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5161 - val_loss: 0.6922 - val_accuracy: 0.5167\n",
      "Epoch 8/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5173 - val_loss: 0.6922 - val_accuracy: 0.5172\n",
      "Epoch 9/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5155 - val_loss: 0.6922 - val_accuracy: 0.5169\n",
      "Epoch 10/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5159 - val_loss: 0.6921 - val_accuracy: 0.5158\n",
      "Epoch 11/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5170 - val_loss: 0.6921 - val_accuracy: 0.5152\n",
      "Epoch 12/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5179 - val_loss: 0.6921 - val_accuracy: 0.5163\n",
      "Epoch 13/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5182 - val_loss: 0.6921 - val_accuracy: 0.5152\n",
      "Epoch 14/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5168 - val_loss: 0.6921 - val_accuracy: 0.5176\n",
      "Epoch 15/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5169 - val_loss: 0.6921 - val_accuracy: 0.5159\n",
      "Epoch 16/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5175 - val_loss: 0.6921 - val_accuracy: 0.5158\n",
      "Epoch 17/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5169 - val_loss: 0.6921 - val_accuracy: 0.5144\n",
      "Epoch 18/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5176 - val_loss: 0.6921 - val_accuracy: 0.5146\n",
      "Epoch 19/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5167 - val_loss: 0.6920 - val_accuracy: 0.5161\n",
      "Epoch 20/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5191 - val_loss: 0.6921 - val_accuracy: 0.5162\n",
      "Epoch 21/1000\n",
      "41204/41204 [==============================] - 1s 12us/sample - loss: 0.6917 - accuracy: 0.5161 - val_loss: 0.6921 - val_accuracy: 0.5144\n",
      "Epoch 22/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5192 - val_loss: 0.6920 - val_accuracy: 0.5126\n",
      "Epoch 23/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5177 - val_loss: 0.6920 - val_accuracy: 0.5163\n",
      "Epoch 24/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5202 - val_loss: 0.6920 - val_accuracy: 0.5143\n",
      "Epoch 25/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5185 - val_loss: 0.6920 - val_accuracy: 0.5158\n",
      "Epoch 26/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5191 - val_loss: 0.6921 - val_accuracy: 0.5145\n",
      "Epoch 27/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5194 - val_loss: 0.6920 - val_accuracy: 0.5126\n",
      "Epoch 28/1000\n",
      "41204/41204 [==============================] - 1s 12us/sample - loss: 0.6915 - accuracy: 0.5198 - val_loss: 0.6920 - val_accuracy: 0.5134\n",
      "Epoch 29/1000\n",
      "41204/41204 [==============================] - 1s 12us/sample - loss: 0.6915 - accuracy: 0.5215 - val_loss: 0.6920 - val_accuracy: 0.5145\n",
      "Epoch 30/1000\n",
      "41204/41204 [==============================] - 1s 12us/sample - loss: 0.6915 - accuracy: 0.5167 - val_loss: 0.6921 - val_accuracy: 0.5137\n",
      "Epoch 31/1000\n",
      "41204/41204 [==============================] - 1s 12us/sample - loss: 0.6916 - accuracy: 0.5183 - val_loss: 0.6920 - val_accuracy: 0.5157\n",
      "Epoch 32/1000\n",
      "41204/41204 [==============================] - 1s 12us/sample - loss: 0.6916 - accuracy: 0.5200 - val_loss: 0.6922 - val_accuracy: 0.5148\n",
      "Epoch 33/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5179 - val_loss: 0.6921 - val_accuracy: 0.5147\n",
      "Epoch 34/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5209 - val_loss: 0.6921 - val_accuracy: 0.5119\n",
      "Epoch 35/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5196 - val_loss: 0.6921 - val_accuracy: 0.5124\n",
      "Epoch 36/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5192 - val_loss: 0.6921 - val_accuracy: 0.5116\n",
      "Epoch 37/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5180 - val_loss: 0.6920 - val_accuracy: 0.5111\n",
      "Epoch 38/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5201 - val_loss: 0.6921 - val_accuracy: 0.5122\n",
      "Epoch 39/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5204 - val_loss: 0.6920 - val_accuracy: 0.5139\n",
      "Epoch 40/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5207 - val_loss: 0.6920 - val_accuracy: 0.5116\n",
      "Epoch 41/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5183 - val_loss: 0.6920 - val_accuracy: 0.5119\n",
      "Epoch 42/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5197 - val_loss: 0.6921 - val_accuracy: 0.5138\n",
      "Epoch 43/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5202 - val_loss: 0.6920 - val_accuracy: 0.5123\n",
      "Epoch 44/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5201 - val_loss: 0.6920 - val_accuracy: 0.5107\n",
      "Epoch 45/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5209 - val_loss: 0.6921 - val_accuracy: 0.5127\n",
      "Epoch 46/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5198 - val_loss: 0.6921 - val_accuracy: 0.5136\n",
      "Epoch 47/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5197 - val_loss: 0.6920 - val_accuracy: 0.5133\n",
      "Epoch 48/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5218 - val_loss: 0.6920 - val_accuracy: 0.5146\n",
      "Epoch 49/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5194 - val_loss: 0.6920 - val_accuracy: 0.5149\n",
      "Epoch 50/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5207 - val_loss: 0.6921 - val_accuracy: 0.5128\n",
      "Epoch 51/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5215 - val_loss: 0.6921 - val_accuracy: 0.5115\n",
      "Epoch 52/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5221 - val_loss: 0.6920 - val_accuracy: 0.5121\n",
      "Epoch 53/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5220 - val_loss: 0.6920 - val_accuracy: 0.5134\n",
      "Epoch 54/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5204 - val_loss: 0.6920 - val_accuracy: 0.5133\n",
      "Epoch 55/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5205 - val_loss: 0.6920 - val_accuracy: 0.5137\n",
      "Epoch 56/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5198 - val_loss: 0.6921 - val_accuracy: 0.5124\n",
      "Epoch 57/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5207 - val_loss: 0.6920 - val_accuracy: 0.5140\n",
      "Epoch 58/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5201 - val_loss: 0.6920 - val_accuracy: 0.5128\n",
      "Epoch 59/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5216 - val_loss: 0.6921 - val_accuracy: 0.5147\n",
      "Epoch 60/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5222 - val_loss: 0.6920 - val_accuracy: 0.5119\n",
      "Epoch 61/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5228 - val_loss: 0.6920 - val_accuracy: 0.5140\n",
      "Epoch 62/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5210 - val_loss: 0.6920 - val_accuracy: 0.5138\n",
      "Epoch 63/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5220 - val_loss: 0.6920 - val_accuracy: 0.5100\n",
      "Epoch 64/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5205 - val_loss: 0.6921 - val_accuracy: 0.5132\n",
      "Epoch 65/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5200 - val_loss: 0.6920 - val_accuracy: 0.5121\n",
      "Epoch 66/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5215 - val_loss: 0.6921 - val_accuracy: 0.5153\n",
      "Epoch 67/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5227 - val_loss: 0.6921 - val_accuracy: 0.5126\n",
      "Epoch 68/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5206 - val_loss: 0.6920 - val_accuracy: 0.5148\n",
      "Epoch 69/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5210 - val_loss: 0.6921 - val_accuracy: 0.5101\n",
      "Epoch 70/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5233 - val_loss: 0.6920 - val_accuracy: 0.5137\n",
      "Epoch 71/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5216 - val_loss: 0.6922 - val_accuracy: 0.5133\n",
      "Epoch 72/1000\n",
      "41204/41204 [==============================] - 1s 12us/sample - loss: 0.6912 - accuracy: 0.5219 - val_loss: 0.6920 - val_accuracy: 0.5118\n",
      "Epoch 73/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5201 - val_loss: 0.6921 - val_accuracy: 0.5119\n",
      "Epoch 74/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5218 - val_loss: 0.6920 - val_accuracy: 0.5135\n",
      "Epoch 75/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5220 - val_loss: 0.6920 - val_accuracy: 0.5117\n",
      "Epoch 76/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5217 - val_loss: 0.6920 - val_accuracy: 0.5102\n",
      "Epoch 77/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5206 - val_loss: 0.6921 - val_accuracy: 0.5116\n",
      "Epoch 78/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5210 - val_loss: 0.6920 - val_accuracy: 0.5126\n",
      "Epoch 79/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5206 - val_loss: 0.6920 - val_accuracy: 0.5122\n",
      "Epoch 80/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5210 - val_loss: 0.6921 - val_accuracy: 0.5137\n",
      "Epoch 81/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5238 - val_loss: 0.6921 - val_accuracy: 0.5116\n",
      "Epoch 82/1000\n",
      "41204/41204 [==============================] - 1s 12us/sample - loss: 0.6912 - accuracy: 0.5217 - val_loss: 0.6921 - val_accuracy: 0.5125\n",
      "Epoch 83/1000\n",
      "41204/41204 [==============================] - 1s 12us/sample - loss: 0.6912 - accuracy: 0.5206 - val_loss: 0.6920 - val_accuracy: 0.5141\n",
      "Epoch 84/1000\n",
      "41204/41204 [==============================] - 1s 12us/sample - loss: 0.6911 - accuracy: 0.5208 - val_loss: 0.6920 - val_accuracy: 0.5123\n",
      "Epoch 85/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5220 - val_loss: 0.6920 - val_accuracy: 0.5120\n",
      "Epoch 86/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5224 - val_loss: 0.6922 - val_accuracy: 0.5106\n",
      "Epoch 87/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5225 - val_loss: 0.6921 - val_accuracy: 0.5149\n",
      "Epoch 88/1000\n",
      "41204/41204 [==============================] - 1s 12us/sample - loss: 0.6912 - accuracy: 0.5226 - val_loss: 0.6920 - val_accuracy: 0.5116\n",
      "Epoch 89/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5233 - val_loss: 0.6920 - val_accuracy: 0.5120\n",
      "Epoch 90/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5227 - val_loss: 0.6921 - val_accuracy: 0.5107\n",
      "Epoch 91/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5206 - val_loss: 0.6920 - val_accuracy: 0.5091\n",
      "Epoch 92/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5222 - val_loss: 0.6921 - val_accuracy: 0.5116\n",
      "Training with significance = 2.21, run 8\n",
      "Train on 41204 samples, validate on 10302 samples\n",
      "Epoch 1/1000\n",
      "41204/41204 [==============================] - 2s 50us/sample - loss: 0.6941 - accuracy: 0.5038 - val_loss: 0.6944 - val_accuracy: 0.5019\n",
      "Epoch 2/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5156 - val_loss: 0.6931 - val_accuracy: 0.5088\n",
      "Epoch 3/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5188 - val_loss: 0.6931 - val_accuracy: 0.5097\n",
      "Epoch 4/1000\n",
      "41204/41204 [==============================] - 1s 12us/sample - loss: 0.6919 - accuracy: 0.5175 - val_loss: 0.6931 - val_accuracy: 0.5106\n",
      "Epoch 5/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5163 - val_loss: 0.6928 - val_accuracy: 0.5119\n",
      "Epoch 6/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5168 - val_loss: 0.6927 - val_accuracy: 0.5135\n",
      "Epoch 7/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5179 - val_loss: 0.6926 - val_accuracy: 0.5126\n",
      "Epoch 8/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5186 - val_loss: 0.6925 - val_accuracy: 0.5119\n",
      "Epoch 9/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5185 - val_loss: 0.6926 - val_accuracy: 0.5118\n",
      "Epoch 10/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5189 - val_loss: 0.6925 - val_accuracy: 0.5118\n",
      "Epoch 11/1000\n",
      "41204/41204 [==============================] - 1s 14us/sample - loss: 0.6916 - accuracy: 0.5185 - val_loss: 0.6925 - val_accuracy: 0.5126\n",
      "Epoch 12/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5183 - val_loss: 0.6926 - val_accuracy: 0.5137\n",
      "Epoch 13/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5183 - val_loss: 0.6927 - val_accuracy: 0.5104\n",
      "Epoch 14/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5187 - val_loss: 0.6927 - val_accuracy: 0.5125\n",
      "Epoch 15/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5174 - val_loss: 0.6926 - val_accuracy: 0.5116\n",
      "Epoch 16/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5190 - val_loss: 0.6926 - val_accuracy: 0.5119\n",
      "Epoch 17/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5207 - val_loss: 0.6926 - val_accuracy: 0.5121\n",
      "Epoch 18/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5212 - val_loss: 0.6926 - val_accuracy: 0.5102\n",
      "Epoch 19/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5200 - val_loss: 0.6926 - val_accuracy: 0.5116\n",
      "Epoch 20/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5201 - val_loss: 0.6925 - val_accuracy: 0.5106\n",
      "Epoch 21/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5200 - val_loss: 0.6925 - val_accuracy: 0.5125\n",
      "Epoch 22/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5195 - val_loss: 0.6928 - val_accuracy: 0.5090\n",
      "Epoch 23/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5202 - val_loss: 0.6926 - val_accuracy: 0.5107\n",
      "Epoch 24/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5199 - val_loss: 0.6926 - val_accuracy: 0.5122\n",
      "Epoch 25/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5207 - val_loss: 0.6926 - val_accuracy: 0.5121\n",
      "Epoch 26/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5210 - val_loss: 0.6927 - val_accuracy: 0.5110\n",
      "Epoch 27/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5213 - val_loss: 0.6925 - val_accuracy: 0.5147\n",
      "Epoch 28/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5183 - val_loss: 0.6927 - val_accuracy: 0.5115\n",
      "Epoch 29/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5211 - val_loss: 0.6926 - val_accuracy: 0.5116\n",
      "Epoch 30/1000\n",
      "41204/41204 [==============================] - 1s 12us/sample - loss: 0.6914 - accuracy: 0.5189 - val_loss: 0.6925 - val_accuracy: 0.5141\n",
      "Epoch 31/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5187 - val_loss: 0.6926 - val_accuracy: 0.5129\n",
      "Epoch 32/1000\n",
      "41204/41204 [==============================] - 0s 12us/sample - loss: 0.6913 - accuracy: 0.5210 - val_loss: 0.6927 - val_accuracy: 0.5102\n",
      "Epoch 33/1000\n",
      "41204/41204 [==============================] - 1s 12us/sample - loss: 0.6912 - accuracy: 0.5221 - val_loss: 0.6928 - val_accuracy: 0.5100\n",
      "Epoch 34/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5208 - val_loss: 0.6926 - val_accuracy: 0.5124\n",
      "Epoch 35/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5211 - val_loss: 0.6929 - val_accuracy: 0.5117\n",
      "Epoch 36/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5208 - val_loss: 0.6928 - val_accuracy: 0.5107\n",
      "Epoch 37/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5195 - val_loss: 0.6926 - val_accuracy: 0.5120\n",
      "Epoch 38/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5218 - val_loss: 0.6928 - val_accuracy: 0.5090\n",
      "Epoch 39/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5219 - val_loss: 0.6927 - val_accuracy: 0.5116\n",
      "Epoch 40/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5204 - val_loss: 0.6927 - val_accuracy: 0.5123\n",
      "Epoch 41/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5214 - val_loss: 0.6926 - val_accuracy: 0.5145\n",
      "Training with significance = 2.21, run 9\n",
      "Train on 41204 samples, validate on 10302 samples\n",
      "Epoch 1/1000\n",
      "41204/41204 [==============================] - 1s 27us/sample - loss: 0.6933 - accuracy: 0.5084 - val_loss: 0.6937 - val_accuracy: 0.5040\n",
      "Epoch 2/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5166 - val_loss: 0.6930 - val_accuracy: 0.5073\n",
      "Epoch 3/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5140 - val_loss: 0.6927 - val_accuracy: 0.5090\n",
      "Epoch 4/1000\n",
      "41204/41204 [==============================] - 1s 14us/sample - loss: 0.6922 - accuracy: 0.5181 - val_loss: 0.6925 - val_accuracy: 0.5107\n",
      "Epoch 5/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5166 - val_loss: 0.6924 - val_accuracy: 0.5098\n",
      "Epoch 6/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5164 - val_loss: 0.6924 - val_accuracy: 0.5069\n",
      "Epoch 7/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5174 - val_loss: 0.6926 - val_accuracy: 0.5078\n",
      "Epoch 8/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5191 - val_loss: 0.6924 - val_accuracy: 0.5078\n",
      "Epoch 9/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5179 - val_loss: 0.6924 - val_accuracy: 0.5075\n",
      "Epoch 10/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5176 - val_loss: 0.6925 - val_accuracy: 0.5047\n",
      "Epoch 11/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5196 - val_loss: 0.6925 - val_accuracy: 0.5079\n",
      "Epoch 12/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5177 - val_loss: 0.6926 - val_accuracy: 0.5090\n",
      "Epoch 13/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5182 - val_loss: 0.6925 - val_accuracy: 0.5070\n",
      "Epoch 14/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5189 - val_loss: 0.6925 - val_accuracy: 0.5050\n",
      "Epoch 15/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5195 - val_loss: 0.6926 - val_accuracy: 0.5080\n",
      "Epoch 16/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5199 - val_loss: 0.6924 - val_accuracy: 0.5052\n",
      "Epoch 17/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5188 - val_loss: 0.6924 - val_accuracy: 0.5071\n",
      "Epoch 18/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5213 - val_loss: 0.6926 - val_accuracy: 0.5083\n",
      "Epoch 19/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5183 - val_loss: 0.6927 - val_accuracy: 0.5092\n",
      "Epoch 20/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5200 - val_loss: 0.6925 - val_accuracy: 0.5047\n",
      "Epoch 21/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5206 - val_loss: 0.6924 - val_accuracy: 0.5070\n",
      "Epoch 22/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5183 - val_loss: 0.6924 - val_accuracy: 0.5059\n",
      "Epoch 23/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5210 - val_loss: 0.6926 - val_accuracy: 0.5069\n",
      "Epoch 24/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5207 - val_loss: 0.6925 - val_accuracy: 0.5059\n",
      "Epoch 25/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5190 - val_loss: 0.6924 - val_accuracy: 0.5030\n",
      "Epoch 26/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5197 - val_loss: 0.6925 - val_accuracy: 0.5059\n",
      "Epoch 27/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5212 - val_loss: 0.6925 - val_accuracy: 0.5054\n",
      "Epoch 28/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5202 - val_loss: 0.6925 - val_accuracy: 0.5059\n",
      "Epoch 29/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5208 - val_loss: 0.6924 - val_accuracy: 0.5073\n",
      "Epoch 30/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5217 - val_loss: 0.6925 - val_accuracy: 0.5068\n",
      "Epoch 31/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5209 - val_loss: 0.6925 - val_accuracy: 0.5073\n",
      "Epoch 32/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5223 - val_loss: 0.6926 - val_accuracy: 0.5061\n",
      "Epoch 33/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5196 - val_loss: 0.6927 - val_accuracy: 0.5051\n",
      "Epoch 34/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5214 - val_loss: 0.6926 - val_accuracy: 0.5057\n",
      "Epoch 35/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5191 - val_loss: 0.6926 - val_accuracy: 0.5050\n",
      "Epoch 36/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5217 - val_loss: 0.6926 - val_accuracy: 0.5062\n",
      "Epoch 37/1000\n",
      "41204/41204 [==============================] - 1s 12us/sample - loss: 0.6915 - accuracy: 0.5193 - val_loss: 0.6926 - val_accuracy: 0.5072\n",
      "Epoch 38/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5202 - val_loss: 0.6925 - val_accuracy: 0.5052\n",
      "Epoch 39/1000\n",
      "41204/41204 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5213 - val_loss: 0.6927 - val_accuracy: 0.5035\n",
      "Training with significance = 2.52, run 0\n",
      "Train on 41255 samples, validate on 10314 samples\n",
      "Epoch 1/1000\n",
      "41255/41255 [==============================] - 1s 27us/sample - loss: 0.6935 - accuracy: 0.5063 - val_loss: 0.6940 - val_accuracy: 0.5089\n",
      "Epoch 2/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6926 - accuracy: 0.5115 - val_loss: 0.6933 - val_accuracy: 0.5148\n",
      "Epoch 3/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5163 - val_loss: 0.6928 - val_accuracy: 0.5132\n",
      "Epoch 4/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5143 - val_loss: 0.6926 - val_accuracy: 0.5145\n",
      "Epoch 5/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5162 - val_loss: 0.6926 - val_accuracy: 0.5169\n",
      "Epoch 6/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5156 - val_loss: 0.6925 - val_accuracy: 0.5151\n",
      "Epoch 7/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5143 - val_loss: 0.6923 - val_accuracy: 0.5152\n",
      "Epoch 8/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5149 - val_loss: 0.6925 - val_accuracy: 0.5140\n",
      "Epoch 9/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5140 - val_loss: 0.6922 - val_accuracy: 0.5139\n",
      "Epoch 10/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5160 - val_loss: 0.6922 - val_accuracy: 0.5154\n",
      "Epoch 11/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5153 - val_loss: 0.6923 - val_accuracy: 0.5175\n",
      "Epoch 12/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5174 - val_loss: 0.6923 - val_accuracy: 0.5148\n",
      "Epoch 13/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5157 - val_loss: 0.6923 - val_accuracy: 0.5188\n",
      "Epoch 14/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5159 - val_loss: 0.6923 - val_accuracy: 0.5169\n",
      "Epoch 15/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5169 - val_loss: 0.6923 - val_accuracy: 0.5170\n",
      "Epoch 16/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5165 - val_loss: 0.6922 - val_accuracy: 0.5150\n",
      "Epoch 17/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5166 - val_loss: 0.6922 - val_accuracy: 0.5172\n",
      "Epoch 18/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5167 - val_loss: 0.6923 - val_accuracy: 0.5162\n",
      "Epoch 19/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5160 - val_loss: 0.6925 - val_accuracy: 0.5160\n",
      "Epoch 20/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5155 - val_loss: 0.6922 - val_accuracy: 0.5172\n",
      "Epoch 21/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5163 - val_loss: 0.6922 - val_accuracy: 0.5177\n",
      "Epoch 22/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5170 - val_loss: 0.6923 - val_accuracy: 0.5150\n",
      "Epoch 23/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5184 - val_loss: 0.6925 - val_accuracy: 0.5156\n",
      "Epoch 24/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5175 - val_loss: 0.6922 - val_accuracy: 0.5152\n",
      "Epoch 25/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5189 - val_loss: 0.6922 - val_accuracy: 0.5147\n",
      "Epoch 26/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5180 - val_loss: 0.6922 - val_accuracy: 0.5153\n",
      "Epoch 27/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5177 - val_loss: 0.6921 - val_accuracy: 0.5157\n",
      "Epoch 28/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5154 - val_loss: 0.6922 - val_accuracy: 0.5173\n",
      "Epoch 29/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5155 - val_loss: 0.6922 - val_accuracy: 0.5172\n",
      "Epoch 30/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5177 - val_loss: 0.6924 - val_accuracy: 0.5172\n",
      "Epoch 31/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5169 - val_loss: 0.6924 - val_accuracy: 0.5166\n",
      "Epoch 32/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5180 - val_loss: 0.6923 - val_accuracy: 0.5170\n",
      "Epoch 33/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5179 - val_loss: 0.6922 - val_accuracy: 0.5156\n",
      "Epoch 34/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5176 - val_loss: 0.6922 - val_accuracy: 0.5158\n",
      "Epoch 35/1000\n",
      "41255/41255 [==============================] - 1s 12us/sample - loss: 0.6916 - accuracy: 0.5168 - val_loss: 0.6922 - val_accuracy: 0.5160\n",
      "Epoch 36/1000\n",
      "41255/41255 [==============================] - 0s 12us/sample - loss: 0.6916 - accuracy: 0.5182 - val_loss: 0.6923 - val_accuracy: 0.5145\n",
      "Epoch 37/1000\n",
      "41255/41255 [==============================] - 1s 12us/sample - loss: 0.6916 - accuracy: 0.5170 - val_loss: 0.6925 - val_accuracy: 0.5166\n",
      "Epoch 38/1000\n",
      "41255/41255 [==============================] - 1s 12us/sample - loss: 0.6915 - accuracy: 0.5175 - val_loss: 0.6922 - val_accuracy: 0.5152\n",
      "Epoch 39/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5200 - val_loss: 0.6922 - val_accuracy: 0.5155\n",
      "Epoch 40/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5177 - val_loss: 0.6922 - val_accuracy: 0.5139\n",
      "Epoch 41/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5164 - val_loss: 0.6922 - val_accuracy: 0.5165\n",
      "Epoch 42/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5181 - val_loss: 0.6923 - val_accuracy: 0.5179\n",
      "Epoch 43/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5194 - val_loss: 0.6922 - val_accuracy: 0.5170\n",
      "Epoch 44/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5175 - val_loss: 0.6922 - val_accuracy: 0.5172\n",
      "Epoch 45/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5203 - val_loss: 0.6923 - val_accuracy: 0.5166\n",
      "Epoch 46/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5204 - val_loss: 0.6922 - val_accuracy: 0.5150\n",
      "Epoch 47/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5197 - val_loss: 0.6925 - val_accuracy: 0.5158\n",
      "Epoch 48/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5190 - val_loss: 0.6923 - val_accuracy: 0.5182\n",
      "Epoch 49/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5225 - val_loss: 0.6923 - val_accuracy: 0.5150\n",
      "Epoch 50/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5194 - val_loss: 0.6922 - val_accuracy: 0.5182\n",
      "Epoch 51/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5201 - val_loss: 0.6925 - val_accuracy: 0.5155\n",
      "Epoch 52/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5183 - val_loss: 0.6924 - val_accuracy: 0.5151\n",
      "Epoch 53/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5178 - val_loss: 0.6922 - val_accuracy: 0.5172\n",
      "Epoch 54/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5187 - val_loss: 0.6923 - val_accuracy: 0.5158\n",
      "Epoch 55/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5191 - val_loss: 0.6922 - val_accuracy: 0.5164\n",
      "Epoch 56/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5206 - val_loss: 0.6921 - val_accuracy: 0.5171\n",
      "Epoch 57/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5199 - val_loss: 0.6922 - val_accuracy: 0.5181\n",
      "Training with significance = 2.52, run 1\n",
      "Train on 41255 samples, validate on 10314 samples\n",
      "Epoch 1/1000\n",
      "41255/41255 [==============================] - 1s 28us/sample - loss: 0.6930 - accuracy: 0.5105 - val_loss: 0.6942 - val_accuracy: 0.5045\n",
      "Epoch 2/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6925 - accuracy: 0.5147 - val_loss: 0.6932 - val_accuracy: 0.5165\n",
      "Epoch 3/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5154 - val_loss: 0.6924 - val_accuracy: 0.5221\n",
      "Epoch 4/1000\n",
      "41255/41255 [==============================] - 1s 12us/sample - loss: 0.6920 - accuracy: 0.5175 - val_loss: 0.6928 - val_accuracy: 0.5055\n",
      "Epoch 5/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5186 - val_loss: 0.6927 - val_accuracy: 0.5086\n",
      "Epoch 6/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5177 - val_loss: 0.6924 - val_accuracy: 0.5107\n",
      "Epoch 7/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5192 - val_loss: 0.6923 - val_accuracy: 0.5176\n",
      "Epoch 8/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5188 - val_loss: 0.6923 - val_accuracy: 0.5122\n",
      "Epoch 9/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5202 - val_loss: 0.6923 - val_accuracy: 0.5129\n",
      "Epoch 10/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5185 - val_loss: 0.6922 - val_accuracy: 0.5230\n",
      "Epoch 11/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5187 - val_loss: 0.6923 - val_accuracy: 0.5170\n",
      "Epoch 12/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5209 - val_loss: 0.6924 - val_accuracy: 0.5102\n",
      "Epoch 13/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5192 - val_loss: 0.6923 - val_accuracy: 0.5096\n",
      "Epoch 14/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5205 - val_loss: 0.6922 - val_accuracy: 0.5143\n",
      "Epoch 15/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5211 - val_loss: 0.6922 - val_accuracy: 0.5173\n",
      "Epoch 16/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5214 - val_loss: 0.6924 - val_accuracy: 0.5126\n",
      "Epoch 17/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5179 - val_loss: 0.6921 - val_accuracy: 0.5215\n",
      "Epoch 18/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5201 - val_loss: 0.6922 - val_accuracy: 0.5207\n",
      "Epoch 19/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5195 - val_loss: 0.6924 - val_accuracy: 0.5109\n",
      "Epoch 20/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5189 - val_loss: 0.6920 - val_accuracy: 0.5252\n",
      "Epoch 21/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5179 - val_loss: 0.6923 - val_accuracy: 0.5144\n",
      "Epoch 22/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5219 - val_loss: 0.6924 - val_accuracy: 0.5157\n",
      "Epoch 23/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5202 - val_loss: 0.6925 - val_accuracy: 0.5109\n",
      "Epoch 24/1000\n",
      "41255/41255 [==============================] - 1s 12us/sample - loss: 0.6914 - accuracy: 0.5213 - val_loss: 0.6922 - val_accuracy: 0.5130\n",
      "Epoch 25/1000\n",
      "41255/41255 [==============================] - 1s 12us/sample - loss: 0.6913 - accuracy: 0.5209 - val_loss: 0.6924 - val_accuracy: 0.5099\n",
      "Epoch 26/1000\n",
      "41255/41255 [==============================] - 1s 12us/sample - loss: 0.6914 - accuracy: 0.5210 - val_loss: 0.6922 - val_accuracy: 0.5148\n",
      "Epoch 27/1000\n",
      "41255/41255 [==============================] - 1s 12us/sample - loss: 0.6913 - accuracy: 0.5211 - val_loss: 0.6925 - val_accuracy: 0.5129\n",
      "Epoch 28/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5213 - val_loss: 0.6921 - val_accuracy: 0.5234\n",
      "Epoch 29/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5208 - val_loss: 0.6923 - val_accuracy: 0.5121\n",
      "Epoch 30/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5220 - val_loss: 0.6923 - val_accuracy: 0.5125\n",
      "Epoch 31/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5227 - val_loss: 0.6922 - val_accuracy: 0.5168\n",
      "Epoch 32/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5218 - val_loss: 0.6922 - val_accuracy: 0.5174\n",
      "Epoch 33/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5225 - val_loss: 0.6921 - val_accuracy: 0.5208\n",
      "Epoch 34/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5229 - val_loss: 0.6921 - val_accuracy: 0.5182\n",
      "Epoch 35/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5229 - val_loss: 0.6923 - val_accuracy: 0.5138\n",
      "Epoch 36/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5215 - val_loss: 0.6922 - val_accuracy: 0.5156\n",
      "Epoch 37/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5215 - val_loss: 0.6923 - val_accuracy: 0.5130\n",
      "Epoch 38/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5208 - val_loss: 0.6920 - val_accuracy: 0.5212\n",
      "Epoch 39/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5214 - val_loss: 0.6922 - val_accuracy: 0.5189\n",
      "Epoch 40/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5217 - val_loss: 0.6921 - val_accuracy: 0.5183\n",
      "Epoch 41/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5226 - val_loss: 0.6923 - val_accuracy: 0.5140\n",
      "Epoch 42/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5205 - val_loss: 0.6923 - val_accuracy: 0.5148\n",
      "Epoch 43/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5220 - val_loss: 0.6922 - val_accuracy: 0.5172\n",
      "Epoch 44/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5232 - val_loss: 0.6922 - val_accuracy: 0.5192\n",
      "Epoch 45/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5205 - val_loss: 0.6923 - val_accuracy: 0.5117\n",
      "Epoch 46/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5227 - val_loss: 0.6922 - val_accuracy: 0.5182\n",
      "Epoch 47/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5229 - val_loss: 0.6922 - val_accuracy: 0.5201\n",
      "Epoch 48/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5234 - val_loss: 0.6922 - val_accuracy: 0.5193\n",
      "Epoch 49/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5207 - val_loss: 0.6922 - val_accuracy: 0.5174\n",
      "Epoch 50/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5217 - val_loss: 0.6923 - val_accuracy: 0.5127\n",
      "Epoch 51/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5229 - val_loss: 0.6924 - val_accuracy: 0.5139\n",
      "Epoch 52/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5229 - val_loss: 0.6922 - val_accuracy: 0.5183\n",
      "Epoch 53/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5200 - val_loss: 0.6925 - val_accuracy: 0.5115\n",
      "Epoch 54/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5214 - val_loss: 0.6922 - val_accuracy: 0.5193\n",
      "Epoch 55/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5213 - val_loss: 0.6922 - val_accuracy: 0.5206\n",
      "Epoch 56/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5215 - val_loss: 0.6923 - val_accuracy: 0.5155\n",
      "Epoch 57/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5220 - val_loss: 0.6922 - val_accuracy: 0.5215\n",
      "Epoch 58/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5231 - val_loss: 0.6922 - val_accuracy: 0.5185\n",
      "Epoch 59/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5226 - val_loss: 0.6922 - val_accuracy: 0.5172\n",
      "Epoch 60/1000\n",
      "41255/41255 [==============================] - 1s 12us/sample - loss: 0.6910 - accuracy: 0.5248 - val_loss: 0.6924 - val_accuracy: 0.5152\n",
      "Epoch 61/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5210 - val_loss: 0.6924 - val_accuracy: 0.5133\n",
      "Epoch 62/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5231 - val_loss: 0.6923 - val_accuracy: 0.5153\n",
      "Epoch 63/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5232 - val_loss: 0.6922 - val_accuracy: 0.5189\n",
      "Epoch 64/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5237 - val_loss: 0.6923 - val_accuracy: 0.5142\n",
      "Epoch 65/1000\n",
      "41255/41255 [==============================] - 1s 12us/sample - loss: 0.6909 - accuracy: 0.5226 - val_loss: 0.6923 - val_accuracy: 0.5142\n",
      "Epoch 66/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5206 - val_loss: 0.6925 - val_accuracy: 0.5128\n",
      "Epoch 67/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5230 - val_loss: 0.6924 - val_accuracy: 0.5151\n",
      "Epoch 68/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5222 - val_loss: 0.6923 - val_accuracy: 0.5160\n",
      "Training with significance = 2.52, run 2\n",
      "Train on 41255 samples, validate on 10314 samples\n",
      "Epoch 1/1000\n",
      "41255/41255 [==============================] - 1s 27us/sample - loss: 0.6932 - accuracy: 0.5055 - val_loss: 0.6945 - val_accuracy: 0.4962\n",
      "Epoch 2/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6927 - accuracy: 0.5101 - val_loss: 0.6938 - val_accuracy: 0.5046\n",
      "Epoch 3/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6925 - accuracy: 0.5140 - val_loss: 0.6932 - val_accuracy: 0.5149\n",
      "Epoch 4/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5142 - val_loss: 0.6927 - val_accuracy: 0.5211\n",
      "Epoch 5/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5137 - val_loss: 0.6924 - val_accuracy: 0.5201\n",
      "Epoch 6/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5149 - val_loss: 0.6923 - val_accuracy: 0.5184\n",
      "Epoch 7/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5149 - val_loss: 0.6923 - val_accuracy: 0.5178\n",
      "Epoch 8/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5182 - val_loss: 0.6921 - val_accuracy: 0.5211\n",
      "Epoch 9/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5165 - val_loss: 0.6924 - val_accuracy: 0.5141\n",
      "Epoch 10/1000\n",
      "41255/41255 [==============================] - 1s 12us/sample - loss: 0.6920 - accuracy: 0.5182 - val_loss: 0.6923 - val_accuracy: 0.5200\n",
      "Epoch 11/1000\n",
      "41255/41255 [==============================] - 1s 12us/sample - loss: 0.6921 - accuracy: 0.5173 - val_loss: 0.6921 - val_accuracy: 0.5175\n",
      "Epoch 12/1000\n",
      "41255/41255 [==============================] - 1s 12us/sample - loss: 0.6920 - accuracy: 0.5175 - val_loss: 0.6924 - val_accuracy: 0.5129\n",
      "Epoch 13/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41255/41255 [==============================] - 1s 12us/sample - loss: 0.6919 - accuracy: 0.5181 - val_loss: 0.6922 - val_accuracy: 0.5168\n",
      "Epoch 14/1000\n",
      "41255/41255 [==============================] - 1s 12us/sample - loss: 0.6919 - accuracy: 0.5181 - val_loss: 0.6924 - val_accuracy: 0.5132\n",
      "Epoch 15/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5193 - val_loss: 0.6922 - val_accuracy: 0.5166\n",
      "Epoch 16/1000\n",
      "41255/41255 [==============================] - 1s 12us/sample - loss: 0.6919 - accuracy: 0.5196 - val_loss: 0.6925 - val_accuracy: 0.5119\n",
      "Epoch 17/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5197 - val_loss: 0.6926 - val_accuracy: 0.5112\n",
      "Epoch 18/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5197 - val_loss: 0.6922 - val_accuracy: 0.5154\n",
      "Epoch 19/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5194 - val_loss: 0.6924 - val_accuracy: 0.5149\n",
      "Epoch 20/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5185 - val_loss: 0.6924 - val_accuracy: 0.5139\n",
      "Epoch 21/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5182 - val_loss: 0.6923 - val_accuracy: 0.5165\n",
      "Epoch 22/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5207 - val_loss: 0.6923 - val_accuracy: 0.5171\n",
      "Epoch 23/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5177 - val_loss: 0.6924 - val_accuracy: 0.5124\n",
      "Epoch 24/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5183 - val_loss: 0.6925 - val_accuracy: 0.5119\n",
      "Epoch 25/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5200 - val_loss: 0.6923 - val_accuracy: 0.5131\n",
      "Epoch 26/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5182 - val_loss: 0.6924 - val_accuracy: 0.5107\n",
      "Epoch 27/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5221 - val_loss: 0.6922 - val_accuracy: 0.5141\n",
      "Epoch 28/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5193 - val_loss: 0.6925 - val_accuracy: 0.5184\n",
      "Epoch 29/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5190 - val_loss: 0.6924 - val_accuracy: 0.5198\n",
      "Epoch 30/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5222 - val_loss: 0.6921 - val_accuracy: 0.5182\n",
      "Epoch 31/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5203 - val_loss: 0.6926 - val_accuracy: 0.5094\n",
      "Epoch 32/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5205 - val_loss: 0.6925 - val_accuracy: 0.5126\n",
      "Epoch 33/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5196 - val_loss: 0.6928 - val_accuracy: 0.5145\n",
      "Epoch 34/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5224 - val_loss: 0.6924 - val_accuracy: 0.5120\n",
      "Epoch 35/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5224 - val_loss: 0.6926 - val_accuracy: 0.5166\n",
      "Epoch 36/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5208 - val_loss: 0.6927 - val_accuracy: 0.5154\n",
      "Epoch 37/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5195 - val_loss: 0.6923 - val_accuracy: 0.5152\n",
      "Epoch 38/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5210 - val_loss: 0.6928 - val_accuracy: 0.5156\n",
      "Epoch 39/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5191 - val_loss: 0.6922 - val_accuracy: 0.5191\n",
      "Epoch 40/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5218 - val_loss: 0.6924 - val_accuracy: 0.5147\n",
      "Epoch 41/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5204 - val_loss: 0.6924 - val_accuracy: 0.5134\n",
      "Epoch 42/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5193 - val_loss: 0.6926 - val_accuracy: 0.5141\n",
      "Epoch 43/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5219 - val_loss: 0.6923 - val_accuracy: 0.5136\n",
      "Epoch 44/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5221 - val_loss: 0.6921 - val_accuracy: 0.5185\n",
      "Epoch 45/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5196 - val_loss: 0.6925 - val_accuracy: 0.5131\n",
      "Epoch 46/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5204 - val_loss: 0.6925 - val_accuracy: 0.5115\n",
      "Epoch 47/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5210 - val_loss: 0.6922 - val_accuracy: 0.5160\n",
      "Epoch 48/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5203 - val_loss: 0.6926 - val_accuracy: 0.5110\n",
      "Epoch 49/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5203 - val_loss: 0.6924 - val_accuracy: 0.5145\n",
      "Epoch 50/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5216 - val_loss: 0.6923 - val_accuracy: 0.5170\n",
      "Epoch 51/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5209 - val_loss: 0.6922 - val_accuracy: 0.5193\n",
      "Epoch 52/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5219 - val_loss: 0.6927 - val_accuracy: 0.5108\n",
      "Epoch 53/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5225 - val_loss: 0.6924 - val_accuracy: 0.5156\n",
      "Epoch 54/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5227 - val_loss: 0.6921 - val_accuracy: 0.5190\n",
      "Epoch 55/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5200 - val_loss: 0.6924 - val_accuracy: 0.5128\n",
      "Epoch 56/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5226 - val_loss: 0.6927 - val_accuracy: 0.5116\n",
      "Epoch 57/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5210 - val_loss: 0.6923 - val_accuracy: 0.5163\n",
      "Epoch 58/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5188 - val_loss: 0.6922 - val_accuracy: 0.5178\n",
      "Epoch 59/1000\n",
      "41255/41255 [==============================] - 1s 12us/sample - loss: 0.6914 - accuracy: 0.5219 - val_loss: 0.6924 - val_accuracy: 0.5126\n",
      "Epoch 60/1000\n",
      "41255/41255 [==============================] - 1s 12us/sample - loss: 0.6913 - accuracy: 0.5209 - val_loss: 0.6923 - val_accuracy: 0.5182\n",
      "Epoch 61/1000\n",
      "41255/41255 [==============================] - 1s 12us/sample - loss: 0.6914 - accuracy: 0.5230 - val_loss: 0.6921 - val_accuracy: 0.5203\n",
      "Epoch 62/1000\n",
      "41255/41255 [==============================] - 1s 12us/sample - loss: 0.6913 - accuracy: 0.5218 - val_loss: 0.6920 - val_accuracy: 0.5211\n",
      "Epoch 63/1000\n",
      "41255/41255 [==============================] - 1s 12us/sample - loss: 0.6913 - accuracy: 0.5229 - val_loss: 0.6922 - val_accuracy: 0.5172\n",
      "Epoch 64/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5239 - val_loss: 0.6922 - val_accuracy: 0.5147\n",
      "Epoch 65/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5247 - val_loss: 0.6921 - val_accuracy: 0.5218\n",
      "Epoch 66/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5220 - val_loss: 0.6925 - val_accuracy: 0.5189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5204 - val_loss: 0.6925 - val_accuracy: 0.5142\n",
      "Epoch 68/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5203 - val_loss: 0.6925 - val_accuracy: 0.5137\n",
      "Epoch 69/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5222 - val_loss: 0.6924 - val_accuracy: 0.5145\n",
      "Epoch 70/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5222 - val_loss: 0.6929 - val_accuracy: 0.5143\n",
      "Epoch 71/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5232 - val_loss: 0.6926 - val_accuracy: 0.5169\n",
      "Epoch 72/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5239 - val_loss: 0.6926 - val_accuracy: 0.5144\n",
      "Epoch 73/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5216 - val_loss: 0.6926 - val_accuracy: 0.5173\n",
      "Epoch 74/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5234 - val_loss: 0.6926 - val_accuracy: 0.5156\n",
      "Epoch 75/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5228 - val_loss: 0.6927 - val_accuracy: 0.5135\n",
      "Epoch 76/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5219 - val_loss: 0.6926 - val_accuracy: 0.5146\n",
      "Epoch 77/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5207 - val_loss: 0.6926 - val_accuracy: 0.5143\n",
      "Epoch 78/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5236 - val_loss: 0.6927 - val_accuracy: 0.5136\n",
      "Epoch 79/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5210 - val_loss: 0.6927 - val_accuracy: 0.5132\n",
      "Epoch 80/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5240 - val_loss: 0.6927 - val_accuracy: 0.5153\n",
      "Epoch 81/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5246 - val_loss: 0.6924 - val_accuracy: 0.5147\n",
      "Epoch 82/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5247 - val_loss: 0.6924 - val_accuracy: 0.5179\n",
      "Epoch 83/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5213 - val_loss: 0.6927 - val_accuracy: 0.5144\n",
      "Epoch 84/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5233 - val_loss: 0.6926 - val_accuracy: 0.5148\n",
      "Epoch 85/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5229 - val_loss: 0.6928 - val_accuracy: 0.5124\n",
      "Epoch 86/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5232 - val_loss: 0.6923 - val_accuracy: 0.5181\n",
      "Epoch 87/1000\n",
      "41255/41255 [==============================] - 1s 12us/sample - loss: 0.6912 - accuracy: 0.5231 - val_loss: 0.6926 - val_accuracy: 0.5143\n",
      "Epoch 88/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5225 - val_loss: 0.6924 - val_accuracy: 0.5140\n",
      "Epoch 89/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5247 - val_loss: 0.6923 - val_accuracy: 0.5164\n",
      "Epoch 90/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5223 - val_loss: 0.6923 - val_accuracy: 0.5194\n",
      "Epoch 91/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5242 - val_loss: 0.6924 - val_accuracy: 0.5177\n",
      "Epoch 92/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5214 - val_loss: 0.6925 - val_accuracy: 0.5151\n",
      "Training with significance = 2.52, run 3\n",
      "Train on 41255 samples, validate on 10314 samples\n",
      "Epoch 1/1000\n",
      "41255/41255 [==============================] - 1s 29us/sample - loss: 0.6939 - accuracy: 0.5075 - val_loss: 0.6929 - val_accuracy: 0.5063\n",
      "Epoch 2/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6929 - accuracy: 0.5120 - val_loss: 0.6926 - val_accuracy: 0.5163\n",
      "Epoch 3/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6926 - accuracy: 0.5146 - val_loss: 0.6925 - val_accuracy: 0.5190\n",
      "Epoch 4/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6925 - accuracy: 0.5139 - val_loss: 0.6922 - val_accuracy: 0.5204\n",
      "Epoch 5/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5144 - val_loss: 0.6923 - val_accuracy: 0.5165\n",
      "Epoch 6/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5145 - val_loss: 0.6921 - val_accuracy: 0.5196\n",
      "Epoch 7/1000\n",
      "41255/41255 [==============================] - 1s 12us/sample - loss: 0.6921 - accuracy: 0.5147 - val_loss: 0.6923 - val_accuracy: 0.5175\n",
      "Epoch 8/1000\n",
      "41255/41255 [==============================] - 1s 12us/sample - loss: 0.6922 - accuracy: 0.5147 - val_loss: 0.6921 - val_accuracy: 0.5205\n",
      "Epoch 9/1000\n",
      "41255/41255 [==============================] - 1s 12us/sample - loss: 0.6922 - accuracy: 0.5151 - val_loss: 0.6920 - val_accuracy: 0.5194\n",
      "Epoch 10/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5151 - val_loss: 0.6920 - val_accuracy: 0.5184\n",
      "Epoch 11/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5153 - val_loss: 0.6920 - val_accuracy: 0.5190\n",
      "Epoch 12/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5161 - val_loss: 0.6919 - val_accuracy: 0.5173\n",
      "Epoch 13/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5149 - val_loss: 0.6920 - val_accuracy: 0.5180\n",
      "Epoch 14/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5169 - val_loss: 0.6920 - val_accuracy: 0.5183\n",
      "Epoch 15/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5172 - val_loss: 0.6920 - val_accuracy: 0.5180\n",
      "Epoch 16/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5161 - val_loss: 0.6921 - val_accuracy: 0.5178\n",
      "Epoch 17/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5159 - val_loss: 0.6919 - val_accuracy: 0.5189\n",
      "Epoch 18/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5173 - val_loss: 0.6919 - val_accuracy: 0.5187\n",
      "Epoch 19/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5176 - val_loss: 0.6919 - val_accuracy: 0.5184\n",
      "Epoch 20/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5168 - val_loss: 0.6919 - val_accuracy: 0.5184\n",
      "Epoch 21/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5180 - val_loss: 0.6919 - val_accuracy: 0.5175\n",
      "Epoch 22/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5194 - val_loss: 0.6918 - val_accuracy: 0.5177\n",
      "Epoch 23/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5181 - val_loss: 0.6919 - val_accuracy: 0.5178\n",
      "Epoch 24/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5192 - val_loss: 0.6919 - val_accuracy: 0.5181\n",
      "Epoch 25/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5167 - val_loss: 0.6918 - val_accuracy: 0.5173\n",
      "Epoch 26/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5177 - val_loss: 0.6918 - val_accuracy: 0.5183\n",
      "Epoch 27/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5187 - val_loss: 0.6919 - val_accuracy: 0.5185\n",
      "Epoch 28/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5172 - val_loss: 0.6921 - val_accuracy: 0.5188\n",
      "Epoch 29/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5191 - val_loss: 0.6919 - val_accuracy: 0.5192\n",
      "Epoch 30/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5181 - val_loss: 0.6919 - val_accuracy: 0.5180\n",
      "Epoch 31/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5187 - val_loss: 0.6919 - val_accuracy: 0.5189\n",
      "Epoch 32/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5173 - val_loss: 0.6918 - val_accuracy: 0.5178\n",
      "Epoch 33/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5179 - val_loss: 0.6919 - val_accuracy: 0.5190\n",
      "Epoch 34/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5181 - val_loss: 0.6920 - val_accuracy: 0.5176\n",
      "Epoch 35/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5179 - val_loss: 0.6919 - val_accuracy: 0.5176\n",
      "Epoch 36/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5192 - val_loss: 0.6919 - val_accuracy: 0.5176\n",
      "Epoch 37/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5177 - val_loss: 0.6919 - val_accuracy: 0.5167\n",
      "Epoch 38/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5197 - val_loss: 0.6919 - val_accuracy: 0.5168\n",
      "Epoch 39/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5188 - val_loss: 0.6919 - val_accuracy: 0.5188\n",
      "Epoch 40/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5176 - val_loss: 0.6919 - val_accuracy: 0.5143\n",
      "Epoch 41/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5178 - val_loss: 0.6921 - val_accuracy: 0.5152\n",
      "Epoch 42/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5178 - val_loss: 0.6920 - val_accuracy: 0.5158\n",
      "Epoch 43/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5182 - val_loss: 0.6919 - val_accuracy: 0.5177\n",
      "Epoch 44/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5214 - val_loss: 0.6919 - val_accuracy: 0.5175\n",
      "Epoch 45/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5207 - val_loss: 0.6919 - val_accuracy: 0.5185\n",
      "Epoch 46/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5203 - val_loss: 0.6918 - val_accuracy: 0.5177\n",
      "Epoch 47/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5179 - val_loss: 0.6919 - val_accuracy: 0.5174\n",
      "Epoch 48/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5192 - val_loss: 0.6920 - val_accuracy: 0.5179\n",
      "Epoch 49/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5183 - val_loss: 0.6919 - val_accuracy: 0.5200\n",
      "Epoch 50/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5190 - val_loss: 0.6920 - val_accuracy: 0.5181\n",
      "Epoch 51/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5193 - val_loss: 0.6919 - val_accuracy: 0.5185\n",
      "Epoch 52/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5211 - val_loss: 0.6919 - val_accuracy: 0.5182\n",
      "Epoch 53/1000\n",
      "41255/41255 [==============================] - 1s 12us/sample - loss: 0.6914 - accuracy: 0.5199 - val_loss: 0.6920 - val_accuracy: 0.5155\n",
      "Epoch 54/1000\n",
      "41255/41255 [==============================] - 1s 12us/sample - loss: 0.6915 - accuracy: 0.5206 - val_loss: 0.6919 - val_accuracy: 0.5187\n",
      "Epoch 55/1000\n",
      "41255/41255 [==============================] - 1s 12us/sample - loss: 0.6914 - accuracy: 0.5210 - val_loss: 0.6919 - val_accuracy: 0.5147\n",
      "Epoch 56/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5184 - val_loss: 0.6919 - val_accuracy: 0.5175\n",
      "Training with significance = 2.52, run 4\n",
      "Train on 41255 samples, validate on 10314 samples\n",
      "Epoch 1/1000\n",
      "41255/41255 [==============================] - 2s 51us/sample - loss: 0.6931 - accuracy: 0.5086 - val_loss: 0.6950 - val_accuracy: 0.5011\n",
      "Epoch 2/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5171 - val_loss: 0.6940 - val_accuracy: 0.5097\n",
      "Epoch 3/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5175 - val_loss: 0.6933 - val_accuracy: 0.5083\n",
      "Epoch 4/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5186 - val_loss: 0.6930 - val_accuracy: 0.5059\n",
      "Epoch 5/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5176 - val_loss: 0.6930 - val_accuracy: 0.5053\n",
      "Epoch 6/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5192 - val_loss: 0.6931 - val_accuracy: 0.5074\n",
      "Epoch 7/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5203 - val_loss: 0.6932 - val_accuracy: 0.5091\n",
      "Epoch 8/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5199 - val_loss: 0.6930 - val_accuracy: 0.5090\n",
      "Epoch 9/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5198 - val_loss: 0.6929 - val_accuracy: 0.5104\n",
      "Epoch 10/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5216 - val_loss: 0.6930 - val_accuracy: 0.5080\n",
      "Epoch 11/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5205 - val_loss: 0.6929 - val_accuracy: 0.5090\n",
      "Epoch 12/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5209 - val_loss: 0.6930 - val_accuracy: 0.5078\n",
      "Epoch 13/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5212 - val_loss: 0.6932 - val_accuracy: 0.5085\n",
      "Epoch 14/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5216 - val_loss: 0.6931 - val_accuracy: 0.5051\n",
      "Epoch 15/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5227 - val_loss: 0.6931 - val_accuracy: 0.5089\n",
      "Epoch 16/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5220 - val_loss: 0.6930 - val_accuracy: 0.5082\n",
      "Epoch 17/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5219 - val_loss: 0.6930 - val_accuracy: 0.5117\n",
      "Epoch 18/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5220 - val_loss: 0.6931 - val_accuracy: 0.5085\n",
      "Epoch 19/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5216 - val_loss: 0.6930 - val_accuracy: 0.5097\n",
      "Epoch 20/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5229 - val_loss: 0.6930 - val_accuracy: 0.5075\n",
      "Epoch 21/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5236 - val_loss: 0.6931 - val_accuracy: 0.5101\n",
      "Epoch 22/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5230 - val_loss: 0.6931 - val_accuracy: 0.5081\n",
      "Epoch 23/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5220 - val_loss: 0.6930 - val_accuracy: 0.5089\n",
      "Epoch 24/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5253 - val_loss: 0.6932 - val_accuracy: 0.5079\n",
      "Epoch 25/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5219 - val_loss: 0.6930 - val_accuracy: 0.5108\n",
      "Epoch 26/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5245 - val_loss: 0.6931 - val_accuracy: 0.5109\n",
      "Epoch 27/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5235 - val_loss: 0.6930 - val_accuracy: 0.5097\n",
      "Epoch 28/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5236 - val_loss: 0.6930 - val_accuracy: 0.5103\n",
      "Epoch 29/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5239 - val_loss: 0.6931 - val_accuracy: 0.5091\n",
      "Epoch 30/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5226 - val_loss: 0.6931 - val_accuracy: 0.5084\n",
      "Epoch 31/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5220 - val_loss: 0.6930 - val_accuracy: 0.5086\n",
      "Epoch 32/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5247 - val_loss: 0.6931 - val_accuracy: 0.5055\n",
      "Epoch 33/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5244 - val_loss: 0.6930 - val_accuracy: 0.5086\n",
      "Epoch 34/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5217 - val_loss: 0.6932 - val_accuracy: 0.5079\n",
      "Epoch 35/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5239 - val_loss: 0.6931 - val_accuracy: 0.5084\n",
      "Epoch 36/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5242 - val_loss: 0.6931 - val_accuracy: 0.5095\n",
      "Epoch 37/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5235 - val_loss: 0.6931 - val_accuracy: 0.5081\n",
      "Epoch 38/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5229 - val_loss: 0.6930 - val_accuracy: 0.5081\n",
      "Epoch 39/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5237 - val_loss: 0.6930 - val_accuracy: 0.5057\n",
      "Epoch 40/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5235 - val_loss: 0.6930 - val_accuracy: 0.5074\n",
      "Epoch 41/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5240 - val_loss: 0.6931 - val_accuracy: 0.5067\n",
      "Training with significance = 2.52, run 5\n",
      "Train on 41255 samples, validate on 10314 samples\n",
      "Epoch 1/1000\n",
      "41255/41255 [==============================] - 1s 28us/sample - loss: 0.6928 - accuracy: 0.5092 - val_loss: 0.6934 - val_accuracy: 0.5222\n",
      "Epoch 2/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6925 - accuracy: 0.5114 - val_loss: 0.6924 - val_accuracy: 0.5214\n",
      "Epoch 3/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5113 - val_loss: 0.6921 - val_accuracy: 0.5265\n",
      "Epoch 4/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5131 - val_loss: 0.6922 - val_accuracy: 0.5240\n",
      "Epoch 5/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5137 - val_loss: 0.6923 - val_accuracy: 0.5096\n",
      "Epoch 6/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5157 - val_loss: 0.6920 - val_accuracy: 0.5222\n",
      "Epoch 7/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5153 - val_loss: 0.6921 - val_accuracy: 0.5179\n",
      "Epoch 8/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5122 - val_loss: 0.6920 - val_accuracy: 0.5245\n",
      "Epoch 9/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5156 - val_loss: 0.6921 - val_accuracy: 0.5231\n",
      "Epoch 10/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5128 - val_loss: 0.6922 - val_accuracy: 0.5226\n",
      "Epoch 11/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5136 - val_loss: 0.6919 - val_accuracy: 0.5259\n",
      "Epoch 12/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5149 - val_loss: 0.6923 - val_accuracy: 0.5242\n",
      "Epoch 13/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5163 - val_loss: 0.6918 - val_accuracy: 0.5261\n",
      "Epoch 14/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5154 - val_loss: 0.6923 - val_accuracy: 0.5139\n",
      "Epoch 15/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5162 - val_loss: 0.6920 - val_accuracy: 0.5261\n",
      "Epoch 16/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5179 - val_loss: 0.6921 - val_accuracy: 0.5258\n",
      "Epoch 17/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5166 - val_loss: 0.6922 - val_accuracy: 0.5162\n",
      "Epoch 18/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5168 - val_loss: 0.6921 - val_accuracy: 0.5222\n",
      "Epoch 19/1000\n",
      "41255/41255 [==============================] - 1s 12us/sample - loss: 0.6918 - accuracy: 0.5155 - val_loss: 0.6921 - val_accuracy: 0.5213\n",
      "Epoch 20/1000\n",
      "41255/41255 [==============================] - 1s 12us/sample - loss: 0.6916 - accuracy: 0.5178 - val_loss: 0.6920 - val_accuracy: 0.5260\n",
      "Epoch 21/1000\n",
      "41255/41255 [==============================] - 0s 12us/sample - loss: 0.6917 - accuracy: 0.5170 - val_loss: 0.6921 - val_accuracy: 0.5239\n",
      "Epoch 22/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5173 - val_loss: 0.6925 - val_accuracy: 0.5039\n",
      "Epoch 23/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5195 - val_loss: 0.6920 - val_accuracy: 0.5247\n",
      "Epoch 24/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5174 - val_loss: 0.6921 - val_accuracy: 0.5190\n",
      "Epoch 25/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5193 - val_loss: 0.6918 - val_accuracy: 0.5271\n",
      "Epoch 26/1000\n",
      "41255/41255 [==============================] - 1s 12us/sample - loss: 0.6916 - accuracy: 0.5161 - val_loss: 0.6922 - val_accuracy: 0.5126\n",
      "Epoch 27/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5189 - val_loss: 0.6922 - val_accuracy: 0.5138\n",
      "Epoch 28/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5191 - val_loss: 0.6919 - val_accuracy: 0.5256\n",
      "Epoch 29/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5174 - val_loss: 0.6921 - val_accuracy: 0.5180\n",
      "Epoch 30/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5166 - val_loss: 0.6921 - val_accuracy: 0.5176\n",
      "Epoch 31/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5169 - val_loss: 0.6921 - val_accuracy: 0.5199\n",
      "Epoch 32/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5174 - val_loss: 0.6924 - val_accuracy: 0.5139\n",
      "Epoch 33/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5171 - val_loss: 0.6921 - val_accuracy: 0.5191\n",
      "Epoch 34/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5180 - val_loss: 0.6918 - val_accuracy: 0.5259\n",
      "Epoch 35/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5189 - val_loss: 0.6920 - val_accuracy: 0.5271\n",
      "Epoch 36/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5182 - val_loss: 0.6922 - val_accuracy: 0.5204\n",
      "Epoch 37/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5177 - val_loss: 0.6921 - val_accuracy: 0.5197\n",
      "Epoch 38/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5198 - val_loss: 0.6922 - val_accuracy: 0.5078\n",
      "Epoch 39/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5188 - val_loss: 0.6920 - val_accuracy: 0.5241\n",
      "Epoch 40/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5190 - val_loss: 0.6919 - val_accuracy: 0.5255\n",
      "Epoch 41/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5186 - val_loss: 0.6920 - val_accuracy: 0.5262\n",
      "Epoch 42/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5206 - val_loss: 0.6923 - val_accuracy: 0.5154\n",
      "Epoch 43/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5187 - val_loss: 0.6922 - val_accuracy: 0.5131\n",
      "Epoch 44/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5204 - val_loss: 0.6921 - val_accuracy: 0.5153\n",
      "Epoch 45/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5201 - val_loss: 0.6922 - val_accuracy: 0.5119\n",
      "Epoch 46/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5198 - val_loss: 0.6921 - val_accuracy: 0.5157\n",
      "Epoch 47/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5181 - val_loss: 0.6923 - val_accuracy: 0.5111\n",
      "Epoch 48/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5204 - val_loss: 0.6924 - val_accuracy: 0.5119\n",
      "Epoch 49/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5179 - val_loss: 0.6923 - val_accuracy: 0.5136\n",
      "Epoch 50/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5211 - val_loss: 0.6924 - val_accuracy: 0.5186\n",
      "Epoch 51/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5200 - val_loss: 0.6923 - val_accuracy: 0.5071\n",
      "Epoch 52/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5229 - val_loss: 0.6920 - val_accuracy: 0.5258\n",
      "Epoch 53/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5183 - val_loss: 0.6923 - val_accuracy: 0.5080\n",
      "Epoch 54/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5198 - val_loss: 0.6924 - val_accuracy: 0.5073\n",
      "Epoch 55/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5195 - val_loss: 0.6923 - val_accuracy: 0.5099\n",
      "Training with significance = 2.52, run 6\n",
      "Train on 41255 samples, validate on 10314 samples\n",
      "Epoch 1/1000\n",
      "41255/41255 [==============================] - 1s 28us/sample - loss: 0.6932 - accuracy: 0.5107 - val_loss: 0.6930 - val_accuracy: 0.5085\n",
      "Epoch 2/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6925 - accuracy: 0.5145 - val_loss: 0.6926 - val_accuracy: 0.5072\n",
      "Epoch 3/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5171 - val_loss: 0.6924 - val_accuracy: 0.5086\n",
      "Epoch 4/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5175 - val_loss: 0.6924 - val_accuracy: 0.5084\n",
      "Epoch 5/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5162 - val_loss: 0.6922 - val_accuracy: 0.5122\n",
      "Epoch 6/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5176 - val_loss: 0.6923 - val_accuracy: 0.5102\n",
      "Epoch 7/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5173 - val_loss: 0.6921 - val_accuracy: 0.5168\n",
      "Epoch 8/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5182 - val_loss: 0.6921 - val_accuracy: 0.5151\n",
      "Epoch 9/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5181 - val_loss: 0.6922 - val_accuracy: 0.5160\n",
      "Epoch 10/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5173 - val_loss: 0.6920 - val_accuracy: 0.5163\n",
      "Epoch 11/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5186 - val_loss: 0.6920 - val_accuracy: 0.5164\n",
      "Epoch 12/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5190 - val_loss: 0.6923 - val_accuracy: 0.5129\n",
      "Epoch 13/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5177 - val_loss: 0.6921 - val_accuracy: 0.5150\n",
      "Epoch 14/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5199 - val_loss: 0.6921 - val_accuracy: 0.5165\n",
      "Epoch 15/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5196 - val_loss: 0.6921 - val_accuracy: 0.5167\n",
      "Epoch 16/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5191 - val_loss: 0.6921 - val_accuracy: 0.5153\n",
      "Epoch 17/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5185 - val_loss: 0.6920 - val_accuracy: 0.5182\n",
      "Epoch 18/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5196 - val_loss: 0.6921 - val_accuracy: 0.5144\n",
      "Epoch 19/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5201 - val_loss: 0.6923 - val_accuracy: 0.5141\n",
      "Epoch 20/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5179 - val_loss: 0.6922 - val_accuracy: 0.5134\n",
      "Epoch 21/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5190 - val_loss: 0.6922 - val_accuracy: 0.5131\n",
      "Epoch 22/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5182 - val_loss: 0.6921 - val_accuracy: 0.5150\n",
      "Epoch 23/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5193 - val_loss: 0.6922 - val_accuracy: 0.5161\n",
      "Epoch 24/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5187 - val_loss: 0.6921 - val_accuracy: 0.5153\n",
      "Epoch 25/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5193 - val_loss: 0.6920 - val_accuracy: 0.5152\n",
      "Epoch 26/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5193 - val_loss: 0.6922 - val_accuracy: 0.5132\n",
      "Epoch 27/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5194 - val_loss: 0.6921 - val_accuracy: 0.5140\n",
      "Epoch 28/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5188 - val_loss: 0.6921 - val_accuracy: 0.5138\n",
      "Epoch 29/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5191 - val_loss: 0.6923 - val_accuracy: 0.5130\n",
      "Epoch 30/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5192 - val_loss: 0.6921 - val_accuracy: 0.5139\n",
      "Epoch 31/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5196 - val_loss: 0.6921 - val_accuracy: 0.5139\n",
      "Epoch 32/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5210 - val_loss: 0.6926 - val_accuracy: 0.5124\n",
      "Epoch 33/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5192 - val_loss: 0.6923 - val_accuracy: 0.5117\n",
      "Epoch 34/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5187 - val_loss: 0.6921 - val_accuracy: 0.5140\n",
      "Epoch 35/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5193 - val_loss: 0.6920 - val_accuracy: 0.5128\n",
      "Epoch 36/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5197 - val_loss: 0.6921 - val_accuracy: 0.5114\n",
      "Epoch 37/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5187 - val_loss: 0.6920 - val_accuracy: 0.5137\n",
      "Epoch 38/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5205 - val_loss: 0.6920 - val_accuracy: 0.5126\n",
      "Epoch 39/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5209 - val_loss: 0.6921 - val_accuracy: 0.5128\n",
      "Epoch 40/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5209 - val_loss: 0.6922 - val_accuracy: 0.5140\n",
      "Epoch 41/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5203 - val_loss: 0.6921 - val_accuracy: 0.5146\n",
      "Epoch 42/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5202 - val_loss: 0.6922 - val_accuracy: 0.5126\n",
      "Epoch 43/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5208 - val_loss: 0.6922 - val_accuracy: 0.5119\n",
      "Epoch 44/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5211 - val_loss: 0.6922 - val_accuracy: 0.5132\n",
      "Epoch 45/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5224 - val_loss: 0.6922 - val_accuracy: 0.5138\n",
      "Epoch 46/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5209 - val_loss: 0.6920 - val_accuracy: 0.5150\n",
      "Epoch 47/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5202 - val_loss: 0.6921 - val_accuracy: 0.5108\n",
      "Epoch 48/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5209 - val_loss: 0.6922 - val_accuracy: 0.5104\n",
      "Epoch 49/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5218 - val_loss: 0.6921 - val_accuracy: 0.5112\n",
      "Epoch 50/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5205 - val_loss: 0.6922 - val_accuracy: 0.5109\n",
      "Epoch 51/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5211 - val_loss: 0.6921 - val_accuracy: 0.5125\n",
      "Epoch 52/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5210 - val_loss: 0.6920 - val_accuracy: 0.5159\n",
      "Epoch 53/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5218 - val_loss: 0.6923 - val_accuracy: 0.5130\n",
      "Epoch 54/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5235 - val_loss: 0.6921 - val_accuracy: 0.5130\n",
      "Epoch 55/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5212 - val_loss: 0.6921 - val_accuracy: 0.5134\n",
      "Epoch 56/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5212 - val_loss: 0.6921 - val_accuracy: 0.5127\n",
      "Epoch 57/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5227 - val_loss: 0.6921 - val_accuracy: 0.5115\n",
      "Epoch 58/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5210 - val_loss: 0.6922 - val_accuracy: 0.5115\n",
      "Epoch 59/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5216 - val_loss: 0.6923 - val_accuracy: 0.5109\n",
      "Epoch 60/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5222 - val_loss: 0.6923 - val_accuracy: 0.5092\n",
      "Epoch 61/1000\n",
      "41255/41255 [==============================] - 1s 12us/sample - loss: 0.6914 - accuracy: 0.5204 - val_loss: 0.6922 - val_accuracy: 0.5128\n",
      "Epoch 62/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5203 - val_loss: 0.6920 - val_accuracy: 0.5143\n",
      "Epoch 63/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5218 - val_loss: 0.6921 - val_accuracy: 0.5113\n",
      "Epoch 64/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5221 - val_loss: 0.6920 - val_accuracy: 0.5136\n",
      "Epoch 65/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5239 - val_loss: 0.6920 - val_accuracy: 0.5151\n",
      "Epoch 66/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5223 - val_loss: 0.6923 - val_accuracy: 0.5118\n",
      "Epoch 67/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5217 - val_loss: 0.6921 - val_accuracy: 0.5122\n",
      "Epoch 68/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5213 - val_loss: 0.6921 - val_accuracy: 0.5128\n",
      "Training with significance = 2.52, run 7\n",
      "Train on 41255 samples, validate on 10314 samples\n",
      "Epoch 1/1000\n",
      "41255/41255 [==============================] - 1s 28us/sample - loss: 0.6930 - accuracy: 0.5102 - val_loss: 0.6934 - val_accuracy: 0.5074\n",
      "Epoch 2/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5160 - val_loss: 0.6935 - val_accuracy: 0.5104\n",
      "Epoch 3/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5146 - val_loss: 0.6923 - val_accuracy: 0.5148\n",
      "Epoch 4/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5148 - val_loss: 0.6923 - val_accuracy: 0.5181\n",
      "Epoch 5/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5167 - val_loss: 0.6924 - val_accuracy: 0.5153\n",
      "Epoch 6/1000\n",
      "41255/41255 [==============================] - 1s 12us/sample - loss: 0.6919 - accuracy: 0.5157 - val_loss: 0.6924 - val_accuracy: 0.5132\n",
      "Epoch 7/1000\n",
      "41255/41255 [==============================] - 1s 12us/sample - loss: 0.6919 - accuracy: 0.5168 - val_loss: 0.6923 - val_accuracy: 0.5133\n",
      "Epoch 8/1000\n",
      "41255/41255 [==============================] - 1s 12us/sample - loss: 0.6918 - accuracy: 0.5164 - val_loss: 0.6925 - val_accuracy: 0.5106\n",
      "Epoch 9/1000\n",
      "41255/41255 [==============================] - 1s 12us/sample - loss: 0.6919 - accuracy: 0.5163 - val_loss: 0.6924 - val_accuracy: 0.5096\n",
      "Epoch 10/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5183 - val_loss: 0.6925 - val_accuracy: 0.5111\n",
      "Epoch 11/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5168 - val_loss: 0.6924 - val_accuracy: 0.5098\n",
      "Epoch 12/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5178 - val_loss: 0.6923 - val_accuracy: 0.5111\n",
      "Epoch 13/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5182 - val_loss: 0.6924 - val_accuracy: 0.5101\n",
      "Epoch 14/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5177 - val_loss: 0.6924 - val_accuracy: 0.5120\n",
      "Epoch 15/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5179 - val_loss: 0.6925 - val_accuracy: 0.5109\n",
      "Epoch 16/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5187 - val_loss: 0.6923 - val_accuracy: 0.5105\n",
      "Epoch 17/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5187 - val_loss: 0.6923 - val_accuracy: 0.5098\n",
      "Epoch 18/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5187 - val_loss: 0.6923 - val_accuracy: 0.5133\n",
      "Epoch 19/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5174 - val_loss: 0.6923 - val_accuracy: 0.5119\n",
      "Epoch 20/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5192 - val_loss: 0.6924 - val_accuracy: 0.5102\n",
      "Epoch 21/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5190 - val_loss: 0.6925 - val_accuracy: 0.5080\n",
      "Epoch 22/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5162 - val_loss: 0.6924 - val_accuracy: 0.5119\n",
      "Epoch 23/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5183 - val_loss: 0.6923 - val_accuracy: 0.5089\n",
      "Epoch 24/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5171 - val_loss: 0.6925 - val_accuracy: 0.5112\n",
      "Epoch 25/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5190 - val_loss: 0.6923 - val_accuracy: 0.5108\n",
      "Epoch 26/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5173 - val_loss: 0.6923 - val_accuracy: 0.5096\n",
      "Epoch 27/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5196 - val_loss: 0.6924 - val_accuracy: 0.5102\n",
      "Epoch 28/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5192 - val_loss: 0.6923 - val_accuracy: 0.5081\n",
      "Epoch 29/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5182 - val_loss: 0.6925 - val_accuracy: 0.5075\n",
      "Epoch 30/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5197 - val_loss: 0.6924 - val_accuracy: 0.5088\n",
      "Epoch 31/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5185 - val_loss: 0.6924 - val_accuracy: 0.5111\n",
      "Epoch 32/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5185 - val_loss: 0.6924 - val_accuracy: 0.5104\n",
      "Epoch 33/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5203 - val_loss: 0.6924 - val_accuracy: 0.5126\n",
      "Epoch 34/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5196 - val_loss: 0.6925 - val_accuracy: 0.5074\n",
      "Training with significance = 2.52, run 8\n",
      "Train on 41255 samples, validate on 10314 samples\n",
      "Epoch 1/1000\n",
      "41255/41255 [==============================] - 1s 27us/sample - loss: 0.6934 - accuracy: 0.5039 - val_loss: 0.6929 - val_accuracy: 0.5038\n",
      "Epoch 2/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6926 - accuracy: 0.5155 - val_loss: 0.6924 - val_accuracy: 0.5147\n",
      "Epoch 3/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5162 - val_loss: 0.6921 - val_accuracy: 0.5173\n",
      "Epoch 4/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5155 - val_loss: 0.6921 - val_accuracy: 0.5170\n",
      "Epoch 5/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5163 - val_loss: 0.6921 - val_accuracy: 0.5167\n",
      "Epoch 6/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5179 - val_loss: 0.6921 - val_accuracy: 0.5190\n",
      "Epoch 7/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5177 - val_loss: 0.6921 - val_accuracy: 0.5189\n",
      "Epoch 8/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5187 - val_loss: 0.6922 - val_accuracy: 0.5178\n",
      "Epoch 9/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5173 - val_loss: 0.6922 - val_accuracy: 0.5193\n",
      "Epoch 10/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5199 - val_loss: 0.6922 - val_accuracy: 0.5171\n",
      "Epoch 11/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5184 - val_loss: 0.6921 - val_accuracy: 0.5178\n",
      "Epoch 12/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5198 - val_loss: 0.6921 - val_accuracy: 0.5173\n",
      "Epoch 13/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5192 - val_loss: 0.6921 - val_accuracy: 0.5196\n",
      "Epoch 14/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5205 - val_loss: 0.6922 - val_accuracy: 0.5173\n",
      "Epoch 15/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5182 - val_loss: 0.6922 - val_accuracy: 0.5151\n",
      "Epoch 16/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5181 - val_loss: 0.6920 - val_accuracy: 0.5189\n",
      "Epoch 17/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5192 - val_loss: 0.6920 - val_accuracy: 0.5176\n",
      "Epoch 18/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5193 - val_loss: 0.6922 - val_accuracy: 0.5160\n",
      "Epoch 19/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5194 - val_loss: 0.6922 - val_accuracy: 0.5170\n",
      "Epoch 20/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5187 - val_loss: 0.6922 - val_accuracy: 0.5163\n",
      "Epoch 21/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5198 - val_loss: 0.6922 - val_accuracy: 0.5175\n",
      "Epoch 22/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5184 - val_loss: 0.6923 - val_accuracy: 0.5121\n",
      "Epoch 23/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5194 - val_loss: 0.6921 - val_accuracy: 0.5164\n",
      "Epoch 24/1000\n",
      "41255/41255 [==============================] - 1s 12us/sample - loss: 0.6914 - accuracy: 0.5188 - val_loss: 0.6920 - val_accuracy: 0.5196\n",
      "Epoch 25/1000\n",
      "41255/41255 [==============================] - 1s 12us/sample - loss: 0.6915 - accuracy: 0.5202 - val_loss: 0.6921 - val_accuracy: 0.5172\n",
      "Epoch 26/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5194 - val_loss: 0.6923 - val_accuracy: 0.5128\n",
      "Epoch 27/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5201 - val_loss: 0.6921 - val_accuracy: 0.5179\n",
      "Epoch 28/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5223 - val_loss: 0.6921 - val_accuracy: 0.5179\n",
      "Epoch 29/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5207 - val_loss: 0.6921 - val_accuracy: 0.5176\n",
      "Epoch 30/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5187 - val_loss: 0.6922 - val_accuracy: 0.5156\n",
      "Epoch 31/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5202 - val_loss: 0.6923 - val_accuracy: 0.5133\n",
      "Epoch 32/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5204 - val_loss: 0.6921 - val_accuracy: 0.5175\n",
      "Epoch 33/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5197 - val_loss: 0.6921 - val_accuracy: 0.5157\n",
      "Epoch 34/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5203 - val_loss: 0.6923 - val_accuracy: 0.5158\n",
      "Epoch 35/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5195 - val_loss: 0.6922 - val_accuracy: 0.5173\n",
      "Epoch 36/1000\n",
      "41255/41255 [==============================] - 1s 12us/sample - loss: 0.6913 - accuracy: 0.5206 - val_loss: 0.6922 - val_accuracy: 0.5159\n",
      "Epoch 37/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5171 - val_loss: 0.6921 - val_accuracy: 0.5169\n",
      "Epoch 38/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5191 - val_loss: 0.6922 - val_accuracy: 0.5155\n",
      "Epoch 39/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5206 - val_loss: 0.6922 - val_accuracy: 0.5189\n",
      "Epoch 40/1000\n",
      "41255/41255 [==============================] - 1s 12us/sample - loss: 0.6913 - accuracy: 0.5197 - val_loss: 0.6923 - val_accuracy: 0.5143\n",
      "Epoch 41/1000\n",
      "41255/41255 [==============================] - 1s 12us/sample - loss: 0.6914 - accuracy: 0.5207 - val_loss: 0.6922 - val_accuracy: 0.5163\n",
      "Epoch 42/1000\n",
      "41255/41255 [==============================] - 0s 12us/sample - loss: 0.6914 - accuracy: 0.5201 - val_loss: 0.6923 - val_accuracy: 0.5157\n",
      "Epoch 43/1000\n",
      "41255/41255 [==============================] - 1s 12us/sample - loss: 0.6912 - accuracy: 0.5231 - val_loss: 0.6921 - val_accuracy: 0.5174\n",
      "Epoch 44/1000\n",
      "41255/41255 [==============================] - 1s 12us/sample - loss: 0.6913 - accuracy: 0.5204 - val_loss: 0.6923 - val_accuracy: 0.5148\n",
      "Epoch 45/1000\n",
      "41255/41255 [==============================] - 1s 12us/sample - loss: 0.6912 - accuracy: 0.5216 - val_loss: 0.6923 - val_accuracy: 0.5153\n",
      "Epoch 46/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5207 - val_loss: 0.6923 - val_accuracy: 0.5131\n",
      "Training with significance = 2.52, run 9\n",
      "Train on 41255 samples, validate on 10314 samples\n",
      "Epoch 1/1000\n",
      "41255/41255 [==============================] - 1s 27us/sample - loss: 0.6932 - accuracy: 0.5100 - val_loss: 0.6934 - val_accuracy: 0.4992\n",
      "Epoch 2/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5155 - val_loss: 0.6928 - val_accuracy: 0.5154\n",
      "Epoch 3/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5174 - val_loss: 0.6926 - val_accuracy: 0.5108\n",
      "Epoch 4/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5146 - val_loss: 0.6924 - val_accuracy: 0.5143\n",
      "Epoch 5/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5175 - val_loss: 0.6925 - val_accuracy: 0.5128\n",
      "Epoch 6/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5175 - val_loss: 0.6923 - val_accuracy: 0.5148\n",
      "Epoch 7/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5172 - val_loss: 0.6926 - val_accuracy: 0.5121\n",
      "Epoch 8/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5167 - val_loss: 0.6925 - val_accuracy: 0.5124\n",
      "Epoch 9/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5180 - val_loss: 0.6925 - val_accuracy: 0.5133\n",
      "Epoch 10/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5181 - val_loss: 0.6927 - val_accuracy: 0.5122\n",
      "Epoch 11/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5187 - val_loss: 0.6923 - val_accuracy: 0.5116\n",
      "Epoch 12/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5184 - val_loss: 0.6922 - val_accuracy: 0.5136\n",
      "Epoch 13/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5176 - val_loss: 0.6926 - val_accuracy: 0.5108\n",
      "Epoch 14/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5178 - val_loss: 0.6924 - val_accuracy: 0.5103\n",
      "Epoch 15/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5187 - val_loss: 0.6923 - val_accuracy: 0.5125\n",
      "Epoch 16/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5181 - val_loss: 0.6926 - val_accuracy: 0.5129\n",
      "Epoch 17/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5176 - val_loss: 0.6926 - val_accuracy: 0.5114\n",
      "Epoch 18/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5179 - val_loss: 0.6925 - val_accuracy: 0.5126\n",
      "Epoch 19/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5190 - val_loss: 0.6925 - val_accuracy: 0.5100\n",
      "Epoch 20/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5197 - val_loss: 0.6923 - val_accuracy: 0.5100\n",
      "Epoch 21/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5180 - val_loss: 0.6925 - val_accuracy: 0.5106\n",
      "Epoch 22/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5208 - val_loss: 0.6923 - val_accuracy: 0.5107\n",
      "Epoch 23/1000\n",
      "41255/41255 [==============================] - 1s 12us/sample - loss: 0.6915 - accuracy: 0.5193 - val_loss: 0.6925 - val_accuracy: 0.5108\n",
      "Epoch 24/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5203 - val_loss: 0.6926 - val_accuracy: 0.5111\n",
      "Epoch 25/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5197 - val_loss: 0.6923 - val_accuracy: 0.5117\n",
      "Epoch 26/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5200 - val_loss: 0.6926 - val_accuracy: 0.5124\n",
      "Epoch 27/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5201 - val_loss: 0.6926 - val_accuracy: 0.5122\n",
      "Epoch 28/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5200 - val_loss: 0.6925 - val_accuracy: 0.5126\n",
      "Epoch 29/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5193 - val_loss: 0.6923 - val_accuracy: 0.5098\n",
      "Epoch 30/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5200 - val_loss: 0.6925 - val_accuracy: 0.5092\n",
      "Epoch 31/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5205 - val_loss: 0.6925 - val_accuracy: 0.5095\n",
      "Epoch 32/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5194 - val_loss: 0.6927 - val_accuracy: 0.5117\n",
      "Epoch 33/1000\n",
      "41255/41255 [==============================] - 1s 12us/sample - loss: 0.6915 - accuracy: 0.5198 - val_loss: 0.6925 - val_accuracy: 0.5088\n",
      "Epoch 34/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5195 - val_loss: 0.6928 - val_accuracy: 0.5088\n",
      "Epoch 35/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5206 - val_loss: 0.6927 - val_accuracy: 0.5107\n",
      "Epoch 36/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5188 - val_loss: 0.6926 - val_accuracy: 0.5093\n",
      "Epoch 37/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5211 - val_loss: 0.6925 - val_accuracy: 0.5093\n",
      "Epoch 38/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5187 - val_loss: 0.6924 - val_accuracy: 0.5099\n",
      "Epoch 39/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5196 - val_loss: 0.6925 - val_accuracy: 0.5114\n",
      "Epoch 40/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5214 - val_loss: 0.6928 - val_accuracy: 0.5112\n",
      "Epoch 41/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5201 - val_loss: 0.6924 - val_accuracy: 0.5098\n",
      "Epoch 42/1000\n",
      "41255/41255 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5202 - val_loss: 0.6928 - val_accuracy: 0.5099\n",
      "Training with significance = 2.84, run 0\n",
      "Train on 41306 samples, validate on 10327 samples\n",
      "Epoch 1/1000\n",
      "41306/41306 [==============================] - 2s 53us/sample - loss: 0.6931 - accuracy: 0.5077 - val_loss: 0.6953 - val_accuracy: 0.5007\n",
      "Epoch 2/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6925 - accuracy: 0.5139 - val_loss: 0.6933 - val_accuracy: 0.5054\n",
      "Epoch 3/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5147 - val_loss: 0.6926 - val_accuracy: 0.5115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5160 - val_loss: 0.6924 - val_accuracy: 0.5137\n",
      "Epoch 5/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5145 - val_loss: 0.6923 - val_accuracy: 0.5148\n",
      "Epoch 6/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5156 - val_loss: 0.6922 - val_accuracy: 0.5113\n",
      "Epoch 7/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5155 - val_loss: 0.6921 - val_accuracy: 0.5117\n",
      "Epoch 8/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5155 - val_loss: 0.6922 - val_accuracy: 0.5110\n",
      "Epoch 9/1000\n",
      "41306/41306 [==============================] - 1s 14us/sample - loss: 0.6921 - accuracy: 0.5166 - val_loss: 0.6921 - val_accuracy: 0.5118\n",
      "Epoch 10/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5163 - val_loss: 0.6919 - val_accuracy: 0.5140\n",
      "Epoch 11/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5156 - val_loss: 0.6920 - val_accuracy: 0.5111\n",
      "Epoch 12/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5171 - val_loss: 0.6918 - val_accuracy: 0.5164\n",
      "Epoch 13/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5158 - val_loss: 0.6919 - val_accuracy: 0.5127\n",
      "Epoch 14/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5169 - val_loss: 0.6919 - val_accuracy: 0.5127\n",
      "Epoch 15/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5180 - val_loss: 0.6922 - val_accuracy: 0.5125\n",
      "Epoch 16/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5170 - val_loss: 0.6919 - val_accuracy: 0.5122\n",
      "Epoch 17/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5176 - val_loss: 0.6920 - val_accuracy: 0.5098\n",
      "Epoch 18/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5180 - val_loss: 0.6919 - val_accuracy: 0.5123\n",
      "Epoch 19/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5189 - val_loss: 0.6922 - val_accuracy: 0.5124\n",
      "Epoch 20/1000\n",
      "41306/41306 [==============================] - 1s 12us/sample - loss: 0.6919 - accuracy: 0.5165 - val_loss: 0.6920 - val_accuracy: 0.5148\n",
      "Epoch 21/1000\n",
      "41306/41306 [==============================] - 0s 12us/sample - loss: 0.6918 - accuracy: 0.5191 - val_loss: 0.6920 - val_accuracy: 0.5134\n",
      "Epoch 22/1000\n",
      "41306/41306 [==============================] - 1s 12us/sample - loss: 0.6919 - accuracy: 0.5179 - val_loss: 0.6919 - val_accuracy: 0.5102\n",
      "Epoch 23/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5185 - val_loss: 0.6920 - val_accuracy: 0.5112\n",
      "Epoch 24/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5184 - val_loss: 0.6919 - val_accuracy: 0.5142\n",
      "Epoch 25/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5173 - val_loss: 0.6917 - val_accuracy: 0.5115\n",
      "Epoch 26/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5178 - val_loss: 0.6918 - val_accuracy: 0.5137\n",
      "Epoch 27/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5178 - val_loss: 0.6920 - val_accuracy: 0.5114\n",
      "Epoch 28/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5178 - val_loss: 0.6918 - val_accuracy: 0.5112\n",
      "Epoch 29/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5175 - val_loss: 0.6920 - val_accuracy: 0.5110\n",
      "Epoch 30/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5176 - val_loss: 0.6920 - val_accuracy: 0.5126\n",
      "Epoch 31/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5178 - val_loss: 0.6921 - val_accuracy: 0.5114\n",
      "Epoch 32/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5190 - val_loss: 0.6919 - val_accuracy: 0.5092\n",
      "Epoch 33/1000\n",
      "41306/41306 [==============================] - 1s 12us/sample - loss: 0.6917 - accuracy: 0.5194 - val_loss: 0.6919 - val_accuracy: 0.5115\n",
      "Epoch 34/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5178 - val_loss: 0.6920 - val_accuracy: 0.5119\n",
      "Epoch 35/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5196 - val_loss: 0.6921 - val_accuracy: 0.5164\n",
      "Epoch 36/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5176 - val_loss: 0.6918 - val_accuracy: 0.5106\n",
      "Epoch 37/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5176 - val_loss: 0.6919 - val_accuracy: 0.5104\n",
      "Epoch 38/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5179 - val_loss: 0.6919 - val_accuracy: 0.5114\n",
      "Epoch 39/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5200 - val_loss: 0.6921 - val_accuracy: 0.5136\n",
      "Epoch 40/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5176 - val_loss: 0.6921 - val_accuracy: 0.5111\n",
      "Epoch 41/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5195 - val_loss: 0.6919 - val_accuracy: 0.5114\n",
      "Epoch 42/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5190 - val_loss: 0.6921 - val_accuracy: 0.5090\n",
      "Epoch 43/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5194 - val_loss: 0.6919 - val_accuracy: 0.5114\n",
      "Epoch 44/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5189 - val_loss: 0.6919 - val_accuracy: 0.5100\n",
      "Epoch 45/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5192 - val_loss: 0.6918 - val_accuracy: 0.5086\n",
      "Epoch 46/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5182 - val_loss: 0.6919 - val_accuracy: 0.5107\n",
      "Epoch 47/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5197 - val_loss: 0.6920 - val_accuracy: 0.5096\n",
      "Epoch 48/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5190 - val_loss: 0.6921 - val_accuracy: 0.5098\n",
      "Epoch 49/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5188 - val_loss: 0.6918 - val_accuracy: 0.5131\n",
      "Epoch 50/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5194 - val_loss: 0.6921 - val_accuracy: 0.5130\n",
      "Epoch 51/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5197 - val_loss: 0.6918 - val_accuracy: 0.5098\n",
      "Epoch 52/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5195 - val_loss: 0.6920 - val_accuracy: 0.5107\n",
      "Epoch 53/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5212 - val_loss: 0.6917 - val_accuracy: 0.5132\n",
      "Epoch 54/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5184 - val_loss: 0.6917 - val_accuracy: 0.5122\n",
      "Epoch 55/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5192 - val_loss: 0.6919 - val_accuracy: 0.5150\n",
      "Epoch 56/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5179 - val_loss: 0.6919 - val_accuracy: 0.5101\n",
      "Epoch 57/1000\n",
      "41306/41306 [==============================] - 1s 12us/sample - loss: 0.6915 - accuracy: 0.5190 - val_loss: 0.6918 - val_accuracy: 0.5116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/1000\n",
      "41306/41306 [==============================] - 1s 12us/sample - loss: 0.6915 - accuracy: 0.5183 - val_loss: 0.6918 - val_accuracy: 0.5128\n",
      "Epoch 59/1000\n",
      "41306/41306 [==============================] - 1s 12us/sample - loss: 0.6915 - accuracy: 0.5201 - val_loss: 0.6918 - val_accuracy: 0.5122\n",
      "Epoch 60/1000\n",
      "41306/41306 [==============================] - 1s 12us/sample - loss: 0.6915 - accuracy: 0.5193 - val_loss: 0.6920 - val_accuracy: 0.5089\n",
      "Epoch 61/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5188 - val_loss: 0.6920 - val_accuracy: 0.5129\n",
      "Epoch 62/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5204 - val_loss: 0.6919 - val_accuracy: 0.5091\n",
      "Epoch 63/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5203 - val_loss: 0.6918 - val_accuracy: 0.5108\n",
      "Epoch 64/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5197 - val_loss: 0.6918 - val_accuracy: 0.5099\n",
      "Epoch 65/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5194 - val_loss: 0.6921 - val_accuracy: 0.5071\n",
      "Epoch 66/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5202 - val_loss: 0.6918 - val_accuracy: 0.5101\n",
      "Epoch 67/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5216 - val_loss: 0.6917 - val_accuracy: 0.5154\n",
      "Epoch 68/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5207 - val_loss: 0.6919 - val_accuracy: 0.5120\n",
      "Epoch 69/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5206 - val_loss: 0.6919 - val_accuracy: 0.5126\n",
      "Epoch 70/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5209 - val_loss: 0.6920 - val_accuracy: 0.5073\n",
      "Epoch 71/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5218 - val_loss: 0.6918 - val_accuracy: 0.5124\n",
      "Epoch 72/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5198 - val_loss: 0.6919 - val_accuracy: 0.5117\n",
      "Epoch 73/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5184 - val_loss: 0.6921 - val_accuracy: 0.5139\n",
      "Epoch 74/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5183 - val_loss: 0.6921 - val_accuracy: 0.5121\n",
      "Epoch 75/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5188 - val_loss: 0.6919 - val_accuracy: 0.5124\n",
      "Epoch 76/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5201 - val_loss: 0.6918 - val_accuracy: 0.5113\n",
      "Epoch 77/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5199 - val_loss: 0.6921 - val_accuracy: 0.5142\n",
      "Epoch 78/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5182 - val_loss: 0.6918 - val_accuracy: 0.5143\n",
      "Epoch 79/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5202 - val_loss: 0.6919 - val_accuracy: 0.5140\n",
      "Epoch 80/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5186 - val_loss: 0.6919 - val_accuracy: 0.5127\n",
      "Epoch 81/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5206 - val_loss: 0.6918 - val_accuracy: 0.5120\n",
      "Epoch 82/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5218 - val_loss: 0.6921 - val_accuracy: 0.5118\n",
      "Epoch 83/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5212 - val_loss: 0.6917 - val_accuracy: 0.5115\n",
      "Epoch 84/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5197 - val_loss: 0.6920 - val_accuracy: 0.5154\n",
      "Epoch 85/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5195 - val_loss: 0.6917 - val_accuracy: 0.5133\n",
      "Epoch 86/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5211 - val_loss: 0.6919 - val_accuracy: 0.5100\n",
      "Epoch 87/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5192 - val_loss: 0.6918 - val_accuracy: 0.5123\n",
      "Epoch 88/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5198 - val_loss: 0.6918 - val_accuracy: 0.5119\n",
      "Epoch 89/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5179 - val_loss: 0.6919 - val_accuracy: 0.5102\n",
      "Epoch 90/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5214 - val_loss: 0.6919 - val_accuracy: 0.5115\n",
      "Epoch 91/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5220 - val_loss: 0.6918 - val_accuracy: 0.5135\n",
      "Epoch 92/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5225 - val_loss: 0.6922 - val_accuracy: 0.5114\n",
      "Epoch 93/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5201 - val_loss: 0.6918 - val_accuracy: 0.5127\n",
      "Epoch 94/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5198 - val_loss: 0.6918 - val_accuracy: 0.5123\n",
      "Epoch 95/1000\n",
      "41306/41306 [==============================] - 1s 12us/sample - loss: 0.6912 - accuracy: 0.5207 - val_loss: 0.6918 - val_accuracy: 0.5119\n",
      "Epoch 96/1000\n",
      "41306/41306 [==============================] - 0s 12us/sample - loss: 0.6912 - accuracy: 0.5211 - val_loss: 0.6919 - val_accuracy: 0.5118\n",
      "Epoch 97/1000\n",
      "41306/41306 [==============================] - 0s 12us/sample - loss: 0.6914 - accuracy: 0.5205 - val_loss: 0.6921 - val_accuracy: 0.5099\n",
      "Epoch 98/1000\n",
      "41306/41306 [==============================] - 1s 12us/sample - loss: 0.6912 - accuracy: 0.5197 - val_loss: 0.6919 - val_accuracy: 0.5156\n",
      "Epoch 99/1000\n",
      "41306/41306 [==============================] - 1s 12us/sample - loss: 0.6911 - accuracy: 0.5210 - val_loss: 0.6916 - val_accuracy: 0.5124\n",
      "Epoch 100/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5208 - val_loss: 0.6919 - val_accuracy: 0.5146\n",
      "Epoch 101/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5196 - val_loss: 0.6919 - val_accuracy: 0.5128\n",
      "Epoch 102/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5200 - val_loss: 0.6918 - val_accuracy: 0.5117\n",
      "Epoch 103/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5218 - val_loss: 0.6919 - val_accuracy: 0.5076\n",
      "Epoch 104/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5208 - val_loss: 0.6917 - val_accuracy: 0.5132\n",
      "Epoch 105/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5197 - val_loss: 0.6917 - val_accuracy: 0.5132\n",
      "Epoch 106/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5216 - val_loss: 0.6917 - val_accuracy: 0.5109\n",
      "Epoch 107/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5197 - val_loss: 0.6918 - val_accuracy: 0.5096\n",
      "Epoch 108/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5212 - val_loss: 0.6917 - val_accuracy: 0.5142\n",
      "Epoch 109/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5221 - val_loss: 0.6918 - val_accuracy: 0.5094\n",
      "Epoch 110/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5223 - val_loss: 0.6918 - val_accuracy: 0.5123\n",
      "Epoch 111/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5205 - val_loss: 0.6921 - val_accuracy: 0.5113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5212 - val_loss: 0.6919 - val_accuracy: 0.5166\n",
      "Epoch 113/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5215 - val_loss: 0.6919 - val_accuracy: 0.5126\n",
      "Epoch 114/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5226 - val_loss: 0.6919 - val_accuracy: 0.5124\n",
      "Epoch 115/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5200 - val_loss: 0.6917 - val_accuracy: 0.5146\n",
      "Epoch 116/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5214 - val_loss: 0.6919 - val_accuracy: 0.5139\n",
      "Epoch 117/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5220 - val_loss: 0.6916 - val_accuracy: 0.5163\n",
      "Epoch 118/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5229 - val_loss: 0.6920 - val_accuracy: 0.5135\n",
      "Epoch 119/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5201 - val_loss: 0.6919 - val_accuracy: 0.5135\n",
      "Epoch 120/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5202 - val_loss: 0.6919 - val_accuracy: 0.5121\n",
      "Epoch 121/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5224 - val_loss: 0.6919 - val_accuracy: 0.5106\n",
      "Epoch 122/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5211 - val_loss: 0.6919 - val_accuracy: 0.5128\n",
      "Epoch 123/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5230 - val_loss: 0.6919 - val_accuracy: 0.5125\n",
      "Epoch 124/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5213 - val_loss: 0.6918 - val_accuracy: 0.5119\n",
      "Epoch 125/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5192 - val_loss: 0.6919 - val_accuracy: 0.5129\n",
      "Epoch 126/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5191 - val_loss: 0.6921 - val_accuracy: 0.5089\n",
      "Epoch 127/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5196 - val_loss: 0.6919 - val_accuracy: 0.5118\n",
      "Epoch 128/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5205 - val_loss: 0.6919 - val_accuracy: 0.5094\n",
      "Epoch 129/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5210 - val_loss: 0.6917 - val_accuracy: 0.5106\n",
      "Training with significance = 2.84, run 1\n",
      "Train on 41306 samples, validate on 10327 samples\n",
      "Epoch 1/1000\n",
      "41306/41306 [==============================] - 1s 29us/sample - loss: 0.6937 - accuracy: 0.5028 - val_loss: 0.6936 - val_accuracy: 0.5011\n",
      "Epoch 2/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5168 - val_loss: 0.6927 - val_accuracy: 0.5143\n",
      "Epoch 3/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5161 - val_loss: 0.6928 - val_accuracy: 0.5185\n",
      "Epoch 4/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5169 - val_loss: 0.6927 - val_accuracy: 0.5178\n",
      "Epoch 5/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5188 - val_loss: 0.6926 - val_accuracy: 0.5156\n",
      "Epoch 6/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5200 - val_loss: 0.6928 - val_accuracy: 0.5116\n",
      "Epoch 7/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5192 - val_loss: 0.6926 - val_accuracy: 0.5119\n",
      "Epoch 8/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5212 - val_loss: 0.6926 - val_accuracy: 0.5122\n",
      "Epoch 9/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5185 - val_loss: 0.6931 - val_accuracy: 0.5083\n",
      "Epoch 10/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5196 - val_loss: 0.6926 - val_accuracy: 0.5131\n",
      "Epoch 11/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5203 - val_loss: 0.6927 - val_accuracy: 0.5109\n",
      "Epoch 12/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5229 - val_loss: 0.6927 - val_accuracy: 0.5108\n",
      "Epoch 13/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5215 - val_loss: 0.6927 - val_accuracy: 0.5134\n",
      "Epoch 14/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5208 - val_loss: 0.6926 - val_accuracy: 0.5110\n",
      "Epoch 15/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5236 - val_loss: 0.6926 - val_accuracy: 0.5113\n",
      "Epoch 16/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5228 - val_loss: 0.6926 - val_accuracy: 0.5108\n",
      "Epoch 17/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5230 - val_loss: 0.6926 - val_accuracy: 0.5114\n",
      "Epoch 18/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5213 - val_loss: 0.6927 - val_accuracy: 0.5115\n",
      "Epoch 19/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5221 - val_loss: 0.6926 - val_accuracy: 0.5133\n",
      "Epoch 20/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5216 - val_loss: 0.6926 - val_accuracy: 0.5107\n",
      "Epoch 21/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5210 - val_loss: 0.6928 - val_accuracy: 0.5120\n",
      "Epoch 22/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5218 - val_loss: 0.6927 - val_accuracy: 0.5071\n",
      "Epoch 23/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5221 - val_loss: 0.6926 - val_accuracy: 0.5126\n",
      "Epoch 24/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5213 - val_loss: 0.6925 - val_accuracy: 0.5137\n",
      "Epoch 25/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5215 - val_loss: 0.6926 - val_accuracy: 0.5174\n",
      "Epoch 26/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5221 - val_loss: 0.6927 - val_accuracy: 0.5115\n",
      "Epoch 27/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5243 - val_loss: 0.6926 - val_accuracy: 0.5124\n",
      "Epoch 28/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5215 - val_loss: 0.6927 - val_accuracy: 0.5126\n",
      "Epoch 29/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5216 - val_loss: 0.6926 - val_accuracy: 0.5092\n",
      "Epoch 30/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5222 - val_loss: 0.6926 - val_accuracy: 0.5126\n",
      "Epoch 31/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5229 - val_loss: 0.6926 - val_accuracy: 0.5104\n",
      "Epoch 32/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5248 - val_loss: 0.6926 - val_accuracy: 0.5150\n",
      "Epoch 33/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5230 - val_loss: 0.6926 - val_accuracy: 0.5161\n",
      "Epoch 34/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5245 - val_loss: 0.6926 - val_accuracy: 0.5115\n",
      "Epoch 35/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5233 - val_loss: 0.6927 - val_accuracy: 0.5120\n",
      "Epoch 36/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5233 - val_loss: 0.6927 - val_accuracy: 0.5094\n",
      "Epoch 37/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5230 - val_loss: 0.6927 - val_accuracy: 0.5136\n",
      "Epoch 38/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5233 - val_loss: 0.6926 - val_accuracy: 0.5147\n",
      "Epoch 39/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5230 - val_loss: 0.6927 - val_accuracy: 0.5121\n",
      "Epoch 40/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5240 - val_loss: 0.6926 - val_accuracy: 0.5160\n",
      "Epoch 41/1000\n",
      "41306/41306 [==============================] - 1s 12us/sample - loss: 0.6909 - accuracy: 0.5247 - val_loss: 0.6926 - val_accuracy: 0.5090\n",
      "Epoch 42/1000\n",
      "41306/41306 [==============================] - 0s 12us/sample - loss: 0.6909 - accuracy: 0.5233 - val_loss: 0.6926 - val_accuracy: 0.5153\n",
      "Epoch 43/1000\n",
      "41306/41306 [==============================] - 0s 12us/sample - loss: 0.6909 - accuracy: 0.5225 - val_loss: 0.6927 - val_accuracy: 0.5095\n",
      "Epoch 44/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5235 - val_loss: 0.6927 - val_accuracy: 0.5092\n",
      "Epoch 45/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5247 - val_loss: 0.6926 - val_accuracy: 0.5122\n",
      "Epoch 46/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5256 - val_loss: 0.6927 - val_accuracy: 0.5090\n",
      "Epoch 47/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5228 - val_loss: 0.6926 - val_accuracy: 0.5127\n",
      "Epoch 48/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5243 - val_loss: 0.6929 - val_accuracy: 0.5077\n",
      "Epoch 49/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5238 - val_loss: 0.6927 - val_accuracy: 0.5079\n",
      "Epoch 50/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5241 - val_loss: 0.6927 - val_accuracy: 0.5093\n",
      "Epoch 51/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5241 - val_loss: 0.6926 - val_accuracy: 0.5114\n",
      "Epoch 52/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5249 - val_loss: 0.6928 - val_accuracy: 0.5105\n",
      "Epoch 53/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5230 - val_loss: 0.6926 - val_accuracy: 0.5093\n",
      "Epoch 54/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5237 - val_loss: 0.6927 - val_accuracy: 0.5154\n",
      "Training with significance = 2.84, run 2\n",
      "Train on 41306 samples, validate on 10327 samples\n",
      "Epoch 1/1000\n",
      "41306/41306 [==============================] - 1s 28us/sample - loss: 0.6940 - accuracy: 0.5050 - val_loss: 0.6927 - val_accuracy: 0.5141\n",
      "Epoch 2/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6927 - accuracy: 0.5132 - val_loss: 0.6923 - val_accuracy: 0.5171\n",
      "Epoch 3/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6925 - accuracy: 0.5150 - val_loss: 0.6921 - val_accuracy: 0.5183\n",
      "Epoch 4/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5148 - val_loss: 0.6922 - val_accuracy: 0.5213\n",
      "Epoch 5/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5154 - val_loss: 0.6921 - val_accuracy: 0.5194\n",
      "Epoch 6/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5155 - val_loss: 0.6922 - val_accuracy: 0.5189\n",
      "Epoch 7/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5162 - val_loss: 0.6921 - val_accuracy: 0.5169\n",
      "Epoch 8/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5180 - val_loss: 0.6922 - val_accuracy: 0.5189\n",
      "Epoch 9/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5182 - val_loss: 0.6922 - val_accuracy: 0.5142\n",
      "Epoch 10/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5177 - val_loss: 0.6922 - val_accuracy: 0.5183\n",
      "Epoch 11/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5182 - val_loss: 0.6923 - val_accuracy: 0.5186\n",
      "Epoch 12/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5180 - val_loss: 0.6923 - val_accuracy: 0.5170\n",
      "Epoch 13/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5176 - val_loss: 0.6923 - val_accuracy: 0.5157\n",
      "Epoch 14/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5172 - val_loss: 0.6922 - val_accuracy: 0.5173\n",
      "Epoch 15/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5192 - val_loss: 0.6922 - val_accuracy: 0.5185\n",
      "Epoch 16/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5182 - val_loss: 0.6923 - val_accuracy: 0.5147\n",
      "Epoch 17/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5193 - val_loss: 0.6924 - val_accuracy: 0.5165\n",
      "Epoch 18/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5178 - val_loss: 0.6923 - val_accuracy: 0.5195\n",
      "Epoch 19/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5207 - val_loss: 0.6924 - val_accuracy: 0.5178\n",
      "Epoch 20/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5203 - val_loss: 0.6925 - val_accuracy: 0.5154\n",
      "Epoch 21/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5199 - val_loss: 0.6924 - val_accuracy: 0.5146\n",
      "Epoch 22/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5199 - val_loss: 0.6925 - val_accuracy: 0.5168\n",
      "Epoch 23/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5211 - val_loss: 0.6924 - val_accuracy: 0.5168\n",
      "Epoch 24/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5197 - val_loss: 0.6924 - val_accuracy: 0.5160\n",
      "Epoch 25/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5197 - val_loss: 0.6924 - val_accuracy: 0.5189\n",
      "Epoch 26/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5212 - val_loss: 0.6925 - val_accuracy: 0.5129\n",
      "Epoch 27/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5210 - val_loss: 0.6925 - val_accuracy: 0.5156\n",
      "Epoch 28/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5206 - val_loss: 0.6925 - val_accuracy: 0.5128\n",
      "Epoch 29/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5202 - val_loss: 0.6925 - val_accuracy: 0.5150\n",
      "Epoch 30/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5224 - val_loss: 0.6925 - val_accuracy: 0.5178\n",
      "Epoch 31/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5190 - val_loss: 0.6927 - val_accuracy: 0.5153\n",
      "Epoch 32/1000\n",
      "41306/41306 [==============================] - 1s 12us/sample - loss: 0.6916 - accuracy: 0.5187 - val_loss: 0.6925 - val_accuracy: 0.5167\n",
      "Epoch 33/1000\n",
      "41306/41306 [==============================] - 0s 12us/sample - loss: 0.6916 - accuracy: 0.5207 - val_loss: 0.6924 - val_accuracy: 0.5144\n",
      "Training with significance = 2.84, run 3\n",
      "Train on 41306 samples, validate on 10327 samples\n",
      "Epoch 1/1000\n",
      "41306/41306 [==============================] - 1s 28us/sample - loss: 0.6942 - accuracy: 0.5038 - val_loss: 0.6931 - val_accuracy: 0.5135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6928 - accuracy: 0.5121 - val_loss: 0.6931 - val_accuracy: 0.5111\n",
      "Epoch 3/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6927 - accuracy: 0.5132 - val_loss: 0.6923 - val_accuracy: 0.5205\n",
      "Epoch 4/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5123 - val_loss: 0.6921 - val_accuracy: 0.5169\n",
      "Epoch 5/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5123 - val_loss: 0.6922 - val_accuracy: 0.5186\n",
      "Epoch 6/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5140 - val_loss: 0.6920 - val_accuracy: 0.5206\n",
      "Epoch 7/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5142 - val_loss: 0.6921 - val_accuracy: 0.5193\n",
      "Epoch 8/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5164 - val_loss: 0.6919 - val_accuracy: 0.5179\n",
      "Epoch 9/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5183 - val_loss: 0.6923 - val_accuracy: 0.5203\n",
      "Epoch 10/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5167 - val_loss: 0.6919 - val_accuracy: 0.5198\n",
      "Epoch 11/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5155 - val_loss: 0.6920 - val_accuracy: 0.5212\n",
      "Epoch 12/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5163 - val_loss: 0.6920 - val_accuracy: 0.5166\n",
      "Epoch 13/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5173 - val_loss: 0.6920 - val_accuracy: 0.5202\n",
      "Epoch 14/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5194 - val_loss: 0.6920 - val_accuracy: 0.5170\n",
      "Epoch 15/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5175 - val_loss: 0.6919 - val_accuracy: 0.5204\n",
      "Epoch 16/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5164 - val_loss: 0.6918 - val_accuracy: 0.5200\n",
      "Epoch 17/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5169 - val_loss: 0.6919 - val_accuracy: 0.5162\n",
      "Epoch 18/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5180 - val_loss: 0.6919 - val_accuracy: 0.5204\n",
      "Epoch 19/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5168 - val_loss: 0.6920 - val_accuracy: 0.5183\n",
      "Epoch 20/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5189 - val_loss: 0.6919 - val_accuracy: 0.5198\n",
      "Epoch 21/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5181 - val_loss: 0.6919 - val_accuracy: 0.5202\n",
      "Epoch 22/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5179 - val_loss: 0.6920 - val_accuracy: 0.5207\n",
      "Epoch 23/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5175 - val_loss: 0.6919 - val_accuracy: 0.5187\n",
      "Epoch 24/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5172 - val_loss: 0.6920 - val_accuracy: 0.5181\n",
      "Epoch 25/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5196 - val_loss: 0.6919 - val_accuracy: 0.5176\n",
      "Epoch 26/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5178 - val_loss: 0.6919 - val_accuracy: 0.5183\n",
      "Epoch 27/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5205 - val_loss: 0.6920 - val_accuracy: 0.5188\n",
      "Epoch 28/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5185 - val_loss: 0.6920 - val_accuracy: 0.5183\n",
      "Epoch 29/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5197 - val_loss: 0.6920 - val_accuracy: 0.5160\n",
      "Epoch 30/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5185 - val_loss: 0.6919 - val_accuracy: 0.5172\n",
      "Epoch 31/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5189 - val_loss: 0.6921 - val_accuracy: 0.5139\n",
      "Epoch 32/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5194 - val_loss: 0.6921 - val_accuracy: 0.5187\n",
      "Epoch 33/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5199 - val_loss: 0.6920 - val_accuracy: 0.5174\n",
      "Epoch 34/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5195 - val_loss: 0.6921 - val_accuracy: 0.5171\n",
      "Epoch 35/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5200 - val_loss: 0.6919 - val_accuracy: 0.5169\n",
      "Epoch 36/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5194 - val_loss: 0.6919 - val_accuracy: 0.5158\n",
      "Epoch 37/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5184 - val_loss: 0.6920 - val_accuracy: 0.5160\n",
      "Epoch 38/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5195 - val_loss: 0.6920 - val_accuracy: 0.5128\n",
      "Epoch 39/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5201 - val_loss: 0.6919 - val_accuracy: 0.5171\n",
      "Epoch 40/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5215 - val_loss: 0.6920 - val_accuracy: 0.5177\n",
      "Epoch 41/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5199 - val_loss: 0.6921 - val_accuracy: 0.5177\n",
      "Epoch 42/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5183 - val_loss: 0.6919 - val_accuracy: 0.5157\n",
      "Epoch 43/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5217 - val_loss: 0.6921 - val_accuracy: 0.5095\n",
      "Epoch 44/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5215 - val_loss: 0.6920 - val_accuracy: 0.5164\n",
      "Epoch 45/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5197 - val_loss: 0.6920 - val_accuracy: 0.5153\n",
      "Epoch 46/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5201 - val_loss: 0.6920 - val_accuracy: 0.5173\n",
      "Training with significance = 2.84, run 4\n",
      "Train on 41306 samples, validate on 10327 samples\n",
      "Epoch 1/1000\n",
      "41306/41306 [==============================] - 1s 29us/sample - loss: 0.6929 - accuracy: 0.5075 - val_loss: 0.6937 - val_accuracy: 0.5104\n",
      "Epoch 2/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5159 - val_loss: 0.6922 - val_accuracy: 0.5158\n",
      "Epoch 3/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5176 - val_loss: 0.6919 - val_accuracy: 0.5190\n",
      "Epoch 4/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5167 - val_loss: 0.6919 - val_accuracy: 0.5182\n",
      "Epoch 5/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5163 - val_loss: 0.6919 - val_accuracy: 0.5200\n",
      "Epoch 6/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5172 - val_loss: 0.6919 - val_accuracy: 0.5200\n",
      "Epoch 7/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5186 - val_loss: 0.6919 - val_accuracy: 0.5200\n",
      "Epoch 8/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5178 - val_loss: 0.6917 - val_accuracy: 0.5188\n",
      "Epoch 9/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5208 - val_loss: 0.6917 - val_accuracy: 0.5183\n",
      "Epoch 10/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5181 - val_loss: 0.6918 - val_accuracy: 0.5171\n",
      "Epoch 11/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5201 - val_loss: 0.6917 - val_accuracy: 0.5194\n",
      "Epoch 12/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5193 - val_loss: 0.6920 - val_accuracy: 0.5183\n",
      "Epoch 13/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5209 - val_loss: 0.6919 - val_accuracy: 0.5195\n",
      "Epoch 14/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5182 - val_loss: 0.6919 - val_accuracy: 0.5169\n",
      "Epoch 15/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5194 - val_loss: 0.6918 - val_accuracy: 0.5135\n",
      "Epoch 16/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5216 - val_loss: 0.6919 - val_accuracy: 0.5208\n",
      "Epoch 17/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5204 - val_loss: 0.6918 - val_accuracy: 0.5201\n",
      "Epoch 18/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5211 - val_loss: 0.6918 - val_accuracy: 0.5148\n",
      "Epoch 19/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5210 - val_loss: 0.6918 - val_accuracy: 0.5200\n",
      "Epoch 20/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5202 - val_loss: 0.6917 - val_accuracy: 0.5176\n",
      "Epoch 21/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5220 - val_loss: 0.6918 - val_accuracy: 0.5167\n",
      "Epoch 22/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5191 - val_loss: 0.6921 - val_accuracy: 0.5201\n",
      "Epoch 23/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5207 - val_loss: 0.6919 - val_accuracy: 0.5153\n",
      "Epoch 24/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5228 - val_loss: 0.6917 - val_accuracy: 0.5187\n",
      "Epoch 25/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5226 - val_loss: 0.6918 - val_accuracy: 0.5199\n",
      "Epoch 26/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5201 - val_loss: 0.6919 - val_accuracy: 0.5170\n",
      "Epoch 27/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5218 - val_loss: 0.6918 - val_accuracy: 0.5186\n",
      "Epoch 28/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5245 - val_loss: 0.6923 - val_accuracy: 0.5075\n",
      "Epoch 29/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5206 - val_loss: 0.6918 - val_accuracy: 0.5184\n",
      "Epoch 30/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5214 - val_loss: 0.6918 - val_accuracy: 0.5212\n",
      "Epoch 31/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5187 - val_loss: 0.6918 - val_accuracy: 0.5183\n",
      "Epoch 32/1000\n",
      "41306/41306 [==============================] - 1s 12us/sample - loss: 0.6910 - accuracy: 0.5222 - val_loss: 0.6922 - val_accuracy: 0.5153\n",
      "Epoch 33/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5226 - val_loss: 0.6920 - val_accuracy: 0.5150\n",
      "Epoch 34/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5216 - val_loss: 0.6921 - val_accuracy: 0.5187\n",
      "Epoch 35/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5219 - val_loss: 0.6921 - val_accuracy: 0.5186\n",
      "Epoch 36/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5216 - val_loss: 0.6919 - val_accuracy: 0.5198\n",
      "Epoch 37/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5212 - val_loss: 0.6919 - val_accuracy: 0.5174\n",
      "Epoch 38/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5207 - val_loss: 0.6917 - val_accuracy: 0.5186\n",
      "Epoch 39/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5239 - val_loss: 0.6918 - val_accuracy: 0.5155\n",
      "Epoch 40/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5226 - val_loss: 0.6920 - val_accuracy: 0.5154\n",
      "Epoch 41/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5224 - val_loss: 0.6919 - val_accuracy: 0.5195\n",
      "Training with significance = 2.84, run 5\n",
      "Train on 41306 samples, validate on 10327 samples\n",
      "Epoch 1/1000\n",
      "41306/41306 [==============================] - 1s 27us/sample - loss: 0.6960 - accuracy: 0.5023 - val_loss: 0.6930 - val_accuracy: 0.5141\n",
      "Epoch 2/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6926 - accuracy: 0.5142 - val_loss: 0.6927 - val_accuracy: 0.5157\n",
      "Epoch 3/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5137 - val_loss: 0.6923 - val_accuracy: 0.5190\n",
      "Epoch 4/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5157 - val_loss: 0.6921 - val_accuracy: 0.5176\n",
      "Epoch 5/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5149 - val_loss: 0.6922 - val_accuracy: 0.5117\n",
      "Epoch 6/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5149 - val_loss: 0.6921 - val_accuracy: 0.5154\n",
      "Epoch 7/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5162 - val_loss: 0.6920 - val_accuracy: 0.5179\n",
      "Epoch 8/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5178 - val_loss: 0.6922 - val_accuracy: 0.5095\n",
      "Epoch 9/1000\n",
      "41306/41306 [==============================] - 1s 12us/sample - loss: 0.6919 - accuracy: 0.5177 - val_loss: 0.6920 - val_accuracy: 0.5127\n",
      "Epoch 10/1000\n",
      "41306/41306 [==============================] - 1s 12us/sample - loss: 0.6918 - accuracy: 0.5168 - val_loss: 0.6921 - val_accuracy: 0.5161\n",
      "Epoch 11/1000\n",
      "41306/41306 [==============================] - 1s 12us/sample - loss: 0.6918 - accuracy: 0.5177 - val_loss: 0.6919 - val_accuracy: 0.5141\n",
      "Epoch 12/1000\n",
      "41306/41306 [==============================] - 1s 12us/sample - loss: 0.6917 - accuracy: 0.5183 - val_loss: 0.6921 - val_accuracy: 0.5092\n",
      "Epoch 13/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5199 - val_loss: 0.6921 - val_accuracy: 0.5100\n",
      "Epoch 14/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5199 - val_loss: 0.6921 - val_accuracy: 0.5099\n",
      "Epoch 15/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5196 - val_loss: 0.6922 - val_accuracy: 0.5151\n",
      "Epoch 16/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5183 - val_loss: 0.6920 - val_accuracy: 0.5098\n",
      "Epoch 17/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5173 - val_loss: 0.6923 - val_accuracy: 0.5128\n",
      "Epoch 18/1000\n",
      "41306/41306 [==============================] - 1s 12us/sample - loss: 0.6917 - accuracy: 0.5193 - val_loss: 0.6920 - val_accuracy: 0.5110\n",
      "Epoch 19/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5216 - val_loss: 0.6922 - val_accuracy: 0.5103\n",
      "Epoch 20/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5185 - val_loss: 0.6920 - val_accuracy: 0.5086\n",
      "Epoch 21/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5192 - val_loss: 0.6920 - val_accuracy: 0.5125\n",
      "Epoch 22/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5206 - val_loss: 0.6922 - val_accuracy: 0.5069\n",
      "Epoch 23/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5196 - val_loss: 0.6923 - val_accuracy: 0.5040\n",
      "Epoch 24/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5198 - val_loss: 0.6920 - val_accuracy: 0.5090\n",
      "Epoch 25/1000\n",
      "41306/41306 [==============================] - 1s 12us/sample - loss: 0.6914 - accuracy: 0.5204 - val_loss: 0.6922 - val_accuracy: 0.5079\n",
      "Epoch 26/1000\n",
      "41306/41306 [==============================] - 1s 14us/sample - loss: 0.6914 - accuracy: 0.5191 - val_loss: 0.6923 - val_accuracy: 0.5130\n",
      "Epoch 27/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5217 - val_loss: 0.6922 - val_accuracy: 0.5097\n",
      "Epoch 28/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5215 - val_loss: 0.6921 - val_accuracy: 0.5085\n",
      "Epoch 29/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5201 - val_loss: 0.6921 - val_accuracy: 0.5089\n",
      "Epoch 30/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5186 - val_loss: 0.6920 - val_accuracy: 0.5106\n",
      "Epoch 31/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5208 - val_loss: 0.6922 - val_accuracy: 0.5086\n",
      "Epoch 32/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5224 - val_loss: 0.6920 - val_accuracy: 0.5128\n",
      "Epoch 33/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5221 - val_loss: 0.6921 - val_accuracy: 0.5132\n",
      "Epoch 34/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5214 - val_loss: 0.6919 - val_accuracy: 0.5140\n",
      "Epoch 35/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5207 - val_loss: 0.6920 - val_accuracy: 0.5126\n",
      "Epoch 36/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5228 - val_loss: 0.6921 - val_accuracy: 0.5113\n",
      "Epoch 37/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5215 - val_loss: 0.6922 - val_accuracy: 0.5066\n",
      "Epoch 38/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5209 - val_loss: 0.6919 - val_accuracy: 0.5163\n",
      "Epoch 39/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5206 - val_loss: 0.6922 - val_accuracy: 0.5086\n",
      "Epoch 40/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5206 - val_loss: 0.6921 - val_accuracy: 0.5124\n",
      "Epoch 41/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5222 - val_loss: 0.6920 - val_accuracy: 0.5144\n",
      "Epoch 42/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5217 - val_loss: 0.6923 - val_accuracy: 0.5060\n",
      "Epoch 43/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5216 - val_loss: 0.6921 - val_accuracy: 0.5147\n",
      "Epoch 44/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5224 - val_loss: 0.6919 - val_accuracy: 0.5150\n",
      "Epoch 45/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5199 - val_loss: 0.6921 - val_accuracy: 0.5133\n",
      "Epoch 46/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5233 - val_loss: 0.6921 - val_accuracy: 0.5154\n",
      "Epoch 47/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5214 - val_loss: 0.6920 - val_accuracy: 0.5132\n",
      "Epoch 48/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5232 - val_loss: 0.6921 - val_accuracy: 0.5103\n",
      "Epoch 49/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5208 - val_loss: 0.6921 - val_accuracy: 0.5090\n",
      "Epoch 50/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5223 - val_loss: 0.6921 - val_accuracy: 0.5133\n",
      "Epoch 51/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5230 - val_loss: 0.6922 - val_accuracy: 0.5085\n",
      "Epoch 52/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5218 - val_loss: 0.6921 - val_accuracy: 0.5086\n",
      "Epoch 53/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5216 - val_loss: 0.6920 - val_accuracy: 0.5157\n",
      "Epoch 54/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5227 - val_loss: 0.6921 - val_accuracy: 0.5117\n",
      "Epoch 55/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5222 - val_loss: 0.6922 - val_accuracy: 0.5102\n",
      "Epoch 56/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5222 - val_loss: 0.6920 - val_accuracy: 0.5151\n",
      "Epoch 57/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5232 - val_loss: 0.6921 - val_accuracy: 0.5124\n",
      "Epoch 58/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5248 - val_loss: 0.6921 - val_accuracy: 0.5157\n",
      "Epoch 59/1000\n",
      "41306/41306 [==============================] - 1s 12us/sample - loss: 0.6910 - accuracy: 0.5215 - val_loss: 0.6920 - val_accuracy: 0.5133\n",
      "Epoch 60/1000\n",
      "41306/41306 [==============================] - 1s 12us/sample - loss: 0.6911 - accuracy: 0.5225 - val_loss: 0.6923 - val_accuracy: 0.5089\n",
      "Epoch 61/1000\n",
      "41306/41306 [==============================] - 0s 12us/sample - loss: 0.6910 - accuracy: 0.5234 - val_loss: 0.6921 - val_accuracy: 0.5143\n",
      "Epoch 62/1000\n",
      "41306/41306 [==============================] - 0s 12us/sample - loss: 0.6909 - accuracy: 0.5224 - val_loss: 0.6922 - val_accuracy: 0.5099\n",
      "Epoch 63/1000\n",
      "41306/41306 [==============================] - 1s 12us/sample - loss: 0.6912 - accuracy: 0.5223 - val_loss: 0.6920 - val_accuracy: 0.5161\n",
      "Epoch 64/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5251 - val_loss: 0.6921 - val_accuracy: 0.5144\n",
      "Epoch 65/1000\n",
      "41306/41306 [==============================] - 1s 12us/sample - loss: 0.6909 - accuracy: 0.5232 - val_loss: 0.6921 - val_accuracy: 0.5120\n",
      "Epoch 66/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5230 - val_loss: 0.6924 - val_accuracy: 0.5085\n",
      "Epoch 67/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5231 - val_loss: 0.6921 - val_accuracy: 0.5154\n",
      "Epoch 68/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5238 - val_loss: 0.6921 - val_accuracy: 0.5127\n",
      "Training with significance = 2.84, run 6\n",
      "Train on 41306 samples, validate on 10327 samples\n",
      "Epoch 1/1000\n",
      "41306/41306 [==============================] - 1s 27us/sample - loss: 0.6935 - accuracy: 0.5064 - val_loss: 0.6933 - val_accuracy: 0.5103\n",
      "Epoch 2/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5159 - val_loss: 0.6926 - val_accuracy: 0.5150\n",
      "Epoch 3/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5161 - val_loss: 0.6926 - val_accuracy: 0.5149\n",
      "Epoch 4/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5158 - val_loss: 0.6923 - val_accuracy: 0.5145\n",
      "Epoch 5/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5172 - val_loss: 0.6923 - val_accuracy: 0.5142\n",
      "Epoch 6/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5170 - val_loss: 0.6924 - val_accuracy: 0.5138\n",
      "Epoch 7/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5181 - val_loss: 0.6923 - val_accuracy: 0.5117\n",
      "Epoch 8/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5174 - val_loss: 0.6924 - val_accuracy: 0.5152\n",
      "Epoch 9/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5168 - val_loss: 0.6924 - val_accuracy: 0.5108\n",
      "Epoch 10/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5179 - val_loss: 0.6924 - val_accuracy: 0.5153\n",
      "Epoch 11/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5181 - val_loss: 0.6923 - val_accuracy: 0.5145\n",
      "Epoch 12/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5172 - val_loss: 0.6924 - val_accuracy: 0.5140\n",
      "Epoch 13/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5167 - val_loss: 0.6923 - val_accuracy: 0.5157\n",
      "Epoch 14/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5172 - val_loss: 0.6922 - val_accuracy: 0.5138\n",
      "Epoch 15/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5202 - val_loss: 0.6924 - val_accuracy: 0.5146\n",
      "Epoch 16/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5190 - val_loss: 0.6923 - val_accuracy: 0.5133\n",
      "Epoch 17/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5199 - val_loss: 0.6923 - val_accuracy: 0.5149\n",
      "Epoch 18/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5187 - val_loss: 0.6923 - val_accuracy: 0.5159\n",
      "Epoch 19/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5183 - val_loss: 0.6925 - val_accuracy: 0.5139\n",
      "Epoch 20/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5182 - val_loss: 0.6924 - val_accuracy: 0.5161\n",
      "Epoch 21/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5184 - val_loss: 0.6923 - val_accuracy: 0.5139\n",
      "Epoch 22/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5178 - val_loss: 0.6922 - val_accuracy: 0.5141\n",
      "Epoch 23/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5180 - val_loss: 0.6921 - val_accuracy: 0.5137\n",
      "Epoch 24/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5188 - val_loss: 0.6922 - val_accuracy: 0.5144\n",
      "Epoch 25/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5199 - val_loss: 0.6922 - val_accuracy: 0.5141\n",
      "Epoch 26/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5199 - val_loss: 0.6921 - val_accuracy: 0.5146\n",
      "Epoch 27/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5176 - val_loss: 0.6921 - val_accuracy: 0.5170\n",
      "Epoch 28/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5191 - val_loss: 0.6922 - val_accuracy: 0.5138\n",
      "Epoch 29/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5168 - val_loss: 0.6922 - val_accuracy: 0.5137\n",
      "Epoch 30/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5191 - val_loss: 0.6920 - val_accuracy: 0.5144\n",
      "Epoch 31/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5204 - val_loss: 0.6920 - val_accuracy: 0.5151\n",
      "Epoch 32/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5199 - val_loss: 0.6921 - val_accuracy: 0.5138\n",
      "Epoch 33/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5197 - val_loss: 0.6922 - val_accuracy: 0.5132\n",
      "Epoch 34/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5189 - val_loss: 0.6922 - val_accuracy: 0.5172\n",
      "Epoch 35/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5184 - val_loss: 0.6923 - val_accuracy: 0.5152\n",
      "Epoch 36/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5204 - val_loss: 0.6922 - val_accuracy: 0.5154\n",
      "Epoch 37/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5198 - val_loss: 0.6920 - val_accuracy: 0.5138\n",
      "Epoch 38/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5199 - val_loss: 0.6922 - val_accuracy: 0.5158\n",
      "Epoch 39/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5206 - val_loss: 0.6923 - val_accuracy: 0.5143\n",
      "Epoch 40/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5205 - val_loss: 0.6922 - val_accuracy: 0.5142\n",
      "Epoch 41/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5194 - val_loss: 0.6921 - val_accuracy: 0.5140\n",
      "Epoch 42/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5204 - val_loss: 0.6923 - val_accuracy: 0.5136\n",
      "Epoch 43/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5213 - val_loss: 0.6920 - val_accuracy: 0.5129\n",
      "Epoch 44/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5207 - val_loss: 0.6920 - val_accuracy: 0.5146\n",
      "Epoch 45/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5197 - val_loss: 0.6924 - val_accuracy: 0.5144\n",
      "Epoch 46/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5197 - val_loss: 0.6922 - val_accuracy: 0.5152\n",
      "Epoch 47/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5201 - val_loss: 0.6922 - val_accuracy: 0.5136\n",
      "Epoch 48/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5190 - val_loss: 0.6921 - val_accuracy: 0.5147\n",
      "Epoch 49/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5218 - val_loss: 0.6921 - val_accuracy: 0.5142\n",
      "Epoch 50/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5202 - val_loss: 0.6922 - val_accuracy: 0.5153\n",
      "Epoch 51/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5188 - val_loss: 0.6922 - val_accuracy: 0.5145\n",
      "Epoch 52/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5203 - val_loss: 0.6921 - val_accuracy: 0.5159\n",
      "Epoch 53/1000\n",
      "41306/41306 [==============================] - 1s 12us/sample - loss: 0.6914 - accuracy: 0.5198 - val_loss: 0.6921 - val_accuracy: 0.5152\n",
      "Epoch 54/1000\n",
      "41306/41306 [==============================] - 1s 12us/sample - loss: 0.6912 - accuracy: 0.5219 - val_loss: 0.6921 - val_accuracy: 0.5156\n",
      "Epoch 55/1000\n",
      "41306/41306 [==============================] - 0s 12us/sample - loss: 0.6913 - accuracy: 0.5200 - val_loss: 0.6922 - val_accuracy: 0.5141\n",
      "Epoch 56/1000\n",
      "41306/41306 [==============================] - 1s 12us/sample - loss: 0.6913 - accuracy: 0.5210 - val_loss: 0.6922 - val_accuracy: 0.5144\n",
      "Epoch 57/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5208 - val_loss: 0.6921 - val_accuracy: 0.5144\n",
      "Epoch 58/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5208 - val_loss: 0.6922 - val_accuracy: 0.5138\n",
      "Epoch 59/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5226 - val_loss: 0.6922 - val_accuracy: 0.5155\n",
      "Epoch 60/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5202 - val_loss: 0.6922 - val_accuracy: 0.5151\n",
      "Epoch 61/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5206 - val_loss: 0.6922 - val_accuracy: 0.5150\n",
      "Epoch 62/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5207 - val_loss: 0.6922 - val_accuracy: 0.5119\n",
      "Epoch 63/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5214 - val_loss: 0.6922 - val_accuracy: 0.5153\n",
      "Epoch 64/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5206 - val_loss: 0.6921 - val_accuracy: 0.5135\n",
      "Epoch 65/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5225 - val_loss: 0.6921 - val_accuracy: 0.5161\n",
      "Epoch 66/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5216 - val_loss: 0.6922 - val_accuracy: 0.5193\n",
      "Epoch 67/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5214 - val_loss: 0.6921 - val_accuracy: 0.5151\n",
      "Epoch 68/1000\n",
      "41306/41306 [==============================] - 1s 12us/sample - loss: 0.6913 - accuracy: 0.5202 - val_loss: 0.6920 - val_accuracy: 0.5190\n",
      "Epoch 69/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5213 - val_loss: 0.6921 - val_accuracy: 0.5148\n",
      "Epoch 70/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5221 - val_loss: 0.6921 - val_accuracy: 0.5206\n",
      "Epoch 71/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5217 - val_loss: 0.6922 - val_accuracy: 0.5168\n",
      "Epoch 72/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5211 - val_loss: 0.6922 - val_accuracy: 0.5165\n",
      "Epoch 73/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5202 - val_loss: 0.6922 - val_accuracy: 0.5164\n",
      "Epoch 74/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5217 - val_loss: 0.6921 - val_accuracy: 0.5160\n",
      "Training with significance = 2.84, run 7\n",
      "Train on 41306 samples, validate on 10327 samples\n",
      "Epoch 1/1000\n",
      "41306/41306 [==============================] - 2s 55us/sample - loss: 0.6929 - accuracy: 0.5084 - val_loss: 0.6931 - val_accuracy: 0.5091\n",
      "Epoch 2/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6925 - accuracy: 0.5130 - val_loss: 0.6926 - val_accuracy: 0.5181\n",
      "Epoch 3/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5127 - val_loss: 0.6921 - val_accuracy: 0.5223\n",
      "Epoch 4/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5152 - val_loss: 0.6920 - val_accuracy: 0.5231\n",
      "Epoch 5/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5130 - val_loss: 0.6919 - val_accuracy: 0.5203\n",
      "Epoch 6/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5140 - val_loss: 0.6919 - val_accuracy: 0.5214\n",
      "Epoch 7/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5138 - val_loss: 0.6920 - val_accuracy: 0.5222\n",
      "Epoch 8/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5158 - val_loss: 0.6919 - val_accuracy: 0.5225\n",
      "Epoch 9/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5152 - val_loss: 0.6919 - val_accuracy: 0.5187\n",
      "Epoch 10/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5141 - val_loss: 0.6919 - val_accuracy: 0.5215\n",
      "Epoch 11/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5138 - val_loss: 0.6918 - val_accuracy: 0.5199\n",
      "Epoch 12/1000\n",
      "41306/41306 [==============================] - 1s 12us/sample - loss: 0.6917 - accuracy: 0.5147 - val_loss: 0.6920 - val_accuracy: 0.5219\n",
      "Epoch 13/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5148 - val_loss: 0.6919 - val_accuracy: 0.5209\n",
      "Epoch 14/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5171 - val_loss: 0.6920 - val_accuracy: 0.5206\n",
      "Epoch 15/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5142 - val_loss: 0.6920 - val_accuracy: 0.5221\n",
      "Epoch 16/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5162 - val_loss: 0.6919 - val_accuracy: 0.5212\n",
      "Epoch 17/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5144 - val_loss: 0.6920 - val_accuracy: 0.5234\n",
      "Epoch 18/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5155 - val_loss: 0.6919 - val_accuracy: 0.5219\n",
      "Epoch 19/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5175 - val_loss: 0.6919 - val_accuracy: 0.5204\n",
      "Epoch 20/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5177 - val_loss: 0.6920 - val_accuracy: 0.5224\n",
      "Epoch 21/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5158 - val_loss: 0.6920 - val_accuracy: 0.5217\n",
      "Epoch 22/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5169 - val_loss: 0.6919 - val_accuracy: 0.5223\n",
      "Epoch 23/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5166 - val_loss: 0.6919 - val_accuracy: 0.5233\n",
      "Epoch 24/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5162 - val_loss: 0.6920 - val_accuracy: 0.5218\n",
      "Epoch 25/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5171 - val_loss: 0.6920 - val_accuracy: 0.5236\n",
      "Epoch 26/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5179 - val_loss: 0.6919 - val_accuracy: 0.5221\n",
      "Epoch 27/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5173 - val_loss: 0.6920 - val_accuracy: 0.5220\n",
      "Epoch 28/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5194 - val_loss: 0.6919 - val_accuracy: 0.5226\n",
      "Epoch 29/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5189 - val_loss: 0.6920 - val_accuracy: 0.5207\n",
      "Epoch 30/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5185 - val_loss: 0.6919 - val_accuracy: 0.5216\n",
      "Epoch 31/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5182 - val_loss: 0.6919 - val_accuracy: 0.5215\n",
      "Epoch 32/1000\n",
      "41306/41306 [==============================] - 1s 12us/sample - loss: 0.6914 - accuracy: 0.5174 - val_loss: 0.6921 - val_accuracy: 0.5133\n",
      "Epoch 33/1000\n",
      "41306/41306 [==============================] - 1s 12us/sample - loss: 0.6914 - accuracy: 0.5176 - val_loss: 0.6920 - val_accuracy: 0.5230\n",
      "Epoch 34/1000\n",
      "41306/41306 [==============================] - 1s 12us/sample - loss: 0.6915 - accuracy: 0.5159 - val_loss: 0.6919 - val_accuracy: 0.5241\n",
      "Epoch 35/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5191 - val_loss: 0.6922 - val_accuracy: 0.5109\n",
      "Epoch 36/1000\n",
      "41306/41306 [==============================] - 1s 12us/sample - loss: 0.6913 - accuracy: 0.5174 - val_loss: 0.6920 - val_accuracy: 0.5217\n",
      "Epoch 37/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5180 - val_loss: 0.6920 - val_accuracy: 0.5183\n",
      "Epoch 38/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5190 - val_loss: 0.6921 - val_accuracy: 0.5214\n",
      "Epoch 39/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5174 - val_loss: 0.6920 - val_accuracy: 0.5229\n",
      "Epoch 40/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5195 - val_loss: 0.6920 - val_accuracy: 0.5155\n",
      "Epoch 41/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5189 - val_loss: 0.6919 - val_accuracy: 0.5236\n",
      "Training with significance = 2.84, run 8\n",
      "Train on 41306 samples, validate on 10327 samples\n",
      "Epoch 1/1000\n",
      "41306/41306 [==============================] - 1s 28us/sample - loss: 0.6929 - accuracy: 0.5092 - val_loss: 0.6944 - val_accuracy: 0.5003\n",
      "Epoch 2/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5126 - val_loss: 0.6936 - val_accuracy: 0.5061\n",
      "Epoch 3/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5172 - val_loss: 0.6930 - val_accuracy: 0.5100\n",
      "Epoch 4/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5181 - val_loss: 0.6923 - val_accuracy: 0.5137\n",
      "Epoch 5/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5173 - val_loss: 0.6923 - val_accuracy: 0.5143\n",
      "Epoch 6/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5189 - val_loss: 0.6923 - val_accuracy: 0.5130\n",
      "Epoch 7/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5186 - val_loss: 0.6922 - val_accuracy: 0.5144\n",
      "Epoch 8/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5192 - val_loss: 0.6921 - val_accuracy: 0.5160\n",
      "Epoch 9/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5187 - val_loss: 0.6921 - val_accuracy: 0.5173\n",
      "Epoch 10/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5192 - val_loss: 0.6921 - val_accuracy: 0.5168\n",
      "Epoch 11/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5194 - val_loss: 0.6920 - val_accuracy: 0.5156\n",
      "Epoch 12/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5178 - val_loss: 0.6921 - val_accuracy: 0.5170\n",
      "Epoch 13/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5196 - val_loss: 0.6920 - val_accuracy: 0.5189\n",
      "Epoch 14/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5190 - val_loss: 0.6919 - val_accuracy: 0.5189\n",
      "Epoch 15/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5196 - val_loss: 0.6921 - val_accuracy: 0.5157\n",
      "Epoch 16/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5182 - val_loss: 0.6920 - val_accuracy: 0.5190\n",
      "Epoch 17/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5209 - val_loss: 0.6921 - val_accuracy: 0.5182\n",
      "Epoch 18/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5195 - val_loss: 0.6920 - val_accuracy: 0.5190\n",
      "Epoch 19/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5213 - val_loss: 0.6920 - val_accuracy: 0.5169\n",
      "Epoch 20/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5195 - val_loss: 0.6919 - val_accuracy: 0.5178\n",
      "Epoch 21/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5197 - val_loss: 0.6921 - val_accuracy: 0.5175\n",
      "Epoch 22/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5190 - val_loss: 0.6920 - val_accuracy: 0.5214\n",
      "Epoch 23/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5187 - val_loss: 0.6920 - val_accuracy: 0.5197\n",
      "Epoch 24/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5193 - val_loss: 0.6921 - val_accuracy: 0.5210\n",
      "Epoch 25/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5185 - val_loss: 0.6921 - val_accuracy: 0.5178\n",
      "Epoch 26/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5197 - val_loss: 0.6921 - val_accuracy: 0.5178\n",
      "Epoch 27/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5212 - val_loss: 0.6918 - val_accuracy: 0.5162\n",
      "Epoch 28/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5196 - val_loss: 0.6919 - val_accuracy: 0.5149\n",
      "Epoch 29/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5202 - val_loss: 0.6921 - val_accuracy: 0.5189\n",
      "Epoch 30/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5190 - val_loss: 0.6919 - val_accuracy: 0.5201\n",
      "Epoch 31/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5223 - val_loss: 0.6919 - val_accuracy: 0.5194\n",
      "Epoch 32/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5201 - val_loss: 0.6919 - val_accuracy: 0.5182\n",
      "Epoch 33/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5211 - val_loss: 0.6920 - val_accuracy: 0.5196\n",
      "Epoch 34/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5196 - val_loss: 0.6921 - val_accuracy: 0.5187\n",
      "Epoch 35/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5209 - val_loss: 0.6919 - val_accuracy: 0.5152\n",
      "Epoch 36/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5210 - val_loss: 0.6920 - val_accuracy: 0.5203\n",
      "Epoch 37/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5210 - val_loss: 0.6921 - val_accuracy: 0.5173\n",
      "Epoch 38/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5226 - val_loss: 0.6920 - val_accuracy: 0.5189\n",
      "Epoch 39/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5239 - val_loss: 0.6921 - val_accuracy: 0.5178\n",
      "Epoch 40/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5203 - val_loss: 0.6921 - val_accuracy: 0.5201\n",
      "Epoch 41/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5210 - val_loss: 0.6919 - val_accuracy: 0.5193\n",
      "Epoch 42/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5234 - val_loss: 0.6921 - val_accuracy: 0.5181\n",
      "Epoch 43/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5205 - val_loss: 0.6921 - val_accuracy: 0.5194\n",
      "Epoch 44/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5228 - val_loss: 0.6922 - val_accuracy: 0.5171\n",
      "Epoch 45/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5207 - val_loss: 0.6920 - val_accuracy: 0.5201\n",
      "Epoch 46/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5210 - val_loss: 0.6921 - val_accuracy: 0.5197\n",
      "Epoch 47/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5218 - val_loss: 0.6923 - val_accuracy: 0.5157\n",
      "Epoch 48/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5235 - val_loss: 0.6924 - val_accuracy: 0.5186\n",
      "Epoch 49/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5212 - val_loss: 0.6920 - val_accuracy: 0.5206\n",
      "Epoch 50/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5220 - val_loss: 0.6920 - val_accuracy: 0.5216\n",
      "Epoch 51/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5199 - val_loss: 0.6919 - val_accuracy: 0.5205\n",
      "Epoch 52/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5219 - val_loss: 0.6919 - val_accuracy: 0.5190\n",
      "Epoch 53/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5208 - val_loss: 0.6919 - val_accuracy: 0.5186\n",
      "Epoch 54/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5211 - val_loss: 0.6920 - val_accuracy: 0.5176\n",
      "Epoch 55/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5203 - val_loss: 0.6919 - val_accuracy: 0.5164\n",
      "Epoch 56/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5235 - val_loss: 0.6920 - val_accuracy: 0.5187\n",
      "Epoch 57/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5201 - val_loss: 0.6920 - val_accuracy: 0.5202\n",
      "Training with significance = 2.84, run 9\n",
      "Train on 41306 samples, validate on 10327 samples\n",
      "Epoch 1/1000\n",
      "41306/41306 [==============================] - 1s 27us/sample - loss: 0.6937 - accuracy: 0.5047 - val_loss: 0.6931 - val_accuracy: 0.5086\n",
      "Epoch 2/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6926 - accuracy: 0.5122 - val_loss: 0.6919 - val_accuracy: 0.5170\n",
      "Epoch 3/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5134 - val_loss: 0.6919 - val_accuracy: 0.5165\n",
      "Epoch 4/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5145 - val_loss: 0.6918 - val_accuracy: 0.5197\n",
      "Epoch 5/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5139 - val_loss: 0.6921 - val_accuracy: 0.5128\n",
      "Epoch 6/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5129 - val_loss: 0.6921 - val_accuracy: 0.5153\n",
      "Epoch 7/1000\n",
      "41306/41306 [==============================] - 1s 12us/sample - loss: 0.6923 - accuracy: 0.5148 - val_loss: 0.6920 - val_accuracy: 0.5158\n",
      "Epoch 8/1000\n",
      "41306/41306 [==============================] - 1s 12us/sample - loss: 0.6922 - accuracy: 0.5152 - val_loss: 0.6920 - val_accuracy: 0.5202\n",
      "Epoch 9/1000\n",
      "41306/41306 [==============================] - 0s 12us/sample - loss: 0.6921 - accuracy: 0.5145 - val_loss: 0.6920 - val_accuracy: 0.5201\n",
      "Epoch 10/1000\n",
      "41306/41306 [==============================] - 1s 12us/sample - loss: 0.6921 - accuracy: 0.5142 - val_loss: 0.6924 - val_accuracy: 0.5115\n",
      "Epoch 11/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5140 - val_loss: 0.6921 - val_accuracy: 0.5152\n",
      "Epoch 12/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5161 - val_loss: 0.6921 - val_accuracy: 0.5182\n",
      "Epoch 13/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5172 - val_loss: 0.6920 - val_accuracy: 0.5188\n",
      "Epoch 14/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5166 - val_loss: 0.6921 - val_accuracy: 0.5155\n",
      "Epoch 15/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5140 - val_loss: 0.6921 - val_accuracy: 0.5167\n",
      "Epoch 16/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5146 - val_loss: 0.6921 - val_accuracy: 0.5214\n",
      "Epoch 17/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5149 - val_loss: 0.6920 - val_accuracy: 0.5205\n",
      "Epoch 18/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5149 - val_loss: 0.6921 - val_accuracy: 0.5111\n",
      "Epoch 19/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5163 - val_loss: 0.6922 - val_accuracy: 0.5131\n",
      "Epoch 20/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5159 - val_loss: 0.6921 - val_accuracy: 0.5156\n",
      "Epoch 21/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5152 - val_loss: 0.6920 - val_accuracy: 0.5212\n",
      "Epoch 22/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5161 - val_loss: 0.6921 - val_accuracy: 0.5161\n",
      "Epoch 23/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5165 - val_loss: 0.6920 - val_accuracy: 0.5172\n",
      "Epoch 24/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5168 - val_loss: 0.6921 - val_accuracy: 0.5161\n",
      "Epoch 25/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5148 - val_loss: 0.6921 - val_accuracy: 0.5153\n",
      "Epoch 26/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5171 - val_loss: 0.6921 - val_accuracy: 0.5166\n",
      "Epoch 27/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5158 - val_loss: 0.6920 - val_accuracy: 0.5184\n",
      "Epoch 28/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5161 - val_loss: 0.6921 - val_accuracy: 0.5162\n",
      "Epoch 29/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5160 - val_loss: 0.6921 - val_accuracy: 0.5185\n",
      "Epoch 30/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5163 - val_loss: 0.6919 - val_accuracy: 0.5193\n",
      "Epoch 31/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5174 - val_loss: 0.6920 - val_accuracy: 0.5172\n",
      "Epoch 32/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5162 - val_loss: 0.6919 - val_accuracy: 0.5188\n",
      "Epoch 33/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5162 - val_loss: 0.6921 - val_accuracy: 0.5195\n",
      "Epoch 34/1000\n",
      "41306/41306 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5163 - val_loss: 0.6920 - val_accuracy: 0.5187\n",
      "Training with significance = 3.15, run 0\n",
      "Train on 41356 samples, validate on 10340 samples\n",
      "Epoch 1/1000\n",
      "41356/41356 [==============================] - 1s 28us/sample - loss: 0.6935 - accuracy: 0.5083 - val_loss: 0.6943 - val_accuracy: 0.5008\n",
      "Epoch 2/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5139 - val_loss: 0.6933 - val_accuracy: 0.5107\n",
      "Epoch 3/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5153 - val_loss: 0.6931 - val_accuracy: 0.5103\n",
      "Epoch 4/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5156 - val_loss: 0.6929 - val_accuracy: 0.5100\n",
      "Epoch 5/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5164 - val_loss: 0.6928 - val_accuracy: 0.5104\n",
      "Epoch 6/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5164 - val_loss: 0.6928 - val_accuracy: 0.5091\n",
      "Epoch 7/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5183 - val_loss: 0.6928 - val_accuracy: 0.5109\n",
      "Epoch 8/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5157 - val_loss: 0.6927 - val_accuracy: 0.5111\n",
      "Epoch 9/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5186 - val_loss: 0.6929 - val_accuracy: 0.5107\n",
      "Epoch 10/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5176 - val_loss: 0.6930 - val_accuracy: 0.5109\n",
      "Epoch 11/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5178 - val_loss: 0.6928 - val_accuracy: 0.5116\n",
      "Epoch 12/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5178 - val_loss: 0.6929 - val_accuracy: 0.5128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5184 - val_loss: 0.6927 - val_accuracy: 0.5106\n",
      "Epoch 14/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5163 - val_loss: 0.6927 - val_accuracy: 0.5107\n",
      "Epoch 15/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5179 - val_loss: 0.6928 - val_accuracy: 0.5109\n",
      "Epoch 16/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5175 - val_loss: 0.6929 - val_accuracy: 0.5103\n",
      "Epoch 17/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5186 - val_loss: 0.6927 - val_accuracy: 0.5106\n",
      "Epoch 18/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5194 - val_loss: 0.6928 - val_accuracy: 0.5108\n",
      "Epoch 19/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5177 - val_loss: 0.6929 - val_accuracy: 0.5117\n",
      "Epoch 20/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5197 - val_loss: 0.6930 - val_accuracy: 0.5100\n",
      "Epoch 21/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5186 - val_loss: 0.6929 - val_accuracy: 0.5096\n",
      "Epoch 22/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5189 - val_loss: 0.6927 - val_accuracy: 0.5102\n",
      "Epoch 23/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5210 - val_loss: 0.6928 - val_accuracy: 0.5107\n",
      "Epoch 24/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5197 - val_loss: 0.6930 - val_accuracy: 0.5105\n",
      "Epoch 25/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5191 - val_loss: 0.6927 - val_accuracy: 0.5115\n",
      "Epoch 26/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5213 - val_loss: 0.6930 - val_accuracy: 0.5114\n",
      "Epoch 27/1000\n",
      "41356/41356 [==============================] - 0s 12us/sample - loss: 0.6914 - accuracy: 0.5185 - val_loss: 0.6930 - val_accuracy: 0.5111\n",
      "Epoch 28/1000\n",
      "41356/41356 [==============================] - 0s 12us/sample - loss: 0.6914 - accuracy: 0.5188 - val_loss: 0.6927 - val_accuracy: 0.5122\n",
      "Epoch 29/1000\n",
      "41356/41356 [==============================] - 1s 12us/sample - loss: 0.6914 - accuracy: 0.5189 - val_loss: 0.6929 - val_accuracy: 0.5102\n",
      "Epoch 30/1000\n",
      "41356/41356 [==============================] - 0s 12us/sample - loss: 0.6915 - accuracy: 0.5178 - val_loss: 0.6929 - val_accuracy: 0.5103\n",
      "Epoch 31/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5181 - val_loss: 0.6932 - val_accuracy: 0.5107\n",
      "Epoch 32/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5175 - val_loss: 0.6928 - val_accuracy: 0.5130\n",
      "Epoch 33/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5205 - val_loss: 0.6931 - val_accuracy: 0.5102\n",
      "Epoch 34/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5199 - val_loss: 0.6927 - val_accuracy: 0.5127\n",
      "Epoch 35/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5207 - val_loss: 0.6928 - val_accuracy: 0.5106\n",
      "Epoch 36/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5201 - val_loss: 0.6928 - val_accuracy: 0.5104\n",
      "Epoch 37/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5203 - val_loss: 0.6928 - val_accuracy: 0.5124\n",
      "Epoch 38/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5194 - val_loss: 0.6927 - val_accuracy: 0.5103\n",
      "Epoch 39/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5215 - val_loss: 0.6928 - val_accuracy: 0.5101\n",
      "Epoch 40/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5218 - val_loss: 0.6927 - val_accuracy: 0.5113\n",
      "Epoch 41/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5185 - val_loss: 0.6929 - val_accuracy: 0.5127\n",
      "Epoch 42/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5207 - val_loss: 0.6930 - val_accuracy: 0.5103\n",
      "Epoch 43/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5192 - val_loss: 0.6929 - val_accuracy: 0.5103\n",
      "Epoch 44/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5216 - val_loss: 0.6928 - val_accuracy: 0.5100\n",
      "Epoch 45/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5221 - val_loss: 0.6931 - val_accuracy: 0.5095\n",
      "Epoch 46/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5207 - val_loss: 0.6927 - val_accuracy: 0.5137\n",
      "Epoch 47/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5204 - val_loss: 0.6928 - val_accuracy: 0.5104\n",
      "Epoch 48/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5226 - val_loss: 0.6929 - val_accuracy: 0.5084\n",
      "Epoch 49/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5215 - val_loss: 0.6930 - val_accuracy: 0.5116\n",
      "Epoch 50/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5219 - val_loss: 0.6928 - val_accuracy: 0.5108\n",
      "Epoch 51/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5186 - val_loss: 0.6928 - val_accuracy: 0.5113\n",
      "Epoch 52/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5229 - val_loss: 0.6931 - val_accuracy: 0.5101\n",
      "Epoch 53/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5187 - val_loss: 0.6931 - val_accuracy: 0.5094\n",
      "Epoch 54/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5215 - val_loss: 0.6931 - val_accuracy: 0.5093\n",
      "Epoch 55/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5216 - val_loss: 0.6929 - val_accuracy: 0.5110\n",
      "Epoch 56/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5218 - val_loss: 0.6931 - val_accuracy: 0.5127\n",
      "Epoch 57/1000\n",
      "41356/41356 [==============================] - 1s 12us/sample - loss: 0.6911 - accuracy: 0.5215 - val_loss: 0.6927 - val_accuracy: 0.5101\n",
      "Epoch 58/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5220 - val_loss: 0.6929 - val_accuracy: 0.5118\n",
      "Epoch 59/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5216 - val_loss: 0.6932 - val_accuracy: 0.5101\n",
      "Epoch 60/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5231 - val_loss: 0.6928 - val_accuracy: 0.5119\n",
      "Epoch 61/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5218 - val_loss: 0.6930 - val_accuracy: 0.5108\n",
      "Epoch 62/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5214 - val_loss: 0.6930 - val_accuracy: 0.5112\n",
      "Epoch 63/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5217 - val_loss: 0.6929 - val_accuracy: 0.5086\n",
      "Epoch 64/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5208 - val_loss: 0.6930 - val_accuracy: 0.5115\n",
      "Epoch 65/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5215 - val_loss: 0.6929 - val_accuracy: 0.5102\n",
      "Epoch 66/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5232 - val_loss: 0.6928 - val_accuracy: 0.5119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5221 - val_loss: 0.6930 - val_accuracy: 0.5114\n",
      "Epoch 68/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5223 - val_loss: 0.6931 - val_accuracy: 0.5101\n",
      "Epoch 69/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5228 - val_loss: 0.6931 - val_accuracy: 0.5084\n",
      "Epoch 70/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5229 - val_loss: 0.6930 - val_accuracy: 0.5104\n",
      "Training with significance = 3.15, run 1\n",
      "Train on 41356 samples, validate on 10340 samples\n",
      "Epoch 1/1000\n",
      "41356/41356 [==============================] - 1s 27us/sample - loss: 0.6937 - accuracy: 0.5087 - val_loss: 0.6930 - val_accuracy: 0.5077\n",
      "Epoch 2/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5162 - val_loss: 0.6927 - val_accuracy: 0.5093\n",
      "Epoch 3/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5153 - val_loss: 0.6924 - val_accuracy: 0.5128\n",
      "Epoch 4/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5171 - val_loss: 0.6923 - val_accuracy: 0.5129\n",
      "Epoch 5/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5200 - val_loss: 0.6921 - val_accuracy: 0.5124\n",
      "Epoch 6/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5185 - val_loss: 0.6924 - val_accuracy: 0.5124\n",
      "Epoch 7/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5183 - val_loss: 0.6921 - val_accuracy: 0.5127\n",
      "Epoch 8/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5197 - val_loss: 0.6921 - val_accuracy: 0.5111\n",
      "Epoch 9/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5200 - val_loss: 0.6921 - val_accuracy: 0.5116\n",
      "Epoch 10/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5206 - val_loss: 0.6920 - val_accuracy: 0.5134\n",
      "Epoch 11/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5206 - val_loss: 0.6919 - val_accuracy: 0.5183\n",
      "Epoch 12/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5209 - val_loss: 0.6920 - val_accuracy: 0.5122\n",
      "Epoch 13/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5210 - val_loss: 0.6921 - val_accuracy: 0.5108\n",
      "Epoch 14/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5214 - val_loss: 0.6922 - val_accuracy: 0.5107\n",
      "Epoch 15/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5207 - val_loss: 0.6921 - val_accuracy: 0.5110\n",
      "Epoch 16/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5222 - val_loss: 0.6920 - val_accuracy: 0.5173\n",
      "Epoch 17/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5206 - val_loss: 0.6922 - val_accuracy: 0.5120\n",
      "Epoch 18/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5217 - val_loss: 0.6922 - val_accuracy: 0.5130\n",
      "Epoch 19/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5206 - val_loss: 0.6922 - val_accuracy: 0.5116\n",
      "Epoch 20/1000\n",
      "41356/41356 [==============================] - 1s 12us/sample - loss: 0.6911 - accuracy: 0.5217 - val_loss: 0.6919 - val_accuracy: 0.5153\n",
      "Epoch 21/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5205 - val_loss: 0.6921 - val_accuracy: 0.5136\n",
      "Epoch 22/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5224 - val_loss: 0.6919 - val_accuracy: 0.5166\n",
      "Epoch 23/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5222 - val_loss: 0.6920 - val_accuracy: 0.5132\n",
      "Epoch 24/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5220 - val_loss: 0.6921 - val_accuracy: 0.5133\n",
      "Epoch 25/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5225 - val_loss: 0.6921 - val_accuracy: 0.5120\n",
      "Epoch 26/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5216 - val_loss: 0.6922 - val_accuracy: 0.5132\n",
      "Epoch 27/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5231 - val_loss: 0.6920 - val_accuracy: 0.5145\n",
      "Epoch 28/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5218 - val_loss: 0.6921 - val_accuracy: 0.5141\n",
      "Epoch 29/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5230 - val_loss: 0.6920 - val_accuracy: 0.5148\n",
      "Epoch 30/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5202 - val_loss: 0.6919 - val_accuracy: 0.5158\n",
      "Epoch 31/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5220 - val_loss: 0.6922 - val_accuracy: 0.5128\n",
      "Epoch 32/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5203 - val_loss: 0.6922 - val_accuracy: 0.5144\n",
      "Epoch 33/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5226 - val_loss: 0.6919 - val_accuracy: 0.5187\n",
      "Epoch 34/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5222 - val_loss: 0.6921 - val_accuracy: 0.5132\n",
      "Epoch 35/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5237 - val_loss: 0.6923 - val_accuracy: 0.5089\n",
      "Epoch 36/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5234 - val_loss: 0.6921 - val_accuracy: 0.5149\n",
      "Epoch 37/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5226 - val_loss: 0.6921 - val_accuracy: 0.5129\n",
      "Epoch 38/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5229 - val_loss: 0.6921 - val_accuracy: 0.5140\n",
      "Epoch 39/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5229 - val_loss: 0.6924 - val_accuracy: 0.5105\n",
      "Epoch 40/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5219 - val_loss: 0.6922 - val_accuracy: 0.5133\n",
      "Epoch 41/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5224 - val_loss: 0.6920 - val_accuracy: 0.5209\n",
      "Training with significance = 3.15, run 2\n",
      "Train on 41356 samples, validate on 10340 samples\n",
      "Epoch 1/1000\n",
      "41356/41356 [==============================] - 1s 28us/sample - loss: 0.6933 - accuracy: 0.5066 - val_loss: 0.6935 - val_accuracy: 0.5015\n",
      "Epoch 2/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6925 - accuracy: 0.5129 - val_loss: 0.6933 - val_accuracy: 0.5058\n",
      "Epoch 3/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5141 - val_loss: 0.6932 - val_accuracy: 0.5060\n",
      "Epoch 4/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5158 - val_loss: 0.6927 - val_accuracy: 0.5125\n",
      "Epoch 5/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5169 - val_loss: 0.6926 - val_accuracy: 0.5181\n",
      "Epoch 6/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5159 - val_loss: 0.6926 - val_accuracy: 0.5175\n",
      "Epoch 7/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5161 - val_loss: 0.6925 - val_accuracy: 0.5172\n",
      "Epoch 8/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5176 - val_loss: 0.6925 - val_accuracy: 0.5194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5170 - val_loss: 0.6924 - val_accuracy: 0.5185\n",
      "Epoch 10/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5162 - val_loss: 0.6924 - val_accuracy: 0.5205\n",
      "Epoch 11/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5190 - val_loss: 0.6925 - val_accuracy: 0.5180\n",
      "Epoch 12/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5178 - val_loss: 0.6924 - val_accuracy: 0.5198\n",
      "Epoch 13/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5173 - val_loss: 0.6924 - val_accuracy: 0.5196\n",
      "Epoch 14/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5175 - val_loss: 0.6924 - val_accuracy: 0.5197\n",
      "Epoch 15/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5172 - val_loss: 0.6924 - val_accuracy: 0.5216\n",
      "Epoch 16/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5192 - val_loss: 0.6924 - val_accuracy: 0.5226\n",
      "Epoch 17/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5176 - val_loss: 0.6924 - val_accuracy: 0.5219\n",
      "Epoch 18/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5153 - val_loss: 0.6923 - val_accuracy: 0.5210\n",
      "Epoch 19/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5187 - val_loss: 0.6926 - val_accuracy: 0.5168\n",
      "Epoch 20/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5209 - val_loss: 0.6925 - val_accuracy: 0.5186\n",
      "Epoch 21/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5180 - val_loss: 0.6923 - val_accuracy: 0.5223\n",
      "Epoch 22/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5187 - val_loss: 0.6924 - val_accuracy: 0.5192\n",
      "Epoch 23/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5184 - val_loss: 0.6923 - val_accuracy: 0.5188\n",
      "Epoch 24/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5204 - val_loss: 0.6924 - val_accuracy: 0.5206\n",
      "Epoch 25/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5187 - val_loss: 0.6923 - val_accuracy: 0.5204\n",
      "Epoch 26/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5182 - val_loss: 0.6923 - val_accuracy: 0.5202\n",
      "Epoch 27/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5191 - val_loss: 0.6924 - val_accuracy: 0.5210\n",
      "Epoch 28/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5201 - val_loss: 0.6924 - val_accuracy: 0.5205\n",
      "Epoch 29/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5167 - val_loss: 0.6923 - val_accuracy: 0.5205\n",
      "Epoch 30/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5179 - val_loss: 0.6925 - val_accuracy: 0.5217\n",
      "Epoch 31/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5188 - val_loss: 0.6924 - val_accuracy: 0.5199\n",
      "Epoch 32/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5174 - val_loss: 0.6924 - val_accuracy: 0.5205\n",
      "Epoch 33/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5184 - val_loss: 0.6922 - val_accuracy: 0.5221\n",
      "Epoch 34/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5197 - val_loss: 0.6923 - val_accuracy: 0.5205\n",
      "Epoch 35/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5191 - val_loss: 0.6923 - val_accuracy: 0.5196\n",
      "Epoch 36/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5199 - val_loss: 0.6924 - val_accuracy: 0.5189\n",
      "Epoch 37/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5189 - val_loss: 0.6923 - val_accuracy: 0.5191\n",
      "Epoch 38/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5210 - val_loss: 0.6923 - val_accuracy: 0.5191\n",
      "Epoch 39/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5211 - val_loss: 0.6924 - val_accuracy: 0.5190\n",
      "Epoch 40/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5209 - val_loss: 0.6924 - val_accuracy: 0.5210\n",
      "Epoch 41/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5209 - val_loss: 0.6924 - val_accuracy: 0.5179\n",
      "Epoch 42/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5202 - val_loss: 0.6924 - val_accuracy: 0.5187\n",
      "Epoch 43/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5191 - val_loss: 0.6925 - val_accuracy: 0.5163\n",
      "Epoch 44/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5187 - val_loss: 0.6924 - val_accuracy: 0.5205\n",
      "Epoch 45/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5206 - val_loss: 0.6925 - val_accuracy: 0.5186\n",
      "Epoch 46/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5189 - val_loss: 0.6924 - val_accuracy: 0.5189\n",
      "Epoch 47/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5202 - val_loss: 0.6924 - val_accuracy: 0.5212\n",
      "Epoch 48/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5211 - val_loss: 0.6925 - val_accuracy: 0.5150\n",
      "Epoch 49/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5219 - val_loss: 0.6923 - val_accuracy: 0.5207\n",
      "Epoch 50/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5195 - val_loss: 0.6924 - val_accuracy: 0.5205\n",
      "Epoch 51/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5193 - val_loss: 0.6924 - val_accuracy: 0.5171\n",
      "Epoch 52/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5203 - val_loss: 0.6924 - val_accuracy: 0.5180\n",
      "Epoch 53/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5214 - val_loss: 0.6925 - val_accuracy: 0.5177\n",
      "Epoch 54/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5216 - val_loss: 0.6924 - val_accuracy: 0.5193\n",
      "Epoch 55/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5202 - val_loss: 0.6924 - val_accuracy: 0.5199\n",
      "Epoch 56/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5219 - val_loss: 0.6924 - val_accuracy: 0.5189\n",
      "Epoch 57/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5187 - val_loss: 0.6923 - val_accuracy: 0.5168\n",
      "Epoch 58/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5206 - val_loss: 0.6924 - val_accuracy: 0.5231\n",
      "Epoch 59/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5215 - val_loss: 0.6924 - val_accuracy: 0.5197\n",
      "Epoch 60/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5207 - val_loss: 0.6924 - val_accuracy: 0.5251\n",
      "Epoch 61/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5214 - val_loss: 0.6924 - val_accuracy: 0.5214\n",
      "Epoch 62/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5185 - val_loss: 0.6924 - val_accuracy: 0.5184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5214 - val_loss: 0.6925 - val_accuracy: 0.5214\n",
      "Training with significance = 3.15, run 3\n",
      "Train on 41356 samples, validate on 10340 samples\n",
      "Epoch 1/1000\n",
      "41356/41356 [==============================] - 1s 28us/sample - loss: 0.6928 - accuracy: 0.5082 - val_loss: 0.6944 - val_accuracy: 0.5014\n",
      "Epoch 2/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5153 - val_loss: 0.6927 - val_accuracy: 0.5105\n",
      "Epoch 3/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5167 - val_loss: 0.6925 - val_accuracy: 0.5135\n",
      "Epoch 4/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5173 - val_loss: 0.6925 - val_accuracy: 0.5113\n",
      "Epoch 5/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5186 - val_loss: 0.6926 - val_accuracy: 0.5120\n",
      "Epoch 6/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5167 - val_loss: 0.6926 - val_accuracy: 0.5116\n",
      "Epoch 7/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5183 - val_loss: 0.6925 - val_accuracy: 0.5116\n",
      "Epoch 8/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5201 - val_loss: 0.6925 - val_accuracy: 0.5117\n",
      "Epoch 9/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5180 - val_loss: 0.6928 - val_accuracy: 0.5097\n",
      "Epoch 10/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5186 - val_loss: 0.6929 - val_accuracy: 0.5103\n",
      "Epoch 11/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5187 - val_loss: 0.6926 - val_accuracy: 0.5101\n",
      "Epoch 12/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5175 - val_loss: 0.6927 - val_accuracy: 0.5103\n",
      "Epoch 13/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5182 - val_loss: 0.6927 - val_accuracy: 0.5101\n",
      "Epoch 14/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5179 - val_loss: 0.6929 - val_accuracy: 0.5082\n",
      "Epoch 15/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5181 - val_loss: 0.6928 - val_accuracy: 0.5074\n",
      "Epoch 16/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5185 - val_loss: 0.6928 - val_accuracy: 0.5119\n",
      "Epoch 17/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5192 - val_loss: 0.6928 - val_accuracy: 0.5050\n",
      "Epoch 18/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5185 - val_loss: 0.6928 - val_accuracy: 0.5065\n",
      "Epoch 19/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5192 - val_loss: 0.6927 - val_accuracy: 0.5089\n",
      "Epoch 20/1000\n",
      "41356/41356 [==============================] - 1s 12us/sample - loss: 0.6913 - accuracy: 0.5197 - val_loss: 0.6927 - val_accuracy: 0.5129\n",
      "Epoch 21/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5194 - val_loss: 0.6929 - val_accuracy: 0.5094\n",
      "Epoch 22/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5197 - val_loss: 0.6930 - val_accuracy: 0.5064\n",
      "Epoch 23/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5203 - val_loss: 0.6928 - val_accuracy: 0.5101\n",
      "Epoch 24/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5203 - val_loss: 0.6928 - val_accuracy: 0.5099\n",
      "Epoch 25/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5185 - val_loss: 0.6928 - val_accuracy: 0.5092\n",
      "Epoch 26/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5198 - val_loss: 0.6929 - val_accuracy: 0.5090\n",
      "Epoch 27/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5215 - val_loss: 0.6929 - val_accuracy: 0.5063\n",
      "Epoch 28/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5194 - val_loss: 0.6929 - val_accuracy: 0.5075\n",
      "Epoch 29/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5198 - val_loss: 0.6931 - val_accuracy: 0.5077\n",
      "Epoch 30/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5209 - val_loss: 0.6931 - val_accuracy: 0.5075\n",
      "Epoch 31/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5219 - val_loss: 0.6928 - val_accuracy: 0.5092\n",
      "Epoch 32/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5230 - val_loss: 0.6931 - val_accuracy: 0.5090\n",
      "Epoch 33/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5209 - val_loss: 0.6929 - val_accuracy: 0.5094\n",
      "Epoch 34/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5218 - val_loss: 0.6928 - val_accuracy: 0.5086\n",
      "Epoch 35/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5210 - val_loss: 0.6931 - val_accuracy: 0.5069\n",
      "Epoch 36/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5204 - val_loss: 0.6929 - val_accuracy: 0.5080\n",
      "Epoch 37/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5220 - val_loss: 0.6929 - val_accuracy: 0.5084\n",
      "Training with significance = 3.15, run 4\n",
      "Train on 41356 samples, validate on 10340 samples\n",
      "Epoch 1/1000\n",
      "41356/41356 [==============================] - 1s 28us/sample - loss: 0.6936 - accuracy: 0.4975 - val_loss: 0.6930 - val_accuracy: 0.5056\n",
      "Epoch 2/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6926 - accuracy: 0.5128 - val_loss: 0.6918 - val_accuracy: 0.5208\n",
      "Epoch 3/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5111 - val_loss: 0.6915 - val_accuracy: 0.5288\n",
      "Epoch 4/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5148 - val_loss: 0.6915 - val_accuracy: 0.5279\n",
      "Epoch 5/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5137 - val_loss: 0.6913 - val_accuracy: 0.5286\n",
      "Epoch 6/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5159 - val_loss: 0.6912 - val_accuracy: 0.5254\n",
      "Epoch 7/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5132 - val_loss: 0.6912 - val_accuracy: 0.5282\n",
      "Epoch 8/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5158 - val_loss: 0.6911 - val_accuracy: 0.5256\n",
      "Epoch 9/1000\n",
      "41356/41356 [==============================] - 1s 12us/sample - loss: 0.6918 - accuracy: 0.5165 - val_loss: 0.6911 - val_accuracy: 0.5264\n",
      "Epoch 10/1000\n",
      "41356/41356 [==============================] - 1s 12us/sample - loss: 0.6917 - accuracy: 0.5175 - val_loss: 0.6913 - val_accuracy: 0.5243\n",
      "Epoch 11/1000\n",
      "41356/41356 [==============================] - 1s 12us/sample - loss: 0.6917 - accuracy: 0.5173 - val_loss: 0.6910 - val_accuracy: 0.5246\n",
      "Epoch 12/1000\n",
      "41356/41356 [==============================] - 0s 12us/sample - loss: 0.6917 - accuracy: 0.5164 - val_loss: 0.6910 - val_accuracy: 0.5250\n",
      "Epoch 13/1000\n",
      "41356/41356 [==============================] - 1s 12us/sample - loss: 0.6917 - accuracy: 0.5170 - val_loss: 0.6911 - val_accuracy: 0.5249\n",
      "Epoch 14/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5187 - val_loss: 0.6910 - val_accuracy: 0.5249\n",
      "Epoch 15/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5183 - val_loss: 0.6910 - val_accuracy: 0.5226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5170 - val_loss: 0.6912 - val_accuracy: 0.5221\n",
      "Epoch 17/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5196 - val_loss: 0.6909 - val_accuracy: 0.5249\n",
      "Epoch 18/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5190 - val_loss: 0.6910 - val_accuracy: 0.5250\n",
      "Epoch 19/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5182 - val_loss: 0.6909 - val_accuracy: 0.5239\n",
      "Epoch 20/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5184 - val_loss: 0.6909 - val_accuracy: 0.5250\n",
      "Epoch 21/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5188 - val_loss: 0.6910 - val_accuracy: 0.5241\n",
      "Epoch 22/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5180 - val_loss: 0.6909 - val_accuracy: 0.5230\n",
      "Epoch 23/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5198 - val_loss: 0.6911 - val_accuracy: 0.5245\n",
      "Epoch 24/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5199 - val_loss: 0.6908 - val_accuracy: 0.5211\n",
      "Epoch 25/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5186 - val_loss: 0.6909 - val_accuracy: 0.5242\n",
      "Epoch 26/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5182 - val_loss: 0.6909 - val_accuracy: 0.5241\n",
      "Epoch 27/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5201 - val_loss: 0.6909 - val_accuracy: 0.5227\n",
      "Epoch 28/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5204 - val_loss: 0.6910 - val_accuracy: 0.5224\n",
      "Epoch 29/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5221 - val_loss: 0.6908 - val_accuracy: 0.5229\n",
      "Epoch 30/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5205 - val_loss: 0.6910 - val_accuracy: 0.5209\n",
      "Epoch 31/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5209 - val_loss: 0.6908 - val_accuracy: 0.5224\n",
      "Epoch 32/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5228 - val_loss: 0.6908 - val_accuracy: 0.5218\n",
      "Epoch 33/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5197 - val_loss: 0.6909 - val_accuracy: 0.5244\n",
      "Epoch 34/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5231 - val_loss: 0.6910 - val_accuracy: 0.5231\n",
      "Epoch 35/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5199 - val_loss: 0.6910 - val_accuracy: 0.5219\n",
      "Epoch 36/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5217 - val_loss: 0.6909 - val_accuracy: 0.5219\n",
      "Epoch 37/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5204 - val_loss: 0.6907 - val_accuracy: 0.5240\n",
      "Epoch 38/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5200 - val_loss: 0.6908 - val_accuracy: 0.5236\n",
      "Epoch 39/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5207 - val_loss: 0.6910 - val_accuracy: 0.5216\n",
      "Epoch 40/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5226 - val_loss: 0.6907 - val_accuracy: 0.5215\n",
      "Epoch 41/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5224 - val_loss: 0.6909 - val_accuracy: 0.5194\n",
      "Epoch 42/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5221 - val_loss: 0.6908 - val_accuracy: 0.5218\n",
      "Epoch 43/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5253 - val_loss: 0.6910 - val_accuracy: 0.5206\n",
      "Epoch 44/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5238 - val_loss: 0.6907 - val_accuracy: 0.5238\n",
      "Epoch 45/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5212 - val_loss: 0.6909 - val_accuracy: 0.5206\n",
      "Epoch 46/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5225 - val_loss: 0.6908 - val_accuracy: 0.5222\n",
      "Epoch 47/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5213 - val_loss: 0.6909 - val_accuracy: 0.5237\n",
      "Epoch 48/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5232 - val_loss: 0.6910 - val_accuracy: 0.5235\n",
      "Epoch 49/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5216 - val_loss: 0.6908 - val_accuracy: 0.5216\n",
      "Epoch 50/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5203 - val_loss: 0.6910 - val_accuracy: 0.5238\n",
      "Epoch 51/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5211 - val_loss: 0.6910 - val_accuracy: 0.5254\n",
      "Epoch 52/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5230 - val_loss: 0.6910 - val_accuracy: 0.5209\n",
      "Epoch 53/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5215 - val_loss: 0.6908 - val_accuracy: 0.5233\n",
      "Epoch 54/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5229 - val_loss: 0.6908 - val_accuracy: 0.5233\n",
      "Epoch 55/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5212 - val_loss: 0.6909 - val_accuracy: 0.5219\n",
      "Epoch 56/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5204 - val_loss: 0.6908 - val_accuracy: 0.5223\n",
      "Epoch 57/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5213 - val_loss: 0.6908 - val_accuracy: 0.5211\n",
      "Epoch 58/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5252 - val_loss: 0.6909 - val_accuracy: 0.5231\n",
      "Epoch 59/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5243 - val_loss: 0.6908 - val_accuracy: 0.5226\n",
      "Epoch 60/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5239 - val_loss: 0.6908 - val_accuracy: 0.5228\n",
      "Epoch 61/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5250 - val_loss: 0.6909 - val_accuracy: 0.5226\n",
      "Epoch 62/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5221 - val_loss: 0.6909 - val_accuracy: 0.5222\n",
      "Epoch 63/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5220 - val_loss: 0.6908 - val_accuracy: 0.5214\n",
      "Epoch 64/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5236 - val_loss: 0.6908 - val_accuracy: 0.5221\n",
      "Epoch 65/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5232 - val_loss: 0.6908 - val_accuracy: 0.5217\n",
      "Epoch 66/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5237 - val_loss: 0.6909 - val_accuracy: 0.5253\n",
      "Epoch 67/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5234 - val_loss: 0.6908 - val_accuracy: 0.5223\n",
      "Epoch 68/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5254 - val_loss: 0.6909 - val_accuracy: 0.5231\n",
      "Epoch 69/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5220 - val_loss: 0.6909 - val_accuracy: 0.5247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5239 - val_loss: 0.6908 - val_accuracy: 0.5225\n",
      "Epoch 71/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5244 - val_loss: 0.6913 - val_accuracy: 0.5241\n",
      "Epoch 72/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5242 - val_loss: 0.6909 - val_accuracy: 0.5233\n",
      "Epoch 73/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5238 - val_loss: 0.6909 - val_accuracy: 0.5231\n",
      "Epoch 74/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5232 - val_loss: 0.6907 - val_accuracy: 0.5219\n",
      "Epoch 75/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5238 - val_loss: 0.6910 - val_accuracy: 0.5254\n",
      "Epoch 76/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5219 - val_loss: 0.6909 - val_accuracy: 0.5239\n",
      "Epoch 77/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5251 - val_loss: 0.6910 - val_accuracy: 0.5247\n",
      "Epoch 78/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5237 - val_loss: 0.6909 - val_accuracy: 0.5241\n",
      "Epoch 79/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5225 - val_loss: 0.6907 - val_accuracy: 0.5212\n",
      "Epoch 80/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5218 - val_loss: 0.6907 - val_accuracy: 0.5250\n",
      "Epoch 81/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5225 - val_loss: 0.6907 - val_accuracy: 0.5228\n",
      "Epoch 82/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5250 - val_loss: 0.6908 - val_accuracy: 0.5230\n",
      "Epoch 83/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5222 - val_loss: 0.6909 - val_accuracy: 0.5231\n",
      "Epoch 84/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5244 - val_loss: 0.6909 - val_accuracy: 0.5226\n",
      "Epoch 85/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5224 - val_loss: 0.6908 - val_accuracy: 0.5249\n",
      "Epoch 86/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5235 - val_loss: 0.6911 - val_accuracy: 0.5234\n",
      "Epoch 87/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5239 - val_loss: 0.6908 - val_accuracy: 0.5227\n",
      "Epoch 88/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5238 - val_loss: 0.6909 - val_accuracy: 0.5231\n",
      "Epoch 89/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5228 - val_loss: 0.6908 - val_accuracy: 0.5215\n",
      "Epoch 90/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5247 - val_loss: 0.6909 - val_accuracy: 0.5212\n",
      "Epoch 91/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5242 - val_loss: 0.6908 - val_accuracy: 0.5218\n",
      "Epoch 92/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5238 - val_loss: 0.6908 - val_accuracy: 0.5201\n",
      "Epoch 93/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5271 - val_loss: 0.6909 - val_accuracy: 0.5223\n",
      "Epoch 94/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5227 - val_loss: 0.6909 - val_accuracy: 0.5214\n",
      "Epoch 95/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5229 - val_loss: 0.6908 - val_accuracy: 0.5230\n",
      "Epoch 96/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5261 - val_loss: 0.6910 - val_accuracy: 0.5220\n",
      "Epoch 97/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5228 - val_loss: 0.6910 - val_accuracy: 0.5208\n",
      "Epoch 98/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5242 - val_loss: 0.6909 - val_accuracy: 0.5213\n",
      "Epoch 99/1000\n",
      "41356/41356 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5241 - val_loss: 0.6909 - val_accuracy: 0.5211\n",
      "Epoch 100/1000\n",
      "41356/41356 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5268 - val_loss: 0.6908 - val_accuracy: 0.5223\n",
      "Epoch 101/1000\n",
      "41356/41356 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5247 - val_loss: 0.6909 - val_accuracy: 0.5236\n",
      "Epoch 102/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5267 - val_loss: 0.6908 - val_accuracy: 0.5209\n",
      "Epoch 103/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5236 - val_loss: 0.6909 - val_accuracy: 0.5218\n",
      "Epoch 104/1000\n",
      "41356/41356 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5255 - val_loss: 0.6911 - val_accuracy: 0.5224\n",
      "Epoch 105/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5251 - val_loss: 0.6908 - val_accuracy: 0.5220\n",
      "Epoch 106/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5229 - val_loss: 0.6910 - val_accuracy: 0.5221\n",
      "Epoch 107/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5270 - val_loss: 0.6910 - val_accuracy: 0.5248\n",
      "Epoch 108/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5251 - val_loss: 0.6909 - val_accuracy: 0.5221\n",
      "Epoch 109/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5273 - val_loss: 0.6909 - val_accuracy: 0.5201\n",
      "Epoch 110/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5267 - val_loss: 0.6910 - val_accuracy: 0.5224\n",
      "Training with significance = 3.15, run 5\n",
      "Train on 41356 samples, validate on 10340 samples\n",
      "Epoch 1/1000\n",
      "41356/41356 [==============================] - 1s 28us/sample - loss: 0.6928 - accuracy: 0.5110 - val_loss: 0.6932 - val_accuracy: 0.5071\n",
      "Epoch 2/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5134 - val_loss: 0.6925 - val_accuracy: 0.5169\n",
      "Epoch 3/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5164 - val_loss: 0.6922 - val_accuracy: 0.5150\n",
      "Epoch 4/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5170 - val_loss: 0.6923 - val_accuracy: 0.5188\n",
      "Epoch 5/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5173 - val_loss: 0.6922 - val_accuracy: 0.5176\n",
      "Epoch 6/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5155 - val_loss: 0.6923 - val_accuracy: 0.5132\n",
      "Epoch 7/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5178 - val_loss: 0.6924 - val_accuracy: 0.5108\n",
      "Epoch 8/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5166 - val_loss: 0.6922 - val_accuracy: 0.5092\n",
      "Epoch 9/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5176 - val_loss: 0.6923 - val_accuracy: 0.5103\n",
      "Epoch 10/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5197 - val_loss: 0.6921 - val_accuracy: 0.5099\n",
      "Epoch 11/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5195 - val_loss: 0.6921 - val_accuracy: 0.5115\n",
      "Epoch 12/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5194 - val_loss: 0.6922 - val_accuracy: 0.5099\n",
      "Epoch 13/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5209 - val_loss: 0.6922 - val_accuracy: 0.5132\n",
      "Epoch 14/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5185 - val_loss: 0.6924 - val_accuracy: 0.5099\n",
      "Epoch 15/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5185 - val_loss: 0.6926 - val_accuracy: 0.5135\n",
      "Epoch 16/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5216 - val_loss: 0.6922 - val_accuracy: 0.5151\n",
      "Epoch 17/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5217 - val_loss: 0.6920 - val_accuracy: 0.5101\n",
      "Epoch 18/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5205 - val_loss: 0.6921 - val_accuracy: 0.5129\n",
      "Epoch 19/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5185 - val_loss: 0.6920 - val_accuracy: 0.5126\n",
      "Epoch 20/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5203 - val_loss: 0.6921 - val_accuracy: 0.5088\n",
      "Epoch 21/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5218 - val_loss: 0.6922 - val_accuracy: 0.5117\n",
      "Epoch 22/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5218 - val_loss: 0.6921 - val_accuracy: 0.5107\n",
      "Epoch 23/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5206 - val_loss: 0.6920 - val_accuracy: 0.5123\n",
      "Epoch 24/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5219 - val_loss: 0.6922 - val_accuracy: 0.5118\n",
      "Epoch 25/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5215 - val_loss: 0.6920 - val_accuracy: 0.5119\n",
      "Epoch 26/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5211 - val_loss: 0.6921 - val_accuracy: 0.5129\n",
      "Epoch 27/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5228 - val_loss: 0.6922 - val_accuracy: 0.5129\n",
      "Epoch 28/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5205 - val_loss: 0.6924 - val_accuracy: 0.5118\n",
      "Epoch 29/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5205 - val_loss: 0.6923 - val_accuracy: 0.5134\n",
      "Epoch 30/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5227 - val_loss: 0.6923 - val_accuracy: 0.5125\n",
      "Epoch 31/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5230 - val_loss: 0.6922 - val_accuracy: 0.5139\n",
      "Epoch 32/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5206 - val_loss: 0.6923 - val_accuracy: 0.5129\n",
      "Epoch 33/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5216 - val_loss: 0.6922 - val_accuracy: 0.5133\n",
      "Epoch 34/1000\n",
      "41356/41356 [==============================] - 1s 12us/sample - loss: 0.6912 - accuracy: 0.5212 - val_loss: 0.6922 - val_accuracy: 0.5135\n",
      "Epoch 35/1000\n",
      "41356/41356 [==============================] - 0s 12us/sample - loss: 0.6913 - accuracy: 0.5208 - val_loss: 0.6921 - val_accuracy: 0.5132\n",
      "Epoch 36/1000\n",
      "41356/41356 [==============================] - 1s 12us/sample - loss: 0.6911 - accuracy: 0.5229 - val_loss: 0.6923 - val_accuracy: 0.5126\n",
      "Epoch 37/1000\n",
      "41356/41356 [==============================] - 1s 12us/sample - loss: 0.6912 - accuracy: 0.5192 - val_loss: 0.6922 - val_accuracy: 0.5126\n",
      "Epoch 38/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5206 - val_loss: 0.6923 - val_accuracy: 0.5053\n",
      "Epoch 39/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5198 - val_loss: 0.6920 - val_accuracy: 0.5109\n",
      "Epoch 40/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5217 - val_loss: 0.6921 - val_accuracy: 0.5141\n",
      "Epoch 41/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5233 - val_loss: 0.6920 - val_accuracy: 0.5133\n",
      "Epoch 42/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5220 - val_loss: 0.6924 - val_accuracy: 0.5131\n",
      "Epoch 43/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5214 - val_loss: 0.6922 - val_accuracy: 0.5084\n",
      "Epoch 44/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5221 - val_loss: 0.6921 - val_accuracy: 0.5122\n",
      "Epoch 45/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5234 - val_loss: 0.6921 - val_accuracy: 0.5113\n",
      "Epoch 46/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5212 - val_loss: 0.6923 - val_accuracy: 0.5133\n",
      "Epoch 47/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5224 - val_loss: 0.6928 - val_accuracy: 0.5128\n",
      "Epoch 48/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5215 - val_loss: 0.6921 - val_accuracy: 0.5158\n",
      "Epoch 49/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5213 - val_loss: 0.6922 - val_accuracy: 0.5147\n",
      "Epoch 50/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5252 - val_loss: 0.6923 - val_accuracy: 0.5123\n",
      "Epoch 51/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5226 - val_loss: 0.6922 - val_accuracy: 0.5109\n",
      "Epoch 52/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5210 - val_loss: 0.6921 - val_accuracy: 0.5127\n",
      "Epoch 53/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5211 - val_loss: 0.6924 - val_accuracy: 0.5145\n",
      "Epoch 54/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5227 - val_loss: 0.6921 - val_accuracy: 0.5117\n",
      "Epoch 55/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5230 - val_loss: 0.6921 - val_accuracy: 0.5100\n",
      "Epoch 56/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5222 - val_loss: 0.6920 - val_accuracy: 0.5115\n",
      "Epoch 57/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5237 - val_loss: 0.6925 - val_accuracy: 0.5134\n",
      "Epoch 58/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5218 - val_loss: 0.6922 - val_accuracy: 0.5109\n",
      "Epoch 59/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5218 - val_loss: 0.6924 - val_accuracy: 0.5119\n",
      "Epoch 60/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5206 - val_loss: 0.6922 - val_accuracy: 0.5136\n",
      "Epoch 61/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5211 - val_loss: 0.6922 - val_accuracy: 0.5129\n",
      "Epoch 62/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5219 - val_loss: 0.6924 - val_accuracy: 0.5120\n",
      "Epoch 63/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5228 - val_loss: 0.6924 - val_accuracy: 0.5141\n",
      "Epoch 64/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5234 - val_loss: 0.6923 - val_accuracy: 0.5112\n",
      "Epoch 65/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5230 - val_loss: 0.6923 - val_accuracy: 0.5139\n",
      "Epoch 66/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5231 - val_loss: 0.6924 - val_accuracy: 0.5151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5224 - val_loss: 0.6921 - val_accuracy: 0.5097\n",
      "Epoch 68/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5227 - val_loss: 0.6922 - val_accuracy: 0.5131\n",
      "Epoch 69/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5236 - val_loss: 0.6922 - val_accuracy: 0.5122\n",
      "Epoch 70/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5218 - val_loss: 0.6922 - val_accuracy: 0.5122\n",
      "Epoch 71/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5228 - val_loss: 0.6922 - val_accuracy: 0.5138\n",
      "Training with significance = 3.15, run 6\n",
      "Train on 41356 samples, validate on 10340 samples\n",
      "Epoch 1/1000\n",
      "41356/41356 [==============================] - 1s 29us/sample - loss: 0.6932 - accuracy: 0.5058 - val_loss: 0.6930 - val_accuracy: 0.5014\n",
      "Epoch 2/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5104 - val_loss: 0.6927 - val_accuracy: 0.5074\n",
      "Epoch 3/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5150 - val_loss: 0.6923 - val_accuracy: 0.5141\n",
      "Epoch 4/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5157 - val_loss: 0.6922 - val_accuracy: 0.5149\n",
      "Epoch 5/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5156 - val_loss: 0.6921 - val_accuracy: 0.5195\n",
      "Epoch 6/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5146 - val_loss: 0.6920 - val_accuracy: 0.5174\n",
      "Epoch 7/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5153 - val_loss: 0.6919 - val_accuracy: 0.5180\n",
      "Epoch 8/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5165 - val_loss: 0.6920 - val_accuracy: 0.5183\n",
      "Epoch 9/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5165 - val_loss: 0.6918 - val_accuracy: 0.5196\n",
      "Epoch 10/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5188 - val_loss: 0.6918 - val_accuracy: 0.5174\n",
      "Epoch 11/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5164 - val_loss: 0.6918 - val_accuracy: 0.5189\n",
      "Epoch 12/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5170 - val_loss: 0.6919 - val_accuracy: 0.5187\n",
      "Epoch 13/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5176 - val_loss: 0.6917 - val_accuracy: 0.5192\n",
      "Epoch 14/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5178 - val_loss: 0.6918 - val_accuracy: 0.5183\n",
      "Epoch 15/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5145 - val_loss: 0.6919 - val_accuracy: 0.5183\n",
      "Epoch 16/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5170 - val_loss: 0.6919 - val_accuracy: 0.5198\n",
      "Epoch 17/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5181 - val_loss: 0.6918 - val_accuracy: 0.5189\n",
      "Epoch 18/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5177 - val_loss: 0.6919 - val_accuracy: 0.5199\n",
      "Epoch 19/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5189 - val_loss: 0.6919 - val_accuracy: 0.5207\n",
      "Epoch 20/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5200 - val_loss: 0.6918 - val_accuracy: 0.5222\n",
      "Epoch 21/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5183 - val_loss: 0.6918 - val_accuracy: 0.5212\n",
      "Epoch 22/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5183 - val_loss: 0.6917 - val_accuracy: 0.5212\n",
      "Epoch 23/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5168 - val_loss: 0.6919 - val_accuracy: 0.5182\n",
      "Epoch 24/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5198 - val_loss: 0.6918 - val_accuracy: 0.5207\n",
      "Epoch 25/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5197 - val_loss: 0.6919 - val_accuracy: 0.5195\n",
      "Epoch 26/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5192 - val_loss: 0.6918 - val_accuracy: 0.5202\n",
      "Epoch 27/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5184 - val_loss: 0.6918 - val_accuracy: 0.5215\n",
      "Epoch 28/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5195 - val_loss: 0.6918 - val_accuracy: 0.5220\n",
      "Epoch 29/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5220 - val_loss: 0.6917 - val_accuracy: 0.5207\n",
      "Epoch 30/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5192 - val_loss: 0.6917 - val_accuracy: 0.5217\n",
      "Epoch 31/1000\n",
      "41356/41356 [==============================] - 0s 12us/sample - loss: 0.6914 - accuracy: 0.5178 - val_loss: 0.6919 - val_accuracy: 0.5176\n",
      "Epoch 32/1000\n",
      "41356/41356 [==============================] - 1s 12us/sample - loss: 0.6914 - accuracy: 0.5190 - val_loss: 0.6920 - val_accuracy: 0.5159\n",
      "Epoch 33/1000\n",
      "41356/41356 [==============================] - 1s 12us/sample - loss: 0.6913 - accuracy: 0.5200 - val_loss: 0.6918 - val_accuracy: 0.5191\n",
      "Epoch 34/1000\n",
      "41356/41356 [==============================] - 1s 12us/sample - loss: 0.6914 - accuracy: 0.5196 - val_loss: 0.6919 - val_accuracy: 0.5187\n",
      "Epoch 35/1000\n",
      "41356/41356 [==============================] - 0s 12us/sample - loss: 0.6913 - accuracy: 0.5219 - val_loss: 0.6919 - val_accuracy: 0.5188\n",
      "Epoch 36/1000\n",
      "41356/41356 [==============================] - 1s 12us/sample - loss: 0.6914 - accuracy: 0.5192 - val_loss: 0.6918 - val_accuracy: 0.5202\n",
      "Epoch 37/1000\n",
      "41356/41356 [==============================] - 1s 12us/sample - loss: 0.6913 - accuracy: 0.5210 - val_loss: 0.6918 - val_accuracy: 0.5178\n",
      "Epoch 38/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5199 - val_loss: 0.6918 - val_accuracy: 0.5199\n",
      "Epoch 39/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5209 - val_loss: 0.6919 - val_accuracy: 0.5178\n",
      "Epoch 40/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5199 - val_loss: 0.6918 - val_accuracy: 0.5181\n",
      "Epoch 41/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5192 - val_loss: 0.6919 - val_accuracy: 0.5211\n",
      "Epoch 42/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5199 - val_loss: 0.6918 - val_accuracy: 0.5211\n",
      "Epoch 43/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5201 - val_loss: 0.6919 - val_accuracy: 0.5192\n",
      "Epoch 44/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5193 - val_loss: 0.6918 - val_accuracy: 0.5207\n",
      "Epoch 45/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5204 - val_loss: 0.6920 - val_accuracy: 0.5157\n",
      "Epoch 46/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5208 - val_loss: 0.6918 - val_accuracy: 0.5190\n",
      "Epoch 47/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5189 - val_loss: 0.6918 - val_accuracy: 0.5205\n",
      "Epoch 48/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5206 - val_loss: 0.6919 - val_accuracy: 0.5191\n",
      "Epoch 49/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5195 - val_loss: 0.6918 - val_accuracy: 0.5183\n",
      "Epoch 50/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5201 - val_loss: 0.6918 - val_accuracy: 0.5169\n",
      "Epoch 51/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5215 - val_loss: 0.6920 - val_accuracy: 0.5170\n",
      "Epoch 52/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5203 - val_loss: 0.6919 - val_accuracy: 0.5221\n",
      "Epoch 53/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5199 - val_loss: 0.6919 - val_accuracy: 0.5202\n",
      "Epoch 54/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5218 - val_loss: 0.6918 - val_accuracy: 0.5194\n",
      "Epoch 55/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5212 - val_loss: 0.6918 - val_accuracy: 0.5188\n",
      "Epoch 56/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5223 - val_loss: 0.6919 - val_accuracy: 0.5178\n",
      "Epoch 57/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5206 - val_loss: 0.6920 - val_accuracy: 0.5155\n",
      "Epoch 58/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5226 - val_loss: 0.6920 - val_accuracy: 0.5196\n",
      "Epoch 59/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5200 - val_loss: 0.6919 - val_accuracy: 0.5177\n",
      "Epoch 60/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5242 - val_loss: 0.6920 - val_accuracy: 0.5152\n",
      "Training with significance = 3.15, run 7\n",
      "Train on 41356 samples, validate on 10340 samples\n",
      "Epoch 1/1000\n",
      "41356/41356 [==============================] - 1s 28us/sample - loss: 0.6928 - accuracy: 0.5112 - val_loss: 0.6928 - val_accuracy: 0.5099\n",
      "Epoch 2/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5160 - val_loss: 0.6920 - val_accuracy: 0.5171\n",
      "Epoch 3/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5150 - val_loss: 0.6919 - val_accuracy: 0.5162\n",
      "Epoch 4/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5179 - val_loss: 0.6918 - val_accuracy: 0.5166\n",
      "Epoch 5/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5156 - val_loss: 0.6920 - val_accuracy: 0.5163\n",
      "Epoch 6/1000\n",
      "41356/41356 [==============================] - 1s 12us/sample - loss: 0.6917 - accuracy: 0.5171 - val_loss: 0.6921 - val_accuracy: 0.5192\n",
      "Epoch 7/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5184 - val_loss: 0.6918 - val_accuracy: 0.5127\n",
      "Epoch 8/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5166 - val_loss: 0.6918 - val_accuracy: 0.5139\n",
      "Epoch 9/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5165 - val_loss: 0.6919 - val_accuracy: 0.5132\n",
      "Epoch 10/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5166 - val_loss: 0.6920 - val_accuracy: 0.5178\n",
      "Epoch 11/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5164 - val_loss: 0.6920 - val_accuracy: 0.5173\n",
      "Epoch 12/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5182 - val_loss: 0.6919 - val_accuracy: 0.5166\n",
      "Epoch 13/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5192 - val_loss: 0.6918 - val_accuracy: 0.5140\n",
      "Epoch 14/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5173 - val_loss: 0.6919 - val_accuracy: 0.5162\n",
      "Epoch 15/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5200 - val_loss: 0.6919 - val_accuracy: 0.5164\n",
      "Epoch 16/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5207 - val_loss: 0.6920 - val_accuracy: 0.5166\n",
      "Epoch 17/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5191 - val_loss: 0.6918 - val_accuracy: 0.5172\n",
      "Epoch 18/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5178 - val_loss: 0.6919 - val_accuracy: 0.5184\n",
      "Epoch 19/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5219 - val_loss: 0.6923 - val_accuracy: 0.5170\n",
      "Epoch 20/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5201 - val_loss: 0.6919 - val_accuracy: 0.5125\n",
      "Epoch 21/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5198 - val_loss: 0.6919 - val_accuracy: 0.5181\n",
      "Epoch 22/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5195 - val_loss: 0.6919 - val_accuracy: 0.5160\n",
      "Epoch 23/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5209 - val_loss: 0.6919 - val_accuracy: 0.5147\n",
      "Epoch 24/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5204 - val_loss: 0.6919 - val_accuracy: 0.5175\n",
      "Epoch 25/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5196 - val_loss: 0.6918 - val_accuracy: 0.5121\n",
      "Epoch 26/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5198 - val_loss: 0.6919 - val_accuracy: 0.5149\n",
      "Epoch 27/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5220 - val_loss: 0.6918 - val_accuracy: 0.5149\n",
      "Epoch 28/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5225 - val_loss: 0.6919 - val_accuracy: 0.5168\n",
      "Epoch 29/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5217 - val_loss: 0.6918 - val_accuracy: 0.5188\n",
      "Epoch 30/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5212 - val_loss: 0.6918 - val_accuracy: 0.5128\n",
      "Epoch 31/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5222 - val_loss: 0.6918 - val_accuracy: 0.5131\n",
      "Epoch 32/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5199 - val_loss: 0.6917 - val_accuracy: 0.5157\n",
      "Epoch 33/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5213 - val_loss: 0.6919 - val_accuracy: 0.5173\n",
      "Epoch 34/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5209 - val_loss: 0.6917 - val_accuracy: 0.5169\n",
      "Epoch 35/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5228 - val_loss: 0.6919 - val_accuracy: 0.5174\n",
      "Epoch 36/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5207 - val_loss: 0.6921 - val_accuracy: 0.5180\n",
      "Epoch 37/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5190 - val_loss: 0.6919 - val_accuracy: 0.5165\n",
      "Epoch 38/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5207 - val_loss: 0.6918 - val_accuracy: 0.5173\n",
      "Epoch 39/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5199 - val_loss: 0.6920 - val_accuracy: 0.5192\n",
      "Epoch 40/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5215 - val_loss: 0.6919 - val_accuracy: 0.5164\n",
      "Epoch 41/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5206 - val_loss: 0.6919 - val_accuracy: 0.5166\n",
      "Epoch 42/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5227 - val_loss: 0.6921 - val_accuracy: 0.5186\n",
      "Epoch 43/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5218 - val_loss: 0.6918 - val_accuracy: 0.5169\n",
      "Epoch 44/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5202 - val_loss: 0.6919 - val_accuracy: 0.5190\n",
      "Epoch 45/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5222 - val_loss: 0.6919 - val_accuracy: 0.5145\n",
      "Epoch 46/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5231 - val_loss: 0.6920 - val_accuracy: 0.5145\n",
      "Epoch 47/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5231 - val_loss: 0.6919 - val_accuracy: 0.5157\n",
      "Epoch 48/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5243 - val_loss: 0.6920 - val_accuracy: 0.5178\n",
      "Epoch 49/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5217 - val_loss: 0.6918 - val_accuracy: 0.5154\n",
      "Epoch 50/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5229 - val_loss: 0.6919 - val_accuracy: 0.5177\n",
      "Epoch 51/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5226 - val_loss: 0.6919 - val_accuracy: 0.5155\n",
      "Epoch 52/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5215 - val_loss: 0.6919 - val_accuracy: 0.5173\n",
      "Epoch 53/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5222 - val_loss: 0.6918 - val_accuracy: 0.5161\n",
      "Epoch 54/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5212 - val_loss: 0.6919 - val_accuracy: 0.5170\n",
      "Epoch 55/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5247 - val_loss: 0.6920 - val_accuracy: 0.5161\n",
      "Epoch 56/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5206 - val_loss: 0.6918 - val_accuracy: 0.5164\n",
      "Epoch 57/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5217 - val_loss: 0.6918 - val_accuracy: 0.5137\n",
      "Epoch 58/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5228 - val_loss: 0.6918 - val_accuracy: 0.5133\n",
      "Epoch 59/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5223 - val_loss: 0.6919 - val_accuracy: 0.5166\n",
      "Epoch 60/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5230 - val_loss: 0.6919 - val_accuracy: 0.5173\n",
      "Epoch 61/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5213 - val_loss: 0.6919 - val_accuracy: 0.5152\n",
      "Epoch 62/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5269 - val_loss: 0.6920 - val_accuracy: 0.5150\n",
      "Epoch 63/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5213 - val_loss: 0.6919 - val_accuracy: 0.5147\n",
      "Epoch 64/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5228 - val_loss: 0.6919 - val_accuracy: 0.5138\n",
      "Training with significance = 3.15, run 8\n",
      "Train on 41356 samples, validate on 10340 samples\n",
      "Epoch 1/1000\n",
      "41356/41356 [==============================] - 1s 28us/sample - loss: 0.6929 - accuracy: 0.5100 - val_loss: 0.6934 - val_accuracy: 0.5077\n",
      "Epoch 2/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5135 - val_loss: 0.6921 - val_accuracy: 0.5142\n",
      "Epoch 3/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5183 - val_loss: 0.6917 - val_accuracy: 0.5168\n",
      "Epoch 4/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5152 - val_loss: 0.6916 - val_accuracy: 0.5198\n",
      "Epoch 5/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5165 - val_loss: 0.6914 - val_accuracy: 0.5227\n",
      "Epoch 6/1000\n",
      "41356/41356 [==============================] - 1s 12us/sample - loss: 0.6919 - accuracy: 0.5171 - val_loss: 0.6918 - val_accuracy: 0.5190\n",
      "Epoch 7/1000\n",
      "41356/41356 [==============================] - 1s 12us/sample - loss: 0.6918 - accuracy: 0.5177 - val_loss: 0.6916 - val_accuracy: 0.5235\n",
      "Epoch 8/1000\n",
      "41356/41356 [==============================] - 1s 12us/sample - loss: 0.6918 - accuracy: 0.5173 - val_loss: 0.6914 - val_accuracy: 0.5195\n",
      "Epoch 9/1000\n",
      "41356/41356 [==============================] - 0s 12us/sample - loss: 0.6918 - accuracy: 0.5169 - val_loss: 0.6918 - val_accuracy: 0.5159\n",
      "Epoch 10/1000\n",
      "41356/41356 [==============================] - 1s 12us/sample - loss: 0.6917 - accuracy: 0.5187 - val_loss: 0.6917 - val_accuracy: 0.5218\n",
      "Epoch 11/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5170 - val_loss: 0.6917 - val_accuracy: 0.5170\n",
      "Epoch 12/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5194 - val_loss: 0.6916 - val_accuracy: 0.5186\n",
      "Epoch 13/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5183 - val_loss: 0.6915 - val_accuracy: 0.5188\n",
      "Epoch 14/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5176 - val_loss: 0.6913 - val_accuracy: 0.5194\n",
      "Epoch 15/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5195 - val_loss: 0.6918 - val_accuracy: 0.5183\n",
      "Epoch 16/1000\n",
      "41356/41356 [==============================] - 1s 14us/sample - loss: 0.6915 - accuracy: 0.5206 - val_loss: 0.6917 - val_accuracy: 0.5189\n",
      "Epoch 17/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5192 - val_loss: 0.6917 - val_accuracy: 0.5184\n",
      "Epoch 18/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5198 - val_loss: 0.6918 - val_accuracy: 0.5183\n",
      "Epoch 19/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5212 - val_loss: 0.6912 - val_accuracy: 0.5203\n",
      "Epoch 20/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5200 - val_loss: 0.6916 - val_accuracy: 0.5158\n",
      "Epoch 21/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5183 - val_loss: 0.6914 - val_accuracy: 0.5200\n",
      "Epoch 22/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5187 - val_loss: 0.6914 - val_accuracy: 0.5169\n",
      "Epoch 23/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5186 - val_loss: 0.6919 - val_accuracy: 0.5203\n",
      "Epoch 24/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5208 - val_loss: 0.6918 - val_accuracy: 0.5202\n",
      "Epoch 25/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5190 - val_loss: 0.6919 - val_accuracy: 0.5189\n",
      "Epoch 26/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5191 - val_loss: 0.6914 - val_accuracy: 0.5191\n",
      "Epoch 27/1000\n",
      "41356/41356 [==============================] - 1s 12us/sample - loss: 0.6913 - accuracy: 0.5179 - val_loss: 0.6912 - val_accuracy: 0.5217\n",
      "Epoch 28/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5208 - val_loss: 0.6915 - val_accuracy: 0.5202\n",
      "Epoch 29/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5199 - val_loss: 0.6915 - val_accuracy: 0.5176\n",
      "Epoch 30/1000\n",
      "41356/41356 [==============================] - 1s 12us/sample - loss: 0.6911 - accuracy: 0.5214 - val_loss: 0.6914 - val_accuracy: 0.5190\n",
      "Epoch 31/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5206 - val_loss: 0.6912 - val_accuracy: 0.5198\n",
      "Epoch 32/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5198 - val_loss: 0.6916 - val_accuracy: 0.5176\n",
      "Epoch 33/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5209 - val_loss: 0.6915 - val_accuracy: 0.5177\n",
      "Epoch 34/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5201 - val_loss: 0.6915 - val_accuracy: 0.5193\n",
      "Epoch 35/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5206 - val_loss: 0.6917 - val_accuracy: 0.5187\n",
      "Epoch 36/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5198 - val_loss: 0.6918 - val_accuracy: 0.5185\n",
      "Epoch 37/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5201 - val_loss: 0.6917 - val_accuracy: 0.5172\n",
      "Epoch 38/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5199 - val_loss: 0.6915 - val_accuracy: 0.5191\n",
      "Epoch 39/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5205 - val_loss: 0.6918 - val_accuracy: 0.5191\n",
      "Epoch 40/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5198 - val_loss: 0.6918 - val_accuracy: 0.5191\n",
      "Epoch 41/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5200 - val_loss: 0.6914 - val_accuracy: 0.5192\n",
      "Epoch 42/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5204 - val_loss: 0.6915 - val_accuracy: 0.5189\n",
      "Epoch 43/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5220 - val_loss: 0.6916 - val_accuracy: 0.5193\n",
      "Epoch 44/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5202 - val_loss: 0.6913 - val_accuracy: 0.5192\n",
      "Epoch 45/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5207 - val_loss: 0.6917 - val_accuracy: 0.5187\n",
      "Epoch 46/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5210 - val_loss: 0.6915 - val_accuracy: 0.5211\n",
      "Epoch 47/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5201 - val_loss: 0.6918 - val_accuracy: 0.5194\n",
      "Epoch 48/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5220 - val_loss: 0.6916 - val_accuracy: 0.5196\n",
      "Epoch 49/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5228 - val_loss: 0.6916 - val_accuracy: 0.5185\n",
      "Training with significance = 3.15, run 9\n",
      "Train on 41356 samples, validate on 10340 samples\n",
      "Epoch 1/1000\n",
      "41356/41356 [==============================] - 1s 27us/sample - loss: 0.6959 - accuracy: 0.5045 - val_loss: 0.6935 - val_accuracy: 0.4932\n",
      "Epoch 2/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6927 - accuracy: 0.5071 - val_loss: 0.6932 - val_accuracy: 0.5098\n",
      "Epoch 3/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6925 - accuracy: 0.5126 - val_loss: 0.6924 - val_accuracy: 0.5109\n",
      "Epoch 4/1000\n",
      "41356/41356 [==============================] - 1s 14us/sample - loss: 0.6923 - accuracy: 0.5152 - val_loss: 0.6921 - val_accuracy: 0.5126\n",
      "Epoch 5/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5148 - val_loss: 0.6920 - val_accuracy: 0.5146\n",
      "Epoch 6/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5138 - val_loss: 0.6918 - val_accuracy: 0.5180\n",
      "Epoch 7/1000\n",
      "41356/41356 [==============================] - 1s 12us/sample - loss: 0.6922 - accuracy: 0.5170 - val_loss: 0.6919 - val_accuracy: 0.5146\n",
      "Epoch 8/1000\n",
      "41356/41356 [==============================] - 0s 12us/sample - loss: 0.6921 - accuracy: 0.5167 - val_loss: 0.6919 - val_accuracy: 0.5166\n",
      "Epoch 9/1000\n",
      "41356/41356 [==============================] - 1s 12us/sample - loss: 0.6920 - accuracy: 0.5160 - val_loss: 0.6920 - val_accuracy: 0.5140\n",
      "Epoch 10/1000\n",
      "41356/41356 [==============================] - 0s 12us/sample - loss: 0.6921 - accuracy: 0.5172 - val_loss: 0.6921 - val_accuracy: 0.5118\n",
      "Epoch 11/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5158 - val_loss: 0.6923 - val_accuracy: 0.5104\n",
      "Epoch 12/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5163 - val_loss: 0.6920 - val_accuracy: 0.5149\n",
      "Epoch 13/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5172 - val_loss: 0.6920 - val_accuracy: 0.5117\n",
      "Epoch 14/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5160 - val_loss: 0.6920 - val_accuracy: 0.5103\n",
      "Epoch 15/1000\n",
      "41356/41356 [==============================] - 1s 12us/sample - loss: 0.6919 - accuracy: 0.5179 - val_loss: 0.6919 - val_accuracy: 0.5156\n",
      "Epoch 16/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5171 - val_loss: 0.6918 - val_accuracy: 0.5136\n",
      "Epoch 17/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5181 - val_loss: 0.6920 - val_accuracy: 0.5099\n",
      "Epoch 18/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5166 - val_loss: 0.6920 - val_accuracy: 0.5144\n",
      "Epoch 19/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5179 - val_loss: 0.6919 - val_accuracy: 0.5151\n",
      "Epoch 20/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5183 - val_loss: 0.6919 - val_accuracy: 0.5121\n",
      "Epoch 21/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5179 - val_loss: 0.6919 - val_accuracy: 0.5092\n",
      "Epoch 22/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5174 - val_loss: 0.6919 - val_accuracy: 0.5126\n",
      "Epoch 23/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5188 - val_loss: 0.6918 - val_accuracy: 0.5148\n",
      "Epoch 24/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5170 - val_loss: 0.6919 - val_accuracy: 0.5136\n",
      "Epoch 25/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5189 - val_loss: 0.6923 - val_accuracy: 0.5025\n",
      "Epoch 26/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5178 - val_loss: 0.6919 - val_accuracy: 0.5162\n",
      "Epoch 27/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5181 - val_loss: 0.6918 - val_accuracy: 0.5157\n",
      "Epoch 28/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5181 - val_loss: 0.6919 - val_accuracy: 0.5110\n",
      "Epoch 29/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5186 - val_loss: 0.6919 - val_accuracy: 0.5162\n",
      "Epoch 30/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5172 - val_loss: 0.6918 - val_accuracy: 0.5168\n",
      "Epoch 31/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5208 - val_loss: 0.6918 - val_accuracy: 0.5174\n",
      "Epoch 32/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5183 - val_loss: 0.6919 - val_accuracy: 0.5147\n",
      "Epoch 33/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5184 - val_loss: 0.6919 - val_accuracy: 0.5146\n",
      "Epoch 34/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5176 - val_loss: 0.6919 - val_accuracy: 0.5125\n",
      "Epoch 35/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5183 - val_loss: 0.6923 - val_accuracy: 0.5082\n",
      "Epoch 36/1000\n",
      "41356/41356 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5197 - val_loss: 0.6919 - val_accuracy: 0.5158\n",
      "Training with significance = 3.78, run 0\n",
      "Train on 41457 samples, validate on 10365 samples\n",
      "Epoch 1/1000\n",
      "41457/41457 [==============================] - 1s 27us/sample - loss: 0.6931 - accuracy: 0.5085 - val_loss: 0.6941 - val_accuracy: 0.4975\n",
      "Epoch 2/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6925 - accuracy: 0.5117 - val_loss: 0.6929 - val_accuracy: 0.5074\n",
      "Epoch 3/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5157 - val_loss: 0.6930 - val_accuracy: 0.5087\n",
      "Epoch 4/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5136 - val_loss: 0.6926 - val_accuracy: 0.5143\n",
      "Epoch 5/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5142 - val_loss: 0.6924 - val_accuracy: 0.5156\n",
      "Epoch 6/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5143 - val_loss: 0.6922 - val_accuracy: 0.5161\n",
      "Epoch 7/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5174 - val_loss: 0.6922 - val_accuracy: 0.5150\n",
      "Epoch 8/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5147 - val_loss: 0.6921 - val_accuracy: 0.5168\n",
      "Epoch 9/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5156 - val_loss: 0.6921 - val_accuracy: 0.5155\n",
      "Epoch 10/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5164 - val_loss: 0.6921 - val_accuracy: 0.5141\n",
      "Epoch 11/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5157 - val_loss: 0.6921 - val_accuracy: 0.5142\n",
      "Epoch 12/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5167 - val_loss: 0.6921 - val_accuracy: 0.5177\n",
      "Epoch 13/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5175 - val_loss: 0.6921 - val_accuracy: 0.5169\n",
      "Epoch 14/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5173 - val_loss: 0.6921 - val_accuracy: 0.5158\n",
      "Epoch 15/1000\n",
      "41457/41457 [==============================] - 1s 12us/sample - loss: 0.6916 - accuracy: 0.5175 - val_loss: 0.6922 - val_accuracy: 0.5161\n",
      "Epoch 16/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5154 - val_loss: 0.6921 - val_accuracy: 0.5159\n",
      "Epoch 17/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5165 - val_loss: 0.6921 - val_accuracy: 0.5168\n",
      "Epoch 18/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5169 - val_loss: 0.6921 - val_accuracy: 0.5165\n",
      "Epoch 19/1000\n",
      "41457/41457 [==============================] - 1s 12us/sample - loss: 0.6916 - accuracy: 0.5163 - val_loss: 0.6922 - val_accuracy: 0.5125\n",
      "Epoch 20/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5175 - val_loss: 0.6920 - val_accuracy: 0.5157\n",
      "Epoch 21/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5177 - val_loss: 0.6920 - val_accuracy: 0.5177\n",
      "Epoch 22/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5182 - val_loss: 0.6920 - val_accuracy: 0.5153\n",
      "Epoch 23/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5183 - val_loss: 0.6922 - val_accuracy: 0.5140\n",
      "Epoch 24/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5183 - val_loss: 0.6921 - val_accuracy: 0.5174\n",
      "Epoch 25/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5189 - val_loss: 0.6920 - val_accuracy: 0.5173\n",
      "Epoch 26/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5177 - val_loss: 0.6921 - val_accuracy: 0.5142\n",
      "Epoch 27/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5180 - val_loss: 0.6920 - val_accuracy: 0.5156\n",
      "Epoch 28/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5185 - val_loss: 0.6923 - val_accuracy: 0.5144\n",
      "Epoch 29/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5194 - val_loss: 0.6920 - val_accuracy: 0.5154\n",
      "Epoch 30/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5176 - val_loss: 0.6921 - val_accuracy: 0.5157\n",
      "Epoch 31/1000\n",
      "41457/41457 [==============================] - 1s 12us/sample - loss: 0.6913 - accuracy: 0.5203 - val_loss: 0.6921 - val_accuracy: 0.5141\n",
      "Epoch 32/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5182 - val_loss: 0.6920 - val_accuracy: 0.5176\n",
      "Epoch 33/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5210 - val_loss: 0.6920 - val_accuracy: 0.5172\n",
      "Epoch 34/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5198 - val_loss: 0.6921 - val_accuracy: 0.5179\n",
      "Epoch 35/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5186 - val_loss: 0.6920 - val_accuracy: 0.5175\n",
      "Epoch 36/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5180 - val_loss: 0.6920 - val_accuracy: 0.5172\n",
      "Epoch 37/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5170 - val_loss: 0.6920 - val_accuracy: 0.5163\n",
      "Epoch 38/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5179 - val_loss: 0.6920 - val_accuracy: 0.5176\n",
      "Epoch 39/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5178 - val_loss: 0.6920 - val_accuracy: 0.5172\n",
      "Epoch 40/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5211 - val_loss: 0.6919 - val_accuracy: 0.5185\n",
      "Epoch 41/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5168 - val_loss: 0.6921 - val_accuracy: 0.5176\n",
      "Epoch 42/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5175 - val_loss: 0.6919 - val_accuracy: 0.5170\n",
      "Epoch 43/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5186 - val_loss: 0.6919 - val_accuracy: 0.5180\n",
      "Epoch 44/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5172 - val_loss: 0.6920 - val_accuracy: 0.5147\n",
      "Epoch 45/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5183 - val_loss: 0.6920 - val_accuracy: 0.5170\n",
      "Epoch 46/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5196 - val_loss: 0.6919 - val_accuracy: 0.5168\n",
      "Epoch 47/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5188 - val_loss: 0.6921 - val_accuracy: 0.5166\n",
      "Epoch 48/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5193 - val_loss: 0.6920 - val_accuracy: 0.5158\n",
      "Epoch 49/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5214 - val_loss: 0.6920 - val_accuracy: 0.5164\n",
      "Epoch 50/1000\n",
      "41457/41457 [==============================] - 1s 12us/sample - loss: 0.6912 - accuracy: 0.5192 - val_loss: 0.6920 - val_accuracy: 0.5177\n",
      "Epoch 51/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5179 - val_loss: 0.6921 - val_accuracy: 0.5163\n",
      "Epoch 52/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5203 - val_loss: 0.6923 - val_accuracy: 0.5070\n",
      "Epoch 53/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5204 - val_loss: 0.6920 - val_accuracy: 0.5158\n",
      "Epoch 54/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5223 - val_loss: 0.6919 - val_accuracy: 0.5178\n",
      "Epoch 55/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5219 - val_loss: 0.6920 - val_accuracy: 0.5168\n",
      "Epoch 56/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5200 - val_loss: 0.6920 - val_accuracy: 0.5166\n",
      "Epoch 57/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5176 - val_loss: 0.6920 - val_accuracy: 0.5187\n",
      "Epoch 58/1000\n",
      "41457/41457 [==============================] - 1s 12us/sample - loss: 0.6911 - accuracy: 0.5206 - val_loss: 0.6921 - val_accuracy: 0.5162\n",
      "Epoch 59/1000\n",
      "41457/41457 [==============================] - 1s 12us/sample - loss: 0.6911 - accuracy: 0.5219 - val_loss: 0.6920 - val_accuracy: 0.5184\n",
      "Epoch 60/1000\n",
      "41457/41457 [==============================] - 0s 12us/sample - loss: 0.6911 - accuracy: 0.5193 - val_loss: 0.6920 - val_accuracy: 0.5167\n",
      "Epoch 61/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5196 - val_loss: 0.6921 - val_accuracy: 0.5163\n",
      "Epoch 62/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5204 - val_loss: 0.6920 - val_accuracy: 0.5176\n",
      "Epoch 63/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5221 - val_loss: 0.6920 - val_accuracy: 0.5164\n",
      "Epoch 64/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5208 - val_loss: 0.6920 - val_accuracy: 0.5162\n",
      "Epoch 65/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5203 - val_loss: 0.6919 - val_accuracy: 0.5175\n",
      "Epoch 66/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5199 - val_loss: 0.6920 - val_accuracy: 0.5177\n",
      "Epoch 67/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5208 - val_loss: 0.6919 - val_accuracy: 0.5194\n",
      "Epoch 68/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5210 - val_loss: 0.6920 - val_accuracy: 0.5162\n",
      "Epoch 69/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5215 - val_loss: 0.6921 - val_accuracy: 0.5164\n",
      "Epoch 70/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5200 - val_loss: 0.6920 - val_accuracy: 0.5178\n",
      "Epoch 71/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5218 - val_loss: 0.6921 - val_accuracy: 0.5167\n",
      "Epoch 72/1000\n",
      "41457/41457 [==============================] - 1s 12us/sample - loss: 0.6909 - accuracy: 0.5216 - val_loss: 0.6920 - val_accuracy: 0.5186\n",
      "Epoch 73/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5217 - val_loss: 0.6921 - val_accuracy: 0.5155\n",
      "Epoch 74/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5215 - val_loss: 0.6920 - val_accuracy: 0.5186\n",
      "Epoch 75/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5240 - val_loss: 0.6921 - val_accuracy: 0.5159\n",
      "Epoch 76/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5184 - val_loss: 0.6921 - val_accuracy: 0.5164\n",
      "Epoch 77/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5239 - val_loss: 0.6922 - val_accuracy: 0.5130\n",
      "Epoch 78/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5209 - val_loss: 0.6920 - val_accuracy: 0.5177\n",
      "Epoch 79/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5215 - val_loss: 0.6920 - val_accuracy: 0.5169\n",
      "Epoch 80/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5238 - val_loss: 0.6921 - val_accuracy: 0.5154\n",
      "Epoch 81/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5196 - val_loss: 0.6921 - val_accuracy: 0.5145\n",
      "Epoch 82/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5218 - val_loss: 0.6920 - val_accuracy: 0.5174\n",
      "Epoch 83/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5219 - val_loss: 0.6920 - val_accuracy: 0.5169\n",
      "Epoch 84/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5198 - val_loss: 0.6921 - val_accuracy: 0.5163\n",
      "Epoch 85/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5225 - val_loss: 0.6921 - val_accuracy: 0.5167\n",
      "Epoch 86/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5221 - val_loss: 0.6920 - val_accuracy: 0.5178\n",
      "Epoch 87/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5233 - val_loss: 0.6920 - val_accuracy: 0.5188\n",
      "Epoch 88/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5229 - val_loss: 0.6921 - val_accuracy: 0.5178\n",
      "Epoch 89/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5223 - val_loss: 0.6921 - val_accuracy: 0.5193\n",
      "Epoch 90/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5249 - val_loss: 0.6921 - val_accuracy: 0.5182\n",
      "Epoch 91/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5230 - val_loss: 0.6922 - val_accuracy: 0.5107\n",
      "Epoch 92/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5221 - val_loss: 0.6921 - val_accuracy: 0.5189\n",
      "Epoch 93/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5231 - val_loss: 0.6920 - val_accuracy: 0.5186\n",
      "Epoch 94/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5231 - val_loss: 0.6921 - val_accuracy: 0.5160\n",
      "Epoch 95/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5235 - val_loss: 0.6922 - val_accuracy: 0.5139\n",
      "Epoch 96/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5207 - val_loss: 0.6920 - val_accuracy: 0.5168\n",
      "Epoch 97/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5220 - val_loss: 0.6921 - val_accuracy: 0.5154\n",
      "Training with significance = 3.78, run 1\n",
      "Train on 41457 samples, validate on 10365 samples\n",
      "Epoch 1/1000\n",
      "41457/41457 [==============================] - 1s 27us/sample - loss: 0.6932 - accuracy: 0.5033 - val_loss: 0.6933 - val_accuracy: 0.4965\n",
      "Epoch 2/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6925 - accuracy: 0.5128 - val_loss: 0.6929 - val_accuracy: 0.5094\n",
      "Epoch 3/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5149 - val_loss: 0.6921 - val_accuracy: 0.5182\n",
      "Epoch 4/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5139 - val_loss: 0.6919 - val_accuracy: 0.5200\n",
      "Epoch 5/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5169 - val_loss: 0.6918 - val_accuracy: 0.5190\n",
      "Epoch 6/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5194 - val_loss: 0.6917 - val_accuracy: 0.5206\n",
      "Epoch 7/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5188 - val_loss: 0.6916 - val_accuracy: 0.5218\n",
      "Epoch 8/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5182 - val_loss: 0.6916 - val_accuracy: 0.5188\n",
      "Epoch 9/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5189 - val_loss: 0.6915 - val_accuracy: 0.5190\n",
      "Epoch 10/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5188 - val_loss: 0.6916 - val_accuracy: 0.5157\n",
      "Epoch 11/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5178 - val_loss: 0.6915 - val_accuracy: 0.5164\n",
      "Epoch 12/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5200 - val_loss: 0.6914 - val_accuracy: 0.5208\n",
      "Epoch 13/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5206 - val_loss: 0.6915 - val_accuracy: 0.5209\n",
      "Epoch 14/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5196 - val_loss: 0.6914 - val_accuracy: 0.5192\n",
      "Epoch 15/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5186 - val_loss: 0.6915 - val_accuracy: 0.5222\n",
      "Epoch 16/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5195 - val_loss: 0.6914 - val_accuracy: 0.5214\n",
      "Epoch 17/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5204 - val_loss: 0.6914 - val_accuracy: 0.5223\n",
      "Epoch 18/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5212 - val_loss: 0.6914 - val_accuracy: 0.5222\n",
      "Epoch 19/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5196 - val_loss: 0.6914 - val_accuracy: 0.5206\n",
      "Epoch 20/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5202 - val_loss: 0.6916 - val_accuracy: 0.5136\n",
      "Epoch 21/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5223 - val_loss: 0.6913 - val_accuracy: 0.5213\n",
      "Epoch 22/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5191 - val_loss: 0.6915 - val_accuracy: 0.5208\n",
      "Epoch 23/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5209 - val_loss: 0.6914 - val_accuracy: 0.5209\n",
      "Epoch 24/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5200 - val_loss: 0.6914 - val_accuracy: 0.5213\n",
      "Epoch 25/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5216 - val_loss: 0.6913 - val_accuracy: 0.5209\n",
      "Epoch 26/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5208 - val_loss: 0.6913 - val_accuracy: 0.5203\n",
      "Epoch 27/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5211 - val_loss: 0.6913 - val_accuracy: 0.5203\n",
      "Epoch 28/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5203 - val_loss: 0.6914 - val_accuracy: 0.5188\n",
      "Epoch 29/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5219 - val_loss: 0.6913 - val_accuracy: 0.5196\n",
      "Epoch 30/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5212 - val_loss: 0.6914 - val_accuracy: 0.5197\n",
      "Epoch 31/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5201 - val_loss: 0.6914 - val_accuracy: 0.5210\n",
      "Epoch 32/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5213 - val_loss: 0.6913 - val_accuracy: 0.5191\n",
      "Epoch 33/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5204 - val_loss: 0.6913 - val_accuracy: 0.5184\n",
      "Epoch 34/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5211 - val_loss: 0.6913 - val_accuracy: 0.5196\n",
      "Epoch 35/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5211 - val_loss: 0.6913 - val_accuracy: 0.5213\n",
      "Epoch 36/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5195 - val_loss: 0.6914 - val_accuracy: 0.5203\n",
      "Epoch 37/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5211 - val_loss: 0.6913 - val_accuracy: 0.5202\n",
      "Epoch 38/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5212 - val_loss: 0.6912 - val_accuracy: 0.5188\n",
      "Epoch 39/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5219 - val_loss: 0.6913 - val_accuracy: 0.5198\n",
      "Epoch 40/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5209 - val_loss: 0.6912 - val_accuracy: 0.5204\n",
      "Epoch 41/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5212 - val_loss: 0.6913 - val_accuracy: 0.5207\n",
      "Epoch 42/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5250 - val_loss: 0.6917 - val_accuracy: 0.5187\n",
      "Epoch 43/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5221 - val_loss: 0.6914 - val_accuracy: 0.5164\n",
      "Epoch 44/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5218 - val_loss: 0.6913 - val_accuracy: 0.5171\n",
      "Epoch 45/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5232 - val_loss: 0.6913 - val_accuracy: 0.5161\n",
      "Epoch 46/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5234 - val_loss: 0.6913 - val_accuracy: 0.5182\n",
      "Epoch 47/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5219 - val_loss: 0.6912 - val_accuracy: 0.5168\n",
      "Epoch 48/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5225 - val_loss: 0.6913 - val_accuracy: 0.5162\n",
      "Epoch 49/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5207 - val_loss: 0.6914 - val_accuracy: 0.5154\n",
      "Epoch 50/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5232 - val_loss: 0.6913 - val_accuracy: 0.5187\n",
      "Epoch 51/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5221 - val_loss: 0.6913 - val_accuracy: 0.5219\n",
      "Epoch 52/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5222 - val_loss: 0.6912 - val_accuracy: 0.5173\n",
      "Epoch 53/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5212 - val_loss: 0.6912 - val_accuracy: 0.5201\n",
      "Epoch 54/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5200 - val_loss: 0.6913 - val_accuracy: 0.5180\n",
      "Epoch 55/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5225 - val_loss: 0.6913 - val_accuracy: 0.5169\n",
      "Epoch 56/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5206 - val_loss: 0.6912 - val_accuracy: 0.5182\n",
      "Epoch 57/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5234 - val_loss: 0.6913 - val_accuracy: 0.5204\n",
      "Epoch 58/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5229 - val_loss: 0.6913 - val_accuracy: 0.5211\n",
      "Epoch 59/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5229 - val_loss: 0.6913 - val_accuracy: 0.5157\n",
      "Epoch 60/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5233 - val_loss: 0.6913 - val_accuracy: 0.5156\n",
      "Epoch 61/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5235 - val_loss: 0.6913 - val_accuracy: 0.5175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5237 - val_loss: 0.6913 - val_accuracy: 0.5169\n",
      "Epoch 63/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5202 - val_loss: 0.6913 - val_accuracy: 0.5147\n",
      "Epoch 64/1000\n",
      "41457/41457 [==============================] - 1s 12us/sample - loss: 0.6909 - accuracy: 0.5230 - val_loss: 0.6912 - val_accuracy: 0.5176\n",
      "Epoch 65/1000\n",
      "41457/41457 [==============================] - 1s 12us/sample - loss: 0.6909 - accuracy: 0.5223 - val_loss: 0.6915 - val_accuracy: 0.5183\n",
      "Epoch 66/1000\n",
      "41457/41457 [==============================] - 1s 12us/sample - loss: 0.6909 - accuracy: 0.5225 - val_loss: 0.6913 - val_accuracy: 0.5172\n",
      "Epoch 67/1000\n",
      "41457/41457 [==============================] - 0s 12us/sample - loss: 0.6910 - accuracy: 0.5229 - val_loss: 0.6913 - val_accuracy: 0.5172\n",
      "Epoch 68/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5237 - val_loss: 0.6912 - val_accuracy: 0.5169\n",
      "Epoch 69/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5243 - val_loss: 0.6912 - val_accuracy: 0.5165\n",
      "Epoch 70/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5223 - val_loss: 0.6913 - val_accuracy: 0.5185\n",
      "Epoch 71/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5239 - val_loss: 0.6914 - val_accuracy: 0.5205\n",
      "Epoch 72/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5216 - val_loss: 0.6914 - val_accuracy: 0.5184\n",
      "Epoch 73/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5223 - val_loss: 0.6914 - val_accuracy: 0.5182\n",
      "Epoch 74/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5234 - val_loss: 0.6914 - val_accuracy: 0.5138\n",
      "Epoch 75/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5209 - val_loss: 0.6914 - val_accuracy: 0.5139\n",
      "Epoch 76/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5227 - val_loss: 0.6913 - val_accuracy: 0.5135\n",
      "Epoch 77/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5228 - val_loss: 0.6914 - val_accuracy: 0.5172\n",
      "Epoch 78/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5250 - val_loss: 0.6913 - val_accuracy: 0.5146\n",
      "Epoch 79/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5228 - val_loss: 0.6913 - val_accuracy: 0.5193\n",
      "Epoch 80/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5225 - val_loss: 0.6913 - val_accuracy: 0.5178\n",
      "Epoch 81/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5236 - val_loss: 0.6913 - val_accuracy: 0.5154\n",
      "Epoch 82/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5220 - val_loss: 0.6913 - val_accuracy: 0.5185\n",
      "Epoch 83/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5236 - val_loss: 0.6913 - val_accuracy: 0.5186\n",
      "Epoch 84/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5233 - val_loss: 0.6912 - val_accuracy: 0.5167\n",
      "Epoch 85/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5252 - val_loss: 0.6913 - val_accuracy: 0.5190\n",
      "Epoch 86/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5234 - val_loss: 0.6912 - val_accuracy: 0.5159\n",
      "Epoch 87/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5243 - val_loss: 0.6913 - val_accuracy: 0.5180\n",
      "Epoch 88/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5253 - val_loss: 0.6912 - val_accuracy: 0.5162\n",
      "Epoch 89/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5236 - val_loss: 0.6912 - val_accuracy: 0.5156\n",
      "Epoch 90/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5238 - val_loss: 0.6913 - val_accuracy: 0.5174\n",
      "Epoch 91/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5226 - val_loss: 0.6913 - val_accuracy: 0.5178\n",
      "Epoch 92/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5208 - val_loss: 0.6913 - val_accuracy: 0.5175\n",
      "Epoch 93/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5246 - val_loss: 0.6912 - val_accuracy: 0.5161\n",
      "Epoch 94/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5236 - val_loss: 0.6912 - val_accuracy: 0.5183\n",
      "Epoch 95/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5245 - val_loss: 0.6912 - val_accuracy: 0.5167\n",
      "Epoch 96/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5242 - val_loss: 0.6912 - val_accuracy: 0.5172\n",
      "Epoch 97/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5231 - val_loss: 0.6913 - val_accuracy: 0.5166\n",
      "Epoch 98/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5235 - val_loss: 0.6913 - val_accuracy: 0.5158\n",
      "Epoch 99/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5229 - val_loss: 0.6913 - val_accuracy: 0.5153\n",
      "Epoch 100/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5227 - val_loss: 0.6912 - val_accuracy: 0.5181\n",
      "Epoch 101/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5238 - val_loss: 0.6913 - val_accuracy: 0.5182\n",
      "Epoch 102/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5227 - val_loss: 0.6915 - val_accuracy: 0.5221\n",
      "Epoch 103/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5238 - val_loss: 0.6913 - val_accuracy: 0.5145\n",
      "Epoch 104/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5242 - val_loss: 0.6913 - val_accuracy: 0.5189\n",
      "Epoch 105/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5249 - val_loss: 0.6912 - val_accuracy: 0.5156\n",
      "Epoch 106/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5224 - val_loss: 0.6912 - val_accuracy: 0.5165\n",
      "Epoch 107/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5238 - val_loss: 0.6914 - val_accuracy: 0.5199\n",
      "Epoch 108/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5262 - val_loss: 0.6913 - val_accuracy: 0.5188\n",
      "Epoch 109/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5218 - val_loss: 0.6912 - val_accuracy: 0.5198\n",
      "Epoch 110/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5242 - val_loss: 0.6913 - val_accuracy: 0.5148\n",
      "Epoch 111/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5242 - val_loss: 0.6913 - val_accuracy: 0.5175\n",
      "Epoch 112/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5240 - val_loss: 0.6913 - val_accuracy: 0.5152\n",
      "Epoch 113/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5256 - val_loss: 0.6912 - val_accuracy: 0.5180\n",
      "Epoch 114/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5226 - val_loss: 0.6913 - val_accuracy: 0.5122\n",
      "Epoch 115/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5242 - val_loss: 0.6914 - val_accuracy: 0.5193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5231 - val_loss: 0.6913 - val_accuracy: 0.5185\n",
      "Epoch 117/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5250 - val_loss: 0.6915 - val_accuracy: 0.5152\n",
      "Epoch 118/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5239 - val_loss: 0.6913 - val_accuracy: 0.5189\n",
      "Epoch 119/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5237 - val_loss: 0.6914 - val_accuracy: 0.5187\n",
      "Epoch 120/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5243 - val_loss: 0.6913 - val_accuracy: 0.5171\n",
      "Epoch 121/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5246 - val_loss: 0.6913 - val_accuracy: 0.5166\n",
      "Epoch 122/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5248 - val_loss: 0.6912 - val_accuracy: 0.5161\n",
      "Epoch 123/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5241 - val_loss: 0.6913 - val_accuracy: 0.5198\n",
      "Epoch 124/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5236 - val_loss: 0.6913 - val_accuracy: 0.5167\n",
      "Training with significance = 3.78, run 2\n",
      "Train on 41457 samples, validate on 10365 samples\n",
      "Epoch 1/1000\n",
      "41457/41457 [==============================] - 1s 27us/sample - loss: 0.6955 - accuracy: 0.5018 - val_loss: 0.6928 - val_accuracy: 0.5126\n",
      "Epoch 2/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6925 - accuracy: 0.5181 - val_loss: 0.6928 - val_accuracy: 0.5116\n",
      "Epoch 3/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5160 - val_loss: 0.6925 - val_accuracy: 0.5146\n",
      "Epoch 4/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5162 - val_loss: 0.6923 - val_accuracy: 0.5132\n",
      "Epoch 5/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5170 - val_loss: 0.6923 - val_accuracy: 0.5147\n",
      "Epoch 6/1000\n",
      "41457/41457 [==============================] - 1s 12us/sample - loss: 0.6920 - accuracy: 0.5167 - val_loss: 0.6923 - val_accuracy: 0.5120\n",
      "Epoch 7/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5177 - val_loss: 0.6922 - val_accuracy: 0.5154\n",
      "Epoch 8/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5165 - val_loss: 0.6924 - val_accuracy: 0.5147\n",
      "Epoch 9/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5199 - val_loss: 0.6923 - val_accuracy: 0.5144\n",
      "Epoch 10/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5195 - val_loss: 0.6924 - val_accuracy: 0.5164\n",
      "Epoch 11/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5199 - val_loss: 0.6922 - val_accuracy: 0.5153\n",
      "Epoch 12/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5172 - val_loss: 0.6923 - val_accuracy: 0.5156\n",
      "Epoch 13/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5175 - val_loss: 0.6922 - val_accuracy: 0.5163\n",
      "Epoch 14/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5179 - val_loss: 0.6923 - val_accuracy: 0.5142\n",
      "Epoch 15/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5204 - val_loss: 0.6921 - val_accuracy: 0.5168\n",
      "Epoch 16/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5194 - val_loss: 0.6922 - val_accuracy: 0.5166\n",
      "Epoch 17/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5185 - val_loss: 0.6922 - val_accuracy: 0.5153\n",
      "Epoch 18/1000\n",
      "41457/41457 [==============================] - 1s 12us/sample - loss: 0.6916 - accuracy: 0.5192 - val_loss: 0.6922 - val_accuracy: 0.5168\n",
      "Epoch 19/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5202 - val_loss: 0.6921 - val_accuracy: 0.5174\n",
      "Epoch 20/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5187 - val_loss: 0.6922 - val_accuracy: 0.5142\n",
      "Epoch 21/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5209 - val_loss: 0.6923 - val_accuracy: 0.5150\n",
      "Epoch 22/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5194 - val_loss: 0.6924 - val_accuracy: 0.5156\n",
      "Epoch 23/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5221 - val_loss: 0.6924 - val_accuracy: 0.5166\n",
      "Epoch 24/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5205 - val_loss: 0.6922 - val_accuracy: 0.5146\n",
      "Epoch 25/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5200 - val_loss: 0.6923 - val_accuracy: 0.5153\n",
      "Epoch 26/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5200 - val_loss: 0.6922 - val_accuracy: 0.5167\n",
      "Epoch 27/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5206 - val_loss: 0.6923 - val_accuracy: 0.5153\n",
      "Epoch 28/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5195 - val_loss: 0.6922 - val_accuracy: 0.5137\n",
      "Epoch 29/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5210 - val_loss: 0.6922 - val_accuracy: 0.5155\n",
      "Epoch 30/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5197 - val_loss: 0.6924 - val_accuracy: 0.5105\n",
      "Epoch 31/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5204 - val_loss: 0.6923 - val_accuracy: 0.5138\n",
      "Epoch 32/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5204 - val_loss: 0.6922 - val_accuracy: 0.5157\n",
      "Epoch 33/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5220 - val_loss: 0.6922 - val_accuracy: 0.5147\n",
      "Epoch 34/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5220 - val_loss: 0.6922 - val_accuracy: 0.5146\n",
      "Epoch 35/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5207 - val_loss: 0.6923 - val_accuracy: 0.5145\n",
      "Epoch 36/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5219 - val_loss: 0.6922 - val_accuracy: 0.5132\n",
      "Epoch 37/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5215 - val_loss: 0.6927 - val_accuracy: 0.5163\n",
      "Epoch 38/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5202 - val_loss: 0.6923 - val_accuracy: 0.5151\n",
      "Epoch 39/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5203 - val_loss: 0.6923 - val_accuracy: 0.5140\n",
      "Epoch 40/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5207 - val_loss: 0.6923 - val_accuracy: 0.5127\n",
      "Epoch 41/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5210 - val_loss: 0.6924 - val_accuracy: 0.5144\n",
      "Epoch 42/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5197 - val_loss: 0.6922 - val_accuracy: 0.5142\n",
      "Epoch 43/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5222 - val_loss: 0.6925 - val_accuracy: 0.5125\n",
      "Epoch 44/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5192 - val_loss: 0.6924 - val_accuracy: 0.5146\n",
      "Epoch 45/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5223 - val_loss: 0.6924 - val_accuracy: 0.5147\n",
      "Training with significance = 3.78, run 3\n",
      "Train on 41457 samples, validate on 10365 samples\n",
      "Epoch 1/1000\n",
      "41457/41457 [==============================] - 1s 28us/sample - loss: 0.6934 - accuracy: 0.5048 - val_loss: 0.6938 - val_accuracy: 0.4956\n",
      "Epoch 2/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6926 - accuracy: 0.5113 - val_loss: 0.6930 - val_accuracy: 0.5093\n",
      "Epoch 3/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5119 - val_loss: 0.6925 - val_accuracy: 0.5133\n",
      "Epoch 4/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5161 - val_loss: 0.6924 - val_accuracy: 0.5130\n",
      "Epoch 5/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5149 - val_loss: 0.6923 - val_accuracy: 0.5128\n",
      "Epoch 6/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5139 - val_loss: 0.6923 - val_accuracy: 0.5136\n",
      "Epoch 7/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5154 - val_loss: 0.6924 - val_accuracy: 0.5162\n",
      "Epoch 8/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5145 - val_loss: 0.6924 - val_accuracy: 0.5134\n",
      "Epoch 9/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5149 - val_loss: 0.6923 - val_accuracy: 0.5148\n",
      "Epoch 10/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5179 - val_loss: 0.6924 - val_accuracy: 0.5146\n",
      "Epoch 11/1000\n",
      "41457/41457 [==============================] - 1s 12us/sample - loss: 0.6916 - accuracy: 0.5175 - val_loss: 0.6924 - val_accuracy: 0.5135\n",
      "Epoch 12/1000\n",
      "41457/41457 [==============================] - 1s 12us/sample - loss: 0.6915 - accuracy: 0.5172 - val_loss: 0.6924 - val_accuracy: 0.5140\n",
      "Epoch 13/1000\n",
      "41457/41457 [==============================] - 0s 11us/sample - loss: 0.6915 - accuracy: 0.5173 - val_loss: 0.6924 - val_accuracy: 0.5144\n",
      "Epoch 14/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5175 - val_loss: 0.6923 - val_accuracy: 0.5148\n",
      "Epoch 15/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5156 - val_loss: 0.6923 - val_accuracy: 0.5137\n",
      "Epoch 16/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5192 - val_loss: 0.6923 - val_accuracy: 0.5153\n",
      "Epoch 17/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5192 - val_loss: 0.6924 - val_accuracy: 0.5140\n",
      "Epoch 18/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5192 - val_loss: 0.6924 - val_accuracy: 0.5141\n",
      "Epoch 19/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5190 - val_loss: 0.6924 - val_accuracy: 0.5145\n",
      "Epoch 20/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5182 - val_loss: 0.6925 - val_accuracy: 0.5124\n",
      "Epoch 21/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5177 - val_loss: 0.6924 - val_accuracy: 0.5139\n",
      "Epoch 22/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5183 - val_loss: 0.6926 - val_accuracy: 0.5139\n",
      "Epoch 23/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5209 - val_loss: 0.6923 - val_accuracy: 0.5149\n",
      "Epoch 24/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5180 - val_loss: 0.6926 - val_accuracy: 0.5124\n",
      "Epoch 25/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5176 - val_loss: 0.6924 - val_accuracy: 0.5140\n",
      "Epoch 26/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5186 - val_loss: 0.6924 - val_accuracy: 0.5123\n",
      "Epoch 27/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5208 - val_loss: 0.6924 - val_accuracy: 0.5108\n",
      "Epoch 28/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5194 - val_loss: 0.6926 - val_accuracy: 0.5113\n",
      "Epoch 29/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5192 - val_loss: 0.6924 - val_accuracy: 0.5117\n",
      "Epoch 30/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5195 - val_loss: 0.6925 - val_accuracy: 0.5128\n",
      "Epoch 31/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5197 - val_loss: 0.6925 - val_accuracy: 0.5110\n",
      "Epoch 32/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5212 - val_loss: 0.6924 - val_accuracy: 0.5115\n",
      "Epoch 33/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5201 - val_loss: 0.6925 - val_accuracy: 0.5140\n",
      "Epoch 34/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5207 - val_loss: 0.6926 - val_accuracy: 0.5156\n",
      "Epoch 35/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5211 - val_loss: 0.6924 - val_accuracy: 0.5150\n",
      "Epoch 36/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5200 - val_loss: 0.6924 - val_accuracy: 0.5131\n",
      "Epoch 37/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5207 - val_loss: 0.6925 - val_accuracy: 0.5109\n",
      "Epoch 38/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5214 - val_loss: 0.6926 - val_accuracy: 0.5093\n",
      "Epoch 39/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5205 - val_loss: 0.6927 - val_accuracy: 0.5137\n",
      "Epoch 40/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5182 - val_loss: 0.6924 - val_accuracy: 0.5176\n",
      "Epoch 41/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5211 - val_loss: 0.6925 - val_accuracy: 0.5099\n",
      "Epoch 42/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5217 - val_loss: 0.6928 - val_accuracy: 0.5098\n",
      "Epoch 43/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5216 - val_loss: 0.6925 - val_accuracy: 0.5099\n",
      "Epoch 44/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5191 - val_loss: 0.6926 - val_accuracy: 0.5155\n",
      "Epoch 45/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5219 - val_loss: 0.6925 - val_accuracy: 0.5124\n",
      "Epoch 46/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5208 - val_loss: 0.6925 - val_accuracy: 0.5131\n",
      "Training with significance = 3.78, run 4\n",
      "Train on 41457 samples, validate on 10365 samples\n",
      "Epoch 1/1000\n",
      "41457/41457 [==============================] - 1s 27us/sample - loss: 0.6927 - accuracy: 0.5124 - val_loss: 0.6942 - val_accuracy: 0.4991\n",
      "Epoch 2/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5150 - val_loss: 0.6930 - val_accuracy: 0.5154\n",
      "Epoch 3/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5175 - val_loss: 0.6928 - val_accuracy: 0.5092\n",
      "Epoch 4/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5179 - val_loss: 0.6926 - val_accuracy: 0.5061\n",
      "Epoch 5/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5184 - val_loss: 0.6923 - val_accuracy: 0.5077\n",
      "Epoch 6/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5184 - val_loss: 0.6923 - val_accuracy: 0.5083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5189 - val_loss: 0.6922 - val_accuracy: 0.5134\n",
      "Epoch 8/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5185 - val_loss: 0.6924 - val_accuracy: 0.5141\n",
      "Epoch 9/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5192 - val_loss: 0.6924 - val_accuracy: 0.5141\n",
      "Epoch 10/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5201 - val_loss: 0.6922 - val_accuracy: 0.5109\n",
      "Epoch 11/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5195 - val_loss: 0.6921 - val_accuracy: 0.5134\n",
      "Epoch 12/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5202 - val_loss: 0.6922 - val_accuracy: 0.5137\n",
      "Epoch 13/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5197 - val_loss: 0.6924 - val_accuracy: 0.5175\n",
      "Epoch 14/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5210 - val_loss: 0.6922 - val_accuracy: 0.5154\n",
      "Epoch 15/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5193 - val_loss: 0.6924 - val_accuracy: 0.5170\n",
      "Epoch 16/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5198 - val_loss: 0.6921 - val_accuracy: 0.5125\n",
      "Epoch 17/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5203 - val_loss: 0.6923 - val_accuracy: 0.5156\n",
      "Epoch 18/1000\n",
      "41457/41457 [==============================] - 1s 12us/sample - loss: 0.6910 - accuracy: 0.5213 - val_loss: 0.6922 - val_accuracy: 0.5149\n",
      "Epoch 19/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5200 - val_loss: 0.6921 - val_accuracy: 0.5125\n",
      "Epoch 20/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5215 - val_loss: 0.6924 - val_accuracy: 0.5147\n",
      "Epoch 21/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5213 - val_loss: 0.6920 - val_accuracy: 0.5140\n",
      "Epoch 22/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5201 - val_loss: 0.6922 - val_accuracy: 0.5167\n",
      "Epoch 23/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5219 - val_loss: 0.6921 - val_accuracy: 0.5146\n",
      "Epoch 24/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5227 - val_loss: 0.6921 - val_accuracy: 0.5139\n",
      "Epoch 25/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5216 - val_loss: 0.6922 - val_accuracy: 0.5135\n",
      "Epoch 26/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5205 - val_loss: 0.6922 - val_accuracy: 0.5165\n",
      "Epoch 27/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5203 - val_loss: 0.6921 - val_accuracy: 0.5169\n",
      "Epoch 28/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5218 - val_loss: 0.6922 - val_accuracy: 0.5147\n",
      "Epoch 29/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5215 - val_loss: 0.6920 - val_accuracy: 0.5152\n",
      "Epoch 30/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5230 - val_loss: 0.6920 - val_accuracy: 0.5133\n",
      "Epoch 31/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5220 - val_loss: 0.6920 - val_accuracy: 0.5128\n",
      "Epoch 32/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5232 - val_loss: 0.6921 - val_accuracy: 0.5131\n",
      "Epoch 33/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5219 - val_loss: 0.6921 - val_accuracy: 0.5149\n",
      "Epoch 34/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5230 - val_loss: 0.6921 - val_accuracy: 0.5123\n",
      "Epoch 35/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5221 - val_loss: 0.6922 - val_accuracy: 0.5154\n",
      "Epoch 36/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5232 - val_loss: 0.6921 - val_accuracy: 0.5145\n",
      "Epoch 37/1000\n",
      "41457/41457 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5231 - val_loss: 0.6921 - val_accuracy: 0.5127\n",
      "Epoch 38/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5211 - val_loss: 0.6922 - val_accuracy: 0.5148\n",
      "Epoch 39/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5230 - val_loss: 0.6921 - val_accuracy: 0.5160\n",
      "Epoch 40/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5221 - val_loss: 0.6921 - val_accuracy: 0.5147\n",
      "Epoch 41/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5214 - val_loss: 0.6920 - val_accuracy: 0.5152\n",
      "Epoch 42/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5222 - val_loss: 0.6921 - val_accuracy: 0.5129\n",
      "Epoch 43/1000\n",
      "41457/41457 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5225 - val_loss: 0.6921 - val_accuracy: 0.5164\n",
      "Epoch 44/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5237 - val_loss: 0.6922 - val_accuracy: 0.5161\n",
      "Epoch 45/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5236 - val_loss: 0.6922 - val_accuracy: 0.5164\n",
      "Epoch 46/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5221 - val_loss: 0.6922 - val_accuracy: 0.5164\n",
      "Epoch 47/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5239 - val_loss: 0.6921 - val_accuracy: 0.5151\n",
      "Epoch 48/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5250 - val_loss: 0.6922 - val_accuracy: 0.5165\n",
      "Epoch 49/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5221 - val_loss: 0.6923 - val_accuracy: 0.5186\n",
      "Epoch 50/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5231 - val_loss: 0.6922 - val_accuracy: 0.5152\n",
      "Epoch 51/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5234 - val_loss: 0.6922 - val_accuracy: 0.5128\n",
      "Epoch 52/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5244 - val_loss: 0.6924 - val_accuracy: 0.5175\n",
      "Epoch 53/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5242 - val_loss: 0.6922 - val_accuracy: 0.5173\n",
      "Epoch 54/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5225 - val_loss: 0.6922 - val_accuracy: 0.5147\n",
      "Epoch 55/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5230 - val_loss: 0.6923 - val_accuracy: 0.5174\n",
      "Epoch 56/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5227 - val_loss: 0.6921 - val_accuracy: 0.5158\n",
      "Epoch 57/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5235 - val_loss: 0.6922 - val_accuracy: 0.5154\n",
      "Epoch 58/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5256 - val_loss: 0.6923 - val_accuracy: 0.5156\n",
      "Epoch 59/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5236 - val_loss: 0.6922 - val_accuracy: 0.5137\n",
      "Epoch 60/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5239 - val_loss: 0.6922 - val_accuracy: 0.5125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with significance = 3.78, run 5\n",
      "Train on 41457 samples, validate on 10365 samples\n",
      "Epoch 1/1000\n",
      "41457/41457 [==============================] - 1s 28us/sample - loss: 0.6928 - accuracy: 0.5063 - val_loss: 0.6940 - val_accuracy: 0.5043\n",
      "Epoch 2/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5124 - val_loss: 0.6935 - val_accuracy: 0.5095\n",
      "Epoch 3/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5104 - val_loss: 0.6925 - val_accuracy: 0.5156\n",
      "Epoch 4/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5139 - val_loss: 0.6922 - val_accuracy: 0.5143\n",
      "Epoch 5/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5138 - val_loss: 0.6921 - val_accuracy: 0.5192\n",
      "Epoch 6/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5163 - val_loss: 0.6921 - val_accuracy: 0.5160\n",
      "Epoch 7/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5172 - val_loss: 0.6919 - val_accuracy: 0.5162\n",
      "Epoch 8/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5153 - val_loss: 0.6921 - val_accuracy: 0.5150\n",
      "Epoch 9/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5178 - val_loss: 0.6919 - val_accuracy: 0.5156\n",
      "Epoch 10/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5175 - val_loss: 0.6921 - val_accuracy: 0.5147\n",
      "Epoch 11/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5191 - val_loss: 0.6921 - val_accuracy: 0.5134\n",
      "Epoch 12/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5170 - val_loss: 0.6921 - val_accuracy: 0.5153\n",
      "Epoch 13/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5191 - val_loss: 0.6920 - val_accuracy: 0.5144\n",
      "Epoch 14/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5196 - val_loss: 0.6920 - val_accuracy: 0.5145\n",
      "Epoch 15/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5185 - val_loss: 0.6920 - val_accuracy: 0.5147\n",
      "Epoch 16/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5198 - val_loss: 0.6920 - val_accuracy: 0.5167\n",
      "Epoch 17/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5180 - val_loss: 0.6921 - val_accuracy: 0.5169\n",
      "Epoch 18/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5189 - val_loss: 0.6919 - val_accuracy: 0.5189\n",
      "Epoch 19/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5210 - val_loss: 0.6921 - val_accuracy: 0.5159\n",
      "Epoch 20/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5206 - val_loss: 0.6920 - val_accuracy: 0.5165\n",
      "Epoch 21/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5216 - val_loss: 0.6920 - val_accuracy: 0.5137\n",
      "Epoch 22/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5189 - val_loss: 0.6919 - val_accuracy: 0.5156\n",
      "Epoch 23/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5209 - val_loss: 0.6919 - val_accuracy: 0.5159\n",
      "Epoch 24/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5210 - val_loss: 0.6919 - val_accuracy: 0.5174\n",
      "Epoch 25/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5210 - val_loss: 0.6919 - val_accuracy: 0.5158\n",
      "Epoch 26/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5201 - val_loss: 0.6919 - val_accuracy: 0.5153\n",
      "Epoch 27/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5212 - val_loss: 0.6920 - val_accuracy: 0.5138\n",
      "Epoch 28/1000\n",
      "41457/41457 [==============================] - 1s 12us/sample - loss: 0.6911 - accuracy: 0.5234 - val_loss: 0.6919 - val_accuracy: 0.5162\n",
      "Epoch 29/1000\n",
      "41457/41457 [==============================] - 1s 12us/sample - loss: 0.6911 - accuracy: 0.5215 - val_loss: 0.6919 - val_accuracy: 0.5183\n",
      "Epoch 30/1000\n",
      "41457/41457 [==============================] - 0s 12us/sample - loss: 0.6913 - accuracy: 0.5208 - val_loss: 0.6919 - val_accuracy: 0.5148\n",
      "Epoch 31/1000\n",
      "41457/41457 [==============================] - 1s 12us/sample - loss: 0.6911 - accuracy: 0.5215 - val_loss: 0.6920 - val_accuracy: 0.5175\n",
      "Epoch 32/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5202 - val_loss: 0.6920 - val_accuracy: 0.5161\n",
      "Epoch 33/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5210 - val_loss: 0.6920 - val_accuracy: 0.5135\n",
      "Epoch 34/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5218 - val_loss: 0.6921 - val_accuracy: 0.5126\n",
      "Epoch 35/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5211 - val_loss: 0.6920 - val_accuracy: 0.5188\n",
      "Epoch 36/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5208 - val_loss: 0.6920 - val_accuracy: 0.5177\n",
      "Epoch 37/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5220 - val_loss: 0.6919 - val_accuracy: 0.5171\n",
      "Epoch 38/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5224 - val_loss: 0.6923 - val_accuracy: 0.5141\n",
      "Epoch 39/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5219 - val_loss: 0.6919 - val_accuracy: 0.5208\n",
      "Epoch 40/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5227 - val_loss: 0.6919 - val_accuracy: 0.5130\n",
      "Epoch 41/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5221 - val_loss: 0.6919 - val_accuracy: 0.5137\n",
      "Epoch 42/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5214 - val_loss: 0.6918 - val_accuracy: 0.5196\n",
      "Epoch 43/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5221 - val_loss: 0.6922 - val_accuracy: 0.5061\n",
      "Epoch 44/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5246 - val_loss: 0.6921 - val_accuracy: 0.5145\n",
      "Epoch 45/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5237 - val_loss: 0.6919 - val_accuracy: 0.5138\n",
      "Epoch 46/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5243 - val_loss: 0.6919 - val_accuracy: 0.5163\n",
      "Epoch 47/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5241 - val_loss: 0.6920 - val_accuracy: 0.5116\n",
      "Epoch 48/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5234 - val_loss: 0.6920 - val_accuracy: 0.5127\n",
      "Epoch 49/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5232 - val_loss: 0.6920 - val_accuracy: 0.5169\n",
      "Epoch 50/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5223 - val_loss: 0.6920 - val_accuracy: 0.5180\n",
      "Epoch 51/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5219 - val_loss: 0.6920 - val_accuracy: 0.5192\n",
      "Epoch 52/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5235 - val_loss: 0.6919 - val_accuracy: 0.5196\n",
      "Epoch 53/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5222 - val_loss: 0.6919 - val_accuracy: 0.5196\n",
      "Epoch 54/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5241 - val_loss: 0.6920 - val_accuracy: 0.5197\n",
      "Epoch 55/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5236 - val_loss: 0.6922 - val_accuracy: 0.5128\n",
      "Epoch 56/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5235 - val_loss: 0.6920 - val_accuracy: 0.5186\n",
      "Epoch 57/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5222 - val_loss: 0.6922 - val_accuracy: 0.5075\n",
      "Epoch 58/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5228 - val_loss: 0.6919 - val_accuracy: 0.5195\n",
      "Epoch 59/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5242 - val_loss: 0.6923 - val_accuracy: 0.5073\n",
      "Epoch 60/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5236 - val_loss: 0.6920 - val_accuracy: 0.5179\n",
      "Epoch 61/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5228 - val_loss: 0.6922 - val_accuracy: 0.5099\n",
      "Epoch 62/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5239 - val_loss: 0.6919 - val_accuracy: 0.5199\n",
      "Epoch 63/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5236 - val_loss: 0.6920 - val_accuracy: 0.5154\n",
      "Epoch 64/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5240 - val_loss: 0.6919 - val_accuracy: 0.5199\n",
      "Epoch 65/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5261 - val_loss: 0.6924 - val_accuracy: 0.5089\n",
      "Epoch 66/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5230 - val_loss: 0.6919 - val_accuracy: 0.5184\n",
      "Epoch 67/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5252 - val_loss: 0.6921 - val_accuracy: 0.5154\n",
      "Epoch 68/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5247 - val_loss: 0.6920 - val_accuracy: 0.5202\n",
      "Epoch 69/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5251 - val_loss: 0.6921 - val_accuracy: 0.5113\n",
      "Epoch 70/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5229 - val_loss: 0.6919 - val_accuracy: 0.5126\n",
      "Epoch 71/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5224 - val_loss: 0.6920 - val_accuracy: 0.5174\n",
      "Epoch 72/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5238 - val_loss: 0.6920 - val_accuracy: 0.5130\n",
      "Training with significance = 3.78, run 6\n",
      "Train on 41457 samples, validate on 10365 samples\n",
      "Epoch 1/1000\n",
      "41457/41457 [==============================] - 1s 27us/sample - loss: 0.6929 - accuracy: 0.5066 - val_loss: 0.6932 - val_accuracy: 0.4997\n",
      "Epoch 2/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5173 - val_loss: 0.6929 - val_accuracy: 0.5066\n",
      "Epoch 3/1000\n",
      "41457/41457 [==============================] - 1s 12us/sample - loss: 0.6920 - accuracy: 0.5159 - val_loss: 0.6926 - val_accuracy: 0.5110\n",
      "Epoch 4/1000\n",
      "41457/41457 [==============================] - 1s 12us/sample - loss: 0.6918 - accuracy: 0.5181 - val_loss: 0.6925 - val_accuracy: 0.5109\n",
      "Epoch 5/1000\n",
      "41457/41457 [==============================] - 1s 12us/sample - loss: 0.6918 - accuracy: 0.5175 - val_loss: 0.6922 - val_accuracy: 0.5136\n",
      "Epoch 6/1000\n",
      "41457/41457 [==============================] - 0s 12us/sample - loss: 0.6917 - accuracy: 0.5177 - val_loss: 0.6923 - val_accuracy: 0.5124\n",
      "Epoch 7/1000\n",
      "41457/41457 [==============================] - 1s 12us/sample - loss: 0.6918 - accuracy: 0.5171 - val_loss: 0.6921 - val_accuracy: 0.5142\n",
      "Epoch 8/1000\n",
      "41457/41457 [==============================] - 1s 12us/sample - loss: 0.6917 - accuracy: 0.5176 - val_loss: 0.6921 - val_accuracy: 0.5136\n",
      "Epoch 9/1000\n",
      "41457/41457 [==============================] - 1s 12us/sample - loss: 0.6915 - accuracy: 0.5190 - val_loss: 0.6924 - val_accuracy: 0.5137\n",
      "Epoch 10/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5187 - val_loss: 0.6922 - val_accuracy: 0.5137\n",
      "Epoch 11/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5180 - val_loss: 0.6920 - val_accuracy: 0.5149\n",
      "Epoch 12/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5179 - val_loss: 0.6921 - val_accuracy: 0.5132\n",
      "Epoch 13/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5186 - val_loss: 0.6919 - val_accuracy: 0.5146\n",
      "Epoch 14/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5196 - val_loss: 0.6919 - val_accuracy: 0.5134\n",
      "Epoch 15/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5189 - val_loss: 0.6917 - val_accuracy: 0.5155\n",
      "Epoch 16/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5203 - val_loss: 0.6921 - val_accuracy: 0.5142\n",
      "Epoch 17/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5202 - val_loss: 0.6920 - val_accuracy: 0.5148\n",
      "Epoch 18/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5215 - val_loss: 0.6918 - val_accuracy: 0.5171\n",
      "Epoch 19/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5196 - val_loss: 0.6919 - val_accuracy: 0.5145\n",
      "Epoch 20/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5194 - val_loss: 0.6920 - val_accuracy: 0.5139\n",
      "Epoch 21/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5189 - val_loss: 0.6920 - val_accuracy: 0.5151\n",
      "Epoch 22/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5198 - val_loss: 0.6921 - val_accuracy: 0.5154\n",
      "Epoch 23/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5200 - val_loss: 0.6919 - val_accuracy: 0.5124\n",
      "Epoch 24/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5196 - val_loss: 0.6920 - val_accuracy: 0.5167\n",
      "Epoch 25/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5198 - val_loss: 0.6924 - val_accuracy: 0.5132\n",
      "Epoch 26/1000\n",
      "41457/41457 [==============================] - 1s 12us/sample - loss: 0.6911 - accuracy: 0.5213 - val_loss: 0.6918 - val_accuracy: 0.5170\n",
      "Epoch 27/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5201 - val_loss: 0.6917 - val_accuracy: 0.5146\n",
      "Epoch 28/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5206 - val_loss: 0.6918 - val_accuracy: 0.5136\n",
      "Epoch 29/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5206 - val_loss: 0.6919 - val_accuracy: 0.5180\n",
      "Epoch 30/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5198 - val_loss: 0.6918 - val_accuracy: 0.5193\n",
      "Epoch 31/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5198 - val_loss: 0.6923 - val_accuracy: 0.5139\n",
      "Epoch 32/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5214 - val_loss: 0.6919 - val_accuracy: 0.5173\n",
      "Epoch 33/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5199 - val_loss: 0.6920 - val_accuracy: 0.5129\n",
      "Epoch 34/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5199 - val_loss: 0.6923 - val_accuracy: 0.5126\n",
      "Epoch 35/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5186 - val_loss: 0.6921 - val_accuracy: 0.5144\n",
      "Epoch 36/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5201 - val_loss: 0.6920 - val_accuracy: 0.5153\n",
      "Epoch 37/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5205 - val_loss: 0.6921 - val_accuracy: 0.5152\n",
      "Epoch 38/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5210 - val_loss: 0.6922 - val_accuracy: 0.5137\n",
      "Epoch 39/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5198 - val_loss: 0.6921 - val_accuracy: 0.5147\n",
      "Epoch 40/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5216 - val_loss: 0.6921 - val_accuracy: 0.5151\n",
      "Epoch 41/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5186 - val_loss: 0.6919 - val_accuracy: 0.5122\n",
      "Epoch 42/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5193 - val_loss: 0.6918 - val_accuracy: 0.5163\n",
      "Epoch 43/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5211 - val_loss: 0.6919 - val_accuracy: 0.5148\n",
      "Epoch 44/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5192 - val_loss: 0.6920 - val_accuracy: 0.5146\n",
      "Epoch 45/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5205 - val_loss: 0.6925 - val_accuracy: 0.5137\n",
      "Training with significance = 3.78, run 7\n",
      "Train on 41457 samples, validate on 10365 samples\n",
      "Epoch 1/1000\n",
      "41457/41457 [==============================] - 1s 27us/sample - loss: 0.6944 - accuracy: 0.5012 - val_loss: 0.6935 - val_accuracy: 0.4992\n",
      "Epoch 2/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6926 - accuracy: 0.5144 - val_loss: 0.6932 - val_accuracy: 0.4965\n",
      "Epoch 3/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5164 - val_loss: 0.6928 - val_accuracy: 0.5044\n",
      "Epoch 4/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5161 - val_loss: 0.6925 - val_accuracy: 0.5119\n",
      "Epoch 5/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5173 - val_loss: 0.6923 - val_accuracy: 0.5121\n",
      "Epoch 6/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5167 - val_loss: 0.6923 - val_accuracy: 0.5133\n",
      "Epoch 7/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5167 - val_loss: 0.6923 - val_accuracy: 0.5122\n",
      "Epoch 8/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5165 - val_loss: 0.6922 - val_accuracy: 0.5119\n",
      "Epoch 9/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5167 - val_loss: 0.6922 - val_accuracy: 0.5087\n",
      "Epoch 10/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5164 - val_loss: 0.6922 - val_accuracy: 0.5106\n",
      "Epoch 11/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5192 - val_loss: 0.6921 - val_accuracy: 0.5170\n",
      "Epoch 12/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5161 - val_loss: 0.6921 - val_accuracy: 0.5126\n",
      "Epoch 13/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5185 - val_loss: 0.6920 - val_accuracy: 0.5145\n",
      "Epoch 14/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5184 - val_loss: 0.6921 - val_accuracy: 0.5108\n",
      "Epoch 15/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5189 - val_loss: 0.6921 - val_accuracy: 0.5103\n",
      "Epoch 16/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5185 - val_loss: 0.6920 - val_accuracy: 0.5137\n",
      "Epoch 17/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5173 - val_loss: 0.6920 - val_accuracy: 0.5164\n",
      "Epoch 18/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5195 - val_loss: 0.6919 - val_accuracy: 0.5138\n",
      "Epoch 19/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5193 - val_loss: 0.6921 - val_accuracy: 0.5122\n",
      "Epoch 20/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5197 - val_loss: 0.6919 - val_accuracy: 0.5160\n",
      "Epoch 21/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5186 - val_loss: 0.6920 - val_accuracy: 0.5160\n",
      "Epoch 22/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5205 - val_loss: 0.6919 - val_accuracy: 0.5159\n",
      "Epoch 23/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5196 - val_loss: 0.6920 - val_accuracy: 0.5137\n",
      "Epoch 24/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5209 - val_loss: 0.6920 - val_accuracy: 0.5118\n",
      "Epoch 25/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5198 - val_loss: 0.6920 - val_accuracy: 0.5141\n",
      "Epoch 26/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5192 - val_loss: 0.6919 - val_accuracy: 0.5160\n",
      "Epoch 27/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5192 - val_loss: 0.6920 - val_accuracy: 0.5174\n",
      "Epoch 28/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5202 - val_loss: 0.6919 - val_accuracy: 0.5140\n",
      "Epoch 29/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5188 - val_loss: 0.6919 - val_accuracy: 0.5152\n",
      "Epoch 30/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5213 - val_loss: 0.6919 - val_accuracy: 0.5137\n",
      "Epoch 31/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5223 - val_loss: 0.6919 - val_accuracy: 0.5150\n",
      "Epoch 32/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5205 - val_loss: 0.6919 - val_accuracy: 0.5144\n",
      "Epoch 33/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5190 - val_loss: 0.6919 - val_accuracy: 0.5140\n",
      "Epoch 34/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5222 - val_loss: 0.6920 - val_accuracy: 0.5142\n",
      "Epoch 35/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5220 - val_loss: 0.6921 - val_accuracy: 0.5137\n",
      "Epoch 36/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5201 - val_loss: 0.6919 - val_accuracy: 0.5126\n",
      "Epoch 37/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5206 - val_loss: 0.6920 - val_accuracy: 0.5128\n",
      "Epoch 38/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5219 - val_loss: 0.6919 - val_accuracy: 0.5143\n",
      "Epoch 39/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5229 - val_loss: 0.6919 - val_accuracy: 0.5146\n",
      "Epoch 40/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5194 - val_loss: 0.6919 - val_accuracy: 0.5142\n",
      "Epoch 41/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5206 - val_loss: 0.6919 - val_accuracy: 0.5137\n",
      "Epoch 42/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5185 - val_loss: 0.6919 - val_accuracy: 0.5133\n",
      "Epoch 43/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5206 - val_loss: 0.6919 - val_accuracy: 0.5122\n",
      "Epoch 44/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5223 - val_loss: 0.6919 - val_accuracy: 0.5153\n",
      "Epoch 45/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5207 - val_loss: 0.6921 - val_accuracy: 0.5133\n",
      "Epoch 46/1000\n",
      "41457/41457 [==============================] - 1s 12us/sample - loss: 0.6908 - accuracy: 0.5205 - val_loss: 0.6920 - val_accuracy: 0.5126\n",
      "Epoch 47/1000\n",
      "41457/41457 [==============================] - 1s 12us/sample - loss: 0.6910 - accuracy: 0.5224 - val_loss: 0.6921 - val_accuracy: 0.5122\n",
      "Epoch 48/1000\n",
      "41457/41457 [==============================] - 1s 12us/sample - loss: 0.6908 - accuracy: 0.5213 - val_loss: 0.6920 - val_accuracy: 0.5155\n",
      "Epoch 49/1000\n",
      "41457/41457 [==============================] - 1s 12us/sample - loss: 0.6909 - accuracy: 0.5219 - val_loss: 0.6919 - val_accuracy: 0.5118\n",
      "Epoch 50/1000\n",
      "41457/41457 [==============================] - 0s 12us/sample - loss: 0.6908 - accuracy: 0.5210 - val_loss: 0.6919 - val_accuracy: 0.5124\n",
      "Epoch 51/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5226 - val_loss: 0.6920 - val_accuracy: 0.5117\n",
      "Epoch 52/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5231 - val_loss: 0.6919 - val_accuracy: 0.5147\n",
      "Epoch 53/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5211 - val_loss: 0.6921 - val_accuracy: 0.5125\n",
      "Epoch 54/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5217 - val_loss: 0.6919 - val_accuracy: 0.5107\n",
      "Epoch 55/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5211 - val_loss: 0.6920 - val_accuracy: 0.5093\n",
      "Epoch 56/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5227 - val_loss: 0.6920 - val_accuracy: 0.5109\n",
      "Epoch 57/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5207 - val_loss: 0.6919 - val_accuracy: 0.5107\n",
      "Epoch 58/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5233 - val_loss: 0.6921 - val_accuracy: 0.5083\n",
      "Epoch 59/1000\n",
      "41457/41457 [==============================] - 1s 12us/sample - loss: 0.6908 - accuracy: 0.5223 - val_loss: 0.6919 - val_accuracy: 0.5138\n",
      "Epoch 60/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5219 - val_loss: 0.6920 - val_accuracy: 0.5123\n",
      "Epoch 61/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5221 - val_loss: 0.6920 - val_accuracy: 0.5110\n",
      "Epoch 62/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5226 - val_loss: 0.6920 - val_accuracy: 0.5147\n",
      "Epoch 63/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5224 - val_loss: 0.6920 - val_accuracy: 0.5113\n",
      "Epoch 64/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5218 - val_loss: 0.6920 - val_accuracy: 0.5137\n",
      "Epoch 65/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5220 - val_loss: 0.6920 - val_accuracy: 0.5111\n",
      "Epoch 66/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5248 - val_loss: 0.6920 - val_accuracy: 0.5128\n",
      "Epoch 67/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5232 - val_loss: 0.6920 - val_accuracy: 0.5114\n",
      "Epoch 68/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5227 - val_loss: 0.6920 - val_accuracy: 0.5136\n",
      "Training with significance = 3.78, run 8\n",
      "Train on 41457 samples, validate on 10365 samples\n",
      "Epoch 1/1000\n",
      "41457/41457 [==============================] - 1s 28us/sample - loss: 0.6933 - accuracy: 0.5073 - val_loss: 0.6943 - val_accuracy: 0.5029\n",
      "Epoch 2/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5160 - val_loss: 0.6927 - val_accuracy: 0.5102\n",
      "Epoch 3/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5169 - val_loss: 0.6923 - val_accuracy: 0.5147\n",
      "Epoch 4/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5190 - val_loss: 0.6922 - val_accuracy: 0.5142\n",
      "Epoch 5/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5196 - val_loss: 0.6921 - val_accuracy: 0.5146\n",
      "Epoch 6/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5182 - val_loss: 0.6921 - val_accuracy: 0.5129\n",
      "Epoch 7/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5187 - val_loss: 0.6921 - val_accuracy: 0.5154\n",
      "Epoch 8/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5199 - val_loss: 0.6920 - val_accuracy: 0.5132\n",
      "Epoch 9/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5181 - val_loss: 0.6920 - val_accuracy: 0.5121\n",
      "Epoch 10/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5200 - val_loss: 0.6921 - val_accuracy: 0.5138\n",
      "Epoch 11/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5201 - val_loss: 0.6919 - val_accuracy: 0.5115\n",
      "Epoch 12/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5197 - val_loss: 0.6920 - val_accuracy: 0.5140\n",
      "Epoch 13/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5193 - val_loss: 0.6919 - val_accuracy: 0.5115\n",
      "Epoch 14/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5219 - val_loss: 0.6921 - val_accuracy: 0.5153\n",
      "Epoch 15/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5198 - val_loss: 0.6921 - val_accuracy: 0.5160\n",
      "Epoch 16/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5204 - val_loss: 0.6920 - val_accuracy: 0.5140\n",
      "Epoch 17/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5198 - val_loss: 0.6919 - val_accuracy: 0.5138\n",
      "Epoch 18/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5195 - val_loss: 0.6920 - val_accuracy: 0.5142\n",
      "Epoch 19/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5209 - val_loss: 0.6919 - val_accuracy: 0.5110\n",
      "Epoch 20/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5201 - val_loss: 0.6920 - val_accuracy: 0.5192\n",
      "Epoch 21/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5210 - val_loss: 0.6919 - val_accuracy: 0.5132\n",
      "Epoch 22/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5179 - val_loss: 0.6920 - val_accuracy: 0.5143\n",
      "Epoch 23/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5200 - val_loss: 0.6919 - val_accuracy: 0.5162\n",
      "Epoch 24/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5206 - val_loss: 0.6918 - val_accuracy: 0.5147\n",
      "Epoch 25/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5208 - val_loss: 0.6919 - val_accuracy: 0.5137\n",
      "Epoch 26/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5223 - val_loss: 0.6919 - val_accuracy: 0.5143\n",
      "Epoch 27/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5207 - val_loss: 0.6920 - val_accuracy: 0.5149\n",
      "Epoch 28/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5216 - val_loss: 0.6919 - val_accuracy: 0.5126\n",
      "Epoch 29/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5219 - val_loss: 0.6920 - val_accuracy: 0.5141\n",
      "Epoch 30/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5206 - val_loss: 0.6920 - val_accuracy: 0.5145\n",
      "Epoch 31/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5220 - val_loss: 0.6919 - val_accuracy: 0.5125\n",
      "Epoch 32/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5211 - val_loss: 0.6921 - val_accuracy: 0.5132\n",
      "Epoch 33/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5207 - val_loss: 0.6921 - val_accuracy: 0.5137\n",
      "Epoch 34/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5228 - val_loss: 0.6918 - val_accuracy: 0.5166\n",
      "Epoch 35/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5229 - val_loss: 0.6919 - val_accuracy: 0.5141\n",
      "Epoch 36/1000\n",
      "41457/41457 [==============================] - 1s 12us/sample - loss: 0.6911 - accuracy: 0.5208 - val_loss: 0.6920 - val_accuracy: 0.5151\n",
      "Epoch 37/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5209 - val_loss: 0.6917 - val_accuracy: 0.5169\n",
      "Epoch 38/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5205 - val_loss: 0.6918 - val_accuracy: 0.5159\n",
      "Epoch 39/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5205 - val_loss: 0.6918 - val_accuracy: 0.5144\n",
      "Epoch 40/1000\n",
      "41457/41457 [==============================] - 1s 12us/sample - loss: 0.6907 - accuracy: 0.5228 - val_loss: 0.6918 - val_accuracy: 0.5130\n",
      "Epoch 41/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5235 - val_loss: 0.6918 - val_accuracy: 0.5160\n",
      "Epoch 42/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5250 - val_loss: 0.6918 - val_accuracy: 0.5177\n",
      "Epoch 43/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5216 - val_loss: 0.6919 - val_accuracy: 0.5152\n",
      "Epoch 44/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5217 - val_loss: 0.6919 - val_accuracy: 0.5133\n",
      "Epoch 45/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5221 - val_loss: 0.6920 - val_accuracy: 0.5134\n",
      "Epoch 46/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5223 - val_loss: 0.6919 - val_accuracy: 0.5154\n",
      "Epoch 47/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5237 - val_loss: 0.6921 - val_accuracy: 0.5133\n",
      "Epoch 48/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5230 - val_loss: 0.6918 - val_accuracy: 0.5156\n",
      "Epoch 49/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5235 - val_loss: 0.6920 - val_accuracy: 0.5157\n",
      "Epoch 50/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5229 - val_loss: 0.6918 - val_accuracy: 0.5141\n",
      "Epoch 51/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5244 - val_loss: 0.6918 - val_accuracy: 0.5149\n",
      "Epoch 52/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5226 - val_loss: 0.6920 - val_accuracy: 0.5162\n",
      "Epoch 53/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5227 - val_loss: 0.6918 - val_accuracy: 0.5130\n",
      "Epoch 54/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5223 - val_loss: 0.6918 - val_accuracy: 0.5140\n",
      "Epoch 55/1000\n",
      "41457/41457 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5231 - val_loss: 0.6918 - val_accuracy: 0.5153\n",
      "Epoch 56/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5222 - val_loss: 0.6919 - val_accuracy: 0.5140\n",
      "Epoch 57/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5204 - val_loss: 0.6918 - val_accuracy: 0.5148\n",
      "Epoch 58/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5228 - val_loss: 0.6920 - val_accuracy: 0.5136\n",
      "Epoch 59/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5221 - val_loss: 0.6919 - val_accuracy: 0.5141\n",
      "Epoch 60/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5233 - val_loss: 0.6920 - val_accuracy: 0.5133\n",
      "Epoch 61/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5218 - val_loss: 0.6921 - val_accuracy: 0.5141\n",
      "Epoch 62/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5237 - val_loss: 0.6917 - val_accuracy: 0.5173\n",
      "Epoch 63/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5238 - val_loss: 0.6919 - val_accuracy: 0.5141\n",
      "Epoch 64/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5238 - val_loss: 0.6919 - val_accuracy: 0.5151\n",
      "Epoch 65/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5242 - val_loss: 0.6919 - val_accuracy: 0.5123\n",
      "Epoch 66/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5226 - val_loss: 0.6917 - val_accuracy: 0.5136\n",
      "Epoch 67/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5241 - val_loss: 0.6920 - val_accuracy: 0.5134\n",
      "Epoch 68/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5224 - val_loss: 0.6918 - val_accuracy: 0.5156\n",
      "Epoch 69/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5241 - val_loss: 0.6920 - val_accuracy: 0.5142\n",
      "Epoch 70/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5248 - val_loss: 0.6917 - val_accuracy: 0.5166\n",
      "Epoch 71/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5253 - val_loss: 0.6918 - val_accuracy: 0.5156\n",
      "Epoch 72/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5236 - val_loss: 0.6920 - val_accuracy: 0.5115\n",
      "Epoch 73/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5239 - val_loss: 0.6918 - val_accuracy: 0.5161\n",
      "Epoch 74/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5251 - val_loss: 0.6919 - val_accuracy: 0.5137\n",
      "Epoch 75/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5249 - val_loss: 0.6920 - val_accuracy: 0.5149\n",
      "Epoch 76/1000\n",
      "41457/41457 [==============================] - 1s 12us/sample - loss: 0.6907 - accuracy: 0.5241 - val_loss: 0.6919 - val_accuracy: 0.5130\n",
      "Epoch 77/1000\n",
      "41457/41457 [==============================] - 0s 12us/sample - loss: 0.6905 - accuracy: 0.5231 - val_loss: 0.6917 - val_accuracy: 0.5137\n",
      "Epoch 78/1000\n",
      "41457/41457 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5238 - val_loss: 0.6918 - val_accuracy: 0.5135\n",
      "Epoch 79/1000\n",
      "41457/41457 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5246 - val_loss: 0.6919 - val_accuracy: 0.5153\n",
      "Epoch 80/1000\n",
      "41457/41457 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5235 - val_loss: 0.6918 - val_accuracy: 0.5140\n",
      "Epoch 81/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5234 - val_loss: 0.6919 - val_accuracy: 0.5130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5243 - val_loss: 0.6917 - val_accuracy: 0.5137\n",
      "Epoch 83/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5252 - val_loss: 0.6918 - val_accuracy: 0.5158\n",
      "Epoch 84/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5235 - val_loss: 0.6920 - val_accuracy: 0.5126\n",
      "Epoch 85/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5242 - val_loss: 0.6920 - val_accuracy: 0.5131\n",
      "Epoch 86/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5230 - val_loss: 0.6918 - val_accuracy: 0.5124\n",
      "Epoch 87/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5246 - val_loss: 0.6917 - val_accuracy: 0.5136\n",
      "Epoch 88/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5235 - val_loss: 0.6920 - val_accuracy: 0.5144\n",
      "Epoch 89/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5255 - val_loss: 0.6919 - val_accuracy: 0.5133\n",
      "Epoch 90/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5247 - val_loss: 0.6920 - val_accuracy: 0.5111\n",
      "Epoch 91/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5231 - val_loss: 0.6920 - val_accuracy: 0.5127\n",
      "Epoch 92/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5252 - val_loss: 0.6919 - val_accuracy: 0.5137\n",
      "Epoch 93/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5242 - val_loss: 0.6918 - val_accuracy: 0.5129\n",
      "Epoch 94/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5249 - val_loss: 0.6923 - val_accuracy: 0.5122\n",
      "Epoch 95/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5242 - val_loss: 0.6920 - val_accuracy: 0.5134\n",
      "Epoch 96/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5245 - val_loss: 0.6920 - val_accuracy: 0.5145\n",
      "Epoch 97/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5241 - val_loss: 0.6920 - val_accuracy: 0.5133\n",
      "Epoch 98/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5249 - val_loss: 0.6919 - val_accuracy: 0.5152\n",
      "Epoch 99/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5250 - val_loss: 0.6919 - val_accuracy: 0.5151\n",
      "Epoch 100/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5248 - val_loss: 0.6919 - val_accuracy: 0.5142\n",
      "Training with significance = 3.78, run 9\n",
      "Train on 41457 samples, validate on 10365 samples\n",
      "Epoch 1/1000\n",
      "41457/41457 [==============================] - 1s 27us/sample - loss: 0.6941 - accuracy: 0.5073 - val_loss: 0.6948 - val_accuracy: 0.5004\n",
      "Epoch 2/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5156 - val_loss: 0.6932 - val_accuracy: 0.5018\n",
      "Epoch 3/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5183 - val_loss: 0.6930 - val_accuracy: 0.5078\n",
      "Epoch 4/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5165 - val_loss: 0.6928 - val_accuracy: 0.5120\n",
      "Epoch 5/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5178 - val_loss: 0.6928 - val_accuracy: 0.5139\n",
      "Epoch 6/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5186 - val_loss: 0.6928 - val_accuracy: 0.5082\n",
      "Epoch 7/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5184 - val_loss: 0.6928 - val_accuracy: 0.5135\n",
      "Epoch 8/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5185 - val_loss: 0.6929 - val_accuracy: 0.5125\n",
      "Epoch 9/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5178 - val_loss: 0.6929 - val_accuracy: 0.5145\n",
      "Epoch 10/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5180 - val_loss: 0.6928 - val_accuracy: 0.5126\n",
      "Epoch 11/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5180 - val_loss: 0.6929 - val_accuracy: 0.5111\n",
      "Epoch 12/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5173 - val_loss: 0.6928 - val_accuracy: 0.5123\n",
      "Epoch 13/1000\n",
      "41457/41457 [==============================] - 1s 12us/sample - loss: 0.6915 - accuracy: 0.5190 - val_loss: 0.6929 - val_accuracy: 0.5125\n",
      "Epoch 14/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5196 - val_loss: 0.6927 - val_accuracy: 0.5109\n",
      "Epoch 15/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5194 - val_loss: 0.6926 - val_accuracy: 0.5133\n",
      "Epoch 16/1000\n",
      "41457/41457 [==============================] - 1s 12us/sample - loss: 0.6915 - accuracy: 0.5174 - val_loss: 0.6927 - val_accuracy: 0.5132\n",
      "Epoch 17/1000\n",
      "41457/41457 [==============================] - 0s 12us/sample - loss: 0.6914 - accuracy: 0.5203 - val_loss: 0.6930 - val_accuracy: 0.5111\n",
      "Epoch 18/1000\n",
      "41457/41457 [==============================] - 0s 12us/sample - loss: 0.6914 - accuracy: 0.5194 - val_loss: 0.6928 - val_accuracy: 0.5135\n",
      "Epoch 19/1000\n",
      "41457/41457 [==============================] - 1s 12us/sample - loss: 0.6914 - accuracy: 0.5192 - val_loss: 0.6928 - val_accuracy: 0.5129\n",
      "Epoch 20/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5201 - val_loss: 0.6930 - val_accuracy: 0.5105\n",
      "Epoch 21/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5179 - val_loss: 0.6926 - val_accuracy: 0.5131\n",
      "Epoch 22/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5211 - val_loss: 0.6928 - val_accuracy: 0.5142\n",
      "Epoch 23/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5195 - val_loss: 0.6927 - val_accuracy: 0.5137\n",
      "Epoch 24/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5203 - val_loss: 0.6926 - val_accuracy: 0.5129\n",
      "Epoch 25/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5176 - val_loss: 0.6927 - val_accuracy: 0.5143\n",
      "Epoch 26/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5201 - val_loss: 0.6927 - val_accuracy: 0.5124\n",
      "Epoch 27/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5201 - val_loss: 0.6928 - val_accuracy: 0.5121\n",
      "Epoch 28/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5209 - val_loss: 0.6927 - val_accuracy: 0.5114\n",
      "Epoch 29/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5202 - val_loss: 0.6926 - val_accuracy: 0.5152\n",
      "Epoch 30/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5188 - val_loss: 0.6927 - val_accuracy: 0.5112\n",
      "Epoch 31/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5209 - val_loss: 0.6927 - val_accuracy: 0.5102\n",
      "Epoch 32/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5200 - val_loss: 0.6927 - val_accuracy: 0.5116\n",
      "Epoch 33/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5208 - val_loss: 0.6926 - val_accuracy: 0.5153\n",
      "Epoch 34/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5229 - val_loss: 0.6927 - val_accuracy: 0.5137\n",
      "Epoch 35/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5205 - val_loss: 0.6928 - val_accuracy: 0.5113\n",
      "Epoch 36/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5202 - val_loss: 0.6927 - val_accuracy: 0.5139\n",
      "Epoch 37/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5220 - val_loss: 0.6925 - val_accuracy: 0.5140\n",
      "Epoch 38/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5217 - val_loss: 0.6928 - val_accuracy: 0.5110\n",
      "Epoch 39/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5207 - val_loss: 0.6927 - val_accuracy: 0.5134\n",
      "Epoch 40/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5211 - val_loss: 0.6929 - val_accuracy: 0.5106\n",
      "Epoch 41/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5198 - val_loss: 0.6927 - val_accuracy: 0.5146\n",
      "Epoch 42/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5198 - val_loss: 0.6928 - val_accuracy: 0.5124\n",
      "Epoch 43/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5213 - val_loss: 0.6926 - val_accuracy: 0.5109\n",
      "Epoch 44/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5194 - val_loss: 0.6926 - val_accuracy: 0.5141\n",
      "Epoch 45/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5218 - val_loss: 0.6927 - val_accuracy: 0.5124\n",
      "Epoch 46/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5196 - val_loss: 0.6926 - val_accuracy: 0.5115\n",
      "Epoch 47/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5210 - val_loss: 0.6927 - val_accuracy: 0.5148\n",
      "Epoch 48/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5209 - val_loss: 0.6925 - val_accuracy: 0.5140\n",
      "Epoch 49/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5202 - val_loss: 0.6930 - val_accuracy: 0.5132\n",
      "Epoch 50/1000\n",
      "41457/41457 [==============================] - 1s 12us/sample - loss: 0.6910 - accuracy: 0.5202 - val_loss: 0.6926 - val_accuracy: 0.5146\n",
      "Epoch 51/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5217 - val_loss: 0.6927 - val_accuracy: 0.5116\n",
      "Epoch 52/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5220 - val_loss: 0.6926 - val_accuracy: 0.5147\n",
      "Epoch 53/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5210 - val_loss: 0.6927 - val_accuracy: 0.5141\n",
      "Epoch 54/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5227 - val_loss: 0.6928 - val_accuracy: 0.5121\n",
      "Epoch 55/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5221 - val_loss: 0.6927 - val_accuracy: 0.5130\n",
      "Epoch 56/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5229 - val_loss: 0.6926 - val_accuracy: 0.5135\n",
      "Epoch 57/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5207 - val_loss: 0.6926 - val_accuracy: 0.5119\n",
      "Epoch 58/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5217 - val_loss: 0.6930 - val_accuracy: 0.5126\n",
      "Epoch 59/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5224 - val_loss: 0.6926 - val_accuracy: 0.5121\n",
      "Epoch 60/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5223 - val_loss: 0.6926 - val_accuracy: 0.5130\n",
      "Epoch 61/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5206 - val_loss: 0.6926 - val_accuracy: 0.5139\n",
      "Epoch 62/1000\n",
      "41457/41457 [==============================] - 1s 12us/sample - loss: 0.6910 - accuracy: 0.5211 - val_loss: 0.6926 - val_accuracy: 0.5149\n",
      "Epoch 63/1000\n",
      "41457/41457 [==============================] - 1s 12us/sample - loss: 0.6909 - accuracy: 0.5218 - val_loss: 0.6927 - val_accuracy: 0.5121\n",
      "Epoch 64/1000\n",
      "41457/41457 [==============================] - 1s 12us/sample - loss: 0.6909 - accuracy: 0.5210 - val_loss: 0.6928 - val_accuracy: 0.5130\n",
      "Epoch 65/1000\n",
      "41457/41457 [==============================] - 0s 12us/sample - loss: 0.6910 - accuracy: 0.5208 - val_loss: 0.6927 - val_accuracy: 0.5140\n",
      "Epoch 66/1000\n",
      "41457/41457 [==============================] - 1s 12us/sample - loss: 0.6908 - accuracy: 0.5231 - val_loss: 0.6927 - val_accuracy: 0.5142\n",
      "Epoch 67/1000\n",
      "41457/41457 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5217 - val_loss: 0.6927 - val_accuracy: 0.5149\n",
      "Training with significance = 4.41, run 0\n",
      "Train on 41558 samples, validate on 10390 samples\n",
      "Epoch 1/1000\n",
      "41558/41558 [==============================] - 1s 28us/sample - loss: 0.6926 - accuracy: 0.5110 - val_loss: 0.6956 - val_accuracy: 0.4984\n",
      "Epoch 2/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5132 - val_loss: 0.6934 - val_accuracy: 0.5112\n",
      "Epoch 3/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5141 - val_loss: 0.6930 - val_accuracy: 0.5116\n",
      "Epoch 4/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5162 - val_loss: 0.6926 - val_accuracy: 0.5150\n",
      "Epoch 5/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5173 - val_loss: 0.6925 - val_accuracy: 0.5141\n",
      "Epoch 6/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5159 - val_loss: 0.6927 - val_accuracy: 0.5156\n",
      "Epoch 7/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5166 - val_loss: 0.6924 - val_accuracy: 0.5117\n",
      "Epoch 8/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5169 - val_loss: 0.6924 - val_accuracy: 0.5135\n",
      "Epoch 9/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5170 - val_loss: 0.6923 - val_accuracy: 0.5131\n",
      "Epoch 10/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5179 - val_loss: 0.6924 - val_accuracy: 0.5121\n",
      "Epoch 11/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5186 - val_loss: 0.6924 - val_accuracy: 0.5128\n",
      "Epoch 12/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5175 - val_loss: 0.6923 - val_accuracy: 0.5122\n",
      "Epoch 13/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5179 - val_loss: 0.6923 - val_accuracy: 0.5130\n",
      "Epoch 14/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5192 - val_loss: 0.6924 - val_accuracy: 0.5107\n",
      "Epoch 15/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5182 - val_loss: 0.6923 - val_accuracy: 0.5119\n",
      "Epoch 16/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5190 - val_loss: 0.6923 - val_accuracy: 0.5119\n",
      "Epoch 17/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5187 - val_loss: 0.6924 - val_accuracy: 0.5166\n",
      "Epoch 18/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5185 - val_loss: 0.6925 - val_accuracy: 0.5118\n",
      "Epoch 19/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5176 - val_loss: 0.6923 - val_accuracy: 0.5111\n",
      "Epoch 20/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5211 - val_loss: 0.6923 - val_accuracy: 0.5119\n",
      "Epoch 21/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5199 - val_loss: 0.6923 - val_accuracy: 0.5160\n",
      "Epoch 22/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5186 - val_loss: 0.6923 - val_accuracy: 0.5145\n",
      "Epoch 23/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5188 - val_loss: 0.6923 - val_accuracy: 0.5128\n",
      "Epoch 24/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5181 - val_loss: 0.6926 - val_accuracy: 0.5127\n",
      "Epoch 25/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5179 - val_loss: 0.6923 - val_accuracy: 0.5141\n",
      "Epoch 26/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5193 - val_loss: 0.6923 - val_accuracy: 0.5140\n",
      "Epoch 27/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5203 - val_loss: 0.6924 - val_accuracy: 0.5104\n",
      "Epoch 28/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5180 - val_loss: 0.6924 - val_accuracy: 0.5115\n",
      "Epoch 29/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5201 - val_loss: 0.6924 - val_accuracy: 0.5105\n",
      "Epoch 30/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5188 - val_loss: 0.6923 - val_accuracy: 0.5153\n",
      "Epoch 31/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5198 - val_loss: 0.6923 - val_accuracy: 0.5115\n",
      "Epoch 32/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5220 - val_loss: 0.6923 - val_accuracy: 0.5127\n",
      "Epoch 33/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5199 - val_loss: 0.6923 - val_accuracy: 0.5134\n",
      "Epoch 34/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5204 - val_loss: 0.6923 - val_accuracy: 0.5157\n",
      "Epoch 35/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5199 - val_loss: 0.6925 - val_accuracy: 0.5123\n",
      "Epoch 36/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5195 - val_loss: 0.6923 - val_accuracy: 0.5142\n",
      "Epoch 37/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5185 - val_loss: 0.6923 - val_accuracy: 0.5143\n",
      "Epoch 38/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5180 - val_loss: 0.6923 - val_accuracy: 0.5103\n",
      "Epoch 39/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5205 - val_loss: 0.6924 - val_accuracy: 0.5080\n",
      "Epoch 40/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5216 - val_loss: 0.6923 - val_accuracy: 0.5122\n",
      "Epoch 41/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5226 - val_loss: 0.6923 - val_accuracy: 0.5171\n",
      "Epoch 42/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6909 - accuracy: 0.5207 - val_loss: 0.6925 - val_accuracy: 0.5093\n",
      "Epoch 43/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6909 - accuracy: 0.5198 - val_loss: 0.6924 - val_accuracy: 0.5147\n",
      "Epoch 44/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6909 - accuracy: 0.5205 - val_loss: 0.6924 - val_accuracy: 0.5157\n",
      "Epoch 45/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6909 - accuracy: 0.5217 - val_loss: 0.6923 - val_accuracy: 0.5111\n",
      "Epoch 46/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6908 - accuracy: 0.5199 - val_loss: 0.6923 - val_accuracy: 0.5141\n",
      "Epoch 47/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5196 - val_loss: 0.6923 - val_accuracy: 0.5140\n",
      "Epoch 48/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5205 - val_loss: 0.6923 - val_accuracy: 0.5135\n",
      "Epoch 49/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5201 - val_loss: 0.6923 - val_accuracy: 0.5141\n",
      "Epoch 50/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5205 - val_loss: 0.6923 - val_accuracy: 0.5138\n",
      "Epoch 51/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5194 - val_loss: 0.6924 - val_accuracy: 0.5109\n",
      "Epoch 52/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5209 - val_loss: 0.6924 - val_accuracy: 0.5151\n",
      "Epoch 53/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5200 - val_loss: 0.6925 - val_accuracy: 0.5105\n",
      "Epoch 54/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5216 - val_loss: 0.6923 - val_accuracy: 0.5137\n",
      "Epoch 55/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5219 - val_loss: 0.6924 - val_accuracy: 0.5126\n",
      "Epoch 56/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5201 - val_loss: 0.6925 - val_accuracy: 0.5115\n",
      "Epoch 57/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5211 - val_loss: 0.6924 - val_accuracy: 0.5140\n",
      "Epoch 58/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5212 - val_loss: 0.6924 - val_accuracy: 0.5142\n",
      "Epoch 59/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5205 - val_loss: 0.6925 - val_accuracy: 0.5115\n",
      "Epoch 60/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5217 - val_loss: 0.6924 - val_accuracy: 0.5132\n",
      "Epoch 61/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5195 - val_loss: 0.6924 - val_accuracy: 0.5118\n",
      "Epoch 62/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5210 - val_loss: 0.6924 - val_accuracy: 0.5136\n",
      "Epoch 63/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5220 - val_loss: 0.6924 - val_accuracy: 0.5141\n",
      "Epoch 64/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5207 - val_loss: 0.6924 - val_accuracy: 0.5140\n",
      "Epoch 65/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5208 - val_loss: 0.6924 - val_accuracy: 0.5113\n",
      "Epoch 66/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5206 - val_loss: 0.6925 - val_accuracy: 0.5097\n",
      "Epoch 67/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5208 - val_loss: 0.6924 - val_accuracy: 0.5172\n",
      "Training with significance = 4.41, run 1\n",
      "Train on 41558 samples, validate on 10390 samples\n",
      "Epoch 1/1000\n",
      "41558/41558 [==============================] - 2s 59us/sample - loss: 0.6935 - accuracy: 0.5050 - val_loss: 0.6928 - val_accuracy: 0.5058\n",
      "Epoch 2/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5153 - val_loss: 0.6921 - val_accuracy: 0.5183\n",
      "Epoch 3/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5152 - val_loss: 0.6918 - val_accuracy: 0.5167\n",
      "Epoch 4/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5147 - val_loss: 0.6916 - val_accuracy: 0.5200\n",
      "Epoch 5/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5182 - val_loss: 0.6914 - val_accuracy: 0.5174\n",
      "Epoch 6/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5173 - val_loss: 0.6915 - val_accuracy: 0.5208\n",
      "Epoch 7/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5183 - val_loss: 0.6914 - val_accuracy: 0.5193\n",
      "Epoch 8/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5207 - val_loss: 0.6913 - val_accuracy: 0.5202\n",
      "Epoch 9/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5212 - val_loss: 0.6915 - val_accuracy: 0.5179\n",
      "Epoch 10/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5204 - val_loss: 0.6913 - val_accuracy: 0.5175\n",
      "Epoch 11/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5213 - val_loss: 0.6912 - val_accuracy: 0.5189\n",
      "Epoch 12/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5215 - val_loss: 0.6912 - val_accuracy: 0.5182\n",
      "Epoch 13/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5193 - val_loss: 0.6914 - val_accuracy: 0.5188\n",
      "Epoch 14/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5189 - val_loss: 0.6913 - val_accuracy: 0.5181\n",
      "Epoch 15/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5202 - val_loss: 0.6915 - val_accuracy: 0.5200\n",
      "Epoch 16/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5214 - val_loss: 0.6913 - val_accuracy: 0.5194\n",
      "Epoch 17/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5210 - val_loss: 0.6910 - val_accuracy: 0.5180\n",
      "Epoch 18/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6911 - accuracy: 0.5215 - val_loss: 0.6912 - val_accuracy: 0.5198\n",
      "Epoch 19/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5222 - val_loss: 0.6913 - val_accuracy: 0.5197\n",
      "Epoch 20/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5224 - val_loss: 0.6911 - val_accuracy: 0.5212\n",
      "Epoch 21/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5210 - val_loss: 0.6912 - val_accuracy: 0.5192\n",
      "Epoch 22/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5222 - val_loss: 0.6912 - val_accuracy: 0.5193\n",
      "Epoch 23/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5224 - val_loss: 0.6913 - val_accuracy: 0.5195\n",
      "Epoch 24/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5226 - val_loss: 0.6909 - val_accuracy: 0.5195\n",
      "Epoch 25/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5217 - val_loss: 0.6912 - val_accuracy: 0.5196\n",
      "Epoch 26/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5226 - val_loss: 0.6912 - val_accuracy: 0.5206\n",
      "Epoch 27/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5233 - val_loss: 0.6911 - val_accuracy: 0.5206\n",
      "Epoch 28/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5233 - val_loss: 0.6913 - val_accuracy: 0.5182\n",
      "Epoch 29/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5238 - val_loss: 0.6910 - val_accuracy: 0.5194\n",
      "Epoch 30/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5232 - val_loss: 0.6912 - val_accuracy: 0.5208\n",
      "Epoch 31/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5231 - val_loss: 0.6913 - val_accuracy: 0.5197\n",
      "Epoch 32/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5220 - val_loss: 0.6912 - val_accuracy: 0.5200\n",
      "Epoch 33/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5224 - val_loss: 0.6911 - val_accuracy: 0.5196\n",
      "Epoch 34/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5250 - val_loss: 0.6912 - val_accuracy: 0.5192\n",
      "Epoch 35/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5233 - val_loss: 0.6910 - val_accuracy: 0.5182\n",
      "Epoch 36/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5238 - val_loss: 0.6910 - val_accuracy: 0.5184\n",
      "Epoch 37/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5226 - val_loss: 0.6912 - val_accuracy: 0.5200\n",
      "Epoch 38/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5235 - val_loss: 0.6912 - val_accuracy: 0.5167\n",
      "Epoch 39/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5255 - val_loss: 0.6912 - val_accuracy: 0.5187\n",
      "Epoch 40/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5226 - val_loss: 0.6911 - val_accuracy: 0.5172\n",
      "Epoch 41/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5232 - val_loss: 0.6911 - val_accuracy: 0.5204\n",
      "Epoch 42/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5244 - val_loss: 0.6912 - val_accuracy: 0.5177\n",
      "Epoch 43/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5232 - val_loss: 0.6914 - val_accuracy: 0.5192\n",
      "Epoch 44/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5246 - val_loss: 0.6913 - val_accuracy: 0.5162\n",
      "Epoch 45/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5259 - val_loss: 0.6912 - val_accuracy: 0.5186\n",
      "Epoch 46/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5224 - val_loss: 0.6915 - val_accuracy: 0.5184\n",
      "Epoch 47/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5247 - val_loss: 0.6909 - val_accuracy: 0.5175\n",
      "Epoch 48/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5237 - val_loss: 0.6914 - val_accuracy: 0.5193\n",
      "Epoch 49/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5245 - val_loss: 0.6913 - val_accuracy: 0.5180\n",
      "Epoch 50/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5242 - val_loss: 0.6910 - val_accuracy: 0.5186\n",
      "Epoch 51/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5239 - val_loss: 0.6909 - val_accuracy: 0.5198\n",
      "Epoch 52/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5246 - val_loss: 0.6911 - val_accuracy: 0.5192\n",
      "Epoch 53/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5254 - val_loss: 0.6909 - val_accuracy: 0.5185\n",
      "Epoch 54/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5224 - val_loss: 0.6913 - val_accuracy: 0.5156\n",
      "Epoch 55/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5245 - val_loss: 0.6909 - val_accuracy: 0.5208\n",
      "Epoch 56/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5237 - val_loss: 0.6908 - val_accuracy: 0.5178\n",
      "Epoch 57/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5243 - val_loss: 0.6909 - val_accuracy: 0.5205\n",
      "Epoch 58/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5249 - val_loss: 0.6912 - val_accuracy: 0.5167\n",
      "Epoch 59/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5257 - val_loss: 0.6914 - val_accuracy: 0.5172\n",
      "Epoch 60/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5216 - val_loss: 0.6909 - val_accuracy: 0.5186\n",
      "Epoch 61/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5237 - val_loss: 0.6911 - val_accuracy: 0.5178\n",
      "Epoch 62/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6907 - accuracy: 0.5245 - val_loss: 0.6912 - val_accuracy: 0.5155\n",
      "Epoch 63/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5256 - val_loss: 0.6911 - val_accuracy: 0.5176\n",
      "Epoch 64/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5250 - val_loss: 0.6909 - val_accuracy: 0.5184\n",
      "Epoch 65/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5242 - val_loss: 0.6913 - val_accuracy: 0.5170\n",
      "Epoch 66/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5252 - val_loss: 0.6910 - val_accuracy: 0.5197\n",
      "Epoch 67/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5224 - val_loss: 0.6911 - val_accuracy: 0.5147\n",
      "Epoch 68/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5236 - val_loss: 0.6911 - val_accuracy: 0.5195\n",
      "Epoch 69/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5253 - val_loss: 0.6914 - val_accuracy: 0.5181\n",
      "Epoch 70/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5236 - val_loss: 0.6914 - val_accuracy: 0.5173\n",
      "Epoch 71/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5253 - val_loss: 0.6911 - val_accuracy: 0.5171\n",
      "Epoch 72/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5247 - val_loss: 0.6914 - val_accuracy: 0.5169\n",
      "Epoch 73/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5248 - val_loss: 0.6913 - val_accuracy: 0.5178\n",
      "Epoch 74/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5233 - val_loss: 0.6910 - val_accuracy: 0.5180\n",
      "Epoch 75/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5244 - val_loss: 0.6910 - val_accuracy: 0.5189\n",
      "Epoch 76/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5234 - val_loss: 0.6913 - val_accuracy: 0.5195\n",
      "Epoch 77/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5248 - val_loss: 0.6909 - val_accuracy: 0.5175\n",
      "Epoch 78/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5258 - val_loss: 0.6909 - val_accuracy: 0.5188\n",
      "Epoch 79/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5237 - val_loss: 0.6911 - val_accuracy: 0.5180\n",
      "Epoch 80/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5253 - val_loss: 0.6910 - val_accuracy: 0.5192\n",
      "Epoch 81/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5261 - val_loss: 0.6911 - val_accuracy: 0.5168\n",
      "Epoch 82/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5261 - val_loss: 0.6909 - val_accuracy: 0.5187\n",
      "Epoch 83/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5248 - val_loss: 0.6910 - val_accuracy: 0.5175\n",
      "Epoch 84/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5244 - val_loss: 0.6911 - val_accuracy: 0.5200\n",
      "Epoch 85/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5261 - val_loss: 0.6913 - val_accuracy: 0.5189\n",
      "Epoch 86/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5239 - val_loss: 0.6910 - val_accuracy: 0.5197\n",
      "Training with significance = 4.41, run 2\n",
      "Train on 41558 samples, validate on 10390 samples\n",
      "Epoch 1/1000\n",
      "41558/41558 [==============================] - 1s 28us/sample - loss: 0.6971 - accuracy: 0.4998 - val_loss: 0.6935 - val_accuracy: 0.5004\n",
      "Epoch 2/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6928 - accuracy: 0.5075 - val_loss: 0.6927 - val_accuracy: 0.5115\n",
      "Epoch 3/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6925 - accuracy: 0.5125 - val_loss: 0.6919 - val_accuracy: 0.5192\n",
      "Epoch 4/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5154 - val_loss: 0.6915 - val_accuracy: 0.5270\n",
      "Epoch 5/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5150 - val_loss: 0.6913 - val_accuracy: 0.5237\n",
      "Epoch 6/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5160 - val_loss: 0.6911 - val_accuracy: 0.5235\n",
      "Epoch 7/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5161 - val_loss: 0.6910 - val_accuracy: 0.5228\n",
      "Epoch 8/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5167 - val_loss: 0.6910 - val_accuracy: 0.5231\n",
      "Epoch 9/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5165 - val_loss: 0.6911 - val_accuracy: 0.5255\n",
      "Epoch 10/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5167 - val_loss: 0.6911 - val_accuracy: 0.5232\n",
      "Epoch 11/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5182 - val_loss: 0.6910 - val_accuracy: 0.5258\n",
      "Epoch 12/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5169 - val_loss: 0.6909 - val_accuracy: 0.5235\n",
      "Epoch 13/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5172 - val_loss: 0.6909 - val_accuracy: 0.5238\n",
      "Epoch 14/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5176 - val_loss: 0.6909 - val_accuracy: 0.5257\n",
      "Epoch 15/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5181 - val_loss: 0.6908 - val_accuracy: 0.5260\n",
      "Epoch 16/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5165 - val_loss: 0.6908 - val_accuracy: 0.5256\n",
      "Epoch 17/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5183 - val_loss: 0.6909 - val_accuracy: 0.5237\n",
      "Epoch 18/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5199 - val_loss: 0.6907 - val_accuracy: 0.5268\n",
      "Epoch 19/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5192 - val_loss: 0.6907 - val_accuracy: 0.5235\n",
      "Epoch 20/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5188 - val_loss: 0.6908 - val_accuracy: 0.5240\n",
      "Epoch 21/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5193 - val_loss: 0.6908 - val_accuracy: 0.5236\n",
      "Epoch 22/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5179 - val_loss: 0.6907 - val_accuracy: 0.5244\n",
      "Epoch 23/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5178 - val_loss: 0.6907 - val_accuracy: 0.5244\n",
      "Epoch 24/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5190 - val_loss: 0.6908 - val_accuracy: 0.5210\n",
      "Epoch 25/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5185 - val_loss: 0.6908 - val_accuracy: 0.5243\n",
      "Epoch 26/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5191 - val_loss: 0.6910 - val_accuracy: 0.5211\n",
      "Epoch 27/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5197 - val_loss: 0.6907 - val_accuracy: 0.5216\n",
      "Epoch 28/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6916 - accuracy: 0.5185 - val_loss: 0.6908 - val_accuracy: 0.5199\n",
      "Epoch 29/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5208 - val_loss: 0.6908 - val_accuracy: 0.5222\n",
      "Epoch 30/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5199 - val_loss: 0.6910 - val_accuracy: 0.5216\n",
      "Epoch 31/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5199 - val_loss: 0.6907 - val_accuracy: 0.5223\n",
      "Epoch 32/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5202 - val_loss: 0.6907 - val_accuracy: 0.5220\n",
      "Epoch 33/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5188 - val_loss: 0.6907 - val_accuracy: 0.5233\n",
      "Epoch 34/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5202 - val_loss: 0.6908 - val_accuracy: 0.5240\n",
      "Epoch 35/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5186 - val_loss: 0.6908 - val_accuracy: 0.5269\n",
      "Epoch 36/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5197 - val_loss: 0.6907 - val_accuracy: 0.5246\n",
      "Epoch 37/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5182 - val_loss: 0.6906 - val_accuracy: 0.5222\n",
      "Epoch 38/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5195 - val_loss: 0.6908 - val_accuracy: 0.5194\n",
      "Epoch 39/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5195 - val_loss: 0.6907 - val_accuracy: 0.5227\n",
      "Epoch 40/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5204 - val_loss: 0.6907 - val_accuracy: 0.5222\n",
      "Epoch 41/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5210 - val_loss: 0.6908 - val_accuracy: 0.5218\n",
      "Epoch 42/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5214 - val_loss: 0.6908 - val_accuracy: 0.5218\n",
      "Epoch 43/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5208 - val_loss: 0.6906 - val_accuracy: 0.5214\n",
      "Epoch 44/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5199 - val_loss: 0.6906 - val_accuracy: 0.5265\n",
      "Epoch 45/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5215 - val_loss: 0.6907 - val_accuracy: 0.5233\n",
      "Epoch 46/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5212 - val_loss: 0.6907 - val_accuracy: 0.5240\n",
      "Epoch 47/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5210 - val_loss: 0.6907 - val_accuracy: 0.5208\n",
      "Epoch 48/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5197 - val_loss: 0.6907 - val_accuracy: 0.5208\n",
      "Epoch 49/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5190 - val_loss: 0.6906 - val_accuracy: 0.5230\n",
      "Epoch 50/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5205 - val_loss: 0.6907 - val_accuracy: 0.5254\n",
      "Epoch 51/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5196 - val_loss: 0.6906 - val_accuracy: 0.5239\n",
      "Epoch 52/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5220 - val_loss: 0.6907 - val_accuracy: 0.5221\n",
      "Epoch 53/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6914 - accuracy: 0.5219 - val_loss: 0.6907 - val_accuracy: 0.5222\n",
      "Epoch 54/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6914 - accuracy: 0.5215 - val_loss: 0.6906 - val_accuracy: 0.5213\n",
      "Epoch 55/1000\n",
      "41558/41558 [==============================] - 0s 12us/sample - loss: 0.6914 - accuracy: 0.5199 - val_loss: 0.6906 - val_accuracy: 0.5196\n",
      "Epoch 56/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6914 - accuracy: 0.5216 - val_loss: 0.6906 - val_accuracy: 0.5219\n",
      "Epoch 57/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5244 - val_loss: 0.6906 - val_accuracy: 0.5257\n",
      "Epoch 58/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5208 - val_loss: 0.6906 - val_accuracy: 0.5219\n",
      "Epoch 59/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5223 - val_loss: 0.6905 - val_accuracy: 0.5264\n",
      "Epoch 60/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5234 - val_loss: 0.6905 - val_accuracy: 0.5236\n",
      "Epoch 61/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5199 - val_loss: 0.6906 - val_accuracy: 0.5241\n",
      "Epoch 62/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5223 - val_loss: 0.6906 - val_accuracy: 0.5244\n",
      "Epoch 63/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5208 - val_loss: 0.6908 - val_accuracy: 0.5232\n",
      "Epoch 64/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5214 - val_loss: 0.6905 - val_accuracy: 0.5258\n",
      "Epoch 65/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5231 - val_loss: 0.6906 - val_accuracy: 0.5226\n",
      "Epoch 66/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5220 - val_loss: 0.6906 - val_accuracy: 0.5252\n",
      "Epoch 67/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5221 - val_loss: 0.6906 - val_accuracy: 0.5216\n",
      "Epoch 68/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5206 - val_loss: 0.6906 - val_accuracy: 0.5219\n",
      "Epoch 69/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5228 - val_loss: 0.6907 - val_accuracy: 0.5210\n",
      "Epoch 70/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5216 - val_loss: 0.6906 - val_accuracy: 0.5244\n",
      "Epoch 71/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5222 - val_loss: 0.6906 - val_accuracy: 0.5237\n",
      "Epoch 72/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5205 - val_loss: 0.6906 - val_accuracy: 0.5237\n",
      "Epoch 73/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5210 - val_loss: 0.6907 - val_accuracy: 0.5212\n",
      "Epoch 74/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5212 - val_loss: 0.6907 - val_accuracy: 0.5227\n",
      "Epoch 75/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5225 - val_loss: 0.6906 - val_accuracy: 0.5242\n",
      "Epoch 76/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5225 - val_loss: 0.6906 - val_accuracy: 0.5231\n",
      "Epoch 77/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5215 - val_loss: 0.6908 - val_accuracy: 0.5204\n",
      "Epoch 78/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5233 - val_loss: 0.6905 - val_accuracy: 0.5248\n",
      "Epoch 79/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5234 - val_loss: 0.6906 - val_accuracy: 0.5243\n",
      "Epoch 80/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5234 - val_loss: 0.6907 - val_accuracy: 0.5225\n",
      "Epoch 81/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5249 - val_loss: 0.6906 - val_accuracy: 0.5220\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5205 - val_loss: 0.6905 - val_accuracy: 0.5223\n",
      "Epoch 83/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5205 - val_loss: 0.6905 - val_accuracy: 0.5229\n",
      "Epoch 84/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5228 - val_loss: 0.6905 - val_accuracy: 0.5251\n",
      "Epoch 85/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5252 - val_loss: 0.6906 - val_accuracy: 0.5226\n",
      "Epoch 86/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5216 - val_loss: 0.6905 - val_accuracy: 0.5261\n",
      "Epoch 87/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5245 - val_loss: 0.6905 - val_accuracy: 0.5246\n",
      "Epoch 88/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5239 - val_loss: 0.6905 - val_accuracy: 0.5219\n",
      "Epoch 89/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5234 - val_loss: 0.6905 - val_accuracy: 0.5245\n",
      "Epoch 90/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5216 - val_loss: 0.6905 - val_accuracy: 0.5249\n",
      "Epoch 91/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5231 - val_loss: 0.6906 - val_accuracy: 0.5213\n",
      "Epoch 92/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5242 - val_loss: 0.6905 - val_accuracy: 0.5253\n",
      "Epoch 93/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5234 - val_loss: 0.6904 - val_accuracy: 0.5243\n",
      "Epoch 94/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5255 - val_loss: 0.6905 - val_accuracy: 0.5213\n",
      "Epoch 95/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5225 - val_loss: 0.6906 - val_accuracy: 0.5230\n",
      "Epoch 96/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5235 - val_loss: 0.6905 - val_accuracy: 0.5235\n",
      "Epoch 97/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5218 - val_loss: 0.6905 - val_accuracy: 0.5260\n",
      "Epoch 98/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5207 - val_loss: 0.6905 - val_accuracy: 0.5235\n",
      "Epoch 99/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5224 - val_loss: 0.6905 - val_accuracy: 0.5255\n",
      "Epoch 100/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5229 - val_loss: 0.6905 - val_accuracy: 0.5265\n",
      "Epoch 101/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5234 - val_loss: 0.6905 - val_accuracy: 0.5238\n",
      "Epoch 102/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5239 - val_loss: 0.6905 - val_accuracy: 0.5254\n",
      "Epoch 103/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5235 - val_loss: 0.6904 - val_accuracy: 0.5249\n",
      "Epoch 104/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5244 - val_loss: 0.6905 - val_accuracy: 0.5250\n",
      "Epoch 105/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5244 - val_loss: 0.6906 - val_accuracy: 0.5219\n",
      "Epoch 106/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5211 - val_loss: 0.6905 - val_accuracy: 0.5236\n",
      "Epoch 107/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5217 - val_loss: 0.6905 - val_accuracy: 0.5207\n",
      "Epoch 108/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5245 - val_loss: 0.6906 - val_accuracy: 0.5251\n",
      "Epoch 109/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5233 - val_loss: 0.6906 - val_accuracy: 0.5237\n",
      "Epoch 110/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5250 - val_loss: 0.6908 - val_accuracy: 0.5229\n",
      "Epoch 111/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5228 - val_loss: 0.6906 - val_accuracy: 0.5222\n",
      "Epoch 112/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6909 - accuracy: 0.5234 - val_loss: 0.6905 - val_accuracy: 0.5220\n",
      "Epoch 113/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5246 - val_loss: 0.6905 - val_accuracy: 0.5267\n",
      "Epoch 114/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5249 - val_loss: 0.6906 - val_accuracy: 0.5214\n",
      "Epoch 115/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5247 - val_loss: 0.6906 - val_accuracy: 0.5233\n",
      "Epoch 116/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5218 - val_loss: 0.6905 - val_accuracy: 0.5251\n",
      "Epoch 117/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5241 - val_loss: 0.6906 - val_accuracy: 0.5226\n",
      "Epoch 118/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5247 - val_loss: 0.6905 - val_accuracy: 0.5249\n",
      "Epoch 119/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5205 - val_loss: 0.6905 - val_accuracy: 0.5220\n",
      "Epoch 120/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5236 - val_loss: 0.6907 - val_accuracy: 0.5270\n",
      "Epoch 121/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6909 - accuracy: 0.5239 - val_loss: 0.6906 - val_accuracy: 0.5228\n",
      "Epoch 122/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5239 - val_loss: 0.6906 - val_accuracy: 0.5224\n",
      "Epoch 123/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5226 - val_loss: 0.6906 - val_accuracy: 0.5262\n",
      "Epoch 124/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5220 - val_loss: 0.6905 - val_accuracy: 0.5262\n",
      "Epoch 125/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5232 - val_loss: 0.6905 - val_accuracy: 0.5242\n",
      "Epoch 126/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5228 - val_loss: 0.6906 - val_accuracy: 0.5279\n",
      "Epoch 127/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6909 - accuracy: 0.5254 - val_loss: 0.6906 - val_accuracy: 0.5222\n",
      "Epoch 128/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6910 - accuracy: 0.5240 - val_loss: 0.6905 - val_accuracy: 0.5214\n",
      "Epoch 129/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6910 - accuracy: 0.5229 - val_loss: 0.6905 - val_accuracy: 0.5218\n",
      "Epoch 130/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6909 - accuracy: 0.5253 - val_loss: 0.6905 - val_accuracy: 0.5266\n",
      "Epoch 131/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6909 - accuracy: 0.5230 - val_loss: 0.6906 - val_accuracy: 0.5251\n",
      "Epoch 132/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6910 - accuracy: 0.5231 - val_loss: 0.6906 - val_accuracy: 0.5251\n",
      "Epoch 133/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6911 - accuracy: 0.5227 - val_loss: 0.6905 - val_accuracy: 0.5244\n",
      "Training with significance = 4.41, run 3\n",
      "Train on 41558 samples, validate on 10390 samples\n",
      "Epoch 1/1000\n",
      "41558/41558 [==============================] - 1s 27us/sample - loss: 0.6945 - accuracy: 0.5036 - val_loss: 0.6935 - val_accuracy: 0.5047\n",
      "Epoch 2/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6928 - accuracy: 0.5088 - val_loss: 0.6926 - val_accuracy: 0.5109\n",
      "Epoch 3/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6923 - accuracy: 0.5147 - val_loss: 0.6925 - val_accuracy: 0.5194\n",
      "Epoch 4/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6920 - accuracy: 0.5149 - val_loss: 0.6924 - val_accuracy: 0.5167\n",
      "Epoch 5/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5151 - val_loss: 0.6923 - val_accuracy: 0.5193\n",
      "Epoch 6/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5156 - val_loss: 0.6922 - val_accuracy: 0.5189\n",
      "Epoch 7/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5163 - val_loss: 0.6924 - val_accuracy: 0.5152\n",
      "Epoch 8/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5177 - val_loss: 0.6921 - val_accuracy: 0.5179\n",
      "Epoch 9/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5160 - val_loss: 0.6921 - val_accuracy: 0.5168\n",
      "Epoch 10/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5154 - val_loss: 0.6921 - val_accuracy: 0.5169\n",
      "Epoch 11/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5155 - val_loss: 0.6921 - val_accuracy: 0.5165\n",
      "Epoch 12/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5165 - val_loss: 0.6924 - val_accuracy: 0.5124\n",
      "Epoch 13/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5163 - val_loss: 0.6920 - val_accuracy: 0.5166\n",
      "Epoch 14/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5177 - val_loss: 0.6922 - val_accuracy: 0.5140\n",
      "Epoch 15/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5174 - val_loss: 0.6922 - val_accuracy: 0.5158\n",
      "Epoch 16/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5182 - val_loss: 0.6921 - val_accuracy: 0.5194\n",
      "Epoch 17/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5171 - val_loss: 0.6922 - val_accuracy: 0.5167\n",
      "Epoch 18/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5164 - val_loss: 0.6921 - val_accuracy: 0.5145\n",
      "Epoch 19/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5186 - val_loss: 0.6922 - val_accuracy: 0.5174\n",
      "Epoch 20/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5184 - val_loss: 0.6922 - val_accuracy: 0.5154\n",
      "Epoch 21/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5183 - val_loss: 0.6921 - val_accuracy: 0.5143\n",
      "Epoch 22/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5181 - val_loss: 0.6921 - val_accuracy: 0.5159\n",
      "Epoch 23/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6911 - accuracy: 0.5188 - val_loss: 0.6924 - val_accuracy: 0.5160\n",
      "Epoch 24/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5180 - val_loss: 0.6921 - val_accuracy: 0.5145\n",
      "Epoch 25/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5180 - val_loss: 0.6922 - val_accuracy: 0.5148\n",
      "Epoch 26/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6912 - accuracy: 0.5180 - val_loss: 0.6920 - val_accuracy: 0.5186\n",
      "Epoch 27/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5185 - val_loss: 0.6922 - val_accuracy: 0.5189\n",
      "Epoch 28/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5184 - val_loss: 0.6923 - val_accuracy: 0.5165\n",
      "Epoch 29/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5180 - val_loss: 0.6921 - val_accuracy: 0.5169\n",
      "Epoch 30/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5194 - val_loss: 0.6920 - val_accuracy: 0.5166\n",
      "Epoch 31/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5190 - val_loss: 0.6921 - val_accuracy: 0.5170\n",
      "Epoch 32/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5196 - val_loss: 0.6922 - val_accuracy: 0.5171\n",
      "Epoch 33/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6911 - accuracy: 0.5186 - val_loss: 0.6921 - val_accuracy: 0.5162\n",
      "Epoch 34/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5182 - val_loss: 0.6920 - val_accuracy: 0.5161\n",
      "Epoch 35/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5194 - val_loss: 0.6923 - val_accuracy: 0.5115\n",
      "Epoch 36/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5212 - val_loss: 0.6921 - val_accuracy: 0.5149\n",
      "Epoch 37/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6910 - accuracy: 0.5207 - val_loss: 0.6923 - val_accuracy: 0.5156\n",
      "Epoch 38/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5193 - val_loss: 0.6921 - val_accuracy: 0.5186\n",
      "Epoch 39/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5193 - val_loss: 0.6921 - val_accuracy: 0.5153\n",
      "Epoch 40/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5195 - val_loss: 0.6921 - val_accuracy: 0.5203\n",
      "Epoch 41/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5180 - val_loss: 0.6922 - val_accuracy: 0.5181\n",
      "Epoch 42/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5198 - val_loss: 0.6922 - val_accuracy: 0.5167\n",
      "Epoch 43/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6909 - accuracy: 0.5210 - val_loss: 0.6921 - val_accuracy: 0.5176\n",
      "Epoch 44/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5216 - val_loss: 0.6920 - val_accuracy: 0.5176\n",
      "Epoch 45/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5205 - val_loss: 0.6922 - val_accuracy: 0.5185\n",
      "Epoch 46/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5196 - val_loss: 0.6921 - val_accuracy: 0.5132\n",
      "Epoch 47/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5211 - val_loss: 0.6924 - val_accuracy: 0.5151\n",
      "Epoch 48/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5207 - val_loss: 0.6921 - val_accuracy: 0.5127\n",
      "Epoch 49/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5199 - val_loss: 0.6921 - val_accuracy: 0.5180\n",
      "Epoch 50/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5217 - val_loss: 0.6921 - val_accuracy: 0.5181\n",
      "Epoch 51/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5209 - val_loss: 0.6922 - val_accuracy: 0.5116\n",
      "Epoch 52/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5205 - val_loss: 0.6922 - val_accuracy: 0.5182\n",
      "Epoch 53/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5210 - val_loss: 0.6922 - val_accuracy: 0.5133\n",
      "Epoch 54/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5218 - val_loss: 0.6920 - val_accuracy: 0.5144\n",
      "Epoch 55/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5219 - val_loss: 0.6923 - val_accuracy: 0.5137\n",
      "Epoch 56/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5205 - val_loss: 0.6921 - val_accuracy: 0.5158\n",
      "Epoch 57/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5208 - val_loss: 0.6921 - val_accuracy: 0.5167\n",
      "Epoch 58/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5216 - val_loss: 0.6921 - val_accuracy: 0.5134\n",
      "Epoch 59/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5204 - val_loss: 0.6923 - val_accuracy: 0.5160\n",
      "Epoch 60/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6909 - accuracy: 0.5204 - val_loss: 0.6922 - val_accuracy: 0.5134\n",
      "Epoch 61/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5238 - val_loss: 0.6921 - val_accuracy: 0.5160\n",
      "Epoch 62/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5201 - val_loss: 0.6921 - val_accuracy: 0.5125\n",
      "Epoch 63/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6908 - accuracy: 0.5221 - val_loss: 0.6922 - val_accuracy: 0.5140\n",
      "Epoch 64/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5233 - val_loss: 0.6921 - val_accuracy: 0.5166\n",
      "Training with significance = 4.41, run 4\n",
      "Train on 41558 samples, validate on 10390 samples\n",
      "Epoch 1/1000\n",
      "41558/41558 [==============================] - 1s 27us/sample - loss: 0.6937 - accuracy: 0.5044 - val_loss: 0.6945 - val_accuracy: 0.4987\n",
      "Epoch 2/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5159 - val_loss: 0.6937 - val_accuracy: 0.5096\n",
      "Epoch 3/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6918 - accuracy: 0.5162 - val_loss: 0.6929 - val_accuracy: 0.5097\n",
      "Epoch 4/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6916 - accuracy: 0.5185 - val_loss: 0.6922 - val_accuracy: 0.5168\n",
      "Epoch 5/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6915 - accuracy: 0.5197 - val_loss: 0.6926 - val_accuracy: 0.5127\n",
      "Epoch 6/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6914 - accuracy: 0.5190 - val_loss: 0.6922 - val_accuracy: 0.5125\n",
      "Epoch 7/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5192 - val_loss: 0.6919 - val_accuracy: 0.5178\n",
      "Epoch 8/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5194 - val_loss: 0.6921 - val_accuracy: 0.5129\n",
      "Epoch 9/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6912 - accuracy: 0.5201 - val_loss: 0.6922 - val_accuracy: 0.5116\n",
      "Epoch 10/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6912 - accuracy: 0.5199 - val_loss: 0.6920 - val_accuracy: 0.5183\n",
      "Epoch 11/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6911 - accuracy: 0.5209 - val_loss: 0.6921 - val_accuracy: 0.5142\n",
      "Epoch 12/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5193 - val_loss: 0.6921 - val_accuracy: 0.5148\n",
      "Epoch 13/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5198 - val_loss: 0.6922 - val_accuracy: 0.5127\n",
      "Epoch 14/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5209 - val_loss: 0.6921 - val_accuracy: 0.5137\n",
      "Epoch 15/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5214 - val_loss: 0.6921 - val_accuracy: 0.5137\n",
      "Epoch 16/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5206 - val_loss: 0.6918 - val_accuracy: 0.5159\n",
      "Epoch 17/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5208 - val_loss: 0.6921 - val_accuracy: 0.5151\n",
      "Epoch 18/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5193 - val_loss: 0.6919 - val_accuracy: 0.5146\n",
      "Epoch 19/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5204 - val_loss: 0.6919 - val_accuracy: 0.5141\n",
      "Epoch 20/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5207 - val_loss: 0.6920 - val_accuracy: 0.5133\n",
      "Epoch 21/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6908 - accuracy: 0.5224 - val_loss: 0.6918 - val_accuracy: 0.5150\n",
      "Epoch 22/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6908 - accuracy: 0.5219 - val_loss: 0.6918 - val_accuracy: 0.5172\n",
      "Epoch 23/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5215 - val_loss: 0.6918 - val_accuracy: 0.5146\n",
      "Epoch 24/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5230 - val_loss: 0.6917 - val_accuracy: 0.5160\n",
      "Epoch 25/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5225 - val_loss: 0.6917 - val_accuracy: 0.5183\n",
      "Epoch 26/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5216 - val_loss: 0.6919 - val_accuracy: 0.5147\n",
      "Epoch 27/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5223 - val_loss: 0.6918 - val_accuracy: 0.5178\n",
      "Epoch 28/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5221 - val_loss: 0.6920 - val_accuracy: 0.5122\n",
      "Epoch 29/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5213 - val_loss: 0.6919 - val_accuracy: 0.5152\n",
      "Epoch 30/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5224 - val_loss: 0.6919 - val_accuracy: 0.5155\n",
      "Epoch 31/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5235 - val_loss: 0.6917 - val_accuracy: 0.5144\n",
      "Epoch 32/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5133\n",
      "Epoch 33/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5229 - val_loss: 0.6919 - val_accuracy: 0.5143\n",
      "Epoch 34/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5223 - val_loss: 0.6919 - val_accuracy: 0.5155\n",
      "Epoch 35/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5224 - val_loss: 0.6918 - val_accuracy: 0.5161\n",
      "Epoch 36/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5232 - val_loss: 0.6920 - val_accuracy: 0.5190\n",
      "Epoch 37/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5223 - val_loss: 0.6918 - val_accuracy: 0.5158\n",
      "Epoch 38/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5228 - val_loss: 0.6918 - val_accuracy: 0.5169\n",
      "Epoch 39/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5235 - val_loss: 0.6920 - val_accuracy: 0.5155\n",
      "Epoch 40/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5243 - val_loss: 0.6917 - val_accuracy: 0.5186\n",
      "Epoch 41/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5257 - val_loss: 0.6918 - val_accuracy: 0.5147\n",
      "Epoch 42/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5234 - val_loss: 0.6920 - val_accuracy: 0.5168\n",
      "Epoch 43/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5247 - val_loss: 0.6918 - val_accuracy: 0.5187\n",
      "Epoch 44/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5210 - val_loss: 0.6920 - val_accuracy: 0.5186\n",
      "Epoch 45/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5216 - val_loss: 0.6917 - val_accuracy: 0.5182\n",
      "Epoch 46/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5231 - val_loss: 0.6918 - val_accuracy: 0.5147\n",
      "Epoch 47/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5249 - val_loss: 0.6918 - val_accuracy: 0.5163\n",
      "Epoch 48/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5224 - val_loss: 0.6918 - val_accuracy: 0.5193\n",
      "Epoch 49/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5248 - val_loss: 0.6917 - val_accuracy: 0.5161\n",
      "Epoch 50/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5247 - val_loss: 0.6917 - val_accuracy: 0.5184\n",
      "Epoch 51/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5243 - val_loss: 0.6920 - val_accuracy: 0.5179\n",
      "Epoch 52/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5237 - val_loss: 0.6917 - val_accuracy: 0.5191\n",
      "Epoch 53/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6903 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5157\n",
      "Epoch 54/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6901 - accuracy: 0.5233 - val_loss: 0.6921 - val_accuracy: 0.5188\n",
      "Epoch 55/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5245 - val_loss: 0.6917 - val_accuracy: 0.5178\n",
      "Epoch 56/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6903 - accuracy: 0.5233 - val_loss: 0.6920 - val_accuracy: 0.5192\n",
      "Epoch 57/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5246 - val_loss: 0.6920 - val_accuracy: 0.5161\n",
      "Epoch 58/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6904 - accuracy: 0.5237 - val_loss: 0.6919 - val_accuracy: 0.5166\n",
      "Epoch 59/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5253 - val_loss: 0.6922 - val_accuracy: 0.5183\n",
      "Epoch 60/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6902 - accuracy: 0.5243 - val_loss: 0.6917 - val_accuracy: 0.5180\n",
      "Epoch 61/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5251 - val_loss: 0.6918 - val_accuracy: 0.5171\n",
      "Epoch 62/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5244 - val_loss: 0.6918 - val_accuracy: 0.5192\n",
      "Epoch 63/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5248 - val_loss: 0.6917 - val_accuracy: 0.5185\n",
      "Epoch 64/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5239 - val_loss: 0.6921 - val_accuracy: 0.5163\n",
      "Epoch 65/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5207 - val_loss: 0.6919 - val_accuracy: 0.5206\n",
      "Epoch 66/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5248 - val_loss: 0.6921 - val_accuracy: 0.5197\n",
      "Epoch 67/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5233 - val_loss: 0.6921 - val_accuracy: 0.5240\n",
      "Epoch 68/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5241 - val_loss: 0.6919 - val_accuracy: 0.5199\n",
      "Epoch 69/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5256 - val_loss: 0.6919 - val_accuracy: 0.5173\n",
      "Epoch 70/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5242 - val_loss: 0.6918 - val_accuracy: 0.5199\n",
      "Epoch 71/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5230 - val_loss: 0.6919 - val_accuracy: 0.5171\n",
      "Epoch 72/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5257 - val_loss: 0.6919 - val_accuracy: 0.5198\n",
      "Epoch 73/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5256 - val_loss: 0.6921 - val_accuracy: 0.5183\n",
      "Epoch 74/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5238 - val_loss: 0.6921 - val_accuracy: 0.5213\n",
      "Epoch 75/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6901 - accuracy: 0.5250 - val_loss: 0.6919 - val_accuracy: 0.5179\n",
      "Training with significance = 4.41, run 5\n",
      "Train on 41558 samples, validate on 10390 samples\n",
      "Epoch 1/1000\n",
      "41558/41558 [==============================] - 1s 27us/sample - loss: 0.6934 - accuracy: 0.5107 - val_loss: 0.6944 - val_accuracy: 0.5012\n",
      "Epoch 2/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5170 - val_loss: 0.6935 - val_accuracy: 0.5117\n",
      "Epoch 3/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5180 - val_loss: 0.6930 - val_accuracy: 0.5132\n",
      "Epoch 4/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5176 - val_loss: 0.6926 - val_accuracy: 0.5106\n",
      "Epoch 5/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5174 - val_loss: 0.6930 - val_accuracy: 0.5124\n",
      "Epoch 6/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6917 - accuracy: 0.5167 - val_loss: 0.6922 - val_accuracy: 0.5143\n",
      "Epoch 7/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5181 - val_loss: 0.6920 - val_accuracy: 0.5166\n",
      "Epoch 8/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5174 - val_loss: 0.6919 - val_accuracy: 0.5102\n",
      "Epoch 9/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5180 - val_loss: 0.6922 - val_accuracy: 0.5164\n",
      "Epoch 10/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5181 - val_loss: 0.6921 - val_accuracy: 0.5151\n",
      "Epoch 11/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5198 - val_loss: 0.6918 - val_accuracy: 0.5171\n",
      "Epoch 12/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5190 - val_loss: 0.6921 - val_accuracy: 0.5141\n",
      "Epoch 13/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6912 - accuracy: 0.5187 - val_loss: 0.6921 - val_accuracy: 0.5144\n",
      "Epoch 14/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5194 - val_loss: 0.6919 - val_accuracy: 0.5146\n",
      "Epoch 15/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5201 - val_loss: 0.6921 - val_accuracy: 0.5129\n",
      "Epoch 16/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5214 - val_loss: 0.6920 - val_accuracy: 0.5141\n",
      "Epoch 17/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5194 - val_loss: 0.6919 - val_accuracy: 0.5160\n",
      "Epoch 18/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6910 - accuracy: 0.5205 - val_loss: 0.6919 - val_accuracy: 0.5139\n",
      "Epoch 19/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5199 - val_loss: 0.6920 - val_accuracy: 0.5154\n",
      "Epoch 20/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5206 - val_loss: 0.6919 - val_accuracy: 0.5152\n",
      "Epoch 21/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5193 - val_loss: 0.6924 - val_accuracy: 0.5131\n",
      "Epoch 22/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5205 - val_loss: 0.6917 - val_accuracy: 0.5135\n",
      "Epoch 23/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6910 - accuracy: 0.5210 - val_loss: 0.6921 - val_accuracy: 0.5143\n",
      "Epoch 24/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6911 - accuracy: 0.5201 - val_loss: 0.6921 - val_accuracy: 0.5116\n",
      "Epoch 25/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6910 - accuracy: 0.5201 - val_loss: 0.6919 - val_accuracy: 0.5147\n",
      "Epoch 26/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6911 - accuracy: 0.5203 - val_loss: 0.6921 - val_accuracy: 0.5108\n",
      "Epoch 27/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5220 - val_loss: 0.6919 - val_accuracy: 0.5135\n",
      "Epoch 28/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6910 - accuracy: 0.5223 - val_loss: 0.6918 - val_accuracy: 0.5139\n",
      "Epoch 29/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5211 - val_loss: 0.6919 - val_accuracy: 0.5133\n",
      "Epoch 30/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6909 - accuracy: 0.5221 - val_loss: 0.6925 - val_accuracy: 0.5135\n",
      "Epoch 31/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5206 - val_loss: 0.6920 - val_accuracy: 0.5139\n",
      "Epoch 32/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5226 - val_loss: 0.6920 - val_accuracy: 0.5144\n",
      "Epoch 33/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5204 - val_loss: 0.6924 - val_accuracy: 0.5135\n",
      "Epoch 34/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5237 - val_loss: 0.6927 - val_accuracy: 0.5057\n",
      "Epoch 35/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5228 - val_loss: 0.6922 - val_accuracy: 0.5135\n",
      "Epoch 36/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5237 - val_loss: 0.6919 - val_accuracy: 0.5094\n",
      "Epoch 37/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5236 - val_loss: 0.6921 - val_accuracy: 0.5118\n",
      "Epoch 38/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5230 - val_loss: 0.6922 - val_accuracy: 0.5119\n",
      "Epoch 39/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5224 - val_loss: 0.6921 - val_accuracy: 0.5119\n",
      "Epoch 40/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5219 - val_loss: 0.6921 - val_accuracy: 0.5139\n",
      "Epoch 41/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5235 - val_loss: 0.6919 - val_accuracy: 0.5070\n",
      "Epoch 42/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5251 - val_loss: 0.6920 - val_accuracy: 0.5111\n",
      "Epoch 43/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6908 - accuracy: 0.5220 - val_loss: 0.6920 - val_accuracy: 0.5115\n",
      "Epoch 44/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6908 - accuracy: 0.5232 - val_loss: 0.6920 - val_accuracy: 0.5127\n",
      "Epoch 45/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5207 - val_loss: 0.6919 - val_accuracy: 0.5109\n",
      "Epoch 46/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5241 - val_loss: 0.6921 - val_accuracy: 0.5122\n",
      "Epoch 47/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5246 - val_loss: 0.6922 - val_accuracy: 0.5137\n",
      "Epoch 48/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6907 - accuracy: 0.5229 - val_loss: 0.6919 - val_accuracy: 0.5109\n",
      "Epoch 49/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5233 - val_loss: 0.6919 - val_accuracy: 0.5132\n",
      "Epoch 50/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6908 - accuracy: 0.5226 - val_loss: 0.6922 - val_accuracy: 0.5115\n",
      "Epoch 51/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5234 - val_loss: 0.6922 - val_accuracy: 0.5111\n",
      "Epoch 52/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5231 - val_loss: 0.6920 - val_accuracy: 0.5106\n",
      "Training with significance = 4.41, run 6\n",
      "Train on 41558 samples, validate on 10390 samples\n",
      "Epoch 1/1000\n",
      "41558/41558 [==============================] - 1s 27us/sample - loss: 0.6934 - accuracy: 0.5052 - val_loss: 0.6954 - val_accuracy: 0.5019\n",
      "Epoch 2/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5160 - val_loss: 0.6927 - val_accuracy: 0.5117\n",
      "Epoch 3/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5157 - val_loss: 0.6924 - val_accuracy: 0.5122\n",
      "Epoch 4/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5170 - val_loss: 0.6917 - val_accuracy: 0.5144\n",
      "Epoch 5/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5204 - val_loss: 0.6916 - val_accuracy: 0.5162\n",
      "Epoch 6/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5186 - val_loss: 0.6913 - val_accuracy: 0.5163\n",
      "Epoch 7/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5198 - val_loss: 0.6912 - val_accuracy: 0.5194\n",
      "Epoch 8/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5157 - val_loss: 0.6912 - val_accuracy: 0.5185\n",
      "Epoch 9/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5188 - val_loss: 0.6911 - val_accuracy: 0.5207\n",
      "Epoch 10/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5162 - val_loss: 0.6911 - val_accuracy: 0.5228\n",
      "Epoch 11/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5185 - val_loss: 0.6911 - val_accuracy: 0.5175\n",
      "Epoch 12/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5181 - val_loss: 0.6910 - val_accuracy: 0.5240\n",
      "Epoch 13/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6915 - accuracy: 0.5196 - val_loss: 0.6910 - val_accuracy: 0.5215\n",
      "Epoch 14/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6915 - accuracy: 0.5173 - val_loss: 0.6910 - val_accuracy: 0.5216\n",
      "Epoch 15/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5196 - val_loss: 0.6909 - val_accuracy: 0.5210\n",
      "Epoch 16/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6914 - accuracy: 0.5175 - val_loss: 0.6911 - val_accuracy: 0.5192\n",
      "Epoch 17/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5175 - val_loss: 0.6910 - val_accuracy: 0.5173\n",
      "Epoch 18/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5200 - val_loss: 0.6913 - val_accuracy: 0.5143\n",
      "Epoch 19/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5182 - val_loss: 0.6911 - val_accuracy: 0.5197\n",
      "Epoch 20/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6914 - accuracy: 0.5182 - val_loss: 0.6909 - val_accuracy: 0.5227\n",
      "Epoch 21/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5194 - val_loss: 0.6909 - val_accuracy: 0.5219\n",
      "Epoch 22/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6913 - accuracy: 0.5187 - val_loss: 0.6911 - val_accuracy: 0.5200\n",
      "Epoch 23/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5170 - val_loss: 0.6909 - val_accuracy: 0.5212\n",
      "Epoch 24/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6913 - accuracy: 0.5176 - val_loss: 0.6911 - val_accuracy: 0.5191\n",
      "Epoch 25/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5196 - val_loss: 0.6909 - val_accuracy: 0.5222\n",
      "Epoch 26/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5202 - val_loss: 0.6909 - val_accuracy: 0.5208\n",
      "Epoch 27/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5192 - val_loss: 0.6909 - val_accuracy: 0.5230\n",
      "Epoch 28/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5210 - val_loss: 0.6909 - val_accuracy: 0.5234\n",
      "Epoch 29/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5202 - val_loss: 0.6909 - val_accuracy: 0.5237\n",
      "Epoch 30/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5195 - val_loss: 0.6908 - val_accuracy: 0.5218\n",
      "Epoch 31/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5171 - val_loss: 0.6908 - val_accuracy: 0.5239\n",
      "Epoch 32/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6913 - accuracy: 0.5198 - val_loss: 0.6908 - val_accuracy: 0.5232\n",
      "Epoch 33/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5216 - val_loss: 0.6908 - val_accuracy: 0.5235\n",
      "Epoch 34/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5197 - val_loss: 0.6909 - val_accuracy: 0.5211\n",
      "Epoch 35/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5206 - val_loss: 0.6909 - val_accuracy: 0.5225\n",
      "Epoch 36/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5218 - val_loss: 0.6908 - val_accuracy: 0.5250\n",
      "Epoch 37/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5188 - val_loss: 0.6909 - val_accuracy: 0.5220\n",
      "Epoch 38/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5204 - val_loss: 0.6909 - val_accuracy: 0.5217\n",
      "Epoch 39/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5200 - val_loss: 0.6912 - val_accuracy: 0.5164\n",
      "Epoch 40/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5209 - val_loss: 0.6908 - val_accuracy: 0.5195\n",
      "Epoch 41/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5187 - val_loss: 0.6909 - val_accuracy: 0.5217\n",
      "Epoch 42/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6911 - accuracy: 0.5200 - val_loss: 0.6908 - val_accuracy: 0.5223\n",
      "Epoch 43/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6910 - accuracy: 0.5199 - val_loss: 0.6907 - val_accuracy: 0.5218\n",
      "Epoch 44/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6912 - accuracy: 0.5175 - val_loss: 0.6908 - val_accuracy: 0.5240\n",
      "Epoch 45/1000\n",
      "41558/41558 [==============================] - 0s 12us/sample - loss: 0.6910 - accuracy: 0.5205 - val_loss: 0.6909 - val_accuracy: 0.5217\n",
      "Epoch 46/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6911 - accuracy: 0.5217 - val_loss: 0.6908 - val_accuracy: 0.5243\n",
      "Epoch 47/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5196 - val_loss: 0.6908 - val_accuracy: 0.5223\n",
      "Epoch 48/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5213 - val_loss: 0.6908 - val_accuracy: 0.5218\n",
      "Epoch 49/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5224 - val_loss: 0.6908 - val_accuracy: 0.5242\n",
      "Epoch 50/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5187 - val_loss: 0.6910 - val_accuracy: 0.5199\n",
      "Epoch 51/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5205 - val_loss: 0.6908 - val_accuracy: 0.5250\n",
      "Epoch 52/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5219 - val_loss: 0.6907 - val_accuracy: 0.5269\n",
      "Epoch 53/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5192 - val_loss: 0.6907 - val_accuracy: 0.5237\n",
      "Epoch 54/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6911 - accuracy: 0.5205 - val_loss: 0.6907 - val_accuracy: 0.5249\n",
      "Epoch 55/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5200 - val_loss: 0.6907 - val_accuracy: 0.5251\n",
      "Epoch 56/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6910 - accuracy: 0.5215 - val_loss: 0.6908 - val_accuracy: 0.5219\n",
      "Epoch 57/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5207 - val_loss: 0.6909 - val_accuracy: 0.5205\n",
      "Epoch 58/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5185 - val_loss: 0.6910 - val_accuracy: 0.5207\n",
      "Epoch 59/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5221 - val_loss: 0.6908 - val_accuracy: 0.5245\n",
      "Epoch 60/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5208 - val_loss: 0.6907 - val_accuracy: 0.5239\n",
      "Epoch 61/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6909 - accuracy: 0.5208 - val_loss: 0.6906 - val_accuracy: 0.5240\n",
      "Epoch 62/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5220 - val_loss: 0.6907 - val_accuracy: 0.5229\n",
      "Epoch 63/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5226 - val_loss: 0.6907 - val_accuracy: 0.5217\n",
      "Epoch 64/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6909 - accuracy: 0.5223 - val_loss: 0.6907 - val_accuracy: 0.5250\n",
      "Epoch 65/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5218 - val_loss: 0.6907 - val_accuracy: 0.5220\n",
      "Epoch 66/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6908 - accuracy: 0.5213 - val_loss: 0.6908 - val_accuracy: 0.5219\n",
      "Epoch 67/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5223 - val_loss: 0.6907 - val_accuracy: 0.5248\n",
      "Epoch 68/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5210 - val_loss: 0.6907 - val_accuracy: 0.5242\n",
      "Epoch 69/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5214 - val_loss: 0.6907 - val_accuracy: 0.5245\n",
      "Epoch 70/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5204 - val_loss: 0.6906 - val_accuracy: 0.5224\n",
      "Epoch 71/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5224 - val_loss: 0.6907 - val_accuracy: 0.5264\n",
      "Epoch 72/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5210 - val_loss: 0.6907 - val_accuracy: 0.5231\n",
      "Epoch 73/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5213 - val_loss: 0.6909 - val_accuracy: 0.5152\n",
      "Epoch 74/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5206 - val_loss: 0.6909 - val_accuracy: 0.5196\n",
      "Epoch 75/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5228 - val_loss: 0.6907 - val_accuracy: 0.5218\n",
      "Epoch 76/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5212 - val_loss: 0.6908 - val_accuracy: 0.5244\n",
      "Epoch 77/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5211 - val_loss: 0.6908 - val_accuracy: 0.5225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5223 - val_loss: 0.6908 - val_accuracy: 0.5253\n",
      "Epoch 79/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5228 - val_loss: 0.6908 - val_accuracy: 0.5217\n",
      "Epoch 80/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6908 - accuracy: 0.5215 - val_loss: 0.6907 - val_accuracy: 0.5230\n",
      "Epoch 81/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5202 - val_loss: 0.6907 - val_accuracy: 0.5213\n",
      "Epoch 82/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5206 - val_loss: 0.6907 - val_accuracy: 0.5223\n",
      "Epoch 83/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5222 - val_loss: 0.6908 - val_accuracy: 0.5254\n",
      "Epoch 84/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5214 - val_loss: 0.6907 - val_accuracy: 0.5244\n",
      "Epoch 85/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6908 - accuracy: 0.5203 - val_loss: 0.6908 - val_accuracy: 0.5256\n",
      "Epoch 86/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5231 - val_loss: 0.6908 - val_accuracy: 0.5230\n",
      "Epoch 87/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5231 - val_loss: 0.6907 - val_accuracy: 0.5247\n",
      "Epoch 88/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6910 - accuracy: 0.5205 - val_loss: 0.6908 - val_accuracy: 0.5251\n",
      "Epoch 89/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5228 - val_loss: 0.6907 - val_accuracy: 0.5228\n",
      "Epoch 90/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5237 - val_loss: 0.6908 - val_accuracy: 0.5199\n",
      "Epoch 91/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5221 - val_loss: 0.6907 - val_accuracy: 0.5255\n",
      "Epoch 92/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5221 - val_loss: 0.6907 - val_accuracy: 0.5254\n",
      "Epoch 93/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6908 - accuracy: 0.5230 - val_loss: 0.6907 - val_accuracy: 0.5255\n",
      "Epoch 94/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6909 - accuracy: 0.5219 - val_loss: 0.6907 - val_accuracy: 0.5250\n",
      "Epoch 95/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6908 - accuracy: 0.5227 - val_loss: 0.6907 - val_accuracy: 0.5265\n",
      "Epoch 96/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6908 - accuracy: 0.5215 - val_loss: 0.6908 - val_accuracy: 0.5236\n",
      "Epoch 97/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5227 - val_loss: 0.6909 - val_accuracy: 0.5196\n",
      "Epoch 98/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5245 - val_loss: 0.6908 - val_accuracy: 0.5228\n",
      "Epoch 99/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5220 - val_loss: 0.6908 - val_accuracy: 0.5190\n",
      "Epoch 100/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6908 - accuracy: 0.5222 - val_loss: 0.6907 - val_accuracy: 0.5211\n",
      "Training with significance = 4.41, run 7\n",
      "Train on 41558 samples, validate on 10390 samples\n",
      "Epoch 1/1000\n",
      "41558/41558 [==============================] - 1s 27us/sample - loss: 0.6928 - accuracy: 0.5104 - val_loss: 0.6924 - val_accuracy: 0.5099\n",
      "Epoch 2/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5172 - val_loss: 0.6920 - val_accuracy: 0.5124\n",
      "Epoch 3/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6917 - accuracy: 0.5180 - val_loss: 0.6918 - val_accuracy: 0.5178\n",
      "Epoch 4/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5188 - val_loss: 0.6917 - val_accuracy: 0.5159\n",
      "Epoch 5/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5168 - val_loss: 0.6918 - val_accuracy: 0.5155\n",
      "Epoch 6/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5165 - val_loss: 0.6917 - val_accuracy: 0.5152\n",
      "Epoch 7/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5199 - val_loss: 0.6917 - val_accuracy: 0.5142\n",
      "Epoch 8/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5182 - val_loss: 0.6918 - val_accuracy: 0.5136\n",
      "Epoch 9/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6913 - accuracy: 0.5198 - val_loss: 0.6918 - val_accuracy: 0.5126\n",
      "Epoch 10/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5179 - val_loss: 0.6918 - val_accuracy: 0.5130\n",
      "Epoch 11/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5173 - val_loss: 0.6917 - val_accuracy: 0.5114\n",
      "Epoch 12/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6912 - accuracy: 0.5178 - val_loss: 0.6919 - val_accuracy: 0.5098\n",
      "Epoch 13/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5182 - val_loss: 0.6918 - val_accuracy: 0.5095\n",
      "Epoch 14/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5201 - val_loss: 0.6919 - val_accuracy: 0.5098\n",
      "Epoch 15/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5184 - val_loss: 0.6918 - val_accuracy: 0.5087\n",
      "Epoch 16/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5183 - val_loss: 0.6920 - val_accuracy: 0.5115\n",
      "Epoch 17/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6911 - accuracy: 0.5205 - val_loss: 0.6920 - val_accuracy: 0.5127\n",
      "Epoch 18/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5192 - val_loss: 0.6920 - val_accuracy: 0.5132\n",
      "Epoch 19/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5201 - val_loss: 0.6919 - val_accuracy: 0.5105\n",
      "Epoch 20/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5186 - val_loss: 0.6919 - val_accuracy: 0.5132\n",
      "Epoch 21/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6910 - accuracy: 0.5215 - val_loss: 0.6920 - val_accuracy: 0.5141\n",
      "Epoch 22/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5194 - val_loss: 0.6920 - val_accuracy: 0.5099\n",
      "Epoch 23/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5200 - val_loss: 0.6920 - val_accuracy: 0.5107\n",
      "Epoch 24/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5182 - val_loss: 0.6920 - val_accuracy: 0.5124\n",
      "Epoch 25/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5214 - val_loss: 0.6919 - val_accuracy: 0.5121\n",
      "Epoch 26/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5207 - val_loss: 0.6920 - val_accuracy: 0.5120\n",
      "Epoch 27/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5208 - val_loss: 0.6919 - val_accuracy: 0.5089\n",
      "Epoch 28/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5214 - val_loss: 0.6920 - val_accuracy: 0.5100\n",
      "Epoch 29/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5218 - val_loss: 0.6920 - val_accuracy: 0.5103\n",
      "Epoch 30/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5212 - val_loss: 0.6920 - val_accuracy: 0.5106\n",
      "Epoch 31/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5209 - val_loss: 0.6922 - val_accuracy: 0.5141\n",
      "Epoch 32/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6907 - accuracy: 0.5220 - val_loss: 0.6922 - val_accuracy: 0.5132\n",
      "Epoch 33/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6909 - accuracy: 0.5209 - val_loss: 0.6921 - val_accuracy: 0.5121\n",
      "Epoch 34/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5220 - val_loss: 0.6920 - val_accuracy: 0.5127\n",
      "Epoch 35/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5220 - val_loss: 0.6919 - val_accuracy: 0.5144\n",
      "Epoch 36/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5213 - val_loss: 0.6919 - val_accuracy: 0.5100\n",
      "Training with significance = 4.41, run 8\n",
      "Train on 41558 samples, validate on 10390 samples\n",
      "Epoch 1/1000\n",
      "41558/41558 [==============================] - 1s 26us/sample - loss: 0.6932 - accuracy: 0.5111 - val_loss: 0.6932 - val_accuracy: 0.5132\n",
      "Epoch 2/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6924 - accuracy: 0.5153 - val_loss: 0.6926 - val_accuracy: 0.5157\n",
      "Epoch 3/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5137 - val_loss: 0.6923 - val_accuracy: 0.5226\n",
      "Epoch 4/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5161 - val_loss: 0.6922 - val_accuracy: 0.5169\n",
      "Epoch 5/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5156 - val_loss: 0.6919 - val_accuracy: 0.5198\n",
      "Epoch 6/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5176 - val_loss: 0.6917 - val_accuracy: 0.5228\n",
      "Epoch 7/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5149 - val_loss: 0.6916 - val_accuracy: 0.5197\n",
      "Epoch 8/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5192 - val_loss: 0.6916 - val_accuracy: 0.5228\n",
      "Epoch 9/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5168 - val_loss: 0.6916 - val_accuracy: 0.5222\n",
      "Epoch 10/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5159 - val_loss: 0.6915 - val_accuracy: 0.5192\n",
      "Epoch 11/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5166 - val_loss: 0.6915 - val_accuracy: 0.5207\n",
      "Epoch 12/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5177 - val_loss: 0.6914 - val_accuracy: 0.5208\n",
      "Epoch 13/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5179 - val_loss: 0.6914 - val_accuracy: 0.5220\n",
      "Epoch 14/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5173 - val_loss: 0.6914 - val_accuracy: 0.5197\n",
      "Epoch 15/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5186 - val_loss: 0.6914 - val_accuracy: 0.5180\n",
      "Epoch 16/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5191 - val_loss: 0.6914 - val_accuracy: 0.5178\n",
      "Epoch 17/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5191 - val_loss: 0.6913 - val_accuracy: 0.5189\n",
      "Epoch 18/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5179 - val_loss: 0.6913 - val_accuracy: 0.5208\n",
      "Epoch 19/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5172 - val_loss: 0.6913 - val_accuracy: 0.5209\n",
      "Epoch 20/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6912 - accuracy: 0.5193 - val_loss: 0.6913 - val_accuracy: 0.5179\n",
      "Epoch 21/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6913 - accuracy: 0.5182 - val_loss: 0.6913 - val_accuracy: 0.5211\n",
      "Epoch 22/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6913 - accuracy: 0.5184 - val_loss: 0.6914 - val_accuracy: 0.5134\n",
      "Epoch 23/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5209 - val_loss: 0.6912 - val_accuracy: 0.5226\n",
      "Epoch 24/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6912 - accuracy: 0.5183 - val_loss: 0.6912 - val_accuracy: 0.5170\n",
      "Epoch 25/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6911 - accuracy: 0.5201 - val_loss: 0.6913 - val_accuracy: 0.5154\n",
      "Epoch 26/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5197 - val_loss: 0.6911 - val_accuracy: 0.5213\n",
      "Epoch 27/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5187 - val_loss: 0.6912 - val_accuracy: 0.5240\n",
      "Epoch 28/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5173 - val_loss: 0.6913 - val_accuracy: 0.5196\n",
      "Epoch 29/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5186 - val_loss: 0.6911 - val_accuracy: 0.5219\n",
      "Epoch 30/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5180 - val_loss: 0.6913 - val_accuracy: 0.5167\n",
      "Epoch 31/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5193 - val_loss: 0.6912 - val_accuracy: 0.5181\n",
      "Epoch 32/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6909 - accuracy: 0.5208 - val_loss: 0.6913 - val_accuracy: 0.5167\n",
      "Epoch 33/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6909 - accuracy: 0.5211 - val_loss: 0.6912 - val_accuracy: 0.5138\n",
      "Epoch 34/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5199 - val_loss: 0.6912 - val_accuracy: 0.5238\n",
      "Epoch 35/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5190 - val_loss: 0.6912 - val_accuracy: 0.5194\n",
      "Epoch 36/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5188 - val_loss: 0.6911 - val_accuracy: 0.5213\n",
      "Epoch 37/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6909 - accuracy: 0.5210 - val_loss: 0.6911 - val_accuracy: 0.5198\n",
      "Epoch 38/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5211 - val_loss: 0.6911 - val_accuracy: 0.5204\n",
      "Epoch 39/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5206 - val_loss: 0.6911 - val_accuracy: 0.5187\n",
      "Epoch 40/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6909 - accuracy: 0.5215 - val_loss: 0.6911 - val_accuracy: 0.5218\n",
      "Epoch 41/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5206 - val_loss: 0.6912 - val_accuracy: 0.5171\n",
      "Epoch 42/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5211 - val_loss: 0.6911 - val_accuracy: 0.5215\n",
      "Epoch 43/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5223 - val_loss: 0.6912 - val_accuracy: 0.5191\n",
      "Epoch 44/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5205 - val_loss: 0.6912 - val_accuracy: 0.5168\n",
      "Epoch 45/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5198 - val_loss: 0.6911 - val_accuracy: 0.5200\n",
      "Epoch 46/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5197 - val_loss: 0.6911 - val_accuracy: 0.5196\n",
      "Epoch 47/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6909 - accuracy: 0.5221 - val_loss: 0.6912 - val_accuracy: 0.5167\n",
      "Epoch 48/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5224 - val_loss: 0.6911 - val_accuracy: 0.5212\n",
      "Epoch 49/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5213 - val_loss: 0.6912 - val_accuracy: 0.5165\n",
      "Epoch 50/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5233 - val_loss: 0.6910 - val_accuracy: 0.5211\n",
      "Epoch 51/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5207 - val_loss: 0.6912 - val_accuracy: 0.5177\n",
      "Epoch 52/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6908 - accuracy: 0.5215 - val_loss: 0.6911 - val_accuracy: 0.5227\n",
      "Epoch 53/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5217 - val_loss: 0.6911 - val_accuracy: 0.5225\n",
      "Epoch 54/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6909 - accuracy: 0.5207 - val_loss: 0.6911 - val_accuracy: 0.5169\n",
      "Epoch 55/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6907 - accuracy: 0.5214 - val_loss: 0.6912 - val_accuracy: 0.5197\n",
      "Epoch 56/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5223 - val_loss: 0.6912 - val_accuracy: 0.5173\n",
      "Epoch 57/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5201 - val_loss: 0.6911 - val_accuracy: 0.5178\n",
      "Epoch 58/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5220 - val_loss: 0.6911 - val_accuracy: 0.5207\n",
      "Epoch 59/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5227 - val_loss: 0.6911 - val_accuracy: 0.5209\n",
      "Epoch 60/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5206 - val_loss: 0.6911 - val_accuracy: 0.5216\n",
      "Epoch 61/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5225 - val_loss: 0.6911 - val_accuracy: 0.5208\n",
      "Epoch 62/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5204 - val_loss: 0.6911 - val_accuracy: 0.5212\n",
      "Epoch 63/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5208 - val_loss: 0.6911 - val_accuracy: 0.5140\n",
      "Epoch 64/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5228 - val_loss: 0.6911 - val_accuracy: 0.5218\n",
      "Epoch 65/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6907 - accuracy: 0.5192 - val_loss: 0.6911 - val_accuracy: 0.5163\n",
      "Epoch 66/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6907 - accuracy: 0.5220 - val_loss: 0.6911 - val_accuracy: 0.5192\n",
      "Epoch 67/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5224 - val_loss: 0.6911 - val_accuracy: 0.5171\n",
      "Epoch 68/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5213 - val_loss: 0.6911 - val_accuracy: 0.5178\n",
      "Epoch 69/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6907 - accuracy: 0.5207 - val_loss: 0.6911 - val_accuracy: 0.5173\n",
      "Epoch 70/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5219 - val_loss: 0.6911 - val_accuracy: 0.5211\n",
      "Epoch 71/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5222 - val_loss: 0.6911 - val_accuracy: 0.5197\n",
      "Epoch 72/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5219 - val_loss: 0.6911 - val_accuracy: 0.5186\n",
      "Epoch 73/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5224 - val_loss: 0.6911 - val_accuracy: 0.5216\n",
      "Epoch 74/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5226 - val_loss: 0.6912 - val_accuracy: 0.5171\n",
      "Epoch 75/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5225 - val_loss: 0.6912 - val_accuracy: 0.5160\n",
      "Epoch 76/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5216 - val_loss: 0.6911 - val_accuracy: 0.5155\n",
      "Epoch 77/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5221 - val_loss: 0.6912 - val_accuracy: 0.5157\n",
      "Epoch 78/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5240 - val_loss: 0.6911 - val_accuracy: 0.5214\n",
      "Epoch 79/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5225 - val_loss: 0.6911 - val_accuracy: 0.5227\n",
      "Epoch 80/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5224 - val_loss: 0.6912 - val_accuracy: 0.5153\n",
      "Training with significance = 4.41, run 9\n",
      "Train on 41558 samples, validate on 10390 samples\n",
      "Epoch 1/1000\n",
      "41558/41558 [==============================] - 1s 27us/sample - loss: 0.6928 - accuracy: 0.5111 - val_loss: 0.6970 - val_accuracy: 0.5083\n",
      "Epoch 2/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5142 - val_loss: 0.6928 - val_accuracy: 0.5141\n",
      "Epoch 3/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5172 - val_loss: 0.6926 - val_accuracy: 0.5156\n",
      "Epoch 4/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5165 - val_loss: 0.6922 - val_accuracy: 0.5197\n",
      "Epoch 5/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5173 - val_loss: 0.6920 - val_accuracy: 0.5187\n",
      "Epoch 6/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5156 - val_loss: 0.6920 - val_accuracy: 0.5204\n",
      "Epoch 7/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5134 - val_loss: 0.6924 - val_accuracy: 0.5199\n",
      "Epoch 8/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5180 - val_loss: 0.6919 - val_accuracy: 0.5189\n",
      "Epoch 9/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5161 - val_loss: 0.6921 - val_accuracy: 0.5208\n",
      "Epoch 10/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5151 - val_loss: 0.6920 - val_accuracy: 0.5207\n",
      "Epoch 11/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5174 - val_loss: 0.6924 - val_accuracy: 0.5166\n",
      "Epoch 12/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5186 - val_loss: 0.6921 - val_accuracy: 0.5182\n",
      "Epoch 13/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5166 - val_loss: 0.6920 - val_accuracy: 0.5191\n",
      "Epoch 14/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5165 - val_loss: 0.6922 - val_accuracy: 0.5194\n",
      "Epoch 15/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5178 - val_loss: 0.6922 - val_accuracy: 0.5169\n",
      "Epoch 16/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5176 - val_loss: 0.6920 - val_accuracy: 0.5214\n",
      "Epoch 17/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5188 - val_loss: 0.6918 - val_accuracy: 0.5189\n",
      "Epoch 18/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5176 - val_loss: 0.6919 - val_accuracy: 0.5195\n",
      "Epoch 19/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5180 - val_loss: 0.6919 - val_accuracy: 0.5185\n",
      "Epoch 20/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5193 - val_loss: 0.6922 - val_accuracy: 0.5185\n",
      "Epoch 21/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5187 - val_loss: 0.6921 - val_accuracy: 0.5144\n",
      "Epoch 22/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5170 - val_loss: 0.6919 - val_accuracy: 0.5176\n",
      "Epoch 23/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5190 - val_loss: 0.6923 - val_accuracy: 0.5151\n",
      "Epoch 24/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5181 - val_loss: 0.6924 - val_accuracy: 0.5130\n",
      "Epoch 25/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5177 - val_loss: 0.6924 - val_accuracy: 0.5099\n",
      "Epoch 26/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5216 - val_loss: 0.6920 - val_accuracy: 0.5194\n",
      "Epoch 27/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5196 - val_loss: 0.6923 - val_accuracy: 0.5054\n",
      "Epoch 28/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6913 - accuracy: 0.5184 - val_loss: 0.6920 - val_accuracy: 0.5177\n",
      "Epoch 29/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6911 - accuracy: 0.5193 - val_loss: 0.6922 - val_accuracy: 0.5127\n",
      "Epoch 30/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6912 - accuracy: 0.5176 - val_loss: 0.6920 - val_accuracy: 0.5170\n",
      "Epoch 31/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6912 - accuracy: 0.5208 - val_loss: 0.6922 - val_accuracy: 0.5152\n",
      "Epoch 32/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6912 - accuracy: 0.5198 - val_loss: 0.6921 - val_accuracy: 0.5179\n",
      "Epoch 33/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5204 - val_loss: 0.6918 - val_accuracy: 0.5193\n",
      "Epoch 34/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5186 - val_loss: 0.6921 - val_accuracy: 0.5136\n",
      "Epoch 35/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5199 - val_loss: 0.6923 - val_accuracy: 0.5057\n",
      "Epoch 36/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5186 - val_loss: 0.6920 - val_accuracy: 0.5119\n",
      "Epoch 37/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5180 - val_loss: 0.6921 - val_accuracy: 0.5125\n",
      "Epoch 38/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5160 - val_loss: 0.6921 - val_accuracy: 0.5105\n",
      "Epoch 39/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5198 - val_loss: 0.6921 - val_accuracy: 0.5127\n",
      "Epoch 40/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5189 - val_loss: 0.6919 - val_accuracy: 0.5145\n",
      "Epoch 41/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5184 - val_loss: 0.6920 - val_accuracy: 0.5150\n",
      "Epoch 42/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6911 - accuracy: 0.5202 - val_loss: 0.6921 - val_accuracy: 0.5134\n",
      "Epoch 43/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6910 - accuracy: 0.5200 - val_loss: 0.6919 - val_accuracy: 0.5184\n",
      "Epoch 44/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5193 - val_loss: 0.6926 - val_accuracy: 0.5022\n",
      "Epoch 45/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5209 - val_loss: 0.6919 - val_accuracy: 0.5160\n",
      "Epoch 46/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5187 - val_loss: 0.6923 - val_accuracy: 0.5097\n",
      "Epoch 47/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5219 - val_loss: 0.6917 - val_accuracy: 0.5195\n",
      "Epoch 48/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5185 - val_loss: 0.6920 - val_accuracy: 0.5150\n",
      "Epoch 49/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5205 - val_loss: 0.6921 - val_accuracy: 0.5150\n",
      "Epoch 50/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5221 - val_loss: 0.6923 - val_accuracy: 0.5059\n",
      "Epoch 51/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5198 - val_loss: 0.6921 - val_accuracy: 0.5164\n",
      "Epoch 52/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5193 - val_loss: 0.6922 - val_accuracy: 0.5100\n",
      "Epoch 53/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5216 - val_loss: 0.6921 - val_accuracy: 0.5121\n",
      "Epoch 54/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5208 - val_loss: 0.6920 - val_accuracy: 0.5168\n",
      "Epoch 55/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5202 - val_loss: 0.6920 - val_accuracy: 0.5141\n",
      "Epoch 56/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5218 - val_loss: 0.6918 - val_accuracy: 0.5149\n",
      "Epoch 57/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5222 - val_loss: 0.6921 - val_accuracy: 0.5155\n",
      "Epoch 58/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5202 - val_loss: 0.6924 - val_accuracy: 0.5050\n",
      "Epoch 59/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5226 - val_loss: 0.6923 - val_accuracy: 0.5126\n",
      "Epoch 60/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6910 - accuracy: 0.5211 - val_loss: 0.6918 - val_accuracy: 0.5196\n",
      "Epoch 61/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5215 - val_loss: 0.6925 - val_accuracy: 0.5104\n",
      "Epoch 62/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5191 - val_loss: 0.6921 - val_accuracy: 0.5146\n",
      "Epoch 63/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5202 - val_loss: 0.6918 - val_accuracy: 0.5197\n",
      "Epoch 64/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5209 - val_loss: 0.6917 - val_accuracy: 0.5196\n",
      "Epoch 65/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5209 - val_loss: 0.6920 - val_accuracy: 0.5145\n",
      "Epoch 66/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5226 - val_loss: 0.6918 - val_accuracy: 0.5196\n",
      "Epoch 67/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6910 - accuracy: 0.5192 - val_loss: 0.6920 - val_accuracy: 0.5161\n",
      "Epoch 68/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5211 - val_loss: 0.6921 - val_accuracy: 0.5138\n",
      "Epoch 69/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5219 - val_loss: 0.6920 - val_accuracy: 0.5124\n",
      "Epoch 70/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5222 - val_loss: 0.6922 - val_accuracy: 0.5143\n",
      "Epoch 71/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5226 - val_loss: 0.6922 - val_accuracy: 0.5169\n",
      "Epoch 72/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5220 - val_loss: 0.6922 - val_accuracy: 0.5145\n",
      "Epoch 73/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5215 - val_loss: 0.6921 - val_accuracy: 0.5155\n",
      "Epoch 74/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5236 - val_loss: 0.6923 - val_accuracy: 0.5094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5197 - val_loss: 0.6922 - val_accuracy: 0.5116\n",
      "Epoch 76/1000\n",
      "41558/41558 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5224 - val_loss: 0.6923 - val_accuracy: 0.5051\n",
      "Epoch 77/1000\n",
      "41558/41558 [==============================] - 1s 12us/sample - loss: 0.6909 - accuracy: 0.5219 - val_loss: 0.6926 - val_accuracy: 0.5109\n",
      "Training with significance = 5.03, run 0\n",
      "Train on 41660 samples, validate on 10415 samples\n",
      "Epoch 1/1000\n",
      "41660/41660 [==============================] - 3s 62us/sample - loss: 0.6935 - accuracy: 0.5043 - val_loss: 0.6955 - val_accuracy: 0.5021\n",
      "Epoch 2/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5127 - val_loss: 0.6939 - val_accuracy: 0.5083\n",
      "Epoch 3/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5163 - val_loss: 0.6937 - val_accuracy: 0.5061\n",
      "Epoch 4/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5156 - val_loss: 0.6935 - val_accuracy: 0.5134\n",
      "Epoch 5/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5164 - val_loss: 0.6932 - val_accuracy: 0.5120\n",
      "Epoch 6/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5162 - val_loss: 0.6931 - val_accuracy: 0.5155\n",
      "Epoch 7/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5171 - val_loss: 0.6929 - val_accuracy: 0.5137\n",
      "Epoch 8/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5179 - val_loss: 0.6930 - val_accuracy: 0.5143\n",
      "Epoch 9/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5177 - val_loss: 0.6930 - val_accuracy: 0.5132\n",
      "Epoch 10/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6911 - accuracy: 0.5204 - val_loss: 0.6929 - val_accuracy: 0.5140\n",
      "Epoch 11/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5187 - val_loss: 0.6930 - val_accuracy: 0.5134\n",
      "Epoch 12/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5190 - val_loss: 0.6931 - val_accuracy: 0.5136\n",
      "Epoch 13/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5192 - val_loss: 0.6929 - val_accuracy: 0.5149\n",
      "Epoch 14/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5195 - val_loss: 0.6930 - val_accuracy: 0.5147\n",
      "Epoch 15/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5195 - val_loss: 0.6933 - val_accuracy: 0.5100\n",
      "Epoch 16/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5190 - val_loss: 0.6932 - val_accuracy: 0.5147\n",
      "Epoch 17/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6910 - accuracy: 0.5205 - val_loss: 0.6928 - val_accuracy: 0.5152\n",
      "Epoch 18/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5188 - val_loss: 0.6929 - val_accuracy: 0.5157\n",
      "Epoch 19/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6908 - accuracy: 0.5203 - val_loss: 0.6930 - val_accuracy: 0.5135\n",
      "Epoch 20/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5201 - val_loss: 0.6931 - val_accuracy: 0.5152\n",
      "Epoch 21/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5198 - val_loss: 0.6930 - val_accuracy: 0.5145\n",
      "Epoch 22/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5191 - val_loss: 0.6931 - val_accuracy: 0.5111\n",
      "Epoch 23/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6908 - accuracy: 0.5201 - val_loss: 0.6931 - val_accuracy: 0.5152\n",
      "Epoch 24/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5195 - val_loss: 0.6933 - val_accuracy: 0.5050\n",
      "Epoch 25/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6907 - accuracy: 0.5213 - val_loss: 0.6932 - val_accuracy: 0.5120\n",
      "Epoch 26/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5203 - val_loss: 0.6931 - val_accuracy: 0.5134\n",
      "Epoch 27/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5204 - val_loss: 0.6932 - val_accuracy: 0.5074\n",
      "Epoch 28/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5219 - val_loss: 0.6933 - val_accuracy: 0.5140\n",
      "Epoch 29/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5190 - val_loss: 0.6930 - val_accuracy: 0.5145\n",
      "Epoch 30/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5209 - val_loss: 0.6932 - val_accuracy: 0.5124\n",
      "Epoch 31/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5210 - val_loss: 0.6932 - val_accuracy: 0.5140\n",
      "Epoch 32/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5209 - val_loss: 0.6934 - val_accuracy: 0.5091\n",
      "Epoch 33/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5205 - val_loss: 0.6933 - val_accuracy: 0.5093\n",
      "Epoch 34/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5217 - val_loss: 0.6932 - val_accuracy: 0.5144\n",
      "Epoch 35/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5212 - val_loss: 0.6932 - val_accuracy: 0.5086\n",
      "Epoch 36/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5198 - val_loss: 0.6931 - val_accuracy: 0.5121\n",
      "Epoch 37/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5222 - val_loss: 0.6931 - val_accuracy: 0.5119\n",
      "Epoch 38/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5204 - val_loss: 0.6933 - val_accuracy: 0.5089\n",
      "Epoch 39/1000\n",
      "41660/41660 [==============================] - 0s 12us/sample - loss: 0.6906 - accuracy: 0.5188 - val_loss: 0.6932 - val_accuracy: 0.5122\n",
      "Epoch 40/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5210 - val_loss: 0.6931 - val_accuracy: 0.5124\n",
      "Epoch 41/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5219 - val_loss: 0.6932 - val_accuracy: 0.5136\n",
      "Epoch 42/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5193 - val_loss: 0.6933 - val_accuracy: 0.5074\n",
      "Epoch 43/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5215 - val_loss: 0.6933 - val_accuracy: 0.5074\n",
      "Epoch 44/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5223 - val_loss: 0.6935 - val_accuracy: 0.5090\n",
      "Epoch 45/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5212 - val_loss: 0.6933 - val_accuracy: 0.5079\n",
      "Epoch 46/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5233 - val_loss: 0.6931 - val_accuracy: 0.5111\n",
      "Epoch 47/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5238 - val_loss: 0.6934 - val_accuracy: 0.5140\n",
      "Training with significance = 5.03, run 1\n",
      "Train on 41660 samples, validate on 10415 samples\n",
      "Epoch 1/1000\n",
      "41660/41660 [==============================] - 1s 27us/sample - loss: 0.6928 - accuracy: 0.5100 - val_loss: 0.6956 - val_accuracy: 0.4998\n",
      "Epoch 2/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5141 - val_loss: 0.6925 - val_accuracy: 0.5123\n",
      "Epoch 3/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5189 - val_loss: 0.6920 - val_accuracy: 0.5158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5198 - val_loss: 0.6919 - val_accuracy: 0.5144\n",
      "Epoch 5/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5209 - val_loss: 0.6918 - val_accuracy: 0.5156\n",
      "Epoch 6/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5211 - val_loss: 0.6920 - val_accuracy: 0.5149\n",
      "Epoch 7/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5209 - val_loss: 0.6918 - val_accuracy: 0.5156\n",
      "Epoch 8/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5220 - val_loss: 0.6921 - val_accuracy: 0.5130\n",
      "Epoch 9/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5217 - val_loss: 0.6919 - val_accuracy: 0.5121\n",
      "Epoch 10/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5220 - val_loss: 0.6921 - val_accuracy: 0.5084\n",
      "Epoch 11/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6909 - accuracy: 0.5226 - val_loss: 0.6918 - val_accuracy: 0.5155\n",
      "Epoch 12/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5224 - val_loss: 0.6919 - val_accuracy: 0.5106\n",
      "Epoch 13/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5222 - val_loss: 0.6918 - val_accuracy: 0.5150\n",
      "Epoch 14/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5215 - val_loss: 0.6919 - val_accuracy: 0.5125\n",
      "Epoch 15/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5233 - val_loss: 0.6920 - val_accuracy: 0.5120\n",
      "Epoch 16/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5219 - val_loss: 0.6920 - val_accuracy: 0.5103\n",
      "Epoch 17/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5225 - val_loss: 0.6919 - val_accuracy: 0.5112\n",
      "Epoch 18/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5237 - val_loss: 0.6921 - val_accuracy: 0.5105\n",
      "Epoch 19/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5236 - val_loss: 0.6920 - val_accuracy: 0.5138\n",
      "Epoch 20/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5237 - val_loss: 0.6919 - val_accuracy: 0.5131\n",
      "Epoch 21/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5231 - val_loss: 0.6919 - val_accuracy: 0.5137\n",
      "Epoch 22/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6907 - accuracy: 0.5230 - val_loss: 0.6920 - val_accuracy: 0.5123\n",
      "Epoch 23/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5222 - val_loss: 0.6919 - val_accuracy: 0.5139\n",
      "Epoch 24/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5238 - val_loss: 0.6920 - val_accuracy: 0.5113\n",
      "Epoch 25/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5255 - val_loss: 0.6920 - val_accuracy: 0.5119\n",
      "Epoch 26/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5233 - val_loss: 0.6919 - val_accuracy: 0.5123\n",
      "Epoch 27/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5242 - val_loss: 0.6921 - val_accuracy: 0.5107\n",
      "Epoch 28/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5235 - val_loss: 0.6920 - val_accuracy: 0.5123\n",
      "Epoch 29/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5228 - val_loss: 0.6920 - val_accuracy: 0.5136\n",
      "Epoch 30/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5254 - val_loss: 0.6920 - val_accuracy: 0.5133\n",
      "Epoch 31/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5237 - val_loss: 0.6919 - val_accuracy: 0.5130\n",
      "Epoch 32/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5242 - val_loss: 0.6919 - val_accuracy: 0.5123\n",
      "Epoch 33/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5248 - val_loss: 0.6921 - val_accuracy: 0.5119\n",
      "Epoch 34/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5253 - val_loss: 0.6919 - val_accuracy: 0.5133\n",
      "Epoch 35/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5254 - val_loss: 0.6919 - val_accuracy: 0.5137\n",
      "Epoch 36/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5234 - val_loss: 0.6920 - val_accuracy: 0.5144\n",
      "Epoch 37/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5256 - val_loss: 0.6919 - val_accuracy: 0.5131\n",
      "Training with significance = 5.03, run 2\n",
      "Train on 41660 samples, validate on 10415 samples\n",
      "Epoch 1/1000\n",
      "41660/41660 [==============================] - 1s 27us/sample - loss: 0.6951 - accuracy: 0.4948 - val_loss: 0.6931 - val_accuracy: 0.5089\n",
      "Epoch 2/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6925 - accuracy: 0.5139 - val_loss: 0.6925 - val_accuracy: 0.5104\n",
      "Epoch 3/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5176 - val_loss: 0.6927 - val_accuracy: 0.5129\n",
      "Epoch 4/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5168 - val_loss: 0.6922 - val_accuracy: 0.5098\n",
      "Epoch 5/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6920 - accuracy: 0.5186 - val_loss: 0.6921 - val_accuracy: 0.5139\n",
      "Epoch 6/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5188 - val_loss: 0.6920 - val_accuracy: 0.5152\n",
      "Epoch 7/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5183 - val_loss: 0.6919 - val_accuracy: 0.5151\n",
      "Epoch 8/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5195 - val_loss: 0.6919 - val_accuracy: 0.5141\n",
      "Epoch 9/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6916 - accuracy: 0.5191 - val_loss: 0.6920 - val_accuracy: 0.5146\n",
      "Epoch 10/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5173 - val_loss: 0.6919 - val_accuracy: 0.5145\n",
      "Epoch 11/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6916 - accuracy: 0.5203 - val_loss: 0.6920 - val_accuracy: 0.5139\n",
      "Epoch 12/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5203 - val_loss: 0.6920 - val_accuracy: 0.5134\n",
      "Epoch 13/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5200 - val_loss: 0.6918 - val_accuracy: 0.5148\n",
      "Epoch 14/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5202 - val_loss: 0.6919 - val_accuracy: 0.5155\n",
      "Epoch 15/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5204 - val_loss: 0.6919 - val_accuracy: 0.5151\n",
      "Epoch 16/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5196 - val_loss: 0.6918 - val_accuracy: 0.5152\n",
      "Epoch 17/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5198 - val_loss: 0.6920 - val_accuracy: 0.5143\n",
      "Epoch 18/1000\n",
      "41660/41660 [==============================] - 0s 12us/sample - loss: 0.6914 - accuracy: 0.5198 - val_loss: 0.6919 - val_accuracy: 0.5168\n",
      "Epoch 19/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6914 - accuracy: 0.5201 - val_loss: 0.6920 - val_accuracy: 0.5151\n",
      "Epoch 20/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6913 - accuracy: 0.5198 - val_loss: 0.6919 - val_accuracy: 0.5140\n",
      "Epoch 21/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6914 - accuracy: 0.5230 - val_loss: 0.6919 - val_accuracy: 0.5168\n",
      "Epoch 22/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6912 - accuracy: 0.5188 - val_loss: 0.6919 - val_accuracy: 0.5142\n",
      "Epoch 23/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6912 - accuracy: 0.5214 - val_loss: 0.6919 - val_accuracy: 0.5161\n",
      "Epoch 24/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6913 - accuracy: 0.5206 - val_loss: 0.6922 - val_accuracy: 0.5155\n",
      "Epoch 25/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6913 - accuracy: 0.5198 - val_loss: 0.6920 - val_accuracy: 0.5175\n",
      "Epoch 26/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5205 - val_loss: 0.6919 - val_accuracy: 0.5179\n",
      "Epoch 27/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5202 - val_loss: 0.6918 - val_accuracy: 0.5161\n",
      "Epoch 28/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5220 - val_loss: 0.6920 - val_accuracy: 0.5177\n",
      "Epoch 29/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5207 - val_loss: 0.6919 - val_accuracy: 0.5154\n",
      "Epoch 30/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5193 - val_loss: 0.6920 - val_accuracy: 0.5160\n",
      "Epoch 31/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5209 - val_loss: 0.6919 - val_accuracy: 0.5136\n",
      "Epoch 32/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5207 - val_loss: 0.6918 - val_accuracy: 0.5146\n",
      "Epoch 33/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5212 - val_loss: 0.6919 - val_accuracy: 0.5147\n",
      "Epoch 34/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5210 - val_loss: 0.6920 - val_accuracy: 0.5148\n",
      "Epoch 35/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6909 - accuracy: 0.5206 - val_loss: 0.6919 - val_accuracy: 0.5148\n",
      "Epoch 36/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5226 - val_loss: 0.6922 - val_accuracy: 0.5130\n",
      "Epoch 37/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5218 - val_loss: 0.6920 - val_accuracy: 0.5132\n",
      "Epoch 38/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5223 - val_loss: 0.6919 - val_accuracy: 0.5155\n",
      "Epoch 39/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6909 - accuracy: 0.5223 - val_loss: 0.6920 - val_accuracy: 0.5144\n",
      "Epoch 40/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5203 - val_loss: 0.6920 - val_accuracy: 0.5139\n",
      "Epoch 41/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5213 - val_loss: 0.6920 - val_accuracy: 0.5127\n",
      "Epoch 42/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5213 - val_loss: 0.6921 - val_accuracy: 0.5132\n",
      "Epoch 43/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6909 - accuracy: 0.5241 - val_loss: 0.6921 - val_accuracy: 0.5136\n",
      "Epoch 44/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5234 - val_loss: 0.6922 - val_accuracy: 0.5102\n",
      "Epoch 45/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5239 - val_loss: 0.6920 - val_accuracy: 0.5159\n",
      "Epoch 46/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5218 - val_loss: 0.6921 - val_accuracy: 0.5134\n",
      "Training with significance = 5.03, run 3\n",
      "Train on 41660 samples, validate on 10415 samples\n",
      "Epoch 1/1000\n",
      "41660/41660 [==============================] - 1s 26us/sample - loss: 0.6927 - accuracy: 0.5105 - val_loss: 0.6939 - val_accuracy: 0.5062\n",
      "Epoch 2/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6918 - accuracy: 0.5166 - val_loss: 0.6932 - val_accuracy: 0.5031\n",
      "Epoch 3/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6916 - accuracy: 0.5196 - val_loss: 0.6927 - val_accuracy: 0.5023\n",
      "Epoch 4/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5182 - val_loss: 0.6926 - val_accuracy: 0.5033\n",
      "Epoch 5/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5185 - val_loss: 0.6927 - val_accuracy: 0.5060\n",
      "Epoch 6/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5207 - val_loss: 0.6924 - val_accuracy: 0.5105\n",
      "Epoch 7/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6912 - accuracy: 0.5199 - val_loss: 0.6924 - val_accuracy: 0.5104\n",
      "Epoch 8/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6913 - accuracy: 0.5193 - val_loss: 0.6926 - val_accuracy: 0.5132\n",
      "Epoch 9/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5190 - val_loss: 0.6925 - val_accuracy: 0.5110\n",
      "Epoch 10/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5193 - val_loss: 0.6926 - val_accuracy: 0.5113\n",
      "Epoch 11/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5188 - val_loss: 0.6924 - val_accuracy: 0.5112\n",
      "Epoch 12/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5195 - val_loss: 0.6928 - val_accuracy: 0.5075\n",
      "Epoch 13/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5203 - val_loss: 0.6928 - val_accuracy: 0.5105\n",
      "Epoch 14/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5207 - val_loss: 0.6926 - val_accuracy: 0.5103\n",
      "Epoch 15/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5225 - val_loss: 0.6924 - val_accuracy: 0.5100\n",
      "Epoch 16/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6910 - accuracy: 0.5207 - val_loss: 0.6924 - val_accuracy: 0.5114\n",
      "Epoch 17/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6909 - accuracy: 0.5207 - val_loss: 0.6925 - val_accuracy: 0.5094\n",
      "Epoch 18/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5215 - val_loss: 0.6923 - val_accuracy: 0.5061\n",
      "Epoch 19/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5216 - val_loss: 0.6926 - val_accuracy: 0.5085\n",
      "Epoch 20/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5217 - val_loss: 0.6923 - val_accuracy: 0.5089\n",
      "Epoch 21/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6909 - accuracy: 0.5213 - val_loss: 0.6929 - val_accuracy: 0.5063\n",
      "Epoch 22/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5221 - val_loss: 0.6923 - val_accuracy: 0.5083\n",
      "Epoch 23/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5221 - val_loss: 0.6923 - val_accuracy: 0.5094\n",
      "Epoch 24/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5227 - val_loss: 0.6924 - val_accuracy: 0.5093\n",
      "Epoch 25/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5208 - val_loss: 0.6926 - val_accuracy: 0.5080\n",
      "Epoch 26/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5222 - val_loss: 0.6930 - val_accuracy: 0.5057\n",
      "Epoch 27/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5229 - val_loss: 0.6924 - val_accuracy: 0.5090\n",
      "Epoch 28/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5234 - val_loss: 0.6925 - val_accuracy: 0.5066\n",
      "Epoch 29/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5217 - val_loss: 0.6927 - val_accuracy: 0.5070\n",
      "Epoch 30/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5235 - val_loss: 0.6926 - val_accuracy: 0.5096\n",
      "Epoch 31/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5228 - val_loss: 0.6925 - val_accuracy: 0.5071\n",
      "Epoch 32/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6907 - accuracy: 0.5222 - val_loss: 0.6927 - val_accuracy: 0.5098\n",
      "Epoch 33/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5234 - val_loss: 0.6925 - val_accuracy: 0.5056\n",
      "Epoch 34/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5219 - val_loss: 0.6928 - val_accuracy: 0.5084\n",
      "Epoch 35/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5230 - val_loss: 0.6926 - val_accuracy: 0.5072\n",
      "Epoch 36/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5239 - val_loss: 0.6928 - val_accuracy: 0.5074\n",
      "Epoch 37/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5229 - val_loss: 0.6925 - val_accuracy: 0.5056\n",
      "Epoch 38/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5236 - val_loss: 0.6928 - val_accuracy: 0.5079\n",
      "Epoch 39/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5240 - val_loss: 0.6924 - val_accuracy: 0.5056\n",
      "Epoch 40/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5230 - val_loss: 0.6928 - val_accuracy: 0.5065\n",
      "Epoch 41/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5229 - val_loss: 0.6928 - val_accuracy: 0.5086\n",
      "Epoch 42/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5229 - val_loss: 0.6924 - val_accuracy: 0.5055\n",
      "Epoch 43/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5241 - val_loss: 0.6928 - val_accuracy: 0.5076\n",
      "Epoch 44/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5227 - val_loss: 0.6929 - val_accuracy: 0.5075\n",
      "Epoch 45/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5228 - val_loss: 0.6929 - val_accuracy: 0.5086\n",
      "Epoch 46/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5236 - val_loss: 0.6924 - val_accuracy: 0.5055\n",
      "Epoch 47/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5247 - val_loss: 0.6926 - val_accuracy: 0.5035\n",
      "Epoch 48/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5248 - val_loss: 0.6928 - val_accuracy: 0.5043\n",
      "Epoch 49/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5239 - val_loss: 0.6929 - val_accuracy: 0.5072\n",
      "Epoch 50/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5241 - val_loss: 0.6929 - val_accuracy: 0.5066\n",
      "Epoch 51/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5242 - val_loss: 0.6931 - val_accuracy: 0.5089\n",
      "Epoch 52/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5234 - val_loss: 0.6928 - val_accuracy: 0.5050\n",
      "Epoch 53/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5241 - val_loss: 0.6927 - val_accuracy: 0.5043\n",
      "Training with significance = 5.03, run 4\n",
      "Train on 41660 samples, validate on 10415 samples\n",
      "Epoch 1/1000\n",
      "41660/41660 [==============================] - 1s 25us/sample - loss: 0.6934 - accuracy: 0.5088 - val_loss: 0.6933 - val_accuracy: 0.5004\n",
      "Epoch 2/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5138 - val_loss: 0.6926 - val_accuracy: 0.5098\n",
      "Epoch 3/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6917 - accuracy: 0.5173 - val_loss: 0.6922 - val_accuracy: 0.5165\n",
      "Epoch 4/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5197 - val_loss: 0.6920 - val_accuracy: 0.5165\n",
      "Epoch 5/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5195 - val_loss: 0.6919 - val_accuracy: 0.5142\n",
      "Epoch 6/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6913 - accuracy: 0.5181 - val_loss: 0.6917 - val_accuracy: 0.5183\n",
      "Epoch 7/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5205 - val_loss: 0.6916 - val_accuracy: 0.5196\n",
      "Epoch 8/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5205 - val_loss: 0.6916 - val_accuracy: 0.5183\n",
      "Epoch 9/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5195 - val_loss: 0.6916 - val_accuracy: 0.5174\n",
      "Epoch 10/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6911 - accuracy: 0.5195 - val_loss: 0.6916 - val_accuracy: 0.5157\n",
      "Epoch 11/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5205 - val_loss: 0.6915 - val_accuracy: 0.5183\n",
      "Epoch 12/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6910 - accuracy: 0.5209 - val_loss: 0.6916 - val_accuracy: 0.5154\n",
      "Epoch 13/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5223 - val_loss: 0.6914 - val_accuracy: 0.5201\n",
      "Epoch 14/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6907 - accuracy: 0.5228 - val_loss: 0.6915 - val_accuracy: 0.5168\n",
      "Epoch 15/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5205 - val_loss: 0.6914 - val_accuracy: 0.5197\n",
      "Epoch 16/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5232 - val_loss: 0.6915 - val_accuracy: 0.5193\n",
      "Epoch 17/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5208 - val_loss: 0.6914 - val_accuracy: 0.5169\n",
      "Epoch 18/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6907 - accuracy: 0.5203 - val_loss: 0.6915 - val_accuracy: 0.5203\n",
      "Epoch 19/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5218 - val_loss: 0.6914 - val_accuracy: 0.5183\n",
      "Epoch 20/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5233 - val_loss: 0.6913 - val_accuracy: 0.5166\n",
      "Epoch 21/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6907 - accuracy: 0.5234 - val_loss: 0.6913 - val_accuracy: 0.5166\n",
      "Epoch 22/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6907 - accuracy: 0.5233 - val_loss: 0.6915 - val_accuracy: 0.5183\n",
      "Epoch 23/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5203 - val_loss: 0.6913 - val_accuracy: 0.5180\n",
      "Epoch 24/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5224 - val_loss: 0.6913 - val_accuracy: 0.5195\n",
      "Epoch 25/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5231 - val_loss: 0.6914 - val_accuracy: 0.5183\n",
      "Epoch 26/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5213 - val_loss: 0.6912 - val_accuracy: 0.5195\n",
      "Epoch 27/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6904 - accuracy: 0.5225 - val_loss: 0.6913 - val_accuracy: 0.5214\n",
      "Epoch 28/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5210 - val_loss: 0.6912 - val_accuracy: 0.5188\n",
      "Epoch 29/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5235 - val_loss: 0.6913 - val_accuracy: 0.5224\n",
      "Epoch 30/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5239 - val_loss: 0.6912 - val_accuracy: 0.5214\n",
      "Epoch 31/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6904 - accuracy: 0.5221 - val_loss: 0.6914 - val_accuracy: 0.5214\n",
      "Epoch 32/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5231 - val_loss: 0.6914 - val_accuracy: 0.5188\n",
      "Epoch 33/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5226 - val_loss: 0.6912 - val_accuracy: 0.5209\n",
      "Epoch 34/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5225 - val_loss: 0.6912 - val_accuracy: 0.5197\n",
      "Epoch 35/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5230 - val_loss: 0.6911 - val_accuracy: 0.5219\n",
      "Epoch 36/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5223 - val_loss: 0.6911 - val_accuracy: 0.5190\n",
      "Epoch 37/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5232 - val_loss: 0.6913 - val_accuracy: 0.5196\n",
      "Epoch 38/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5216 - val_loss: 0.6911 - val_accuracy: 0.5214\n",
      "Epoch 39/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5233 - val_loss: 0.6913 - val_accuracy: 0.5206\n",
      "Epoch 40/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5237 - val_loss: 0.6913 - val_accuracy: 0.5203\n",
      "Epoch 41/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5223 - val_loss: 0.6912 - val_accuracy: 0.5226\n",
      "Epoch 42/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5242 - val_loss: 0.6915 - val_accuracy: 0.5206\n",
      "Epoch 43/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6903 - accuracy: 0.5240 - val_loss: 0.6911 - val_accuracy: 0.5218\n",
      "Epoch 44/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6903 - accuracy: 0.5241 - val_loss: 0.6912 - val_accuracy: 0.5195\n",
      "Epoch 45/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6903 - accuracy: 0.5254 - val_loss: 0.6912 - val_accuracy: 0.5190\n",
      "Epoch 46/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6902 - accuracy: 0.5236 - val_loss: 0.6912 - val_accuracy: 0.5236\n",
      "Epoch 47/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5252 - val_loss: 0.6912 - val_accuracy: 0.5219\n",
      "Epoch 48/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5232 - val_loss: 0.6912 - val_accuracy: 0.5210\n",
      "Epoch 49/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6902 - accuracy: 0.5225 - val_loss: 0.6911 - val_accuracy: 0.5193\n",
      "Epoch 50/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6903 - accuracy: 0.5241 - val_loss: 0.6911 - val_accuracy: 0.5221\n",
      "Epoch 51/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5241 - val_loss: 0.6912 - val_accuracy: 0.5206\n",
      "Epoch 52/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5234 - val_loss: 0.6912 - val_accuracy: 0.5216\n",
      "Epoch 53/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5245 - val_loss: 0.6913 - val_accuracy: 0.5201\n",
      "Epoch 54/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5240 - val_loss: 0.6911 - val_accuracy: 0.5193\n",
      "Epoch 55/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5232 - val_loss: 0.6911 - val_accuracy: 0.5224\n",
      "Epoch 56/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6902 - accuracy: 0.5238 - val_loss: 0.6912 - val_accuracy: 0.5228\n",
      "Epoch 57/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5252 - val_loss: 0.6911 - val_accuracy: 0.5219\n",
      "Epoch 58/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5247 - val_loss: 0.6912 - val_accuracy: 0.5173\n",
      "Epoch 59/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5233 - val_loss: 0.6911 - val_accuracy: 0.5240\n",
      "Epoch 60/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6902 - accuracy: 0.5236 - val_loss: 0.6912 - val_accuracy: 0.5225\n",
      "Epoch 61/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5240 - val_loss: 0.6911 - val_accuracy: 0.5212\n",
      "Epoch 62/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5268 - val_loss: 0.6912 - val_accuracy: 0.5227\n",
      "Epoch 63/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5247 - val_loss: 0.6913 - val_accuracy: 0.5225\n",
      "Epoch 64/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5229 - val_loss: 0.6913 - val_accuracy: 0.5198\n",
      "Epoch 65/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6902 - accuracy: 0.5229 - val_loss: 0.6912 - val_accuracy: 0.5207\n",
      "Epoch 66/1000\n",
      "41660/41660 [==============================] - 0s 12us/sample - loss: 0.6901 - accuracy: 0.5231 - val_loss: 0.6912 - val_accuracy: 0.5240\n",
      "Epoch 67/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5263 - val_loss: 0.6912 - val_accuracy: 0.5235\n",
      "Epoch 68/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5242 - val_loss: 0.6913 - val_accuracy: 0.5231\n",
      "Epoch 69/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5264 - val_loss: 0.6911 - val_accuracy: 0.5223\n",
      "Epoch 70/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6900 - accuracy: 0.5250 - val_loss: 0.6912 - val_accuracy: 0.5210\n",
      "Epoch 71/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6898 - accuracy: 0.5263 - val_loss: 0.6913 - val_accuracy: 0.5215\n",
      "Epoch 72/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5247 - val_loss: 0.6912 - val_accuracy: 0.5178\n",
      "Epoch 73/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5253 - val_loss: 0.6912 - val_accuracy: 0.5198\n",
      "Epoch 74/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6899 - accuracy: 0.5266 - val_loss: 0.6914 - val_accuracy: 0.5192\n",
      "Epoch 75/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5235 - val_loss: 0.6912 - val_accuracy: 0.5222\n",
      "Epoch 76/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6901 - accuracy: 0.5246 - val_loss: 0.6912 - val_accuracy: 0.5206\n",
      "Epoch 77/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5239 - val_loss: 0.6912 - val_accuracy: 0.5217\n",
      "Epoch 78/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6898 - accuracy: 0.5265 - val_loss: 0.6914 - val_accuracy: 0.5192\n",
      "Epoch 79/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5237 - val_loss: 0.6913 - val_accuracy: 0.5201\n",
      "Epoch 80/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6898 - accuracy: 0.5265 - val_loss: 0.6912 - val_accuracy: 0.5210\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5247 - val_loss: 0.6912 - val_accuracy: 0.5212\n",
      "Epoch 82/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6898 - accuracy: 0.5257 - val_loss: 0.6913 - val_accuracy: 0.5212\n",
      "Epoch 83/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5242 - val_loss: 0.6912 - val_accuracy: 0.5238\n",
      "Epoch 84/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6898 - accuracy: 0.5251 - val_loss: 0.6914 - val_accuracy: 0.5207\n",
      "Epoch 85/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5235 - val_loss: 0.6913 - val_accuracy: 0.5234\n",
      "Epoch 86/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5267 - val_loss: 0.6912 - val_accuracy: 0.5241\n",
      "Epoch 87/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6898 - accuracy: 0.5259 - val_loss: 0.6912 - val_accuracy: 0.5212\n",
      "Training with significance = 5.03, run 5\n",
      "Train on 41660 samples, validate on 10415 samples\n",
      "Epoch 1/1000\n",
      "41660/41660 [==============================] - 1s 27us/sample - loss: 0.6931 - accuracy: 0.5086 - val_loss: 0.6948 - val_accuracy: 0.4976\n",
      "Epoch 2/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5157 - val_loss: 0.6930 - val_accuracy: 0.5075\n",
      "Epoch 3/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5173 - val_loss: 0.6923 - val_accuracy: 0.5125\n",
      "Epoch 4/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5173 - val_loss: 0.6921 - val_accuracy: 0.5138\n",
      "Epoch 5/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5176 - val_loss: 0.6920 - val_accuracy: 0.5135\n",
      "Epoch 6/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6914 - accuracy: 0.5187 - val_loss: 0.6920 - val_accuracy: 0.5154\n",
      "Epoch 7/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5194 - val_loss: 0.6920 - val_accuracy: 0.5095\n",
      "Epoch 8/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5179 - val_loss: 0.6919 - val_accuracy: 0.5113\n",
      "Epoch 9/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5181 - val_loss: 0.6920 - val_accuracy: 0.5150\n",
      "Epoch 10/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5200 - val_loss: 0.6919 - val_accuracy: 0.5127\n",
      "Epoch 11/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6912 - accuracy: 0.5184 - val_loss: 0.6919 - val_accuracy: 0.5121\n",
      "Epoch 12/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5199 - val_loss: 0.6918 - val_accuracy: 0.5151\n",
      "Epoch 13/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5185 - val_loss: 0.6918 - val_accuracy: 0.5121\n",
      "Epoch 14/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5211 - val_loss: 0.6919 - val_accuracy: 0.5148\n",
      "Epoch 15/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5215 - val_loss: 0.6919 - val_accuracy: 0.5134\n",
      "Epoch 16/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5214 - val_loss: 0.6920 - val_accuracy: 0.5114\n",
      "Epoch 17/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5212 - val_loss: 0.6919 - val_accuracy: 0.5138\n",
      "Epoch 18/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5201 - val_loss: 0.6918 - val_accuracy: 0.5135\n",
      "Epoch 19/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6909 - accuracy: 0.5206 - val_loss: 0.6918 - val_accuracy: 0.5099\n",
      "Epoch 20/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6909 - accuracy: 0.5195 - val_loss: 0.6919 - val_accuracy: 0.5140\n",
      "Epoch 21/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6908 - accuracy: 0.5223 - val_loss: 0.6919 - val_accuracy: 0.5125\n",
      "Epoch 22/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6909 - accuracy: 0.5228 - val_loss: 0.6919 - val_accuracy: 0.5167\n",
      "Epoch 23/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5217 - val_loss: 0.6918 - val_accuracy: 0.5131\n",
      "Epoch 24/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5216 - val_loss: 0.6918 - val_accuracy: 0.5153\n",
      "Epoch 25/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6909 - accuracy: 0.5222 - val_loss: 0.6918 - val_accuracy: 0.5131\n",
      "Epoch 26/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5205 - val_loss: 0.6918 - val_accuracy: 0.5140\n",
      "Epoch 27/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6908 - accuracy: 0.5224 - val_loss: 0.6918 - val_accuracy: 0.5151\n",
      "Epoch 28/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5222 - val_loss: 0.6919 - val_accuracy: 0.5144\n",
      "Epoch 29/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6907 - accuracy: 0.5215 - val_loss: 0.6919 - val_accuracy: 0.5140\n",
      "Epoch 30/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5232 - val_loss: 0.6918 - val_accuracy: 0.5154\n",
      "Epoch 31/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5216 - val_loss: 0.6918 - val_accuracy: 0.5144\n",
      "Epoch 32/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5229 - val_loss: 0.6919 - val_accuracy: 0.5140\n",
      "Epoch 33/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5234 - val_loss: 0.6919 - val_accuracy: 0.5128\n",
      "Epoch 34/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5222 - val_loss: 0.6920 - val_accuracy: 0.5141\n",
      "Epoch 35/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5223 - val_loss: 0.6919 - val_accuracy: 0.5148\n",
      "Epoch 36/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5216 - val_loss: 0.6919 - val_accuracy: 0.5134\n",
      "Epoch 37/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5214 - val_loss: 0.6918 - val_accuracy: 0.5125\n",
      "Epoch 38/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5249 - val_loss: 0.6919 - val_accuracy: 0.5151\n",
      "Epoch 39/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5218 - val_loss: 0.6919 - val_accuracy: 0.5139\n",
      "Epoch 40/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5238 - val_loss: 0.6919 - val_accuracy: 0.5126\n",
      "Epoch 41/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5232 - val_loss: 0.6918 - val_accuracy: 0.5153\n",
      "Epoch 42/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5232 - val_loss: 0.6919 - val_accuracy: 0.5162\n",
      "Epoch 43/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5236 - val_loss: 0.6919 - val_accuracy: 0.5161\n",
      "Epoch 44/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5220 - val_loss: 0.6919 - val_accuracy: 0.5132\n",
      "Epoch 45/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5242 - val_loss: 0.6920 - val_accuracy: 0.5129\n",
      "Epoch 46/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5241 - val_loss: 0.6919 - val_accuracy: 0.5171\n",
      "Epoch 47/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5259 - val_loss: 0.6919 - val_accuracy: 0.5169\n",
      "Epoch 48/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5235 - val_loss: 0.6919 - val_accuracy: 0.5148\n",
      "Epoch 49/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5240 - val_loss: 0.6918 - val_accuracy: 0.5139\n",
      "Epoch 50/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5240 - val_loss: 0.6918 - val_accuracy: 0.5158\n",
      "Epoch 51/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5223 - val_loss: 0.6919 - val_accuracy: 0.5140\n",
      "Epoch 52/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5227 - val_loss: 0.6919 - val_accuracy: 0.5139\n",
      "Epoch 53/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5248 - val_loss: 0.6918 - val_accuracy: 0.5164\n",
      "Epoch 54/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5158\n",
      "Epoch 55/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6904 - accuracy: 0.5224 - val_loss: 0.6919 - val_accuracy: 0.5147\n",
      "Epoch 56/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5223 - val_loss: 0.6919 - val_accuracy: 0.5150\n",
      "Training with significance = 5.03, run 6\n",
      "Train on 41660 samples, validate on 10415 samples\n",
      "Epoch 1/1000\n",
      "41660/41660 [==============================] - 1s 27us/sample - loss: 0.6930 - accuracy: 0.5074 - val_loss: 0.6930 - val_accuracy: 0.5125\n",
      "Epoch 2/1000\n",
      "41660/41660 [==============================] - 0s 12us/sample - loss: 0.6920 - accuracy: 0.5166 - val_loss: 0.6921 - val_accuracy: 0.5201\n",
      "Epoch 3/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5157 - val_loss: 0.6916 - val_accuracy: 0.5223\n",
      "Epoch 4/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5170 - val_loss: 0.6916 - val_accuracy: 0.5206\n",
      "Epoch 5/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5198 - val_loss: 0.6915 - val_accuracy: 0.5211\n",
      "Epoch 6/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5187 - val_loss: 0.6913 - val_accuracy: 0.5215\n",
      "Epoch 7/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5193 - val_loss: 0.6915 - val_accuracy: 0.5170\n",
      "Epoch 8/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6915 - accuracy: 0.5176 - val_loss: 0.6913 - val_accuracy: 0.5213\n",
      "Epoch 9/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5195 - val_loss: 0.6913 - val_accuracy: 0.5185\n",
      "Epoch 10/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6914 - accuracy: 0.5180 - val_loss: 0.6912 - val_accuracy: 0.5208\n",
      "Epoch 11/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6913 - accuracy: 0.5190 - val_loss: 0.6916 - val_accuracy: 0.5207\n",
      "Epoch 12/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5188 - val_loss: 0.6912 - val_accuracy: 0.5219\n",
      "Epoch 13/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6913 - accuracy: 0.5196 - val_loss: 0.6912 - val_accuracy: 0.5197\n",
      "Epoch 14/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5198 - val_loss: 0.6914 - val_accuracy: 0.5200\n",
      "Epoch 15/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5181 - val_loss: 0.6912 - val_accuracy: 0.5198\n",
      "Epoch 16/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5183 - val_loss: 0.6913 - val_accuracy: 0.5190\n",
      "Epoch 17/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5203 - val_loss: 0.6914 - val_accuracy: 0.5210\n",
      "Epoch 18/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5188 - val_loss: 0.6912 - val_accuracy: 0.5193\n",
      "Epoch 19/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5188 - val_loss: 0.6912 - val_accuracy: 0.5173\n",
      "Epoch 20/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5227 - val_loss: 0.6912 - val_accuracy: 0.5157\n",
      "Epoch 21/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5208 - val_loss: 0.6913 - val_accuracy: 0.5170\n",
      "Epoch 22/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5175 - val_loss: 0.6914 - val_accuracy: 0.5202\n",
      "Epoch 23/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6910 - accuracy: 0.5186 - val_loss: 0.6911 - val_accuracy: 0.5162\n",
      "Epoch 24/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6910 - accuracy: 0.5193 - val_loss: 0.6912 - val_accuracy: 0.5157\n",
      "Epoch 25/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5199 - val_loss: 0.6911 - val_accuracy: 0.5156\n",
      "Epoch 26/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5215 - val_loss: 0.6914 - val_accuracy: 0.5203\n",
      "Epoch 27/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6909 - accuracy: 0.5187 - val_loss: 0.6914 - val_accuracy: 0.5149\n",
      "Epoch 28/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6909 - accuracy: 0.5195 - val_loss: 0.6914 - val_accuracy: 0.5175\n",
      "Epoch 29/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5201 - val_loss: 0.6911 - val_accuracy: 0.5150\n",
      "Epoch 30/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5192 - val_loss: 0.6916 - val_accuracy: 0.5159\n",
      "Epoch 31/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5198 - val_loss: 0.6913 - val_accuracy: 0.5157\n",
      "Epoch 32/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5223 - val_loss: 0.6911 - val_accuracy: 0.5171\n",
      "Epoch 33/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5208 - val_loss: 0.6913 - val_accuracy: 0.5191\n",
      "Epoch 34/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5210 - val_loss: 0.6912 - val_accuracy: 0.5138\n",
      "Epoch 35/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6909 - accuracy: 0.5217 - val_loss: 0.6913 - val_accuracy: 0.5178\n",
      "Epoch 36/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5205 - val_loss: 0.6912 - val_accuracy: 0.5183\n",
      "Epoch 37/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6909 - accuracy: 0.5193 - val_loss: 0.6916 - val_accuracy: 0.5208\n",
      "Epoch 38/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5200 - val_loss: 0.6914 - val_accuracy: 0.5139\n",
      "Epoch 39/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5227 - val_loss: 0.6913 - val_accuracy: 0.5170\n",
      "Epoch 40/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5215 - val_loss: 0.6915 - val_accuracy: 0.5162\n",
      "Epoch 41/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5211 - val_loss: 0.6915 - val_accuracy: 0.5158\n",
      "Epoch 42/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5209 - val_loss: 0.6914 - val_accuracy: 0.5178\n",
      "Epoch 43/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6909 - accuracy: 0.5205 - val_loss: 0.6914 - val_accuracy: 0.5110\n",
      "Epoch 44/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6908 - accuracy: 0.5205 - val_loss: 0.6914 - val_accuracy: 0.5186\n",
      "Epoch 45/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6907 - accuracy: 0.5235 - val_loss: 0.6912 - val_accuracy: 0.5169\n",
      "Epoch 46/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6907 - accuracy: 0.5207 - val_loss: 0.6913 - val_accuracy: 0.5112\n",
      "Epoch 47/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6908 - accuracy: 0.5207 - val_loss: 0.6914 - val_accuracy: 0.5112\n",
      "Epoch 48/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5203 - val_loss: 0.6913 - val_accuracy: 0.5158\n",
      "Epoch 49/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5200 - val_loss: 0.6912 - val_accuracy: 0.5152\n",
      "Epoch 50/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5207 - val_loss: 0.6913 - val_accuracy: 0.5151\n",
      "Epoch 51/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6907 - accuracy: 0.5216 - val_loss: 0.6915 - val_accuracy: 0.5113\n",
      "Epoch 52/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5200 - val_loss: 0.6915 - val_accuracy: 0.5107\n",
      "Epoch 53/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5212 - val_loss: 0.6912 - val_accuracy: 0.5165\n",
      "Epoch 54/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6908 - accuracy: 0.5216 - val_loss: 0.6912 - val_accuracy: 0.5165\n",
      "Epoch 55/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5212 - val_loss: 0.6914 - val_accuracy: 0.5123\n",
      "Epoch 56/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6907 - accuracy: 0.5227 - val_loss: 0.6913 - val_accuracy: 0.5172\n",
      "Epoch 57/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5214 - val_loss: 0.6914 - val_accuracy: 0.5106\n",
      "Epoch 58/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5214 - val_loss: 0.6913 - val_accuracy: 0.5135\n",
      "Epoch 59/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5229 - val_loss: 0.6914 - val_accuracy: 0.5126\n",
      "Epoch 60/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5211 - val_loss: 0.6913 - val_accuracy: 0.5148\n",
      "Epoch 61/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5205 - val_loss: 0.6917 - val_accuracy: 0.5148\n",
      "Epoch 62/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5224 - val_loss: 0.6915 - val_accuracy: 0.5171\n",
      "Training with significance = 5.03, run 7\n",
      "Train on 41660 samples, validate on 10415 samples\n",
      "Epoch 1/1000\n",
      "41660/41660 [==============================] - 1s 28us/sample - loss: 0.6929 - accuracy: 0.5120 - val_loss: 0.6930 - val_accuracy: 0.5158\n",
      "Epoch 2/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5148 - val_loss: 0.6928 - val_accuracy: 0.5184\n",
      "Epoch 3/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5137 - val_loss: 0.6922 - val_accuracy: 0.5155\n",
      "Epoch 4/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5152 - val_loss: 0.6914 - val_accuracy: 0.5252\n",
      "Epoch 5/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5169 - val_loss: 0.6913 - val_accuracy: 0.5244\n",
      "Epoch 6/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6914 - accuracy: 0.5165 - val_loss: 0.6914 - val_accuracy: 0.5212\n",
      "Epoch 7/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5151 - val_loss: 0.6915 - val_accuracy: 0.5249\n",
      "Epoch 8/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5158 - val_loss: 0.6914 - val_accuracy: 0.5219\n",
      "Epoch 9/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5178 - val_loss: 0.6912 - val_accuracy: 0.5228\n",
      "Epoch 10/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6913 - accuracy: 0.5169 - val_loss: 0.6914 - val_accuracy: 0.5222\n",
      "Epoch 11/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5175 - val_loss: 0.6912 - val_accuracy: 0.5222\n",
      "Epoch 12/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5178 - val_loss: 0.6914 - val_accuracy: 0.5256\n",
      "Epoch 13/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5173 - val_loss: 0.6912 - val_accuracy: 0.5232\n",
      "Epoch 14/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6911 - accuracy: 0.5177 - val_loss: 0.6914 - val_accuracy: 0.5228\n",
      "Epoch 15/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5190 - val_loss: 0.6914 - val_accuracy: 0.5189\n",
      "Epoch 16/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6910 - accuracy: 0.5170 - val_loss: 0.6914 - val_accuracy: 0.5184\n",
      "Epoch 17/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6910 - accuracy: 0.5204 - val_loss: 0.6913 - val_accuracy: 0.5225\n",
      "Epoch 18/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5190 - val_loss: 0.6916 - val_accuracy: 0.5210\n",
      "Epoch 19/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6910 - accuracy: 0.5202 - val_loss: 0.6914 - val_accuracy: 0.5224\n",
      "Epoch 20/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6909 - accuracy: 0.5201 - val_loss: 0.6913 - val_accuracy: 0.5226\n",
      "Epoch 21/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6907 - accuracy: 0.5215 - val_loss: 0.6915 - val_accuracy: 0.5190\n",
      "Epoch 22/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5198 - val_loss: 0.6914 - val_accuracy: 0.5237\n",
      "Epoch 23/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6908 - accuracy: 0.5207 - val_loss: 0.6914 - val_accuracy: 0.5217\n",
      "Epoch 24/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6908 - accuracy: 0.5207 - val_loss: 0.6913 - val_accuracy: 0.5190\n",
      "Epoch 25/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5190 - val_loss: 0.6914 - val_accuracy: 0.5182\n",
      "Epoch 26/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5197 - val_loss: 0.6913 - val_accuracy: 0.5238\n",
      "Epoch 27/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5209 - val_loss: 0.6913 - val_accuracy: 0.5221\n",
      "Epoch 28/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5212 - val_loss: 0.6914 - val_accuracy: 0.5161\n",
      "Epoch 29/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6908 - accuracy: 0.5201 - val_loss: 0.6914 - val_accuracy: 0.5204\n",
      "Epoch 30/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6907 - accuracy: 0.5207 - val_loss: 0.6913 - val_accuracy: 0.5186\n",
      "Epoch 31/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6907 - accuracy: 0.5203 - val_loss: 0.6914 - val_accuracy: 0.5181\n",
      "Epoch 32/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6908 - accuracy: 0.5212 - val_loss: 0.6913 - val_accuracy: 0.5216\n",
      "Epoch 33/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5206 - val_loss: 0.6914 - val_accuracy: 0.5170\n",
      "Epoch 34/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6907 - accuracy: 0.5202 - val_loss: 0.6913 - val_accuracy: 0.5180\n",
      "Epoch 35/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5213 - val_loss: 0.6914 - val_accuracy: 0.5159\n",
      "Epoch 36/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5210 - val_loss: 0.6914 - val_accuracy: 0.5220\n",
      "Epoch 37/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6907 - accuracy: 0.5212 - val_loss: 0.6915 - val_accuracy: 0.5151\n",
      "Epoch 38/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5220 - val_loss: 0.6914 - val_accuracy: 0.5193\n",
      "Epoch 39/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5234 - val_loss: 0.6915 - val_accuracy: 0.5165\n",
      "Epoch 40/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5212 - val_loss: 0.6914 - val_accuracy: 0.5163\n",
      "Epoch 41/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5226 - val_loss: 0.6916 - val_accuracy: 0.5146\n",
      "Training with significance = 5.03, run 8\n",
      "Train on 41660 samples, validate on 10415 samples\n",
      "Epoch 1/1000\n",
      "41660/41660 [==============================] - 1s 28us/sample - loss: 0.6928 - accuracy: 0.5113 - val_loss: 0.6925 - val_accuracy: 0.5068\n",
      "Epoch 2/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6921 - accuracy: 0.5169 - val_loss: 0.6913 - val_accuracy: 0.5139\n",
      "Epoch 3/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6920 - accuracy: 0.5167 - val_loss: 0.6909 - val_accuracy: 0.5204\n",
      "Epoch 4/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6918 - accuracy: 0.5190 - val_loss: 0.6908 - val_accuracy: 0.5207\n",
      "Epoch 5/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6918 - accuracy: 0.5179 - val_loss: 0.6907 - val_accuracy: 0.5206\n",
      "Epoch 6/1000\n",
      "41660/41660 [==============================] - 0s 12us/sample - loss: 0.6917 - accuracy: 0.5177 - val_loss: 0.6907 - val_accuracy: 0.5213\n",
      "Epoch 7/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5204 - val_loss: 0.6906 - val_accuracy: 0.5209\n",
      "Epoch 8/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5206 - val_loss: 0.6906 - val_accuracy: 0.5234\n",
      "Epoch 9/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5194 - val_loss: 0.6905 - val_accuracy: 0.5231\n",
      "Epoch 10/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5194 - val_loss: 0.6905 - val_accuracy: 0.5231\n",
      "Epoch 11/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5187 - val_loss: 0.6905 - val_accuracy: 0.5187\n",
      "Epoch 12/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5183 - val_loss: 0.6904 - val_accuracy: 0.5219\n",
      "Epoch 13/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5199 - val_loss: 0.6904 - val_accuracy: 0.5219\n",
      "Epoch 14/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5192 - val_loss: 0.6905 - val_accuracy: 0.5211\n",
      "Epoch 15/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5202 - val_loss: 0.6905 - val_accuracy: 0.5198\n",
      "Epoch 16/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5215 - val_loss: 0.6905 - val_accuracy: 0.5206\n",
      "Epoch 17/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6913 - accuracy: 0.5203 - val_loss: 0.6905 - val_accuracy: 0.5184\n",
      "Epoch 18/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5194 - val_loss: 0.6904 - val_accuracy: 0.5200\n",
      "Epoch 19/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6911 - accuracy: 0.5216 - val_loss: 0.6906 - val_accuracy: 0.5216\n",
      "Epoch 20/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6912 - accuracy: 0.5195 - val_loss: 0.6904 - val_accuracy: 0.5185\n",
      "Epoch 21/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5198 - val_loss: 0.6903 - val_accuracy: 0.5218\n",
      "Epoch 22/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5188 - val_loss: 0.6903 - val_accuracy: 0.5212\n",
      "Epoch 23/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5197 - val_loss: 0.6904 - val_accuracy: 0.5208\n",
      "Epoch 24/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5190 - val_loss: 0.6903 - val_accuracy: 0.5209\n",
      "Epoch 25/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5209 - val_loss: 0.6903 - val_accuracy: 0.5226\n",
      "Epoch 26/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5199 - val_loss: 0.6903 - val_accuracy: 0.5197\n",
      "Epoch 27/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5201 - val_loss: 0.6902 - val_accuracy: 0.5201\n",
      "Epoch 28/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6911 - accuracy: 0.5199 - val_loss: 0.6903 - val_accuracy: 0.5218\n",
      "Epoch 29/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5211 - val_loss: 0.6903 - val_accuracy: 0.5226\n",
      "Epoch 30/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6911 - accuracy: 0.5193 - val_loss: 0.6903 - val_accuracy: 0.5196\n",
      "Epoch 31/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5205 - val_loss: 0.6902 - val_accuracy: 0.5202\n",
      "Epoch 32/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5199 - val_loss: 0.6902 - val_accuracy: 0.5214\n",
      "Epoch 33/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5203 - val_loss: 0.6902 - val_accuracy: 0.5205\n",
      "Epoch 34/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5213 - val_loss: 0.6902 - val_accuracy: 0.5211\n",
      "Epoch 35/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5197 - val_loss: 0.6903 - val_accuracy: 0.5220\n",
      "Epoch 36/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5200 - val_loss: 0.6903 - val_accuracy: 0.5202\n",
      "Epoch 37/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5207 - val_loss: 0.6902 - val_accuracy: 0.5199\n",
      "Epoch 38/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5209 - val_loss: 0.6901 - val_accuracy: 0.5210\n",
      "Epoch 39/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5196 - val_loss: 0.6902 - val_accuracy: 0.5203\n",
      "Epoch 40/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5208 - val_loss: 0.6902 - val_accuracy: 0.5203\n",
      "Epoch 41/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5230 - val_loss: 0.6902 - val_accuracy: 0.5206\n",
      "Epoch 42/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6909 - accuracy: 0.5195 - val_loss: 0.6902 - val_accuracy: 0.5217\n",
      "Epoch 43/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5210 - val_loss: 0.6901 - val_accuracy: 0.5215\n",
      "Epoch 44/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6908 - accuracy: 0.5211 - val_loss: 0.6902 - val_accuracy: 0.5187\n",
      "Epoch 45/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5209 - val_loss: 0.6901 - val_accuracy: 0.5191\n",
      "Epoch 46/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5211 - val_loss: 0.6901 - val_accuracy: 0.5205\n",
      "Epoch 47/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5209 - val_loss: 0.6902 - val_accuracy: 0.5192\n",
      "Epoch 48/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5224 - val_loss: 0.6902 - val_accuracy: 0.5224\n",
      "Epoch 49/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5217 - val_loss: 0.6901 - val_accuracy: 0.5237\n",
      "Epoch 50/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6908 - accuracy: 0.5215 - val_loss: 0.6901 - val_accuracy: 0.5233\n",
      "Epoch 51/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6908 - accuracy: 0.5217 - val_loss: 0.6902 - val_accuracy: 0.5217\n",
      "Epoch 52/1000\n",
      "41660/41660 [==============================] - 0s 12us/sample - loss: 0.6909 - accuracy: 0.5213 - val_loss: 0.6901 - val_accuracy: 0.5194\n",
      "Epoch 53/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6907 - accuracy: 0.5222 - val_loss: 0.6901 - val_accuracy: 0.5225\n",
      "Epoch 54/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5229 - val_loss: 0.6901 - val_accuracy: 0.5228\n",
      "Epoch 55/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5217 - val_loss: 0.6902 - val_accuracy: 0.5223\n",
      "Epoch 56/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5231 - val_loss: 0.6900 - val_accuracy: 0.5212\n",
      "Epoch 57/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5191 - val_loss: 0.6901 - val_accuracy: 0.5225\n",
      "Epoch 58/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5219 - val_loss: 0.6901 - val_accuracy: 0.5216\n",
      "Epoch 59/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5232 - val_loss: 0.6900 - val_accuracy: 0.5251\n",
      "Epoch 60/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6908 - accuracy: 0.5222 - val_loss: 0.6899 - val_accuracy: 0.5230\n",
      "Epoch 61/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5219 - val_loss: 0.6901 - val_accuracy: 0.5220\n",
      "Epoch 62/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5212 - val_loss: 0.6900 - val_accuracy: 0.5217\n",
      "Epoch 63/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5233 - val_loss: 0.6900 - val_accuracy: 0.5219\n",
      "Epoch 64/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6907 - accuracy: 0.5231 - val_loss: 0.6900 - val_accuracy: 0.5233\n",
      "Epoch 65/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5213 - val_loss: 0.6900 - val_accuracy: 0.5234\n",
      "Epoch 66/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5220 - val_loss: 0.6900 - val_accuracy: 0.5231\n",
      "Epoch 67/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5215 - val_loss: 0.6901 - val_accuracy: 0.5217\n",
      "Epoch 68/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5218 - val_loss: 0.6900 - val_accuracy: 0.5216\n",
      "Epoch 69/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5233 - val_loss: 0.6901 - val_accuracy: 0.5209\n",
      "Epoch 70/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5232 - val_loss: 0.6901 - val_accuracy: 0.5213\n",
      "Epoch 71/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5233 - val_loss: 0.6899 - val_accuracy: 0.5211\n",
      "Epoch 72/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5208 - val_loss: 0.6900 - val_accuracy: 0.5217\n",
      "Epoch 73/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5221 - val_loss: 0.6901 - val_accuracy: 0.5212\n",
      "Epoch 74/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5230 - val_loss: 0.6899 - val_accuracy: 0.5224\n",
      "Epoch 75/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5212 - val_loss: 0.6899 - val_accuracy: 0.5215\n",
      "Epoch 76/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5230 - val_loss: 0.6899 - val_accuracy: 0.5223\n",
      "Epoch 77/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6904 - accuracy: 0.5249 - val_loss: 0.6900 - val_accuracy: 0.5233\n",
      "Epoch 78/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5225 - val_loss: 0.6900 - val_accuracy: 0.5236\n",
      "Epoch 79/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5227 - val_loss: 0.6899 - val_accuracy: 0.5226\n",
      "Epoch 80/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5227 - val_loss: 0.6901 - val_accuracy: 0.5203\n",
      "Epoch 81/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5213 - val_loss: 0.6899 - val_accuracy: 0.5237\n",
      "Epoch 82/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5215 - val_loss: 0.6900 - val_accuracy: 0.5238\n",
      "Epoch 83/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5222 - val_loss: 0.6900 - val_accuracy: 0.5199\n",
      "Epoch 84/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5228 - val_loss: 0.6900 - val_accuracy: 0.5220\n",
      "Epoch 85/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5229 - val_loss: 0.6899 - val_accuracy: 0.5241\n",
      "Epoch 86/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6904 - accuracy: 0.5222 - val_loss: 0.6900 - val_accuracy: 0.5228\n",
      "Epoch 87/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5201 - val_loss: 0.6899 - val_accuracy: 0.5226\n",
      "Epoch 88/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5236 - val_loss: 0.6899 - val_accuracy: 0.5231\n",
      "Epoch 89/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5241 - val_loss: 0.6899 - val_accuracy: 0.5209\n",
      "Epoch 90/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5215 - val_loss: 0.6901 - val_accuracy: 0.5258\n",
      "Epoch 91/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5210 - val_loss: 0.6900 - val_accuracy: 0.5237\n",
      "Epoch 92/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5231 - val_loss: 0.6900 - val_accuracy: 0.5208\n",
      "Epoch 93/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5237 - val_loss: 0.6899 - val_accuracy: 0.5244\n",
      "Epoch 94/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6904 - accuracy: 0.5225 - val_loss: 0.6901 - val_accuracy: 0.5241\n",
      "Epoch 95/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5231 - val_loss: 0.6900 - val_accuracy: 0.5239\n",
      "Epoch 96/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5208 - val_loss: 0.6899 - val_accuracy: 0.5241\n",
      "Epoch 97/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5235 - val_loss: 0.6899 - val_accuracy: 0.5237\n",
      "Epoch 98/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5235 - val_loss: 0.6900 - val_accuracy: 0.5222\n",
      "Epoch 99/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5226 - val_loss: 0.6900 - val_accuracy: 0.5225\n",
      "Epoch 100/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5216 - val_loss: 0.6899 - val_accuracy: 0.5235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5243 - val_loss: 0.6899 - val_accuracy: 0.5236\n",
      "Epoch 102/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6904 - accuracy: 0.5245 - val_loss: 0.6901 - val_accuracy: 0.5229\n",
      "Epoch 103/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5234 - val_loss: 0.6900 - val_accuracy: 0.5211\n",
      "Epoch 104/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5233 - val_loss: 0.6901 - val_accuracy: 0.5181\n",
      "Epoch 105/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6903 - accuracy: 0.5235 - val_loss: 0.6900 - val_accuracy: 0.5217\n",
      "Epoch 106/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6904 - accuracy: 0.5221 - val_loss: 0.6900 - val_accuracy: 0.5201\n",
      "Epoch 107/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6904 - accuracy: 0.5228 - val_loss: 0.6900 - val_accuracy: 0.5236\n",
      "Epoch 108/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6902 - accuracy: 0.5217 - val_loss: 0.6900 - val_accuracy: 0.5215\n",
      "Epoch 109/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5223 - val_loss: 0.6900 - val_accuracy: 0.5208\n",
      "Epoch 110/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5250 - val_loss: 0.6899 - val_accuracy: 0.5238\n",
      "Epoch 111/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5221 - val_loss: 0.6899 - val_accuracy: 0.5247\n",
      "Epoch 112/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6903 - accuracy: 0.5236 - val_loss: 0.6901 - val_accuracy: 0.5249\n",
      "Epoch 113/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6904 - accuracy: 0.5232 - val_loss: 0.6899 - val_accuracy: 0.5213\n",
      "Epoch 114/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5233 - val_loss: 0.6901 - val_accuracy: 0.5200\n",
      "Epoch 115/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5220 - val_loss: 0.6899 - val_accuracy: 0.5246\n",
      "Epoch 116/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5246 - val_loss: 0.6898 - val_accuracy: 0.5233\n",
      "Epoch 117/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5246 - val_loss: 0.6900 - val_accuracy: 0.5237\n",
      "Epoch 118/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5237 - val_loss: 0.6902 - val_accuracy: 0.5219\n",
      "Epoch 119/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5233 - val_loss: 0.6900 - val_accuracy: 0.5219\n",
      "Epoch 120/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5259 - val_loss: 0.6899 - val_accuracy: 0.5234\n",
      "Epoch 121/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5242 - val_loss: 0.6900 - val_accuracy: 0.5226\n",
      "Epoch 122/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5240 - val_loss: 0.6900 - val_accuracy: 0.5238\n",
      "Epoch 123/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6901 - accuracy: 0.5250 - val_loss: 0.6900 - val_accuracy: 0.5230\n",
      "Epoch 124/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5231 - val_loss: 0.6900 - val_accuracy: 0.5217\n",
      "Epoch 125/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5238 - val_loss: 0.6899 - val_accuracy: 0.5260\n",
      "Epoch 126/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5248 - val_loss: 0.6901 - val_accuracy: 0.5250\n",
      "Epoch 127/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5236 - val_loss: 0.6900 - val_accuracy: 0.5225\n",
      "Epoch 128/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5254 - val_loss: 0.6902 - val_accuracy: 0.5193\n",
      "Epoch 129/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5237 - val_loss: 0.6900 - val_accuracy: 0.5225\n",
      "Epoch 130/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5244 - val_loss: 0.6899 - val_accuracy: 0.5244\n",
      "Epoch 131/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5228 - val_loss: 0.6900 - val_accuracy: 0.5217\n",
      "Epoch 132/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5240 - val_loss: 0.6900 - val_accuracy: 0.5226\n",
      "Epoch 133/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5264 - val_loss: 0.6901 - val_accuracy: 0.5241\n",
      "Epoch 134/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5229 - val_loss: 0.6900 - val_accuracy: 0.5225\n",
      "Epoch 135/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5244 - val_loss: 0.6900 - val_accuracy: 0.5223\n",
      "Epoch 136/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6900 - accuracy: 0.5250 - val_loss: 0.6900 - val_accuracy: 0.5231\n",
      "Epoch 137/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5229 - val_loss: 0.6900 - val_accuracy: 0.5244\n",
      "Epoch 138/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5245 - val_loss: 0.6901 - val_accuracy: 0.5215\n",
      "Epoch 139/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5248 - val_loss: 0.6900 - val_accuracy: 0.5201\n",
      "Epoch 140/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5215 - val_loss: 0.6901 - val_accuracy: 0.5193\n",
      "Epoch 141/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5249 - val_loss: 0.6900 - val_accuracy: 0.5215\n",
      "Epoch 142/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6901 - accuracy: 0.5236 - val_loss: 0.6900 - val_accuracy: 0.5193\n",
      "Epoch 143/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6902 - accuracy: 0.5226 - val_loss: 0.6901 - val_accuracy: 0.5222\n",
      "Epoch 144/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5254 - val_loss: 0.6900 - val_accuracy: 0.5221\n",
      "Epoch 145/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5243 - val_loss: 0.6901 - val_accuracy: 0.5182\n",
      "Epoch 146/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5259 - val_loss: 0.6899 - val_accuracy: 0.5243\n",
      "Training with significance = 5.03, run 9\n",
      "Train on 41660 samples, validate on 10415 samples\n",
      "Epoch 1/1000\n",
      "41660/41660 [==============================] - 1s 28us/sample - loss: 0.6941 - accuracy: 0.5031 - val_loss: 0.6940 - val_accuracy: 0.4957\n",
      "Epoch 2/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5158 - val_loss: 0.6929 - val_accuracy: 0.5018\n",
      "Epoch 3/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6919 - accuracy: 0.5191 - val_loss: 0.6928 - val_accuracy: 0.5054\n",
      "Epoch 4/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5184 - val_loss: 0.6926 - val_accuracy: 0.5116\n",
      "Epoch 5/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5179 - val_loss: 0.6927 - val_accuracy: 0.5149\n",
      "Epoch 6/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5197 - val_loss: 0.6927 - val_accuracy: 0.5134\n",
      "Epoch 7/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5184 - val_loss: 0.6926 - val_accuracy: 0.5106\n",
      "Epoch 8/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6914 - accuracy: 0.5187 - val_loss: 0.6926 - val_accuracy: 0.5147\n",
      "Epoch 9/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5185 - val_loss: 0.6928 - val_accuracy: 0.5155\n",
      "Epoch 10/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6914 - accuracy: 0.5192 - val_loss: 0.6926 - val_accuracy: 0.5117\n",
      "Epoch 11/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5206 - val_loss: 0.6928 - val_accuracy: 0.5145\n",
      "Epoch 12/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5185 - val_loss: 0.6926 - val_accuracy: 0.5147\n",
      "Epoch 13/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5200 - val_loss: 0.6926 - val_accuracy: 0.5142\n",
      "Epoch 14/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5190 - val_loss: 0.6925 - val_accuracy: 0.5132\n",
      "Epoch 15/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5194 - val_loss: 0.6925 - val_accuracy: 0.5113\n",
      "Epoch 16/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5213 - val_loss: 0.6924 - val_accuracy: 0.5126\n",
      "Epoch 17/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5200 - val_loss: 0.6925 - val_accuracy: 0.5132\n",
      "Epoch 18/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5216 - val_loss: 0.6925 - val_accuracy: 0.5150\n",
      "Epoch 19/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6911 - accuracy: 0.5185 - val_loss: 0.6925 - val_accuracy: 0.5116\n",
      "Epoch 20/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6911 - accuracy: 0.5210 - val_loss: 0.6926 - val_accuracy: 0.5150\n",
      "Epoch 21/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6911 - accuracy: 0.5207 - val_loss: 0.6925 - val_accuracy: 0.5137\n",
      "Epoch 22/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6911 - accuracy: 0.5209 - val_loss: 0.6925 - val_accuracy: 0.5126\n",
      "Epoch 23/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5215 - val_loss: 0.6925 - val_accuracy: 0.5101\n",
      "Epoch 24/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5213 - val_loss: 0.6926 - val_accuracy: 0.5133\n",
      "Epoch 25/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5224 - val_loss: 0.6925 - val_accuracy: 0.5130\n",
      "Epoch 26/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5222 - val_loss: 0.6925 - val_accuracy: 0.5118\n",
      "Epoch 27/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6911 - accuracy: 0.5197 - val_loss: 0.6925 - val_accuracy: 0.5133\n",
      "Epoch 28/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6910 - accuracy: 0.5216 - val_loss: 0.6926 - val_accuracy: 0.5121\n",
      "Epoch 29/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5205 - val_loss: 0.6924 - val_accuracy: 0.5134\n",
      "Epoch 30/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5235 - val_loss: 0.6924 - val_accuracy: 0.5134\n",
      "Epoch 31/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5217 - val_loss: 0.6924 - val_accuracy: 0.5148\n",
      "Epoch 32/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5219 - val_loss: 0.6926 - val_accuracy: 0.5128\n",
      "Epoch 33/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6910 - accuracy: 0.5207 - val_loss: 0.6924 - val_accuracy: 0.5148\n",
      "Epoch 34/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5210 - val_loss: 0.6925 - val_accuracy: 0.5130\n",
      "Epoch 35/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5227 - val_loss: 0.6924 - val_accuracy: 0.5141\n",
      "Epoch 36/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6909 - accuracy: 0.5208 - val_loss: 0.6924 - val_accuracy: 0.5145\n",
      "Epoch 37/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6909 - accuracy: 0.5213 - val_loss: 0.6924 - val_accuracy: 0.5153\n",
      "Epoch 38/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5238 - val_loss: 0.6925 - val_accuracy: 0.5107\n",
      "Epoch 39/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5224 - val_loss: 0.6924 - val_accuracy: 0.5134\n",
      "Epoch 40/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5218 - val_loss: 0.6924 - val_accuracy: 0.5148\n",
      "Epoch 41/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5232 - val_loss: 0.6927 - val_accuracy: 0.5160\n",
      "Epoch 42/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5227 - val_loss: 0.6924 - val_accuracy: 0.5119\n",
      "Epoch 43/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5218 - val_loss: 0.6924 - val_accuracy: 0.5129\n",
      "Epoch 44/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5215 - val_loss: 0.6924 - val_accuracy: 0.5151\n",
      "Epoch 45/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5232 - val_loss: 0.6924 - val_accuracy: 0.5179\n",
      "Epoch 46/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5226 - val_loss: 0.6925 - val_accuracy: 0.5124\n",
      "Epoch 47/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5215 - val_loss: 0.6924 - val_accuracy: 0.5131\n",
      "Epoch 48/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5215 - val_loss: 0.6925 - val_accuracy: 0.5133\n",
      "Epoch 49/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5221 - val_loss: 0.6924 - val_accuracy: 0.5141\n",
      "Epoch 50/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6907 - accuracy: 0.5226 - val_loss: 0.6926 - val_accuracy: 0.5119\n",
      "Epoch 51/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5247 - val_loss: 0.6924 - val_accuracy: 0.5144\n",
      "Epoch 52/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5225 - val_loss: 0.6924 - val_accuracy: 0.5148\n",
      "Epoch 53/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5234 - val_loss: 0.6924 - val_accuracy: 0.5152\n",
      "Epoch 54/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5225 - val_loss: 0.6925 - val_accuracy: 0.5128\n",
      "Epoch 55/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5220 - val_loss: 0.6924 - val_accuracy: 0.5121\n",
      "Epoch 56/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5228 - val_loss: 0.6924 - val_accuracy: 0.5113\n",
      "Epoch 57/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5243 - val_loss: 0.6924 - val_accuracy: 0.5157\n",
      "Epoch 58/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5243 - val_loss: 0.6924 - val_accuracy: 0.5137\n",
      "Epoch 59/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5236 - val_loss: 0.6925 - val_accuracy: 0.5149\n",
      "Epoch 60/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5240 - val_loss: 0.6924 - val_accuracy: 0.5120\n",
      "Epoch 61/1000\n",
      "41660/41660 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5230 - val_loss: 0.6924 - val_accuracy: 0.5155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5230 - val_loss: 0.6924 - val_accuracy: 0.5152\n",
      "Epoch 63/1000\n",
      "41660/41660 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5246 - val_loss: 0.6925 - val_accuracy: 0.5120\n",
      "Training with significance = 5.66, run 0\n",
      "Train on 41760 samples, validate on 10441 samples\n",
      "Epoch 1/1000\n",
      "41760/41760 [==============================] - 3s 64us/sample - loss: 0.6926 - accuracy: 0.5093 - val_loss: 0.6981 - val_accuracy: 0.5050\n",
      "Epoch 2/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5170 - val_loss: 0.6946 - val_accuracy: 0.5091\n",
      "Epoch 3/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6915 - accuracy: 0.5184 - val_loss: 0.6930 - val_accuracy: 0.5122\n",
      "Epoch 4/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6914 - accuracy: 0.5197 - val_loss: 0.6933 - val_accuracy: 0.5131\n",
      "Epoch 5/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5189 - val_loss: 0.6925 - val_accuracy: 0.5121\n",
      "Epoch 6/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5173 - val_loss: 0.6927 - val_accuracy: 0.5139\n",
      "Epoch 7/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5192 - val_loss: 0.6924 - val_accuracy: 0.5142\n",
      "Epoch 8/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6912 - accuracy: 0.5193 - val_loss: 0.6925 - val_accuracy: 0.5133\n",
      "Epoch 9/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6910 - accuracy: 0.5185 - val_loss: 0.6926 - val_accuracy: 0.5137\n",
      "Epoch 10/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5188 - val_loss: 0.6924 - val_accuracy: 0.5122\n",
      "Epoch 11/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5205 - val_loss: 0.6923 - val_accuracy: 0.5138\n",
      "Epoch 12/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5194 - val_loss: 0.6924 - val_accuracy: 0.5114\n",
      "Epoch 13/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5203 - val_loss: 0.6923 - val_accuracy: 0.5146\n",
      "Epoch 14/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5194 - val_loss: 0.6923 - val_accuracy: 0.5135\n",
      "Epoch 15/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5208 - val_loss: 0.6923 - val_accuracy: 0.5118\n",
      "Epoch 16/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5212 - val_loss: 0.6923 - val_accuracy: 0.5121\n",
      "Epoch 17/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5198 - val_loss: 0.6923 - val_accuracy: 0.5133\n",
      "Epoch 18/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5206 - val_loss: 0.6922 - val_accuracy: 0.5122\n",
      "Epoch 19/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6910 - accuracy: 0.5212 - val_loss: 0.6924 - val_accuracy: 0.5132\n",
      "Epoch 20/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5204 - val_loss: 0.6922 - val_accuracy: 0.5134\n",
      "Epoch 21/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5209 - val_loss: 0.6924 - val_accuracy: 0.5138\n",
      "Epoch 22/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5207 - val_loss: 0.6926 - val_accuracy: 0.5126\n",
      "Epoch 23/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6907 - accuracy: 0.5197 - val_loss: 0.6922 - val_accuracy: 0.5137\n",
      "Epoch 24/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6907 - accuracy: 0.5219 - val_loss: 0.6922 - val_accuracy: 0.5122\n",
      "Epoch 25/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5206 - val_loss: 0.6922 - val_accuracy: 0.5108\n",
      "Epoch 26/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6908 - accuracy: 0.5211 - val_loss: 0.6924 - val_accuracy: 0.5113\n",
      "Epoch 27/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5218 - val_loss: 0.6922 - val_accuracy: 0.5130\n",
      "Epoch 28/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6907 - accuracy: 0.5214 - val_loss: 0.6923 - val_accuracy: 0.5136\n",
      "Epoch 29/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5234 - val_loss: 0.6922 - val_accuracy: 0.5112\n",
      "Epoch 30/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5209 - val_loss: 0.6921 - val_accuracy: 0.5135\n",
      "Epoch 31/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5221 - val_loss: 0.6920 - val_accuracy: 0.5103\n",
      "Epoch 32/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5227 - val_loss: 0.6926 - val_accuracy: 0.5107\n",
      "Epoch 33/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6907 - accuracy: 0.5207 - val_loss: 0.6921 - val_accuracy: 0.5110\n",
      "Epoch 34/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5218 - val_loss: 0.6922 - val_accuracy: 0.5119\n",
      "Epoch 35/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5212 - val_loss: 0.6922 - val_accuracy: 0.5119\n",
      "Epoch 36/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5233 - val_loss: 0.6921 - val_accuracy: 0.5113\n",
      "Epoch 37/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5216 - val_loss: 0.6921 - val_accuracy: 0.5114\n",
      "Epoch 38/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5234 - val_loss: 0.6924 - val_accuracy: 0.5120\n",
      "Epoch 39/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5236 - val_loss: 0.6921 - val_accuracy: 0.5100\n",
      "Epoch 40/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5234 - val_loss: 0.6923 - val_accuracy: 0.5112\n",
      "Epoch 41/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5235 - val_loss: 0.6924 - val_accuracy: 0.5106\n",
      "Epoch 42/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6904 - accuracy: 0.5247 - val_loss: 0.6921 - val_accuracy: 0.5119\n",
      "Epoch 43/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5222 - val_loss: 0.6920 - val_accuracy: 0.5113\n",
      "Epoch 44/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5213 - val_loss: 0.6922 - val_accuracy: 0.5112\n",
      "Epoch 45/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5241 - val_loss: 0.6922 - val_accuracy: 0.5121\n",
      "Epoch 46/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5236 - val_loss: 0.6923 - val_accuracy: 0.5085\n",
      "Epoch 47/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5230 - val_loss: 0.6924 - val_accuracy: 0.5120\n",
      "Epoch 48/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5227 - val_loss: 0.6922 - val_accuracy: 0.5136\n",
      "Epoch 49/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6904 - accuracy: 0.5235 - val_loss: 0.6922 - val_accuracy: 0.5103\n",
      "Epoch 50/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5222 - val_loss: 0.6922 - val_accuracy: 0.5103\n",
      "Epoch 51/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5254 - val_loss: 0.6922 - val_accuracy: 0.5113\n",
      "Epoch 52/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5252 - val_loss: 0.6924 - val_accuracy: 0.5130\n",
      "Epoch 53/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5225 - val_loss: 0.6921 - val_accuracy: 0.5089\n",
      "Epoch 54/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5230 - val_loss: 0.6921 - val_accuracy: 0.5107\n",
      "Epoch 55/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5243 - val_loss: 0.6923 - val_accuracy: 0.5080\n",
      "Epoch 56/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5235 - val_loss: 0.6923 - val_accuracy: 0.5100\n",
      "Epoch 57/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5255 - val_loss: 0.6924 - val_accuracy: 0.5123\n",
      "Epoch 58/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5220 - val_loss: 0.6925 - val_accuracy: 0.5103\n",
      "Epoch 59/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5243 - val_loss: 0.6924 - val_accuracy: 0.5101\n",
      "Epoch 60/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5262 - val_loss: 0.6922 - val_accuracy: 0.5095\n",
      "Epoch 61/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5248 - val_loss: 0.6922 - val_accuracy: 0.5116\n",
      "Epoch 62/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5237 - val_loss: 0.6922 - val_accuracy: 0.5084\n",
      "Epoch 63/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5258 - val_loss: 0.6924 - val_accuracy: 0.5096\n",
      "Epoch 64/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5244 - val_loss: 0.6923 - val_accuracy: 0.5127\n",
      "Epoch 65/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5273 - val_loss: 0.6922 - val_accuracy: 0.5093\n",
      "Epoch 66/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5236 - val_loss: 0.6920 - val_accuracy: 0.5114\n",
      "Epoch 67/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5238 - val_loss: 0.6925 - val_accuracy: 0.5098\n",
      "Epoch 68/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6902 - accuracy: 0.5231 - val_loss: 0.6924 - val_accuracy: 0.5083\n",
      "Epoch 69/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6903 - accuracy: 0.5242 - val_loss: 0.6924 - val_accuracy: 0.5101\n",
      "Epoch 70/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5237 - val_loss: 0.6922 - val_accuracy: 0.5074\n",
      "Epoch 71/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5248 - val_loss: 0.6923 - val_accuracy: 0.5069\n",
      "Epoch 72/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5241 - val_loss: 0.6921 - val_accuracy: 0.5139\n",
      "Epoch 73/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5258 - val_loss: 0.6922 - val_accuracy: 0.5109\n",
      "Training with significance = 5.66, run 1\n",
      "Train on 41760 samples, validate on 10441 samples\n",
      "Epoch 1/1000\n",
      "41760/41760 [==============================] - 1s 27us/sample - loss: 0.6939 - accuracy: 0.5044 - val_loss: 0.6941 - val_accuracy: 0.5031\n",
      "Epoch 2/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6921 - accuracy: 0.5126 - val_loss: 0.6927 - val_accuracy: 0.5091\n",
      "Epoch 3/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5159 - val_loss: 0.6921 - val_accuracy: 0.5116\n",
      "Epoch 4/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5190 - val_loss: 0.6918 - val_accuracy: 0.5154\n",
      "Epoch 5/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5176 - val_loss: 0.6916 - val_accuracy: 0.5173\n",
      "Epoch 6/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5187 - val_loss: 0.6914 - val_accuracy: 0.5182\n",
      "Epoch 7/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5199 - val_loss: 0.6916 - val_accuracy: 0.5130\n",
      "Epoch 8/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5191 - val_loss: 0.6913 - val_accuracy: 0.5214\n",
      "Epoch 9/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5202 - val_loss: 0.6912 - val_accuracy: 0.5220\n",
      "Epoch 10/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6910 - accuracy: 0.5178 - val_loss: 0.6912 - val_accuracy: 0.5218\n",
      "Epoch 11/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5197 - val_loss: 0.6911 - val_accuracy: 0.5214\n",
      "Epoch 12/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5204 - val_loss: 0.6912 - val_accuracy: 0.5174\n",
      "Epoch 13/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5200 - val_loss: 0.6913 - val_accuracy: 0.5203\n",
      "Epoch 14/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6908 - accuracy: 0.5206 - val_loss: 0.6912 - val_accuracy: 0.5208\n",
      "Epoch 15/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5208 - val_loss: 0.6912 - val_accuracy: 0.5213\n",
      "Epoch 16/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5212 - val_loss: 0.6912 - val_accuracy: 0.5148\n",
      "Epoch 17/1000\n",
      "41760/41760 [==============================] - 0s 12us/sample - loss: 0.6907 - accuracy: 0.5200 - val_loss: 0.6913 - val_accuracy: 0.5161\n",
      "Epoch 18/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6908 - accuracy: 0.5209 - val_loss: 0.6912 - val_accuracy: 0.5184\n",
      "Epoch 19/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5229 - val_loss: 0.6911 - val_accuracy: 0.5240\n",
      "Epoch 20/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6907 - accuracy: 0.5235 - val_loss: 0.6912 - val_accuracy: 0.5194\n",
      "Epoch 21/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5240 - val_loss: 0.6911 - val_accuracy: 0.5227\n",
      "Epoch 22/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5217 - val_loss: 0.6912 - val_accuracy: 0.5193\n",
      "Epoch 23/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5205 - val_loss: 0.6913 - val_accuracy: 0.5138\n",
      "Epoch 24/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5200 - val_loss: 0.6912 - val_accuracy: 0.5238\n",
      "Epoch 25/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5240 - val_loss: 0.6911 - val_accuracy: 0.5223\n",
      "Epoch 26/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5231 - val_loss: 0.6912 - val_accuracy: 0.5256\n",
      "Epoch 27/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5224 - val_loss: 0.6911 - val_accuracy: 0.5218\n",
      "Epoch 28/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5231 - val_loss: 0.6913 - val_accuracy: 0.5197\n",
      "Epoch 29/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5238 - val_loss: 0.6913 - val_accuracy: 0.5161\n",
      "Epoch 30/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6904 - accuracy: 0.5231 - val_loss: 0.6914 - val_accuracy: 0.5145\n",
      "Epoch 31/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5229 - val_loss: 0.6913 - val_accuracy: 0.5168\n",
      "Epoch 32/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6904 - accuracy: 0.5230 - val_loss: 0.6914 - val_accuracy: 0.5174\n",
      "Epoch 33/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5235 - val_loss: 0.6915 - val_accuracy: 0.5122\n",
      "Epoch 34/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5250 - val_loss: 0.6915 - val_accuracy: 0.5151\n",
      "Epoch 35/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5239 - val_loss: 0.6914 - val_accuracy: 0.5182\n",
      "Epoch 36/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5242 - val_loss: 0.6914 - val_accuracy: 0.5164\n",
      "Epoch 37/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5263 - val_loss: 0.6913 - val_accuracy: 0.5213\n",
      "Epoch 38/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5236 - val_loss: 0.6912 - val_accuracy: 0.5222\n",
      "Epoch 39/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5237 - val_loss: 0.6915 - val_accuracy: 0.5094\n",
      "Epoch 40/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6902 - accuracy: 0.5233 - val_loss: 0.6913 - val_accuracy: 0.5199\n",
      "Epoch 41/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6904 - accuracy: 0.5248 - val_loss: 0.6914 - val_accuracy: 0.5180\n",
      "Epoch 42/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6902 - accuracy: 0.5247 - val_loss: 0.6912 - val_accuracy: 0.5244\n",
      "Epoch 43/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5233 - val_loss: 0.6915 - val_accuracy: 0.5156\n",
      "Epoch 44/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6902 - accuracy: 0.5258 - val_loss: 0.6913 - val_accuracy: 0.5245\n",
      "Epoch 45/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6903 - accuracy: 0.5227 - val_loss: 0.6913 - val_accuracy: 0.5181\n",
      "Epoch 46/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6902 - accuracy: 0.5256 - val_loss: 0.6912 - val_accuracy: 0.5251\n",
      "Epoch 47/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6902 - accuracy: 0.5244 - val_loss: 0.6916 - val_accuracy: 0.5177\n",
      "Epoch 48/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5257 - val_loss: 0.6913 - val_accuracy: 0.5194\n",
      "Epoch 49/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5256 - val_loss: 0.6913 - val_accuracy: 0.5203\n",
      "Epoch 50/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5247 - val_loss: 0.6914 - val_accuracy: 0.5171\n",
      "Epoch 51/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5239 - val_loss: 0.6914 - val_accuracy: 0.5181\n",
      "Training with significance = 5.66, run 2\n",
      "Train on 41760 samples, validate on 10441 samples\n",
      "Epoch 1/1000\n",
      "41760/41760 [==============================] - 1s 27us/sample - loss: 0.6936 - accuracy: 0.5090 - val_loss: 0.6942 - val_accuracy: 0.5041\n",
      "Epoch 2/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6923 - accuracy: 0.5139 - val_loss: 0.6923 - val_accuracy: 0.5173\n",
      "Epoch 3/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6922 - accuracy: 0.5120 - val_loss: 0.6919 - val_accuracy: 0.5170\n",
      "Epoch 4/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5139 - val_loss: 0.6917 - val_accuracy: 0.5230\n",
      "Epoch 5/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6919 - accuracy: 0.5163 - val_loss: 0.6917 - val_accuracy: 0.5205\n",
      "Epoch 6/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5168 - val_loss: 0.6917 - val_accuracy: 0.5204\n",
      "Epoch 7/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5170 - val_loss: 0.6916 - val_accuracy: 0.5250\n",
      "Epoch 8/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5165 - val_loss: 0.6914 - val_accuracy: 0.5241\n",
      "Epoch 9/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5180 - val_loss: 0.6914 - val_accuracy: 0.5246\n",
      "Epoch 10/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5189 - val_loss: 0.6914 - val_accuracy: 0.5267\n",
      "Epoch 11/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5199 - val_loss: 0.6914 - val_accuracy: 0.5242\n",
      "Epoch 12/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5194 - val_loss: 0.6916 - val_accuracy: 0.5249\n",
      "Epoch 13/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5180 - val_loss: 0.6912 - val_accuracy: 0.5258\n",
      "Epoch 14/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5185 - val_loss: 0.6914 - val_accuracy: 0.5248\n",
      "Epoch 15/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5179 - val_loss: 0.6912 - val_accuracy: 0.5246\n",
      "Epoch 16/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5198 - val_loss: 0.6914 - val_accuracy: 0.5263\n",
      "Epoch 17/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5197 - val_loss: 0.6913 - val_accuracy: 0.5243\n",
      "Epoch 18/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5192 - val_loss: 0.6913 - val_accuracy: 0.5258\n",
      "Epoch 19/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6912 - accuracy: 0.5205 - val_loss: 0.6913 - val_accuracy: 0.5233\n",
      "Epoch 20/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5225 - val_loss: 0.6914 - val_accuracy: 0.5219\n",
      "Epoch 21/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6912 - accuracy: 0.5190 - val_loss: 0.6914 - val_accuracy: 0.5228\n",
      "Epoch 22/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6911 - accuracy: 0.5209 - val_loss: 0.6913 - val_accuracy: 0.5242\n",
      "Epoch 23/1000\n",
      "41760/41760 [==============================] - 0s 12us/sample - loss: 0.6911 - accuracy: 0.5202 - val_loss: 0.6913 - val_accuracy: 0.5235\n",
      "Epoch 24/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6911 - accuracy: 0.5194 - val_loss: 0.6913 - val_accuracy: 0.5274\n",
      "Epoch 25/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5226 - val_loss: 0.6914 - val_accuracy: 0.5229\n",
      "Epoch 26/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6910 - accuracy: 0.5228 - val_loss: 0.6914 - val_accuracy: 0.5227\n",
      "Epoch 27/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6911 - accuracy: 0.5215 - val_loss: 0.6913 - val_accuracy: 0.5224\n",
      "Epoch 28/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5208 - val_loss: 0.6913 - val_accuracy: 0.5238\n",
      "Epoch 29/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5211 - val_loss: 0.6913 - val_accuracy: 0.5249\n",
      "Epoch 30/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6911 - accuracy: 0.5192 - val_loss: 0.6915 - val_accuracy: 0.5257\n",
      "Epoch 31/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5231 - val_loss: 0.6916 - val_accuracy: 0.5233\n",
      "Epoch 32/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6910 - accuracy: 0.5228 - val_loss: 0.6915 - val_accuracy: 0.5242\n",
      "Epoch 33/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5217 - val_loss: 0.6914 - val_accuracy: 0.5272\n",
      "Epoch 34/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6909 - accuracy: 0.5225 - val_loss: 0.6913 - val_accuracy: 0.5227\n",
      "Epoch 35/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6909 - accuracy: 0.5229 - val_loss: 0.6914 - val_accuracy: 0.5195\n",
      "Epoch 36/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5241 - val_loss: 0.6915 - val_accuracy: 0.5263\n",
      "Epoch 37/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5258 - val_loss: 0.6914 - val_accuracy: 0.5224\n",
      "Epoch 38/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5226 - val_loss: 0.6916 - val_accuracy: 0.5244\n",
      "Epoch 39/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5228 - val_loss: 0.6914 - val_accuracy: 0.5224\n",
      "Epoch 40/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5217 - val_loss: 0.6915 - val_accuracy: 0.5215\n",
      "Epoch 41/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5255 - val_loss: 0.6915 - val_accuracy: 0.5225\n",
      "Epoch 42/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6908 - accuracy: 0.5229 - val_loss: 0.6915 - val_accuracy: 0.5240\n",
      "Epoch 43/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6908 - accuracy: 0.5226 - val_loss: 0.6915 - val_accuracy: 0.5236\n",
      "Epoch 44/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5245 - val_loss: 0.6915 - val_accuracy: 0.5241\n",
      "Epoch 45/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5219 - val_loss: 0.6915 - val_accuracy: 0.5228\n",
      "Training with significance = 5.66, run 3\n",
      "Train on 41760 samples, validate on 10441 samples\n",
      "Epoch 1/1000\n",
      "41760/41760 [==============================] - 1s 27us/sample - loss: 0.6939 - accuracy: 0.5015 - val_loss: 0.6939 - val_accuracy: 0.4967\n",
      "Epoch 2/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6922 - accuracy: 0.5156 - val_loss: 0.6932 - val_accuracy: 0.5026\n",
      "Epoch 3/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5175 - val_loss: 0.6929 - val_accuracy: 0.5052\n",
      "Epoch 4/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5182 - val_loss: 0.6926 - val_accuracy: 0.4997\n",
      "Epoch 5/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5186 - val_loss: 0.6923 - val_accuracy: 0.5056\n",
      "Epoch 6/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5193 - val_loss: 0.6920 - val_accuracy: 0.5118\n",
      "Epoch 7/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5183 - val_loss: 0.6922 - val_accuracy: 0.5076\n",
      "Epoch 8/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5176 - val_loss: 0.6921 - val_accuracy: 0.5121\n",
      "Epoch 9/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6911 - accuracy: 0.5188 - val_loss: 0.6921 - val_accuracy: 0.5143\n",
      "Epoch 10/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6910 - accuracy: 0.5177 - val_loss: 0.6919 - val_accuracy: 0.5125\n",
      "Epoch 11/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6910 - accuracy: 0.5195 - val_loss: 0.6922 - val_accuracy: 0.5120\n",
      "Epoch 12/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6910 - accuracy: 0.5191 - val_loss: 0.6920 - val_accuracy: 0.5119\n",
      "Epoch 13/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5190 - val_loss: 0.6919 - val_accuracy: 0.5126\n",
      "Epoch 14/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5199 - val_loss: 0.6920 - val_accuracy: 0.5136\n",
      "Epoch 15/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5201 - val_loss: 0.6920 - val_accuracy: 0.5092\n",
      "Epoch 16/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5213 - val_loss: 0.6922 - val_accuracy: 0.5089\n",
      "Epoch 17/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5212 - val_loss: 0.6924 - val_accuracy: 0.5079\n",
      "Epoch 18/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6909 - accuracy: 0.5207 - val_loss: 0.6920 - val_accuracy: 0.5135\n",
      "Epoch 19/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5221 - val_loss: 0.6919 - val_accuracy: 0.5132\n",
      "Epoch 20/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5211 - val_loss: 0.6919 - val_accuracy: 0.5127\n",
      "Epoch 21/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5201 - val_loss: 0.6920 - val_accuracy: 0.5113\n",
      "Epoch 22/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5215 - val_loss: 0.6919 - val_accuracy: 0.5118\n",
      "Epoch 23/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5218 - val_loss: 0.6920 - val_accuracy: 0.5118\n",
      "Epoch 24/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5207 - val_loss: 0.6920 - val_accuracy: 0.5113\n",
      "Epoch 25/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5204 - val_loss: 0.6918 - val_accuracy: 0.5113\n",
      "Epoch 26/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5224 - val_loss: 0.6922 - val_accuracy: 0.5072\n",
      "Epoch 27/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5220 - val_loss: 0.6919 - val_accuracy: 0.5122\n",
      "Epoch 28/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5206 - val_loss: 0.6919 - val_accuracy: 0.5128\n",
      "Epoch 29/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5214 - val_loss: 0.6920 - val_accuracy: 0.5100\n",
      "Epoch 30/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5201 - val_loss: 0.6918 - val_accuracy: 0.5140\n",
      "Epoch 31/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5212 - val_loss: 0.6922 - val_accuracy: 0.5065\n",
      "Epoch 32/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5214 - val_loss: 0.6919 - val_accuracy: 0.5118\n",
      "Epoch 33/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5210 - val_loss: 0.6920 - val_accuracy: 0.5099\n",
      "Epoch 34/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5224 - val_loss: 0.6919 - val_accuracy: 0.5116\n",
      "Epoch 35/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5216 - val_loss: 0.6919 - val_accuracy: 0.5122\n",
      "Epoch 36/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5237 - val_loss: 0.6920 - val_accuracy: 0.5139\n",
      "Epoch 37/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6904 - accuracy: 0.5219 - val_loss: 0.6918 - val_accuracy: 0.5125\n",
      "Epoch 38/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5237 - val_loss: 0.6919 - val_accuracy: 0.5120\n",
      "Epoch 39/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5246 - val_loss: 0.6921 - val_accuracy: 0.5078\n",
      "Epoch 40/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5223 - val_loss: 0.6920 - val_accuracy: 0.5117\n",
      "Epoch 41/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5223 - val_loss: 0.6920 - val_accuracy: 0.5116\n",
      "Epoch 42/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5221 - val_loss: 0.6919 - val_accuracy: 0.5111\n",
      "Epoch 43/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5225 - val_loss: 0.6919 - val_accuracy: 0.5140\n",
      "Epoch 44/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5209 - val_loss: 0.6922 - val_accuracy: 0.5075\n",
      "Epoch 45/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5225 - val_loss: 0.6918 - val_accuracy: 0.5118\n",
      "Epoch 46/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5221 - val_loss: 0.6920 - val_accuracy: 0.5113\n",
      "Epoch 47/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5232 - val_loss: 0.6918 - val_accuracy: 0.5118\n",
      "Epoch 48/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5217 - val_loss: 0.6921 - val_accuracy: 0.5086\n",
      "Epoch 49/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5233 - val_loss: 0.6919 - val_accuracy: 0.5116\n",
      "Epoch 50/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5231 - val_loss: 0.6917 - val_accuracy: 0.5154\n",
      "Epoch 51/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5229 - val_loss: 0.6918 - val_accuracy: 0.5156\n",
      "Epoch 52/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5229 - val_loss: 0.6917 - val_accuracy: 0.5148\n",
      "Epoch 53/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5236 - val_loss: 0.6918 - val_accuracy: 0.5140\n",
      "Epoch 54/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5235 - val_loss: 0.6920 - val_accuracy: 0.5098\n",
      "Epoch 55/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5223 - val_loss: 0.6918 - val_accuracy: 0.5136\n",
      "Epoch 56/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5227 - val_loss: 0.6919 - val_accuracy: 0.5150\n",
      "Epoch 57/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5220 - val_loss: 0.6919 - val_accuracy: 0.5145\n",
      "Epoch 58/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5237 - val_loss: 0.6921 - val_accuracy: 0.5104\n",
      "Epoch 59/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5230 - val_loss: 0.6920 - val_accuracy: 0.5095\n",
      "Epoch 60/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5107\n",
      "Epoch 61/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6903 - accuracy: 0.5240 - val_loss: 0.6919 - val_accuracy: 0.5125\n",
      "Epoch 62/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6903 - accuracy: 0.5240 - val_loss: 0.6918 - val_accuracy: 0.5144\n",
      "Epoch 63/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6903 - accuracy: 0.5252 - val_loss: 0.6920 - val_accuracy: 0.5126\n",
      "Epoch 64/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5245 - val_loss: 0.6921 - val_accuracy: 0.5111\n",
      "Epoch 65/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6903 - accuracy: 0.5242 - val_loss: 0.6919 - val_accuracy: 0.5144\n",
      "Epoch 66/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6903 - accuracy: 0.5250 - val_loss: 0.6919 - val_accuracy: 0.5113\n",
      "Epoch 67/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5231 - val_loss: 0.6919 - val_accuracy: 0.5123\n",
      "Epoch 68/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5244 - val_loss: 0.6919 - val_accuracy: 0.5112\n",
      "Epoch 69/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5222 - val_loss: 0.6918 - val_accuracy: 0.5121\n",
      "Epoch 70/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5257 - val_loss: 0.6919 - val_accuracy: 0.5134\n",
      "Epoch 71/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5259 - val_loss: 0.6920 - val_accuracy: 0.5115\n",
      "Epoch 72/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5243 - val_loss: 0.6919 - val_accuracy: 0.5127\n",
      "Epoch 73/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5233 - val_loss: 0.6919 - val_accuracy: 0.5131\n",
      "Epoch 74/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6901 - accuracy: 0.5243 - val_loss: 0.6918 - val_accuracy: 0.5119\n",
      "Epoch 75/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5250 - val_loss: 0.6918 - val_accuracy: 0.5144\n",
      "Epoch 76/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5233 - val_loss: 0.6920 - val_accuracy: 0.5098\n",
      "Epoch 77/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6901 - accuracy: 0.5226 - val_loss: 0.6918 - val_accuracy: 0.5115\n",
      "Epoch 78/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5250 - val_loss: 0.6919 - val_accuracy: 0.5143\n",
      "Epoch 79/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6904 - accuracy: 0.5226 - val_loss: 0.6920 - val_accuracy: 0.5094\n",
      "Epoch 80/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5258 - val_loss: 0.6917 - val_accuracy: 0.5122\n",
      "Epoch 81/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5242 - val_loss: 0.6921 - val_accuracy: 0.5127\n",
      "Epoch 82/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5256 - val_loss: 0.6919 - val_accuracy: 0.5129\n",
      "Training with significance = 5.66, run 4\n",
      "Train on 41760 samples, validate on 10441 samples\n",
      "Epoch 1/1000\n",
      "41760/41760 [==============================] - 1s 27us/sample - loss: 0.6925 - accuracy: 0.5108 - val_loss: 0.6937 - val_accuracy: 0.5042\n",
      "Epoch 2/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5147 - val_loss: 0.6928 - val_accuracy: 0.5127\n",
      "Epoch 3/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5180 - val_loss: 0.6917 - val_accuracy: 0.5159\n",
      "Epoch 4/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5175 - val_loss: 0.6913 - val_accuracy: 0.5172\n",
      "Epoch 5/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5186 - val_loss: 0.6912 - val_accuracy: 0.5198\n",
      "Epoch 6/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5178 - val_loss: 0.6911 - val_accuracy: 0.5259\n",
      "Epoch 7/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5179 - val_loss: 0.6909 - val_accuracy: 0.5226\n",
      "Epoch 8/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6911 - accuracy: 0.5186 - val_loss: 0.6910 - val_accuracy: 0.5161\n",
      "Epoch 9/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6909 - accuracy: 0.5210 - val_loss: 0.6909 - val_accuracy: 0.5202\n",
      "Epoch 10/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5190 - val_loss: 0.6909 - val_accuracy: 0.5240\n",
      "Epoch 11/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5189 - val_loss: 0.6908 - val_accuracy: 0.5239\n",
      "Epoch 12/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5196 - val_loss: 0.6907 - val_accuracy: 0.5267\n",
      "Epoch 13/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6908 - accuracy: 0.5190 - val_loss: 0.6908 - val_accuracy: 0.5245\n",
      "Epoch 14/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5203 - val_loss: 0.6908 - val_accuracy: 0.5180\n",
      "Epoch 15/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6907 - accuracy: 0.5225 - val_loss: 0.6908 - val_accuracy: 0.5204\n",
      "Epoch 16/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5215 - val_loss: 0.6907 - val_accuracy: 0.5257\n",
      "Epoch 17/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5197 - val_loss: 0.6907 - val_accuracy: 0.5234\n",
      "Epoch 18/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5210 - val_loss: 0.6907 - val_accuracy: 0.5244\n",
      "Epoch 19/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5212 - val_loss: 0.6908 - val_accuracy: 0.5205\n",
      "Epoch 20/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5222 - val_loss: 0.6906 - val_accuracy: 0.5241\n",
      "Epoch 21/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5224 - val_loss: 0.6905 - val_accuracy: 0.5255\n",
      "Epoch 22/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5206 - val_loss: 0.6906 - val_accuracy: 0.5230\n",
      "Epoch 23/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5207 - val_loss: 0.6906 - val_accuracy: 0.5231\n",
      "Epoch 24/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5209 - val_loss: 0.6906 - val_accuracy: 0.5247\n",
      "Epoch 25/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5227 - val_loss: 0.6905 - val_accuracy: 0.5248\n",
      "Epoch 26/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5221 - val_loss: 0.6906 - val_accuracy: 0.5227\n",
      "Epoch 27/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5220 - val_loss: 0.6905 - val_accuracy: 0.5247\n",
      "Epoch 28/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5240 - val_loss: 0.6906 - val_accuracy: 0.5234\n",
      "Epoch 29/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5229 - val_loss: 0.6905 - val_accuracy: 0.5255\n",
      "Epoch 30/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5212 - val_loss: 0.6905 - val_accuracy: 0.5245\n",
      "Epoch 31/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5216 - val_loss: 0.6907 - val_accuracy: 0.5212\n",
      "Epoch 32/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5226 - val_loss: 0.6908 - val_accuracy: 0.5204\n",
      "Epoch 33/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5195 - val_loss: 0.6908 - val_accuracy: 0.5200\n",
      "Epoch 34/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5239 - val_loss: 0.6906 - val_accuracy: 0.5233\n",
      "Epoch 35/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5222 - val_loss: 0.6907 - val_accuracy: 0.5212\n",
      "Epoch 36/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5225 - val_loss: 0.6905 - val_accuracy: 0.5251\n",
      "Epoch 37/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5221 - val_loss: 0.6907 - val_accuracy: 0.5217\n",
      "Epoch 38/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5238 - val_loss: 0.6906 - val_accuracy: 0.5242\n",
      "Epoch 39/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5195 - val_loss: 0.6906 - val_accuracy: 0.5250\n",
      "Epoch 40/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5227 - val_loss: 0.6905 - val_accuracy: 0.5247\n",
      "Epoch 41/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6903 - accuracy: 0.5238 - val_loss: 0.6905 - val_accuracy: 0.5262\n",
      "Epoch 42/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5217 - val_loss: 0.6905 - val_accuracy: 0.5246\n",
      "Epoch 43/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5230 - val_loss: 0.6905 - val_accuracy: 0.5236\n",
      "Epoch 44/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5218 - val_loss: 0.6906 - val_accuracy: 0.5222\n",
      "Epoch 45/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6904 - accuracy: 0.5208 - val_loss: 0.6905 - val_accuracy: 0.5237\n",
      "Epoch 46/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6903 - accuracy: 0.5231 - val_loss: 0.6907 - val_accuracy: 0.5210\n",
      "Epoch 47/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5214 - val_loss: 0.6906 - val_accuracy: 0.5223\n",
      "Epoch 48/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5225 - val_loss: 0.6906 - val_accuracy: 0.5223\n",
      "Epoch 49/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5240 - val_loss: 0.6905 - val_accuracy: 0.5254\n",
      "Epoch 50/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5249 - val_loss: 0.6906 - val_accuracy: 0.5237\n",
      "Epoch 51/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5235 - val_loss: 0.6905 - val_accuracy: 0.5222\n",
      "Epoch 52/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5224 - val_loss: 0.6906 - val_accuracy: 0.5210\n",
      "Epoch 53/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5238 - val_loss: 0.6904 - val_accuracy: 0.5247\n",
      "Epoch 54/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5244 - val_loss: 0.6904 - val_accuracy: 0.5252\n",
      "Epoch 55/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5230 - val_loss: 0.6905 - val_accuracy: 0.5242\n",
      "Epoch 56/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6902 - accuracy: 0.5247 - val_loss: 0.6905 - val_accuracy: 0.5219\n",
      "Epoch 57/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5225 - val_loss: 0.6905 - val_accuracy: 0.5232\n",
      "Epoch 58/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5222 - val_loss: 0.6906 - val_accuracy: 0.5239\n",
      "Epoch 59/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5228 - val_loss: 0.6906 - val_accuracy: 0.5204\n",
      "Epoch 60/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5245 - val_loss: 0.6906 - val_accuracy: 0.5228\n",
      "Epoch 61/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5225 - val_loss: 0.6905 - val_accuracy: 0.5245\n",
      "Epoch 62/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5234 - val_loss: 0.6904 - val_accuracy: 0.5267\n",
      "Epoch 63/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5224 - val_loss: 0.6905 - val_accuracy: 0.5232\n",
      "Epoch 64/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5239 - val_loss: 0.6905 - val_accuracy: 0.5201\n",
      "Epoch 65/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5239 - val_loss: 0.6907 - val_accuracy: 0.5206\n",
      "Epoch 66/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6900 - accuracy: 0.5259 - val_loss: 0.6906 - val_accuracy: 0.5225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6900 - accuracy: 0.5267 - val_loss: 0.6905 - val_accuracy: 0.5251\n",
      "Epoch 68/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6901 - accuracy: 0.5238 - val_loss: 0.6905 - val_accuracy: 0.5271\n",
      "Epoch 69/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6900 - accuracy: 0.5247 - val_loss: 0.6904 - val_accuracy: 0.5257\n",
      "Epoch 70/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5263 - val_loss: 0.6905 - val_accuracy: 0.5245\n",
      "Epoch 71/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5258 - val_loss: 0.6904 - val_accuracy: 0.5227\n",
      "Epoch 72/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5233 - val_loss: 0.6905 - val_accuracy: 0.5246\n",
      "Epoch 73/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5250 - val_loss: 0.6905 - val_accuracy: 0.5262\n",
      "Epoch 74/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5254 - val_loss: 0.6905 - val_accuracy: 0.5258\n",
      "Epoch 75/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6902 - accuracy: 0.5230 - val_loss: 0.6907 - val_accuracy: 0.5206\n",
      "Epoch 76/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5247 - val_loss: 0.6907 - val_accuracy: 0.5211\n",
      "Epoch 77/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6901 - accuracy: 0.5220 - val_loss: 0.6906 - val_accuracy: 0.5224\n",
      "Epoch 78/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6899 - accuracy: 0.5264 - val_loss: 0.6906 - val_accuracy: 0.5194\n",
      "Epoch 79/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5254 - val_loss: 0.6906 - val_accuracy: 0.5216\n",
      "Epoch 80/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5251 - val_loss: 0.6907 - val_accuracy: 0.5216\n",
      "Epoch 81/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5243 - val_loss: 0.6904 - val_accuracy: 0.5234\n",
      "Epoch 82/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5251 - val_loss: 0.6905 - val_accuracy: 0.5220\n",
      "Epoch 83/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5242 - val_loss: 0.6905 - val_accuracy: 0.5226\n",
      "Epoch 84/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5262 - val_loss: 0.6905 - val_accuracy: 0.5238\n",
      "Training with significance = 5.66, run 5\n",
      "Train on 41760 samples, validate on 10441 samples\n",
      "Epoch 1/1000\n",
      "41760/41760 [==============================] - 1s 27us/sample - loss: 0.6921 - accuracy: 0.5159 - val_loss: 0.6962 - val_accuracy: 0.4987\n",
      "Epoch 2/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6914 - accuracy: 0.5177 - val_loss: 0.6934 - val_accuracy: 0.5093\n",
      "Epoch 3/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5181 - val_loss: 0.6925 - val_accuracy: 0.5133\n",
      "Epoch 4/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5180 - val_loss: 0.6921 - val_accuracy: 0.5164\n",
      "Epoch 5/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6911 - accuracy: 0.5182 - val_loss: 0.6918 - val_accuracy: 0.5170\n",
      "Epoch 6/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5172 - val_loss: 0.6920 - val_accuracy: 0.5164\n",
      "Epoch 7/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6910 - accuracy: 0.5168 - val_loss: 0.6919 - val_accuracy: 0.5169\n",
      "Epoch 8/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5190 - val_loss: 0.6920 - val_accuracy: 0.5180\n",
      "Epoch 9/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6909 - accuracy: 0.5193 - val_loss: 0.6919 - val_accuracy: 0.5157\n",
      "Epoch 10/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6908 - accuracy: 0.5190 - val_loss: 0.6919 - val_accuracy: 0.5208\n",
      "Epoch 11/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5214 - val_loss: 0.6919 - val_accuracy: 0.5167\n",
      "Epoch 12/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5200 - val_loss: 0.6919 - val_accuracy: 0.5167\n",
      "Epoch 13/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5195 - val_loss: 0.6919 - val_accuracy: 0.5181\n",
      "Epoch 14/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6907 - accuracy: 0.5204 - val_loss: 0.6920 - val_accuracy: 0.5182\n",
      "Epoch 15/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5231 - val_loss: 0.6919 - val_accuracy: 0.5190\n",
      "Epoch 16/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5213 - val_loss: 0.6918 - val_accuracy: 0.5194\n",
      "Epoch 17/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5208 - val_loss: 0.6918 - val_accuracy: 0.5189\n",
      "Epoch 18/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6907 - accuracy: 0.5203 - val_loss: 0.6921 - val_accuracy: 0.5144\n",
      "Epoch 19/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5204 - val_loss: 0.6919 - val_accuracy: 0.5184\n",
      "Epoch 20/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5209 - val_loss: 0.6921 - val_accuracy: 0.5180\n",
      "Epoch 21/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5215 - val_loss: 0.6919 - val_accuracy: 0.5186\n",
      "Epoch 22/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5240 - val_loss: 0.6920 - val_accuracy: 0.5170\n",
      "Epoch 23/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5223 - val_loss: 0.6920 - val_accuracy: 0.5184\n",
      "Epoch 24/1000\n",
      "41760/41760 [==============================] - 0s 12us/sample - loss: 0.6905 - accuracy: 0.5212 - val_loss: 0.6920 - val_accuracy: 0.5183\n",
      "Epoch 25/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5214 - val_loss: 0.6920 - val_accuracy: 0.5199\n",
      "Epoch 26/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5234 - val_loss: 0.6920 - val_accuracy: 0.5187\n",
      "Epoch 27/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5219 - val_loss: 0.6919 - val_accuracy: 0.5167\n",
      "Epoch 28/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5236 - val_loss: 0.6920 - val_accuracy: 0.5191\n",
      "Epoch 29/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6904 - accuracy: 0.5239 - val_loss: 0.6920 - val_accuracy: 0.5182\n",
      "Epoch 30/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6903 - accuracy: 0.5241 - val_loss: 0.6921 - val_accuracy: 0.5165\n",
      "Epoch 31/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5253 - val_loss: 0.6919 - val_accuracy: 0.5174\n",
      "Epoch 32/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5229 - val_loss: 0.6920 - val_accuracy: 0.5176\n",
      "Epoch 33/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5232 - val_loss: 0.6920 - val_accuracy: 0.5164\n",
      "Epoch 34/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5219 - val_loss: 0.6921 - val_accuracy: 0.5183\n",
      "Epoch 35/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6904 - accuracy: 0.5225 - val_loss: 0.6921 - val_accuracy: 0.5160\n",
      "Epoch 36/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5225 - val_loss: 0.6921 - val_accuracy: 0.5163\n",
      "Epoch 37/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5266 - val_loss: 0.6922 - val_accuracy: 0.5178\n",
      "Epoch 38/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5240 - val_loss: 0.6920 - val_accuracy: 0.5175\n",
      "Epoch 39/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6903 - accuracy: 0.5238 - val_loss: 0.6921 - val_accuracy: 0.5183\n",
      "Epoch 40/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5241 - val_loss: 0.6920 - val_accuracy: 0.5180\n",
      "Epoch 41/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5244 - val_loss: 0.6921 - val_accuracy: 0.5172\n",
      "Epoch 42/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5241 - val_loss: 0.6921 - val_accuracy: 0.5165\n",
      "Epoch 43/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5246 - val_loss: 0.6920 - val_accuracy: 0.5147\n",
      "Epoch 44/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5237 - val_loss: 0.6922 - val_accuracy: 0.5164\n",
      "Epoch 45/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5256 - val_loss: 0.6920 - val_accuracy: 0.5157\n",
      "Epoch 46/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5242 - val_loss: 0.6920 - val_accuracy: 0.5137\n",
      "Training with significance = 5.66, run 6\n",
      "Train on 41760 samples, validate on 10441 samples\n",
      "Epoch 1/1000\n",
      "41760/41760 [==============================] - 1s 26us/sample - loss: 0.6924 - accuracy: 0.5146 - val_loss: 0.6955 - val_accuracy: 0.5033\n",
      "Epoch 2/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5188 - val_loss: 0.6935 - val_accuracy: 0.5065\n",
      "Epoch 3/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6915 - accuracy: 0.5201 - val_loss: 0.6928 - val_accuracy: 0.5115\n",
      "Epoch 4/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5212 - val_loss: 0.6925 - val_accuracy: 0.5112\n",
      "Epoch 5/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5196 - val_loss: 0.6924 - val_accuracy: 0.5115\n",
      "Epoch 6/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5195 - val_loss: 0.6921 - val_accuracy: 0.5129\n",
      "Epoch 7/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5206 - val_loss: 0.6920 - val_accuracy: 0.5125\n",
      "Epoch 8/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5215 - val_loss: 0.6920 - val_accuracy: 0.5136\n",
      "Epoch 9/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5194 - val_loss: 0.6920 - val_accuracy: 0.5114\n",
      "Epoch 10/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5205 - val_loss: 0.6921 - val_accuracy: 0.5107\n",
      "Epoch 11/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5217 - val_loss: 0.6920 - val_accuracy: 0.5122\n",
      "Epoch 12/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5217 - val_loss: 0.6919 - val_accuracy: 0.5115\n",
      "Epoch 13/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6908 - accuracy: 0.5217 - val_loss: 0.6921 - val_accuracy: 0.5125\n",
      "Epoch 14/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5215 - val_loss: 0.6919 - val_accuracy: 0.5136\n",
      "Epoch 15/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5228 - val_loss: 0.6920 - val_accuracy: 0.5115\n",
      "Epoch 16/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5212 - val_loss: 0.6920 - val_accuracy: 0.5108\n",
      "Epoch 17/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6907 - accuracy: 0.5217 - val_loss: 0.6922 - val_accuracy: 0.5111\n",
      "Epoch 18/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5224 - val_loss: 0.6921 - val_accuracy: 0.5127\n",
      "Epoch 19/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5215 - val_loss: 0.6920 - val_accuracy: 0.5128\n",
      "Epoch 20/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5224 - val_loss: 0.6920 - val_accuracy: 0.5132\n",
      "Epoch 21/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5227 - val_loss: 0.6920 - val_accuracy: 0.5125\n",
      "Epoch 22/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5221 - val_loss: 0.6920 - val_accuracy: 0.5123\n",
      "Epoch 23/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5215 - val_loss: 0.6920 - val_accuracy: 0.5121\n",
      "Epoch 24/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5228 - val_loss: 0.6920 - val_accuracy: 0.5110\n",
      "Epoch 25/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5223 - val_loss: 0.6921 - val_accuracy: 0.5114\n",
      "Epoch 26/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5222 - val_loss: 0.6920 - val_accuracy: 0.5118\n",
      "Epoch 27/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5228 - val_loss: 0.6922 - val_accuracy: 0.5114\n",
      "Epoch 28/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5238 - val_loss: 0.6921 - val_accuracy: 0.5103\n",
      "Epoch 29/1000\n",
      "41760/41760 [==============================] - 0s 12us/sample - loss: 0.6904 - accuracy: 0.5222 - val_loss: 0.6920 - val_accuracy: 0.5128\n",
      "Epoch 30/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6904 - accuracy: 0.5224 - val_loss: 0.6921 - val_accuracy: 0.5115\n",
      "Epoch 31/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5242 - val_loss: 0.6920 - val_accuracy: 0.5115\n",
      "Epoch 32/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5213 - val_loss: 0.6922 - val_accuracy: 0.5073\n",
      "Epoch 33/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5226 - val_loss: 0.6921 - val_accuracy: 0.5088\n",
      "Epoch 34/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6903 - accuracy: 0.5228 - val_loss: 0.6921 - val_accuracy: 0.5118\n",
      "Epoch 35/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5234 - val_loss: 0.6921 - val_accuracy: 0.5102\n",
      "Epoch 36/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5232 - val_loss: 0.6921 - val_accuracy: 0.5119\n",
      "Epoch 37/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6903 - accuracy: 0.5233 - val_loss: 0.6920 - val_accuracy: 0.5108\n",
      "Epoch 38/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5238 - val_loss: 0.6922 - val_accuracy: 0.5098\n",
      "Epoch 39/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6902 - accuracy: 0.5238 - val_loss: 0.6922 - val_accuracy: 0.5101\n",
      "Epoch 40/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6903 - accuracy: 0.5239 - val_loss: 0.6922 - val_accuracy: 0.5098\n",
      "Epoch 41/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5235 - val_loss: 0.6922 - val_accuracy: 0.5097\n",
      "Epoch 42/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5251 - val_loss: 0.6921 - val_accuracy: 0.5107\n",
      "Training with significance = 5.66, run 7\n",
      "Train on 41760 samples, validate on 10441 samples\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41760/41760 [==============================] - 1s 27us/sample - loss: 0.6932 - accuracy: 0.5067 - val_loss: 0.6930 - val_accuracy: 0.4989\n",
      "Epoch 2/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5169 - val_loss: 0.6922 - val_accuracy: 0.5091\n",
      "Epoch 3/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5169 - val_loss: 0.6917 - val_accuracy: 0.5120\n",
      "Epoch 4/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5170 - val_loss: 0.6914 - val_accuracy: 0.5168\n",
      "Epoch 5/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5173 - val_loss: 0.6913 - val_accuracy: 0.5164\n",
      "Epoch 6/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5169 - val_loss: 0.6913 - val_accuracy: 0.5166\n",
      "Epoch 7/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5183 - val_loss: 0.6914 - val_accuracy: 0.5134\n",
      "Epoch 8/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5174 - val_loss: 0.6913 - val_accuracy: 0.5148\n",
      "Epoch 9/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5206 - val_loss: 0.6914 - val_accuracy: 0.5149\n",
      "Epoch 10/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6911 - accuracy: 0.5177 - val_loss: 0.6914 - val_accuracy: 0.5163\n",
      "Epoch 11/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5180 - val_loss: 0.6913 - val_accuracy: 0.5180\n",
      "Epoch 12/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5181 - val_loss: 0.6915 - val_accuracy: 0.5108\n",
      "Epoch 13/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5190 - val_loss: 0.6914 - val_accuracy: 0.5108\n",
      "Epoch 14/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6909 - accuracy: 0.5183 - val_loss: 0.6914 - val_accuracy: 0.5170\n",
      "Epoch 15/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6910 - accuracy: 0.5178 - val_loss: 0.6914 - val_accuracy: 0.5152\n",
      "Epoch 16/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6907 - accuracy: 0.5212 - val_loss: 0.6917 - val_accuracy: 0.5161\n",
      "Epoch 17/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6910 - accuracy: 0.5183 - val_loss: 0.6913 - val_accuracy: 0.5154\n",
      "Epoch 18/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5176 - val_loss: 0.6913 - val_accuracy: 0.5173\n",
      "Epoch 19/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6908 - accuracy: 0.5191 - val_loss: 0.6914 - val_accuracy: 0.5165\n",
      "Epoch 20/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6907 - accuracy: 0.5211 - val_loss: 0.6915 - val_accuracy: 0.5176\n",
      "Epoch 21/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6908 - accuracy: 0.5202 - val_loss: 0.6913 - val_accuracy: 0.5158\n",
      "Epoch 22/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5207 - val_loss: 0.6912 - val_accuracy: 0.5183\n",
      "Epoch 23/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5206 - val_loss: 0.6912 - val_accuracy: 0.5174\n",
      "Epoch 24/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6907 - accuracy: 0.5190 - val_loss: 0.6913 - val_accuracy: 0.5161\n",
      "Epoch 25/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5185 - val_loss: 0.6912 - val_accuracy: 0.5159\n",
      "Epoch 26/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5197 - val_loss: 0.6912 - val_accuracy: 0.5171\n",
      "Epoch 27/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5204 - val_loss: 0.6913 - val_accuracy: 0.5160\n",
      "Epoch 28/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5195 - val_loss: 0.6915 - val_accuracy: 0.5171\n",
      "Epoch 29/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5205 - val_loss: 0.6915 - val_accuracy: 0.5159\n",
      "Epoch 30/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5201 - val_loss: 0.6913 - val_accuracy: 0.5161\n",
      "Epoch 31/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5209 - val_loss: 0.6913 - val_accuracy: 0.5166\n",
      "Epoch 32/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5218 - val_loss: 0.6914 - val_accuracy: 0.5160\n",
      "Epoch 33/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5206 - val_loss: 0.6913 - val_accuracy: 0.5163\n",
      "Epoch 34/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6904 - accuracy: 0.5205 - val_loss: 0.6914 - val_accuracy: 0.5159\n",
      "Epoch 35/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5213 - val_loss: 0.6913 - val_accuracy: 0.5174\n",
      "Epoch 36/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5207 - val_loss: 0.6914 - val_accuracy: 0.5169\n",
      "Epoch 37/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5208 - val_loss: 0.6912 - val_accuracy: 0.5170\n",
      "Epoch 38/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5212 - val_loss: 0.6917 - val_accuracy: 0.5141\n",
      "Epoch 39/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5216 - val_loss: 0.6914 - val_accuracy: 0.5160\n",
      "Epoch 40/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5198 - val_loss: 0.6915 - val_accuracy: 0.5149\n",
      "Epoch 41/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6903 - accuracy: 0.5205 - val_loss: 0.6912 - val_accuracy: 0.5173\n",
      "Epoch 42/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5226 - val_loss: 0.6912 - val_accuracy: 0.5158\n",
      "Epoch 43/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5222 - val_loss: 0.6913 - val_accuracy: 0.5151\n",
      "Epoch 44/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5208 - val_loss: 0.6914 - val_accuracy: 0.5158\n",
      "Epoch 45/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6903 - accuracy: 0.5216 - val_loss: 0.6913 - val_accuracy: 0.5159\n",
      "Epoch 46/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6904 - accuracy: 0.5222 - val_loss: 0.6914 - val_accuracy: 0.5136\n",
      "Epoch 47/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5219 - val_loss: 0.6913 - val_accuracy: 0.5157\n",
      "Epoch 48/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5227 - val_loss: 0.6914 - val_accuracy: 0.5164\n",
      "Epoch 49/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5222 - val_loss: 0.6916 - val_accuracy: 0.5166\n",
      "Epoch 50/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6904 - accuracy: 0.5234 - val_loss: 0.6913 - val_accuracy: 0.5158\n",
      "Epoch 51/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5223 - val_loss: 0.6914 - val_accuracy: 0.5166\n",
      "Epoch 52/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6903 - accuracy: 0.5207 - val_loss: 0.6914 - val_accuracy: 0.5166\n",
      "Training with significance = 5.66, run 8\n",
      "Train on 41760 samples, validate on 10441 samples\n",
      "Epoch 1/1000\n",
      "41760/41760 [==============================] - 1s 27us/sample - loss: 0.6927 - accuracy: 0.5136 - val_loss: 0.6933 - val_accuracy: 0.5090\n",
      "Epoch 2/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6918 - accuracy: 0.5192 - val_loss: 0.6914 - val_accuracy: 0.5166\n",
      "Epoch 3/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5193 - val_loss: 0.6914 - val_accuracy: 0.5156\n",
      "Epoch 4/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5188 - val_loss: 0.6913 - val_accuracy: 0.5168\n",
      "Epoch 5/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5193 - val_loss: 0.6915 - val_accuracy: 0.5189\n",
      "Epoch 6/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6913 - accuracy: 0.5207 - val_loss: 0.6917 - val_accuracy: 0.5175\n",
      "Epoch 7/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5192 - val_loss: 0.6912 - val_accuracy: 0.5186\n",
      "Epoch 8/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6911 - accuracy: 0.5207 - val_loss: 0.6914 - val_accuracy: 0.5211\n",
      "Epoch 9/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5206 - val_loss: 0.6915 - val_accuracy: 0.5176\n",
      "Epoch 10/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6911 - accuracy: 0.5215 - val_loss: 0.6913 - val_accuracy: 0.5188\n",
      "Epoch 11/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6911 - accuracy: 0.5194 - val_loss: 0.6911 - val_accuracy: 0.5185\n",
      "Epoch 12/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6910 - accuracy: 0.5183 - val_loss: 0.6911 - val_accuracy: 0.5181\n",
      "Epoch 13/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6910 - accuracy: 0.5201 - val_loss: 0.6911 - val_accuracy: 0.5189\n",
      "Epoch 14/1000\n",
      "41760/41760 [==============================] - 1s 14us/sample - loss: 0.6909 - accuracy: 0.5195 - val_loss: 0.6911 - val_accuracy: 0.5155\n",
      "Epoch 15/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5208 - val_loss: 0.6911 - val_accuracy: 0.5170\n",
      "Epoch 16/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5209 - val_loss: 0.6911 - val_accuracy: 0.5231\n",
      "Epoch 17/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6908 - accuracy: 0.5205 - val_loss: 0.6911 - val_accuracy: 0.5197\n",
      "Epoch 18/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5201 - val_loss: 0.6915 - val_accuracy: 0.5157\n",
      "Epoch 19/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5198 - val_loss: 0.6912 - val_accuracy: 0.5192\n",
      "Epoch 20/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5217 - val_loss: 0.6911 - val_accuracy: 0.5176\n",
      "Epoch 21/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5208 - val_loss: 0.6909 - val_accuracy: 0.5175\n",
      "Epoch 22/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5204 - val_loss: 0.6909 - val_accuracy: 0.5175\n",
      "Epoch 23/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5212 - val_loss: 0.6909 - val_accuracy: 0.5194\n",
      "Epoch 24/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6907 - accuracy: 0.5207 - val_loss: 0.6909 - val_accuracy: 0.5171\n",
      "Epoch 25/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5189 - val_loss: 0.6909 - val_accuracy: 0.5166\n",
      "Epoch 26/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5190 - val_loss: 0.6909 - val_accuracy: 0.5175\n",
      "Epoch 27/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5193 - val_loss: 0.6914 - val_accuracy: 0.5155\n",
      "Epoch 28/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5223 - val_loss: 0.6911 - val_accuracy: 0.5160\n",
      "Epoch 29/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5216 - val_loss: 0.6909 - val_accuracy: 0.5178\n",
      "Epoch 30/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5209 - val_loss: 0.6910 - val_accuracy: 0.5202\n",
      "Epoch 31/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5211 - val_loss: 0.6909 - val_accuracy: 0.5162\n",
      "Epoch 32/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5218 - val_loss: 0.6909 - val_accuracy: 0.5197\n",
      "Epoch 33/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6907 - accuracy: 0.5202 - val_loss: 0.6910 - val_accuracy: 0.5187\n",
      "Epoch 34/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5197 - val_loss: 0.6910 - val_accuracy: 0.5181\n",
      "Epoch 35/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5217 - val_loss: 0.6910 - val_accuracy: 0.5188\n",
      "Epoch 36/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5217 - val_loss: 0.6910 - val_accuracy: 0.5178\n",
      "Epoch 37/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5201 - val_loss: 0.6909 - val_accuracy: 0.5181\n",
      "Epoch 38/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5208 - val_loss: 0.6909 - val_accuracy: 0.5156\n",
      "Epoch 39/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5228 - val_loss: 0.6908 - val_accuracy: 0.5179\n",
      "Epoch 40/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5215 - val_loss: 0.6912 - val_accuracy: 0.5172\n",
      "Epoch 41/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5216 - val_loss: 0.6907 - val_accuracy: 0.5184\n",
      "Epoch 42/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5216 - val_loss: 0.6912 - val_accuracy: 0.5174\n",
      "Epoch 43/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5225 - val_loss: 0.6908 - val_accuracy: 0.5181\n",
      "Epoch 44/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5224 - val_loss: 0.6908 - val_accuracy: 0.5146\n",
      "Epoch 45/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5213 - val_loss: 0.6913 - val_accuracy: 0.5146\n",
      "Epoch 46/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5222 - val_loss: 0.6908 - val_accuracy: 0.5151\n",
      "Epoch 47/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5232 - val_loss: 0.6912 - val_accuracy: 0.5181\n",
      "Epoch 48/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5227 - val_loss: 0.6910 - val_accuracy: 0.5172\n",
      "Epoch 49/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5212 - val_loss: 0.6908 - val_accuracy: 0.5154\n",
      "Epoch 50/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5214 - val_loss: 0.6909 - val_accuracy: 0.5160\n",
      "Epoch 51/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5226 - val_loss: 0.6910 - val_accuracy: 0.5177\n",
      "Epoch 52/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5217 - val_loss: 0.6907 - val_accuracy: 0.5169\n",
      "Epoch 53/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6903 - accuracy: 0.5227 - val_loss: 0.6911 - val_accuracy: 0.5146\n",
      "Epoch 54/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6902 - accuracy: 0.5238 - val_loss: 0.6911 - val_accuracy: 0.5176\n",
      "Epoch 55/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6903 - accuracy: 0.5229 - val_loss: 0.6907 - val_accuracy: 0.5176\n",
      "Epoch 56/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6903 - accuracy: 0.5217 - val_loss: 0.6910 - val_accuracy: 0.5148\n",
      "Epoch 57/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6901 - accuracy: 0.5227 - val_loss: 0.6910 - val_accuracy: 0.5171\n",
      "Epoch 58/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5223 - val_loss: 0.6908 - val_accuracy: 0.5164\n",
      "Epoch 59/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6904 - accuracy: 0.5215 - val_loss: 0.6909 - val_accuracy: 0.5147\n",
      "Epoch 60/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5242 - val_loss: 0.6907 - val_accuracy: 0.5185\n",
      "Epoch 61/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6902 - accuracy: 0.5213 - val_loss: 0.6910 - val_accuracy: 0.5163\n",
      "Epoch 62/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5234 - val_loss: 0.6912 - val_accuracy: 0.5175\n",
      "Epoch 63/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5218 - val_loss: 0.6912 - val_accuracy: 0.5171\n",
      "Epoch 64/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6902 - accuracy: 0.5234 - val_loss: 0.6909 - val_accuracy: 0.5158\n",
      "Epoch 65/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6902 - accuracy: 0.5220 - val_loss: 0.6908 - val_accuracy: 0.5177\n",
      "Epoch 66/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6901 - accuracy: 0.5211 - val_loss: 0.6907 - val_accuracy: 0.5196\n",
      "Epoch 67/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5221 - val_loss: 0.6908 - val_accuracy: 0.5163\n",
      "Epoch 68/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5234 - val_loss: 0.6908 - val_accuracy: 0.5156\n",
      "Epoch 69/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6901 - accuracy: 0.5236 - val_loss: 0.6908 - val_accuracy: 0.5153\n",
      "Epoch 70/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5228 - val_loss: 0.6909 - val_accuracy: 0.5187\n",
      "Epoch 71/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5243 - val_loss: 0.6910 - val_accuracy: 0.5147\n",
      "Epoch 72/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5227 - val_loss: 0.6907 - val_accuracy: 0.5176\n",
      "Epoch 73/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6900 - accuracy: 0.5230 - val_loss: 0.6907 - val_accuracy: 0.5180\n",
      "Epoch 74/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6903 - accuracy: 0.5222 - val_loss: 0.6910 - val_accuracy: 0.5191\n",
      "Epoch 75/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5236 - val_loss: 0.6907 - val_accuracy: 0.5173\n",
      "Epoch 76/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6903 - accuracy: 0.5224 - val_loss: 0.6908 - val_accuracy: 0.5155\n",
      "Epoch 77/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5233 - val_loss: 0.6910 - val_accuracy: 0.5175\n",
      "Epoch 78/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6901 - accuracy: 0.5228 - val_loss: 0.6907 - val_accuracy: 0.5171\n",
      "Epoch 79/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5244 - val_loss: 0.6909 - val_accuracy: 0.5164\n",
      "Epoch 80/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5252 - val_loss: 0.6908 - val_accuracy: 0.5181\n",
      "Epoch 81/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5248 - val_loss: 0.6913 - val_accuracy: 0.5160\n",
      "Epoch 82/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5234 - val_loss: 0.6909 - val_accuracy: 0.5159\n",
      "Epoch 83/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5246 - val_loss: 0.6908 - val_accuracy: 0.5153\n",
      "Epoch 84/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5237 - val_loss: 0.6908 - val_accuracy: 0.5186\n",
      "Epoch 85/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6899 - accuracy: 0.5235 - val_loss: 0.6908 - val_accuracy: 0.5157\n",
      "Epoch 86/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6901 - accuracy: 0.5243 - val_loss: 0.6909 - val_accuracy: 0.5166\n",
      "Epoch 87/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5231 - val_loss: 0.6907 - val_accuracy: 0.5154\n",
      "Epoch 88/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6901 - accuracy: 0.5248 - val_loss: 0.6908 - val_accuracy: 0.5161\n",
      "Epoch 89/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5245 - val_loss: 0.6908 - val_accuracy: 0.5204\n",
      "Epoch 90/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5228 - val_loss: 0.6908 - val_accuracy: 0.5157\n",
      "Epoch 91/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5242 - val_loss: 0.6909 - val_accuracy: 0.5159\n",
      "Epoch 92/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5239 - val_loss: 0.6908 - val_accuracy: 0.5166\n",
      "Epoch 93/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6900 - accuracy: 0.5256 - val_loss: 0.6907 - val_accuracy: 0.5163\n",
      "Epoch 94/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5251 - val_loss: 0.6908 - val_accuracy: 0.5181\n",
      "Epoch 95/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5247 - val_loss: 0.6906 - val_accuracy: 0.5181\n",
      "Epoch 96/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6900 - accuracy: 0.5232 - val_loss: 0.6906 - val_accuracy: 0.5196\n",
      "Epoch 97/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5251 - val_loss: 0.6907 - val_accuracy: 0.5178\n",
      "Epoch 98/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5245 - val_loss: 0.6909 - val_accuracy: 0.5133\n",
      "Epoch 99/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6898 - accuracy: 0.5246 - val_loss: 0.6908 - val_accuracy: 0.5176\n",
      "Epoch 100/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6899 - accuracy: 0.5234 - val_loss: 0.6907 - val_accuracy: 0.5198\n",
      "Epoch 101/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6899 - accuracy: 0.5243 - val_loss: 0.6912 - val_accuracy: 0.5181\n",
      "Epoch 102/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6899 - accuracy: 0.5239 - val_loss: 0.6908 - val_accuracy: 0.5152\n",
      "Epoch 103/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6899 - accuracy: 0.5242 - val_loss: 0.6905 - val_accuracy: 0.5186\n",
      "Epoch 104/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6899 - accuracy: 0.5256 - val_loss: 0.6907 - val_accuracy: 0.5177\n",
      "Epoch 105/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5270 - val_loss: 0.6910 - val_accuracy: 0.5144\n",
      "Epoch 106/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5251 - val_loss: 0.6909 - val_accuracy: 0.5162\n",
      "Epoch 107/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5228 - val_loss: 0.6908 - val_accuracy: 0.5194\n",
      "Epoch 108/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5247 - val_loss: 0.6911 - val_accuracy: 0.5181\n",
      "Epoch 109/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5240 - val_loss: 0.6910 - val_accuracy: 0.5165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5252 - val_loss: 0.6908 - val_accuracy: 0.5199\n",
      "Epoch 111/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5243 - val_loss: 0.6907 - val_accuracy: 0.5181\n",
      "Epoch 112/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5249 - val_loss: 0.6910 - val_accuracy: 0.5181\n",
      "Epoch 113/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6898 - accuracy: 0.5259 - val_loss: 0.6906 - val_accuracy: 0.5157\n",
      "Epoch 114/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6898 - accuracy: 0.5262 - val_loss: 0.6911 - val_accuracy: 0.5171\n",
      "Epoch 115/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6898 - accuracy: 0.5245 - val_loss: 0.6907 - val_accuracy: 0.5173\n",
      "Epoch 116/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6898 - accuracy: 0.5271 - val_loss: 0.6911 - val_accuracy: 0.5149\n",
      "Epoch 117/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6898 - accuracy: 0.5244 - val_loss: 0.6906 - val_accuracy: 0.5195\n",
      "Epoch 118/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6898 - accuracy: 0.5249 - val_loss: 0.6910 - val_accuracy: 0.5149\n",
      "Epoch 119/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6898 - accuracy: 0.5259 - val_loss: 0.6909 - val_accuracy: 0.5163\n",
      "Epoch 120/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6898 - accuracy: 0.5256 - val_loss: 0.6909 - val_accuracy: 0.5166\n",
      "Epoch 121/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5222 - val_loss: 0.6906 - val_accuracy: 0.5189\n",
      "Epoch 122/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5254 - val_loss: 0.6909 - val_accuracy: 0.5198\n",
      "Epoch 123/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6898 - accuracy: 0.5261 - val_loss: 0.6907 - val_accuracy: 0.5194\n",
      "Epoch 124/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6898 - accuracy: 0.5257 - val_loss: 0.6910 - val_accuracy: 0.5173\n",
      "Epoch 125/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6897 - accuracy: 0.5261 - val_loss: 0.6906 - val_accuracy: 0.5186\n",
      "Epoch 126/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5253 - val_loss: 0.6906 - val_accuracy: 0.5199\n",
      "Epoch 127/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6896 - accuracy: 0.5274 - val_loss: 0.6906 - val_accuracy: 0.5184\n",
      "Epoch 128/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6897 - accuracy: 0.5259 - val_loss: 0.6908 - val_accuracy: 0.5137\n",
      "Epoch 129/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6896 - accuracy: 0.5278 - val_loss: 0.6907 - val_accuracy: 0.5170\n",
      "Epoch 130/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6897 - accuracy: 0.5258 - val_loss: 0.6908 - val_accuracy: 0.5171\n",
      "Epoch 131/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6897 - accuracy: 0.5274 - val_loss: 0.6908 - val_accuracy: 0.5174\n",
      "Epoch 132/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6895 - accuracy: 0.5250 - val_loss: 0.6907 - val_accuracy: 0.5187\n",
      "Epoch 133/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6897 - accuracy: 0.5260 - val_loss: 0.6908 - val_accuracy: 0.5175\n",
      "Training with significance = 5.66, run 9\n",
      "Train on 41760 samples, validate on 10441 samples\n",
      "Epoch 1/1000\n",
      "41760/41760 [==============================] - 1s 27us/sample - loss: 0.6928 - accuracy: 0.5067 - val_loss: 0.6953 - val_accuracy: 0.4974\n",
      "Epoch 2/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5167 - val_loss: 0.6936 - val_accuracy: 0.5047\n",
      "Epoch 3/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5175 - val_loss: 0.6932 - val_accuracy: 0.5098\n",
      "Epoch 4/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5185 - val_loss: 0.6928 - val_accuracy: 0.5138\n",
      "Epoch 5/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5171 - val_loss: 0.6925 - val_accuracy: 0.5155\n",
      "Epoch 6/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5187 - val_loss: 0.6928 - val_accuracy: 0.5136\n",
      "Epoch 7/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5170 - val_loss: 0.6925 - val_accuracy: 0.5168\n",
      "Epoch 8/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5189 - val_loss: 0.6923 - val_accuracy: 0.5166\n",
      "Epoch 9/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5191 - val_loss: 0.6926 - val_accuracy: 0.5113\n",
      "Epoch 10/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5182 - val_loss: 0.6922 - val_accuracy: 0.5178\n",
      "Epoch 11/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6912 - accuracy: 0.5197 - val_loss: 0.6924 - val_accuracy: 0.5176\n",
      "Epoch 12/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6911 - accuracy: 0.5198 - val_loss: 0.6925 - val_accuracy: 0.5170\n",
      "Epoch 13/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5198 - val_loss: 0.6923 - val_accuracy: 0.5167\n",
      "Epoch 14/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5197 - val_loss: 0.6924 - val_accuracy: 0.5167\n",
      "Epoch 15/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6910 - accuracy: 0.5185 - val_loss: 0.6924 - val_accuracy: 0.5169\n",
      "Epoch 16/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6909 - accuracy: 0.5204 - val_loss: 0.6923 - val_accuracy: 0.5175\n",
      "Epoch 17/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5204 - val_loss: 0.6925 - val_accuracy: 0.5187\n",
      "Epoch 18/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5189 - val_loss: 0.6923 - val_accuracy: 0.5142\n",
      "Epoch 19/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5206 - val_loss: 0.6925 - val_accuracy: 0.5166\n",
      "Epoch 20/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5194 - val_loss: 0.6925 - val_accuracy: 0.5161\n",
      "Epoch 21/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5192 - val_loss: 0.6928 - val_accuracy: 0.5098\n",
      "Epoch 22/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5202 - val_loss: 0.6926 - val_accuracy: 0.5184\n",
      "Epoch 23/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6909 - accuracy: 0.5194 - val_loss: 0.6925 - val_accuracy: 0.5149\n",
      "Epoch 24/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6908 - accuracy: 0.5207 - val_loss: 0.6926 - val_accuracy: 0.5163\n",
      "Epoch 25/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5209 - val_loss: 0.6927 - val_accuracy: 0.5140\n",
      "Epoch 26/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5207 - val_loss: 0.6925 - val_accuracy: 0.5160\n",
      "Epoch 27/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6907 - accuracy: 0.5214 - val_loss: 0.6926 - val_accuracy: 0.5130\n",
      "Epoch 28/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6907 - accuracy: 0.5212 - val_loss: 0.6927 - val_accuracy: 0.5168\n",
      "Epoch 29/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5222 - val_loss: 0.6926 - val_accuracy: 0.5157\n",
      "Epoch 30/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6907 - accuracy: 0.5220 - val_loss: 0.6928 - val_accuracy: 0.5167\n",
      "Epoch 31/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5223 - val_loss: 0.6926 - val_accuracy: 0.5144\n",
      "Epoch 32/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5218 - val_loss: 0.6927 - val_accuracy: 0.5117\n",
      "Epoch 33/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5201 - val_loss: 0.6929 - val_accuracy: 0.5062\n",
      "Epoch 34/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6908 - accuracy: 0.5223 - val_loss: 0.6928 - val_accuracy: 0.5120\n",
      "Epoch 35/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6907 - accuracy: 0.5205 - val_loss: 0.6926 - val_accuracy: 0.5139\n",
      "Epoch 36/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5225 - val_loss: 0.6925 - val_accuracy: 0.5091\n",
      "Epoch 37/1000\n",
      "41760/41760 [==============================] - 0s 12us/sample - loss: 0.6907 - accuracy: 0.5218 - val_loss: 0.6930 - val_accuracy: 0.5069\n",
      "Epoch 38/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5202 - val_loss: 0.6928 - val_accuracy: 0.5124\n",
      "Epoch 39/1000\n",
      "41760/41760 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5216 - val_loss: 0.6927 - val_accuracy: 0.5154\n",
      "Epoch 40/1000\n",
      "41760/41760 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5238 - val_loss: 0.6926 - val_accuracy: 0.5123\n",
      "Training with significance = 6.28, run 0\n",
      "Train on 41862 samples, validate on 10466 samples\n",
      "Epoch 1/1000\n",
      "41862/41862 [==============================] - 1s 27us/sample - loss: 0.6930 - accuracy: 0.5066 - val_loss: 0.6945 - val_accuracy: 0.5025\n",
      "Epoch 2/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5172 - val_loss: 0.6926 - val_accuracy: 0.5073\n",
      "Epoch 3/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6918 - accuracy: 0.5166 - val_loss: 0.6919 - val_accuracy: 0.5146\n",
      "Epoch 4/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5179 - val_loss: 0.6914 - val_accuracy: 0.5155\n",
      "Epoch 5/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6915 - accuracy: 0.5175 - val_loss: 0.6913 - val_accuracy: 0.5163\n",
      "Epoch 6/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6915 - accuracy: 0.5170 - val_loss: 0.6911 - val_accuracy: 0.5179\n",
      "Epoch 7/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5144 - val_loss: 0.6912 - val_accuracy: 0.5174\n",
      "Epoch 8/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5174 - val_loss: 0.6909 - val_accuracy: 0.5185\n",
      "Epoch 9/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6912 - accuracy: 0.5164 - val_loss: 0.6909 - val_accuracy: 0.5188\n",
      "Epoch 10/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6912 - accuracy: 0.5170 - val_loss: 0.6911 - val_accuracy: 0.5176\n",
      "Epoch 11/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5170 - val_loss: 0.6910 - val_accuracy: 0.5161\n",
      "Epoch 12/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5181 - val_loss: 0.6910 - val_accuracy: 0.5169\n",
      "Epoch 13/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5172 - val_loss: 0.6908 - val_accuracy: 0.5170\n",
      "Epoch 14/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6911 - accuracy: 0.5189 - val_loss: 0.6910 - val_accuracy: 0.5174\n",
      "Epoch 15/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5178 - val_loss: 0.6906 - val_accuracy: 0.5180\n",
      "Epoch 16/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6911 - accuracy: 0.5183 - val_loss: 0.6906 - val_accuracy: 0.5214\n",
      "Epoch 17/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6909 - accuracy: 0.5187 - val_loss: 0.6909 - val_accuracy: 0.5169\n",
      "Epoch 18/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6910 - accuracy: 0.5187 - val_loss: 0.6908 - val_accuracy: 0.5182\n",
      "Epoch 19/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6910 - accuracy: 0.5192 - val_loss: 0.6906 - val_accuracy: 0.5194\n",
      "Epoch 20/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5188 - val_loss: 0.6905 - val_accuracy: 0.5204\n",
      "Epoch 21/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5182 - val_loss: 0.6908 - val_accuracy: 0.5177\n",
      "Epoch 22/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5201 - val_loss: 0.6906 - val_accuracy: 0.5192\n",
      "Epoch 23/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5198 - val_loss: 0.6905 - val_accuracy: 0.5208\n",
      "Epoch 24/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6910 - accuracy: 0.5199 - val_loss: 0.6908 - val_accuracy: 0.5174\n",
      "Epoch 25/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6909 - accuracy: 0.5199 - val_loss: 0.6906 - val_accuracy: 0.5188\n",
      "Epoch 26/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5209 - val_loss: 0.6905 - val_accuracy: 0.5201\n",
      "Epoch 27/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5201 - val_loss: 0.6906 - val_accuracy: 0.5175\n",
      "Epoch 28/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6909 - accuracy: 0.5196 - val_loss: 0.6905 - val_accuracy: 0.5185\n",
      "Epoch 29/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5203 - val_loss: 0.6907 - val_accuracy: 0.5199\n",
      "Epoch 30/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6908 - accuracy: 0.5195 - val_loss: 0.6905 - val_accuracy: 0.5181\n",
      "Epoch 31/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6909 - accuracy: 0.5205 - val_loss: 0.6908 - val_accuracy: 0.5173\n",
      "Epoch 32/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6908 - accuracy: 0.5209 - val_loss: 0.6906 - val_accuracy: 0.5222\n",
      "Epoch 33/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6908 - accuracy: 0.5220 - val_loss: 0.6905 - val_accuracy: 0.5194\n",
      "Epoch 34/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5207 - val_loss: 0.6906 - val_accuracy: 0.5170\n",
      "Epoch 35/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5215 - val_loss: 0.6906 - val_accuracy: 0.5181\n",
      "Epoch 36/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5203 - val_loss: 0.6906 - val_accuracy: 0.5188\n",
      "Epoch 37/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5194 - val_loss: 0.6907 - val_accuracy: 0.5191\n",
      "Epoch 38/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6907 - accuracy: 0.5213 - val_loss: 0.6904 - val_accuracy: 0.5213\n",
      "Epoch 39/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5214 - val_loss: 0.6903 - val_accuracy: 0.5200\n",
      "Epoch 40/1000\n",
      "41862/41862 [==============================] - 0s 12us/sample - loss: 0.6906 - accuracy: 0.5220 - val_loss: 0.6908 - val_accuracy: 0.5181\n",
      "Epoch 41/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5222 - val_loss: 0.6904 - val_accuracy: 0.5183\n",
      "Epoch 42/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5195 - val_loss: 0.6906 - val_accuracy: 0.5182\n",
      "Epoch 43/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5224 - val_loss: 0.6904 - val_accuracy: 0.5177\n",
      "Epoch 44/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5224 - val_loss: 0.6908 - val_accuracy: 0.5171\n",
      "Epoch 45/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5219 - val_loss: 0.6905 - val_accuracy: 0.5175\n",
      "Epoch 46/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5195 - val_loss: 0.6905 - val_accuracy: 0.5182\n",
      "Epoch 47/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5208 - val_loss: 0.6905 - val_accuracy: 0.5181\n",
      "Epoch 48/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5202 - val_loss: 0.6905 - val_accuracy: 0.5191\n",
      "Epoch 49/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5219 - val_loss: 0.6906 - val_accuracy: 0.5154\n",
      "Epoch 50/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5218 - val_loss: 0.6904 - val_accuracy: 0.5168\n",
      "Epoch 51/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5231 - val_loss: 0.6903 - val_accuracy: 0.5185\n",
      "Epoch 52/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5220 - val_loss: 0.6904 - val_accuracy: 0.5188\n",
      "Epoch 53/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5222 - val_loss: 0.6905 - val_accuracy: 0.5173\n",
      "Epoch 54/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5223 - val_loss: 0.6903 - val_accuracy: 0.5204\n",
      "Epoch 55/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5215 - val_loss: 0.6904 - val_accuracy: 0.5202\n",
      "Epoch 56/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5224 - val_loss: 0.6907 - val_accuracy: 0.5175\n",
      "Epoch 57/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5245 - val_loss: 0.6904 - val_accuracy: 0.5182\n",
      "Epoch 58/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5217 - val_loss: 0.6905 - val_accuracy: 0.5189\n",
      "Epoch 59/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5210 - val_loss: 0.6902 - val_accuracy: 0.5161\n",
      "Epoch 60/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5207 - val_loss: 0.6903 - val_accuracy: 0.5195\n",
      "Epoch 61/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5232 - val_loss: 0.6904 - val_accuracy: 0.5182\n",
      "Epoch 62/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5217 - val_loss: 0.6907 - val_accuracy: 0.5178\n",
      "Epoch 63/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5237 - val_loss: 0.6903 - val_accuracy: 0.5189\n",
      "Epoch 64/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5217 - val_loss: 0.6906 - val_accuracy: 0.5172\n",
      "Epoch 65/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5228 - val_loss: 0.6905 - val_accuracy: 0.5170\n",
      "Epoch 66/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5235 - val_loss: 0.6906 - val_accuracy: 0.5162\n",
      "Epoch 67/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5220 - val_loss: 0.6904 - val_accuracy: 0.5185\n",
      "Epoch 68/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6904 - accuracy: 0.5226 - val_loss: 0.6906 - val_accuracy: 0.5171\n",
      "Epoch 69/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5239 - val_loss: 0.6903 - val_accuracy: 0.5170\n",
      "Epoch 70/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5238 - val_loss: 0.6905 - val_accuracy: 0.5171\n",
      "Epoch 71/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5239 - val_loss: 0.6903 - val_accuracy: 0.5186\n",
      "Epoch 72/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5213 - val_loss: 0.6905 - val_accuracy: 0.5185\n",
      "Epoch 73/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5217 - val_loss: 0.6905 - val_accuracy: 0.5157\n",
      "Epoch 74/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5247 - val_loss: 0.6905 - val_accuracy: 0.5170\n",
      "Epoch 75/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5213 - val_loss: 0.6905 - val_accuracy: 0.5162\n",
      "Epoch 76/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6902 - accuracy: 0.5248 - val_loss: 0.6903 - val_accuracy: 0.5182\n",
      "Epoch 77/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5214 - val_loss: 0.6907 - val_accuracy: 0.5164\n",
      "Epoch 78/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5222 - val_loss: 0.6904 - val_accuracy: 0.5177\n",
      "Epoch 79/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6903 - accuracy: 0.5241 - val_loss: 0.6903 - val_accuracy: 0.5163\n",
      "Epoch 80/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5212 - val_loss: 0.6903 - val_accuracy: 0.5165\n",
      "Epoch 81/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6903 - accuracy: 0.5226 - val_loss: 0.6904 - val_accuracy: 0.5165\n",
      "Epoch 82/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6903 - accuracy: 0.5225 - val_loss: 0.6906 - val_accuracy: 0.5154\n",
      "Epoch 83/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6903 - accuracy: 0.5234 - val_loss: 0.6904 - val_accuracy: 0.5158\n",
      "Epoch 84/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5235 - val_loss: 0.6903 - val_accuracy: 0.5161\n",
      "Epoch 85/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5222 - val_loss: 0.6902 - val_accuracy: 0.5184\n",
      "Epoch 86/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6902 - accuracy: 0.5232 - val_loss: 0.6903 - val_accuracy: 0.5200\n",
      "Epoch 87/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5248 - val_loss: 0.6904 - val_accuracy: 0.5164\n",
      "Epoch 88/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5220 - val_loss: 0.6904 - val_accuracy: 0.5131\n",
      "Epoch 89/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5238 - val_loss: 0.6905 - val_accuracy: 0.5182\n",
      "Epoch 90/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6904 - accuracy: 0.5239 - val_loss: 0.6902 - val_accuracy: 0.5171\n",
      "Epoch 91/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6902 - accuracy: 0.5242 - val_loss: 0.6903 - val_accuracy: 0.5170\n",
      "Epoch 92/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5233 - val_loss: 0.6904 - val_accuracy: 0.5162\n",
      "Epoch 93/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6903 - accuracy: 0.5228 - val_loss: 0.6905 - val_accuracy: 0.5153\n",
      "Epoch 94/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6903 - accuracy: 0.5242 - val_loss: 0.6908 - val_accuracy: 0.5168\n",
      "Epoch 95/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5231 - val_loss: 0.6903 - val_accuracy: 0.5168\n",
      "Epoch 96/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6902 - accuracy: 0.5242 - val_loss: 0.6904 - val_accuracy: 0.5166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6902 - accuracy: 0.5244 - val_loss: 0.6903 - val_accuracy: 0.5178\n",
      "Epoch 98/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5244 - val_loss: 0.6904 - val_accuracy: 0.5142\n",
      "Epoch 99/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6902 - accuracy: 0.5242 - val_loss: 0.6902 - val_accuracy: 0.5159\n",
      "Epoch 100/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5246 - val_loss: 0.6903 - val_accuracy: 0.5161\n",
      "Epoch 101/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6903 - accuracy: 0.5221 - val_loss: 0.6905 - val_accuracy: 0.5160\n",
      "Epoch 102/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6902 - accuracy: 0.5233 - val_loss: 0.6903 - val_accuracy: 0.5149\n",
      "Epoch 103/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6902 - accuracy: 0.5242 - val_loss: 0.6902 - val_accuracy: 0.5176\n",
      "Epoch 104/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5243 - val_loss: 0.6904 - val_accuracy: 0.5146\n",
      "Epoch 105/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5265 - val_loss: 0.6903 - val_accuracy: 0.5163\n",
      "Epoch 106/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5228 - val_loss: 0.6902 - val_accuracy: 0.5178\n",
      "Epoch 107/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6901 - accuracy: 0.5251 - val_loss: 0.6904 - val_accuracy: 0.5132\n",
      "Epoch 108/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6903 - accuracy: 0.5234 - val_loss: 0.6902 - val_accuracy: 0.5162\n",
      "Epoch 109/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5259 - val_loss: 0.6902 - val_accuracy: 0.5153\n",
      "Epoch 110/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6902 - accuracy: 0.5241 - val_loss: 0.6906 - val_accuracy: 0.5159\n",
      "Epoch 111/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5230 - val_loss: 0.6908 - val_accuracy: 0.5118\n",
      "Epoch 112/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6902 - accuracy: 0.5249 - val_loss: 0.6908 - val_accuracy: 0.5147\n",
      "Epoch 113/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6901 - accuracy: 0.5230 - val_loss: 0.6904 - val_accuracy: 0.5124\n",
      "Epoch 114/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6901 - accuracy: 0.5242 - val_loss: 0.6905 - val_accuracy: 0.5138\n",
      "Epoch 115/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5260 - val_loss: 0.6904 - val_accuracy: 0.5151\n",
      "Training with significance = 6.28, run 1\n",
      "Train on 41862 samples, validate on 10466 samples\n",
      "Epoch 1/1000\n",
      "41862/41862 [==============================] - 1s 28us/sample - loss: 0.6928 - accuracy: 0.5105 - val_loss: 0.6929 - val_accuracy: 0.5084\n",
      "Epoch 2/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6915 - accuracy: 0.5171 - val_loss: 0.6920 - val_accuracy: 0.5153\n",
      "Epoch 3/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5198 - val_loss: 0.6915 - val_accuracy: 0.5184\n",
      "Epoch 4/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5196 - val_loss: 0.6913 - val_accuracy: 0.5189\n",
      "Epoch 5/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6910 - accuracy: 0.5190 - val_loss: 0.6912 - val_accuracy: 0.5181\n",
      "Epoch 6/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5206 - val_loss: 0.6912 - val_accuracy: 0.5159\n",
      "Epoch 7/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5216 - val_loss: 0.6912 - val_accuracy: 0.5148\n",
      "Epoch 8/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5226 - val_loss: 0.6913 - val_accuracy: 0.5137\n",
      "Epoch 9/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5224 - val_loss: 0.6913 - val_accuracy: 0.5139\n",
      "Epoch 10/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5210 - val_loss: 0.6916 - val_accuracy: 0.5154\n",
      "Epoch 11/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5225 - val_loss: 0.6914 - val_accuracy: 0.5126\n",
      "Epoch 12/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5239 - val_loss: 0.6914 - val_accuracy: 0.5127\n",
      "Epoch 13/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5243 - val_loss: 0.6914 - val_accuracy: 0.5154\n",
      "Epoch 14/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5229 - val_loss: 0.6911 - val_accuracy: 0.5171\n",
      "Epoch 15/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5226 - val_loss: 0.6913 - val_accuracy: 0.5139\n",
      "Epoch 16/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5232 - val_loss: 0.6912 - val_accuracy: 0.5147\n",
      "Epoch 17/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5232 - val_loss: 0.6913 - val_accuracy: 0.5124\n",
      "Epoch 18/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5230 - val_loss: 0.6914 - val_accuracy: 0.5168\n",
      "Epoch 19/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5232 - val_loss: 0.6911 - val_accuracy: 0.5174\n",
      "Epoch 20/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5231 - val_loss: 0.6911 - val_accuracy: 0.5187\n",
      "Epoch 21/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5248 - val_loss: 0.6913 - val_accuracy: 0.5134\n",
      "Epoch 22/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6903 - accuracy: 0.5249 - val_loss: 0.6915 - val_accuracy: 0.5184\n",
      "Epoch 23/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5227 - val_loss: 0.6913 - val_accuracy: 0.5166\n",
      "Epoch 24/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6903 - accuracy: 0.5250 - val_loss: 0.6913 - val_accuracy: 0.5145\n",
      "Epoch 25/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5252 - val_loss: 0.6914 - val_accuracy: 0.5161\n",
      "Epoch 26/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5259 - val_loss: 0.6913 - val_accuracy: 0.5161\n",
      "Epoch 27/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5258 - val_loss: 0.6912 - val_accuracy: 0.5156\n",
      "Epoch 28/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5253 - val_loss: 0.6912 - val_accuracy: 0.5162\n",
      "Epoch 29/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5247 - val_loss: 0.6913 - val_accuracy: 0.5163\n",
      "Epoch 30/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5249 - val_loss: 0.6913 - val_accuracy: 0.5158\n",
      "Epoch 31/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5265 - val_loss: 0.6911 - val_accuracy: 0.5185\n",
      "Epoch 32/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5238 - val_loss: 0.6912 - val_accuracy: 0.5186\n",
      "Epoch 33/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5264 - val_loss: 0.6913 - val_accuracy: 0.5155\n",
      "Epoch 34/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6902 - accuracy: 0.5274 - val_loss: 0.6913 - val_accuracy: 0.5169\n",
      "Epoch 35/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5244 - val_loss: 0.6912 - val_accuracy: 0.5168\n",
      "Epoch 36/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5245 - val_loss: 0.6912 - val_accuracy: 0.5167\n",
      "Epoch 37/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5244 - val_loss: 0.6913 - val_accuracy: 0.5167\n",
      "Epoch 38/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5266 - val_loss: 0.6912 - val_accuracy: 0.5170\n",
      "Epoch 39/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5259 - val_loss: 0.6915 - val_accuracy: 0.5183\n",
      "Epoch 40/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5265 - val_loss: 0.6911 - val_accuracy: 0.5176\n",
      "Epoch 41/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5261 - val_loss: 0.6912 - val_accuracy: 0.5169\n",
      "Epoch 42/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5267 - val_loss: 0.6912 - val_accuracy: 0.5167\n",
      "Epoch 43/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5250 - val_loss: 0.6914 - val_accuracy: 0.5165\n",
      "Epoch 44/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5263 - val_loss: 0.6914 - val_accuracy: 0.5146\n",
      "Epoch 45/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5253 - val_loss: 0.6914 - val_accuracy: 0.5141\n",
      "Epoch 46/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5261 - val_loss: 0.6912 - val_accuracy: 0.5171\n",
      "Epoch 47/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5267 - val_loss: 0.6914 - val_accuracy: 0.5155\n",
      "Epoch 48/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5264 - val_loss: 0.6913 - val_accuracy: 0.5158\n",
      "Epoch 49/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5263 - val_loss: 0.6914 - val_accuracy: 0.5158\n",
      "Training with significance = 6.28, run 2\n",
      "Train on 41862 samples, validate on 10466 samples\n",
      "Epoch 1/1000\n",
      "41862/41862 [==============================] - 1s 27us/sample - loss: 0.6929 - accuracy: 0.5115 - val_loss: 0.6926 - val_accuracy: 0.5058\n",
      "Epoch 2/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5150 - val_loss: 0.6916 - val_accuracy: 0.5099\n",
      "Epoch 3/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5198 - val_loss: 0.6912 - val_accuracy: 0.5124\n",
      "Epoch 4/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5201 - val_loss: 0.6911 - val_accuracy: 0.5121\n",
      "Epoch 5/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5202 - val_loss: 0.6911 - val_accuracy: 0.5172\n",
      "Epoch 6/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5221 - val_loss: 0.6910 - val_accuracy: 0.5182\n",
      "Epoch 7/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5225 - val_loss: 0.6911 - val_accuracy: 0.5184\n",
      "Epoch 8/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6914 - accuracy: 0.5230 - val_loss: 0.6912 - val_accuracy: 0.5165\n",
      "Epoch 9/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6912 - accuracy: 0.5197 - val_loss: 0.6913 - val_accuracy: 0.5148\n",
      "Epoch 10/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5211 - val_loss: 0.6911 - val_accuracy: 0.5182\n",
      "Epoch 11/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5229 - val_loss: 0.6910 - val_accuracy: 0.5194\n",
      "Epoch 12/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5213 - val_loss: 0.6912 - val_accuracy: 0.5175\n",
      "Epoch 13/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5220 - val_loss: 0.6908 - val_accuracy: 0.5165\n",
      "Epoch 14/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5217 - val_loss: 0.6909 - val_accuracy: 0.5158\n",
      "Epoch 15/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6911 - accuracy: 0.5235 - val_loss: 0.6912 - val_accuracy: 0.5155\n",
      "Epoch 16/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5235 - val_loss: 0.6908 - val_accuracy: 0.5177\n",
      "Epoch 17/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5236 - val_loss: 0.6918 - val_accuracy: 0.5158\n",
      "Epoch 18/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5215 - val_loss: 0.6910 - val_accuracy: 0.5153\n",
      "Epoch 19/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5225 - val_loss: 0.6908 - val_accuracy: 0.5176\n",
      "Epoch 20/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6910 - accuracy: 0.5221 - val_loss: 0.6908 - val_accuracy: 0.5156\n",
      "Epoch 21/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5231 - val_loss: 0.6910 - val_accuracy: 0.5168\n",
      "Epoch 22/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5249 - val_loss: 0.6909 - val_accuracy: 0.5177\n",
      "Epoch 23/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5228 - val_loss: 0.6911 - val_accuracy: 0.5147\n",
      "Epoch 24/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6910 - accuracy: 0.5220 - val_loss: 0.6909 - val_accuracy: 0.5150\n",
      "Epoch 25/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6909 - accuracy: 0.5235 - val_loss: 0.6910 - val_accuracy: 0.5152\n",
      "Epoch 26/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5215 - val_loss: 0.6908 - val_accuracy: 0.5164\n",
      "Epoch 27/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5229 - val_loss: 0.6912 - val_accuracy: 0.5170\n",
      "Epoch 28/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5255 - val_loss: 0.6911 - val_accuracy: 0.5152\n",
      "Epoch 29/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5206 - val_loss: 0.6910 - val_accuracy: 0.5157\n",
      "Epoch 30/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5225 - val_loss: 0.6914 - val_accuracy: 0.5136\n",
      "Epoch 31/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5218 - val_loss: 0.6908 - val_accuracy: 0.5155\n",
      "Epoch 32/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5218 - val_loss: 0.6911 - val_accuracy: 0.5165\n",
      "Epoch 33/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5219 - val_loss: 0.6910 - val_accuracy: 0.5153\n",
      "Epoch 34/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5236 - val_loss: 0.6908 - val_accuracy: 0.5178\n",
      "Epoch 35/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5228 - val_loss: 0.6910 - val_accuracy: 0.5154\n",
      "Epoch 36/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5252 - val_loss: 0.6910 - val_accuracy: 0.5189\n",
      "Epoch 37/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5244 - val_loss: 0.6911 - val_accuracy: 0.5142\n",
      "Epoch 38/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5236 - val_loss: 0.6907 - val_accuracy: 0.5188\n",
      "Epoch 39/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6908 - accuracy: 0.5237 - val_loss: 0.6913 - val_accuracy: 0.5146\n",
      "Epoch 40/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5238 - val_loss: 0.6908 - val_accuracy: 0.5158\n",
      "Epoch 41/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5249 - val_loss: 0.6911 - val_accuracy: 0.5146\n",
      "Epoch 42/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5229 - val_loss: 0.6910 - val_accuracy: 0.5186\n",
      "Epoch 43/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5252 - val_loss: 0.6910 - val_accuracy: 0.5145\n",
      "Epoch 44/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5231 - val_loss: 0.6911 - val_accuracy: 0.5141\n",
      "Epoch 45/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5253 - val_loss: 0.6908 - val_accuracy: 0.5171\n",
      "Epoch 46/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5244 - val_loss: 0.6914 - val_accuracy: 0.5137\n",
      "Epoch 47/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6907 - accuracy: 0.5245 - val_loss: 0.6918 - val_accuracy: 0.5150\n",
      "Epoch 48/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5262 - val_loss: 0.6908 - val_accuracy: 0.5161\n",
      "Epoch 49/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6907 - accuracy: 0.5254 - val_loss: 0.6909 - val_accuracy: 0.5153\n",
      "Epoch 50/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6907 - accuracy: 0.5247 - val_loss: 0.6915 - val_accuracy: 0.5146\n",
      "Epoch 51/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5259 - val_loss: 0.6908 - val_accuracy: 0.5162\n",
      "Epoch 52/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5252 - val_loss: 0.6912 - val_accuracy: 0.5151\n",
      "Epoch 53/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6907 - accuracy: 0.5249 - val_loss: 0.6913 - val_accuracy: 0.5153\n",
      "Epoch 54/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5244 - val_loss: 0.6909 - val_accuracy: 0.5179\n",
      "Epoch 55/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6907 - accuracy: 0.5241 - val_loss: 0.6911 - val_accuracy: 0.5152\n",
      "Epoch 56/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5242 - val_loss: 0.6913 - val_accuracy: 0.5145\n",
      "Epoch 57/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5250 - val_loss: 0.6915 - val_accuracy: 0.5144\n",
      "Epoch 58/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5244 - val_loss: 0.6910 - val_accuracy: 0.5146\n",
      "Epoch 59/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5233 - val_loss: 0.6909 - val_accuracy: 0.5163\n",
      "Epoch 60/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5252 - val_loss: 0.6910 - val_accuracy: 0.5155\n",
      "Epoch 61/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5244 - val_loss: 0.6911 - val_accuracy: 0.5147\n",
      "Epoch 62/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5243 - val_loss: 0.6909 - val_accuracy: 0.5151\n",
      "Epoch 63/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6907 - accuracy: 0.5261 - val_loss: 0.6913 - val_accuracy: 0.5129\n",
      "Epoch 64/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5247 - val_loss: 0.6910 - val_accuracy: 0.5159\n",
      "Epoch 65/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5236 - val_loss: 0.6908 - val_accuracy: 0.5180\n",
      "Epoch 66/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5240 - val_loss: 0.6907 - val_accuracy: 0.5165\n",
      "Epoch 67/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5262 - val_loss: 0.6912 - val_accuracy: 0.5156\n",
      "Epoch 68/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5236 - val_loss: 0.6909 - val_accuracy: 0.5189\n",
      "Epoch 69/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5242 - val_loss: 0.6913 - val_accuracy: 0.5148\n",
      "Epoch 70/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5241 - val_loss: 0.6912 - val_accuracy: 0.5142\n",
      "Epoch 71/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6904 - accuracy: 0.5267 - val_loss: 0.6908 - val_accuracy: 0.5161\n",
      "Epoch 72/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5227 - val_loss: 0.6913 - val_accuracy: 0.5158\n",
      "Epoch 73/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5245 - val_loss: 0.6912 - val_accuracy: 0.5161\n",
      "Epoch 74/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5240 - val_loss: 0.6908 - val_accuracy: 0.5182\n",
      "Epoch 75/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6904 - accuracy: 0.5261 - val_loss: 0.6910 - val_accuracy: 0.5161\n",
      "Epoch 76/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5275 - val_loss: 0.6916 - val_accuracy: 0.5145\n",
      "Epoch 77/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5254 - val_loss: 0.6910 - val_accuracy: 0.5177\n",
      "Epoch 78/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5284 - val_loss: 0.6911 - val_accuracy: 0.5159\n",
      "Epoch 79/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5273 - val_loss: 0.6914 - val_accuracy: 0.5137\n",
      "Epoch 80/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5263 - val_loss: 0.6909 - val_accuracy: 0.5164\n",
      "Epoch 81/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5263 - val_loss: 0.6914 - val_accuracy: 0.5140\n",
      "Epoch 82/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5258 - val_loss: 0.6909 - val_accuracy: 0.5161\n",
      "Epoch 83/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5252 - val_loss: 0.6911 - val_accuracy: 0.5170\n",
      "Epoch 84/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6904 - accuracy: 0.5253 - val_loss: 0.6910 - val_accuracy: 0.5142\n",
      "Epoch 85/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5278 - val_loss: 0.6910 - val_accuracy: 0.5138\n",
      "Epoch 86/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5263 - val_loss: 0.6911 - val_accuracy: 0.5171\n",
      "Epoch 87/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5263 - val_loss: 0.6915 - val_accuracy: 0.5140\n",
      "Epoch 88/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5260 - val_loss: 0.6911 - val_accuracy: 0.5127\n",
      "Epoch 89/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6903 - accuracy: 0.5272 - val_loss: 0.6910 - val_accuracy: 0.5178\n",
      "Epoch 90/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6903 - accuracy: 0.5259 - val_loss: 0.6914 - val_accuracy: 0.5146\n",
      "Epoch 91/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5247 - val_loss: 0.6912 - val_accuracy: 0.5145\n",
      "Epoch 92/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6903 - accuracy: 0.5266 - val_loss: 0.6916 - val_accuracy: 0.5151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6903 - accuracy: 0.5252 - val_loss: 0.6909 - val_accuracy: 0.5159\n",
      "Epoch 94/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5265 - val_loss: 0.6909 - val_accuracy: 0.5182\n",
      "Epoch 95/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5281 - val_loss: 0.6907 - val_accuracy: 0.5232\n",
      "Epoch 96/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5256 - val_loss: 0.6908 - val_accuracy: 0.5176\n",
      "Epoch 97/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6903 - accuracy: 0.5255 - val_loss: 0.6911 - val_accuracy: 0.5166\n",
      "Epoch 98/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5273 - val_loss: 0.6908 - val_accuracy: 0.5171\n",
      "Epoch 99/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5247 - val_loss: 0.6909 - val_accuracy: 0.5182\n",
      "Epoch 100/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6904 - accuracy: 0.5267 - val_loss: 0.6909 - val_accuracy: 0.5168\n",
      "Epoch 101/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6904 - accuracy: 0.5257 - val_loss: 0.6910 - val_accuracy: 0.5169\n",
      "Epoch 102/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5261 - val_loss: 0.6908 - val_accuracy: 0.5191\n",
      "Epoch 103/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6903 - accuracy: 0.5282 - val_loss: 0.6909 - val_accuracy: 0.5178\n",
      "Epoch 104/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5266 - val_loss: 0.6909 - val_accuracy: 0.5192\n",
      "Epoch 105/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5275 - val_loss: 0.6916 - val_accuracy: 0.5136\n",
      "Epoch 106/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6903 - accuracy: 0.5277 - val_loss: 0.6910 - val_accuracy: 0.5172\n",
      "Epoch 107/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5279 - val_loss: 0.6909 - val_accuracy: 0.5176\n",
      "Epoch 108/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5277 - val_loss: 0.6908 - val_accuracy: 0.5182\n",
      "Epoch 109/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5246 - val_loss: 0.6908 - val_accuracy: 0.5185\n",
      "Epoch 110/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5255 - val_loss: 0.6910 - val_accuracy: 0.5152\n",
      "Epoch 111/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5276 - val_loss: 0.6914 - val_accuracy: 0.5157\n",
      "Epoch 112/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5265 - val_loss: 0.6910 - val_accuracy: 0.5188\n",
      "Epoch 113/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6903 - accuracy: 0.5266 - val_loss: 0.6908 - val_accuracy: 0.5178\n",
      "Epoch 114/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5272 - val_loss: 0.6912 - val_accuracy: 0.5150\n",
      "Epoch 115/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6902 - accuracy: 0.5278 - val_loss: 0.6908 - val_accuracy: 0.5188\n",
      "Epoch 116/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5257 - val_loss: 0.6910 - val_accuracy: 0.5162\n",
      "Epoch 117/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5260 - val_loss: 0.6910 - val_accuracy: 0.5174\n",
      "Epoch 118/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6903 - accuracy: 0.5265 - val_loss: 0.6911 - val_accuracy: 0.5143\n",
      "Epoch 119/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5274 - val_loss: 0.6910 - val_accuracy: 0.5149\n",
      "Epoch 120/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5287 - val_loss: 0.6910 - val_accuracy: 0.5158\n",
      "Epoch 121/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5283 - val_loss: 0.6910 - val_accuracy: 0.5167\n",
      "Epoch 122/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5264 - val_loss: 0.6910 - val_accuracy: 0.5166\n",
      "Epoch 123/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5274 - val_loss: 0.6907 - val_accuracy: 0.5184\n",
      "Epoch 124/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6902 - accuracy: 0.5256 - val_loss: 0.6912 - val_accuracy: 0.5133\n",
      "Epoch 125/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5280 - val_loss: 0.6910 - val_accuracy: 0.5200\n",
      "Epoch 126/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5290 - val_loss: 0.6913 - val_accuracy: 0.5156\n",
      "Epoch 127/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5274 - val_loss: 0.6910 - val_accuracy: 0.5175\n",
      "Epoch 128/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5272 - val_loss: 0.6909 - val_accuracy: 0.5182\n",
      "Epoch 129/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5290 - val_loss: 0.6911 - val_accuracy: 0.5140\n",
      "Epoch 130/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6900 - accuracy: 0.5272 - val_loss: 0.6909 - val_accuracy: 0.5172\n",
      "Epoch 131/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5271 - val_loss: 0.6910 - val_accuracy: 0.5173\n",
      "Epoch 132/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5278 - val_loss: 0.6916 - val_accuracy: 0.5137\n",
      "Epoch 133/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5263 - val_loss: 0.6919 - val_accuracy: 0.5142\n",
      "Epoch 134/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5276 - val_loss: 0.6909 - val_accuracy: 0.5195\n",
      "Epoch 135/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5275 - val_loss: 0.6910 - val_accuracy: 0.5149\n",
      "Epoch 136/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5271 - val_loss: 0.6907 - val_accuracy: 0.5183\n",
      "Epoch 137/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5269 - val_loss: 0.6907 - val_accuracy: 0.5172\n",
      "Epoch 138/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5269 - val_loss: 0.6908 - val_accuracy: 0.5182\n",
      "Epoch 139/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5271 - val_loss: 0.6910 - val_accuracy: 0.5173\n",
      "Epoch 140/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5274 - val_loss: 0.6916 - val_accuracy: 0.5153\n",
      "Epoch 141/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5287 - val_loss: 0.6910 - val_accuracy: 0.5181\n",
      "Epoch 142/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5281 - val_loss: 0.6910 - val_accuracy: 0.5168\n",
      "Epoch 143/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5270 - val_loss: 0.6911 - val_accuracy: 0.5172\n",
      "Epoch 144/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5290 - val_loss: 0.6908 - val_accuracy: 0.5187\n",
      "Epoch 145/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6901 - accuracy: 0.5276 - val_loss: 0.6910 - val_accuracy: 0.5159\n",
      "Epoch 146/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6901 - accuracy: 0.5274 - val_loss: 0.6916 - val_accuracy: 0.5116\n",
      "Epoch 147/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5279 - val_loss: 0.6916 - val_accuracy: 0.5126\n",
      "Epoch 148/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5270 - val_loss: 0.6911 - val_accuracy: 0.5193\n",
      "Epoch 149/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5277 - val_loss: 0.6912 - val_accuracy: 0.5184\n",
      "Epoch 150/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5284 - val_loss: 0.6910 - val_accuracy: 0.5168\n",
      "Epoch 151/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5294 - val_loss: 0.6909 - val_accuracy: 0.5198\n",
      "Epoch 152/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6899 - accuracy: 0.5288 - val_loss: 0.6910 - val_accuracy: 0.5177\n",
      "Epoch 153/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5266 - val_loss: 0.6913 - val_accuracy: 0.5177\n",
      "Training with significance = 6.28, run 3\n",
      "Train on 41862 samples, validate on 10466 samples\n",
      "Epoch 1/1000\n",
      "41862/41862 [==============================] - 1s 27us/sample - loss: 0.6933 - accuracy: 0.5001 - val_loss: 0.6943 - val_accuracy: 0.4987\n",
      "Epoch 2/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6920 - accuracy: 0.5100 - val_loss: 0.6925 - val_accuracy: 0.5178\n",
      "Epoch 3/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6917 - accuracy: 0.5122 - val_loss: 0.6919 - val_accuracy: 0.5211\n",
      "Epoch 4/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5120 - val_loss: 0.6914 - val_accuracy: 0.5254\n",
      "Epoch 5/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5145 - val_loss: 0.6913 - val_accuracy: 0.5257\n",
      "Epoch 6/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6914 - accuracy: 0.5153 - val_loss: 0.6912 - val_accuracy: 0.5248\n",
      "Epoch 7/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6913 - accuracy: 0.5127 - val_loss: 0.6912 - val_accuracy: 0.5245\n",
      "Epoch 8/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5161 - val_loss: 0.6914 - val_accuracy: 0.5257\n",
      "Epoch 9/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5160 - val_loss: 0.6913 - val_accuracy: 0.5253\n",
      "Epoch 10/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5176 - val_loss: 0.6912 - val_accuracy: 0.5233\n",
      "Epoch 11/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5158 - val_loss: 0.6912 - val_accuracy: 0.5234\n",
      "Epoch 12/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6910 - accuracy: 0.5175 - val_loss: 0.6911 - val_accuracy: 0.5239\n",
      "Epoch 13/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5160 - val_loss: 0.6911 - val_accuracy: 0.5223\n",
      "Epoch 14/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5166 - val_loss: 0.6911 - val_accuracy: 0.5242\n",
      "Epoch 15/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5155 - val_loss: 0.6911 - val_accuracy: 0.5253\n",
      "Epoch 16/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5166 - val_loss: 0.6912 - val_accuracy: 0.5237\n",
      "Epoch 17/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5170 - val_loss: 0.6911 - val_accuracy: 0.5231\n",
      "Epoch 18/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6908 - accuracy: 0.5175 - val_loss: 0.6912 - val_accuracy: 0.5240\n",
      "Epoch 19/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5163 - val_loss: 0.6911 - val_accuracy: 0.5238\n",
      "Epoch 20/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5169 - val_loss: 0.6911 - val_accuracy: 0.5245\n",
      "Epoch 21/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5177 - val_loss: 0.6913 - val_accuracy: 0.5246\n",
      "Epoch 22/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5181 - val_loss: 0.6910 - val_accuracy: 0.5247\n",
      "Epoch 23/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5192 - val_loss: 0.6912 - val_accuracy: 0.5256\n",
      "Epoch 24/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5187 - val_loss: 0.6911 - val_accuracy: 0.5231\n",
      "Epoch 25/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5172 - val_loss: 0.6910 - val_accuracy: 0.5259\n",
      "Epoch 26/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6907 - accuracy: 0.5194 - val_loss: 0.6912 - val_accuracy: 0.5247\n",
      "Epoch 27/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5178 - val_loss: 0.6911 - val_accuracy: 0.5250\n",
      "Epoch 28/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5183 - val_loss: 0.6911 - val_accuracy: 0.5224\n",
      "Epoch 29/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5196 - val_loss: 0.6914 - val_accuracy: 0.5214\n",
      "Epoch 30/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5211 - val_loss: 0.6911 - val_accuracy: 0.5249\n",
      "Epoch 31/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5192 - val_loss: 0.6912 - val_accuracy: 0.5253\n",
      "Epoch 32/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5181 - val_loss: 0.6911 - val_accuracy: 0.5253\n",
      "Epoch 33/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6904 - accuracy: 0.5202 - val_loss: 0.6911 - val_accuracy: 0.5249\n",
      "Epoch 34/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5212 - val_loss: 0.6913 - val_accuracy: 0.5225\n",
      "Epoch 35/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5196 - val_loss: 0.6912 - val_accuracy: 0.5237\n",
      "Epoch 36/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5193 - val_loss: 0.6911 - val_accuracy: 0.5247\n",
      "Epoch 37/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5204 - val_loss: 0.6914 - val_accuracy: 0.5188\n",
      "Epoch 38/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6904 - accuracy: 0.5213 - val_loss: 0.6913 - val_accuracy: 0.5242\n",
      "Epoch 39/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6904 - accuracy: 0.5204 - val_loss: 0.6913 - val_accuracy: 0.5218\n",
      "Epoch 40/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6904 - accuracy: 0.5214 - val_loss: 0.6912 - val_accuracy: 0.5245\n",
      "Epoch 41/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5212 - val_loss: 0.6912 - val_accuracy: 0.5236\n",
      "Epoch 42/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5210 - val_loss: 0.6913 - val_accuracy: 0.5253\n",
      "Epoch 43/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5198 - val_loss: 0.6912 - val_accuracy: 0.5244\n",
      "Epoch 44/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5211 - val_loss: 0.6912 - val_accuracy: 0.5247\n",
      "Epoch 45/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5205 - val_loss: 0.6912 - val_accuracy: 0.5240\n",
      "Epoch 46/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5197 - val_loss: 0.6912 - val_accuracy: 0.5232\n",
      "Epoch 47/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5190 - val_loss: 0.6912 - val_accuracy: 0.5235\n",
      "Epoch 48/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5211 - val_loss: 0.6912 - val_accuracy: 0.5244\n",
      "Epoch 49/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5217 - val_loss: 0.6915 - val_accuracy: 0.5204\n",
      "Epoch 50/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6903 - accuracy: 0.5182 - val_loss: 0.6912 - val_accuracy: 0.5246\n",
      "Epoch 51/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5206 - val_loss: 0.6914 - val_accuracy: 0.5230\n",
      "Epoch 52/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6904 - accuracy: 0.5212 - val_loss: 0.6912 - val_accuracy: 0.5228\n",
      "Epoch 53/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6902 - accuracy: 0.5215 - val_loss: 0.6913 - val_accuracy: 0.5240\n",
      "Epoch 54/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6902 - accuracy: 0.5212 - val_loss: 0.6913 - val_accuracy: 0.5249\n",
      "Epoch 55/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6904 - accuracy: 0.5206 - val_loss: 0.6913 - val_accuracy: 0.5220\n",
      "Training with significance = 6.28, run 4\n",
      "Train on 41862 samples, validate on 10466 samples\n",
      "Epoch 1/1000\n",
      "41862/41862 [==============================] - 1s 26us/sample - loss: 0.6928 - accuracy: 0.5106 - val_loss: 0.6958 - val_accuracy: 0.5074\n",
      "Epoch 2/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5163 - val_loss: 0.6918 - val_accuracy: 0.5217\n",
      "Epoch 3/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5168 - val_loss: 0.6913 - val_accuracy: 0.5234\n",
      "Epoch 4/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6912 - accuracy: 0.5181 - val_loss: 0.6908 - val_accuracy: 0.5221\n",
      "Epoch 5/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5180 - val_loss: 0.6905 - val_accuracy: 0.5247\n",
      "Epoch 6/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5197 - val_loss: 0.6903 - val_accuracy: 0.5241\n",
      "Epoch 7/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6910 - accuracy: 0.5191 - val_loss: 0.6906 - val_accuracy: 0.5212\n",
      "Epoch 8/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5186 - val_loss: 0.6906 - val_accuracy: 0.5216\n",
      "Epoch 9/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6909 - accuracy: 0.5198 - val_loss: 0.6904 - val_accuracy: 0.5225\n",
      "Epoch 10/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6909 - accuracy: 0.5193 - val_loss: 0.6904 - val_accuracy: 0.5247\n",
      "Epoch 11/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5199 - val_loss: 0.6904 - val_accuracy: 0.5231\n",
      "Epoch 12/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5214 - val_loss: 0.6903 - val_accuracy: 0.5253\n",
      "Epoch 13/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5215 - val_loss: 0.6906 - val_accuracy: 0.5237\n",
      "Epoch 14/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5209 - val_loss: 0.6903 - val_accuracy: 0.5229\n",
      "Epoch 15/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5215 - val_loss: 0.6904 - val_accuracy: 0.5227\n",
      "Epoch 16/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5210 - val_loss: 0.6903 - val_accuracy: 0.5200\n",
      "Epoch 17/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5223 - val_loss: 0.6906 - val_accuracy: 0.5240\n",
      "Epoch 18/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5206 - val_loss: 0.6904 - val_accuracy: 0.5228\n",
      "Epoch 19/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5218 - val_loss: 0.6903 - val_accuracy: 0.5215\n",
      "Epoch 20/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5225 - val_loss: 0.6905 - val_accuracy: 0.5269\n",
      "Epoch 21/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5214 - val_loss: 0.6904 - val_accuracy: 0.5227\n",
      "Epoch 22/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6904 - accuracy: 0.5214 - val_loss: 0.6903 - val_accuracy: 0.5257\n",
      "Epoch 23/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5217 - val_loss: 0.6904 - val_accuracy: 0.5209\n",
      "Epoch 24/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5233 - val_loss: 0.6906 - val_accuracy: 0.5247\n",
      "Epoch 25/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6903 - accuracy: 0.5231 - val_loss: 0.6906 - val_accuracy: 0.5236\n",
      "Epoch 26/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5223 - val_loss: 0.6905 - val_accuracy: 0.5225\n",
      "Epoch 27/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5206 - val_loss: 0.6905 - val_accuracy: 0.5256\n",
      "Epoch 28/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5237 - val_loss: 0.6905 - val_accuracy: 0.5251\n",
      "Epoch 29/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6904 - accuracy: 0.5235 - val_loss: 0.6906 - val_accuracy: 0.5240\n",
      "Epoch 30/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6902 - accuracy: 0.5232 - val_loss: 0.6904 - val_accuracy: 0.5257\n",
      "Epoch 31/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5233 - val_loss: 0.6904 - val_accuracy: 0.5255\n",
      "Epoch 32/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6902 - accuracy: 0.5237 - val_loss: 0.6905 - val_accuracy: 0.5239\n",
      "Epoch 33/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6901 - accuracy: 0.5216 - val_loss: 0.6905 - val_accuracy: 0.5249\n",
      "Epoch 34/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5247 - val_loss: 0.6905 - val_accuracy: 0.5240\n",
      "Epoch 35/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5234 - val_loss: 0.6904 - val_accuracy: 0.5230\n",
      "Epoch 36/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5237 - val_loss: 0.6907 - val_accuracy: 0.5230\n",
      "Training with significance = 6.28, run 5\n",
      "Train on 41862 samples, validate on 10466 samples\n",
      "Epoch 1/1000\n",
      "41862/41862 [==============================] - 1s 26us/sample - loss: 0.6929 - accuracy: 0.5077 - val_loss: 0.6931 - val_accuracy: 0.5128\n",
      "Epoch 2/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6917 - accuracy: 0.5145 - val_loss: 0.6916 - val_accuracy: 0.5177\n",
      "Epoch 3/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5179 - val_loss: 0.6912 - val_accuracy: 0.5186\n",
      "Epoch 4/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5189 - val_loss: 0.6908 - val_accuracy: 0.5228\n",
      "Epoch 5/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5209 - val_loss: 0.6908 - val_accuracy: 0.5236\n",
      "Epoch 6/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5193 - val_loss: 0.6905 - val_accuracy: 0.5234\n",
      "Epoch 7/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5196 - val_loss: 0.6908 - val_accuracy: 0.5219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5209 - val_loss: 0.6907 - val_accuracy: 0.5238\n",
      "Epoch 9/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6910 - accuracy: 0.5202 - val_loss: 0.6906 - val_accuracy: 0.5245\n",
      "Epoch 10/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6911 - accuracy: 0.5209 - val_loss: 0.6905 - val_accuracy: 0.5236\n",
      "Epoch 11/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5209 - val_loss: 0.6907 - val_accuracy: 0.5232\n",
      "Epoch 12/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6909 - accuracy: 0.5211 - val_loss: 0.6905 - val_accuracy: 0.5222\n",
      "Epoch 13/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5222 - val_loss: 0.6906 - val_accuracy: 0.5212\n",
      "Epoch 14/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5208 - val_loss: 0.6906 - val_accuracy: 0.5215\n",
      "Epoch 15/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6907 - accuracy: 0.5184 - val_loss: 0.6907 - val_accuracy: 0.5225\n",
      "Epoch 16/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5223 - val_loss: 0.6907 - val_accuracy: 0.5203\n",
      "Epoch 17/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5207 - val_loss: 0.6906 - val_accuracy: 0.5223\n",
      "Epoch 18/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5208 - val_loss: 0.6906 - val_accuracy: 0.5204\n",
      "Epoch 19/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5238 - val_loss: 0.6906 - val_accuracy: 0.5235\n",
      "Epoch 20/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5208 - val_loss: 0.6906 - val_accuracy: 0.5216\n",
      "Epoch 21/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5207 - val_loss: 0.6908 - val_accuracy: 0.5182\n",
      "Epoch 22/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5236 - val_loss: 0.6906 - val_accuracy: 0.5206\n",
      "Epoch 23/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5218 - val_loss: 0.6905 - val_accuracy: 0.5188\n",
      "Epoch 24/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5222 - val_loss: 0.6907 - val_accuracy: 0.5207\n",
      "Epoch 25/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5215 - val_loss: 0.6907 - val_accuracy: 0.5181\n",
      "Epoch 26/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5213 - val_loss: 0.6908 - val_accuracy: 0.5182\n",
      "Epoch 27/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5230 - val_loss: 0.6905 - val_accuracy: 0.5211\n",
      "Epoch 28/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5213 - val_loss: 0.6905 - val_accuracy: 0.5198\n",
      "Epoch 29/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5216 - val_loss: 0.6907 - val_accuracy: 0.5186\n",
      "Epoch 30/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5218 - val_loss: 0.6905 - val_accuracy: 0.5204\n",
      "Epoch 31/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5237 - val_loss: 0.6907 - val_accuracy: 0.5193\n",
      "Epoch 32/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6904 - accuracy: 0.5225 - val_loss: 0.6907 - val_accuracy: 0.5198\n",
      "Epoch 33/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5234 - val_loss: 0.6905 - val_accuracy: 0.5197\n",
      "Epoch 34/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6904 - accuracy: 0.5219 - val_loss: 0.6906 - val_accuracy: 0.5216\n",
      "Epoch 35/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6904 - accuracy: 0.5217 - val_loss: 0.6905 - val_accuracy: 0.5213\n",
      "Epoch 36/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6903 - accuracy: 0.5238 - val_loss: 0.6907 - val_accuracy: 0.5201\n",
      "Epoch 37/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6903 - accuracy: 0.5209 - val_loss: 0.6907 - val_accuracy: 0.5214\n",
      "Epoch 38/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5220 - val_loss: 0.6904 - val_accuracy: 0.5184\n",
      "Epoch 39/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5232 - val_loss: 0.6904 - val_accuracy: 0.5216\n",
      "Epoch 40/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5239 - val_loss: 0.6906 - val_accuracy: 0.5204\n",
      "Epoch 41/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5238 - val_loss: 0.6910 - val_accuracy: 0.5154\n",
      "Epoch 42/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5228 - val_loss: 0.6908 - val_accuracy: 0.5202\n",
      "Epoch 43/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6904 - accuracy: 0.5207 - val_loss: 0.6907 - val_accuracy: 0.5184\n",
      "Epoch 44/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5242 - val_loss: 0.6908 - val_accuracy: 0.5187\n",
      "Epoch 45/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5227 - val_loss: 0.6906 - val_accuracy: 0.5185\n",
      "Epoch 46/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5232 - val_loss: 0.6905 - val_accuracy: 0.5185\n",
      "Epoch 47/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5252 - val_loss: 0.6906 - val_accuracy: 0.5200\n",
      "Epoch 48/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6902 - accuracy: 0.5231 - val_loss: 0.6910 - val_accuracy: 0.5163\n",
      "Epoch 49/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5234 - val_loss: 0.6904 - val_accuracy: 0.5211\n",
      "Epoch 50/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6902 - accuracy: 0.5226 - val_loss: 0.6906 - val_accuracy: 0.5191\n",
      "Epoch 51/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5245 - val_loss: 0.6907 - val_accuracy: 0.5204\n",
      "Epoch 52/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6901 - accuracy: 0.5239 - val_loss: 0.6906 - val_accuracy: 0.5193\n",
      "Epoch 53/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5216 - val_loss: 0.6907 - val_accuracy: 0.5180\n",
      "Epoch 54/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6901 - accuracy: 0.5249 - val_loss: 0.6907 - val_accuracy: 0.5201\n",
      "Epoch 55/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6901 - accuracy: 0.5227 - val_loss: 0.6904 - val_accuracy: 0.5176\n",
      "Epoch 56/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5246 - val_loss: 0.6907 - val_accuracy: 0.5200\n",
      "Epoch 57/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5258 - val_loss: 0.6907 - val_accuracy: 0.5182\n",
      "Epoch 58/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6900 - accuracy: 0.5238 - val_loss: 0.6907 - val_accuracy: 0.5204\n",
      "Epoch 59/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5256 - val_loss: 0.6907 - val_accuracy: 0.5183\n",
      "Epoch 60/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6902 - accuracy: 0.5233 - val_loss: 0.6908 - val_accuracy: 0.5188\n",
      "Epoch 61/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6900 - accuracy: 0.5242 - val_loss: 0.6906 - val_accuracy: 0.5190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5239 - val_loss: 0.6907 - val_accuracy: 0.5193\n",
      "Epoch 63/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5235 - val_loss: 0.6907 - val_accuracy: 0.5202\n",
      "Epoch 64/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6899 - accuracy: 0.5237 - val_loss: 0.6906 - val_accuracy: 0.5207\n",
      "Epoch 65/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5229 - val_loss: 0.6907 - val_accuracy: 0.5190\n",
      "Epoch 66/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6900 - accuracy: 0.5253 - val_loss: 0.6908 - val_accuracy: 0.5173\n",
      "Epoch 67/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5249 - val_loss: 0.6908 - val_accuracy: 0.5185\n",
      "Epoch 68/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6900 - accuracy: 0.5248 - val_loss: 0.6906 - val_accuracy: 0.5197\n",
      "Epoch 69/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5244 - val_loss: 0.6908 - val_accuracy: 0.5165\n",
      "Training with significance = 6.28, run 6\n",
      "Train on 41862 samples, validate on 10466 samples\n",
      "Epoch 1/1000\n",
      "41862/41862 [==============================] - 1s 26us/sample - loss: 0.6929 - accuracy: 0.5089 - val_loss: 0.6954 - val_accuracy: 0.5044\n",
      "Epoch 2/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6917 - accuracy: 0.5168 - val_loss: 0.6929 - val_accuracy: 0.5128\n",
      "Epoch 3/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5176 - val_loss: 0.6923 - val_accuracy: 0.5112\n",
      "Epoch 4/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5198 - val_loss: 0.6914 - val_accuracy: 0.5177\n",
      "Epoch 5/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5189 - val_loss: 0.6913 - val_accuracy: 0.5161\n",
      "Epoch 6/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5206 - val_loss: 0.6913 - val_accuracy: 0.5183\n",
      "Epoch 7/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5193 - val_loss: 0.6909 - val_accuracy: 0.5209\n",
      "Epoch 8/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6909 - accuracy: 0.5203 - val_loss: 0.6910 - val_accuracy: 0.5186\n",
      "Epoch 9/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5207 - val_loss: 0.6908 - val_accuracy: 0.5188\n",
      "Epoch 10/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6909 - accuracy: 0.5219 - val_loss: 0.6908 - val_accuracy: 0.5145\n",
      "Epoch 11/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5211 - val_loss: 0.6907 - val_accuracy: 0.5156\n",
      "Epoch 12/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6908 - accuracy: 0.5205 - val_loss: 0.6909 - val_accuracy: 0.5166\n",
      "Epoch 13/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6908 - accuracy: 0.5200 - val_loss: 0.6908 - val_accuracy: 0.5163\n",
      "Epoch 14/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5219 - val_loss: 0.6907 - val_accuracy: 0.5156\n",
      "Epoch 15/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5194 - val_loss: 0.6908 - val_accuracy: 0.5137\n",
      "Epoch 16/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5221 - val_loss: 0.6908 - val_accuracy: 0.5192\n",
      "Epoch 17/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5206 - val_loss: 0.6913 - val_accuracy: 0.5138\n",
      "Epoch 18/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6907 - accuracy: 0.5209 - val_loss: 0.6906 - val_accuracy: 0.5174\n",
      "Epoch 19/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6907 - accuracy: 0.5212 - val_loss: 0.6907 - val_accuracy: 0.5162\n",
      "Epoch 20/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5218 - val_loss: 0.6907 - val_accuracy: 0.5176\n",
      "Epoch 21/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6907 - accuracy: 0.5201 - val_loss: 0.6910 - val_accuracy: 0.5167\n",
      "Epoch 22/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5222 - val_loss: 0.6912 - val_accuracy: 0.5111\n",
      "Epoch 23/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5226 - val_loss: 0.6907 - val_accuracy: 0.5163\n",
      "Epoch 24/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6907 - accuracy: 0.5226 - val_loss: 0.6911 - val_accuracy: 0.5109\n",
      "Epoch 25/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5215 - val_loss: 0.6908 - val_accuracy: 0.5184\n",
      "Epoch 26/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5237 - val_loss: 0.6908 - val_accuracy: 0.5116\n",
      "Epoch 27/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5225 - val_loss: 0.6907 - val_accuracy: 0.5174\n",
      "Epoch 28/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5221 - val_loss: 0.6908 - val_accuracy: 0.5158\n",
      "Epoch 29/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5239 - val_loss: 0.6907 - val_accuracy: 0.5163\n",
      "Epoch 30/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5224 - val_loss: 0.6911 - val_accuracy: 0.5127\n",
      "Epoch 31/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5204 - val_loss: 0.6909 - val_accuracy: 0.5121\n",
      "Epoch 32/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5217 - val_loss: 0.6910 - val_accuracy: 0.5117\n",
      "Epoch 33/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5224 - val_loss: 0.6908 - val_accuracy: 0.5167\n",
      "Epoch 34/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5222 - val_loss: 0.6908 - val_accuracy: 0.5143\n",
      "Epoch 35/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5226 - val_loss: 0.6909 - val_accuracy: 0.5173\n",
      "Epoch 36/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5226 - val_loss: 0.6907 - val_accuracy: 0.5167\n",
      "Epoch 37/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5222 - val_loss: 0.6909 - val_accuracy: 0.5134\n",
      "Epoch 38/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5199 - val_loss: 0.6907 - val_accuracy: 0.5166\n",
      "Epoch 39/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6903 - accuracy: 0.5236 - val_loss: 0.6908 - val_accuracy: 0.5142\n",
      "Epoch 40/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6904 - accuracy: 0.5227 - val_loss: 0.6911 - val_accuracy: 0.5130\n",
      "Epoch 41/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6904 - accuracy: 0.5226 - val_loss: 0.6910 - val_accuracy: 0.5115\n",
      "Epoch 42/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6904 - accuracy: 0.5230 - val_loss: 0.6908 - val_accuracy: 0.5165\n",
      "Epoch 43/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6903 - accuracy: 0.5224 - val_loss: 0.6907 - val_accuracy: 0.5169\n",
      "Epoch 44/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6904 - accuracy: 0.5236 - val_loss: 0.6907 - val_accuracy: 0.5166\n",
      "Epoch 45/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5242 - val_loss: 0.6907 - val_accuracy: 0.5162\n",
      "Epoch 46/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5242 - val_loss: 0.6911 - val_accuracy: 0.5127\n",
      "Epoch 47/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6903 - accuracy: 0.5250 - val_loss: 0.6907 - val_accuracy: 0.5164\n",
      "Epoch 48/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5235 - val_loss: 0.6913 - val_accuracy: 0.5123\n",
      "Training with significance = 6.28, run 7\n",
      "Train on 41862 samples, validate on 10466 samples\n",
      "Epoch 1/1000\n",
      "41862/41862 [==============================] - 1s 27us/sample - loss: 0.6928 - accuracy: 0.5097 - val_loss: 0.6923 - val_accuracy: 0.5060\n",
      "Epoch 2/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6920 - accuracy: 0.5143 - val_loss: 0.6911 - val_accuracy: 0.5177\n",
      "Epoch 3/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5150 - val_loss: 0.6906 - val_accuracy: 0.5254\n",
      "Epoch 4/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6915 - accuracy: 0.5170 - val_loss: 0.6903 - val_accuracy: 0.5197\n",
      "Epoch 5/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5179 - val_loss: 0.6902 - val_accuracy: 0.5188\n",
      "Epoch 6/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5191 - val_loss: 0.6902 - val_accuracy: 0.5164\n",
      "Epoch 7/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6913 - accuracy: 0.5178 - val_loss: 0.6902 - val_accuracy: 0.5164\n",
      "Epoch 8/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5170 - val_loss: 0.6901 - val_accuracy: 0.5164\n",
      "Epoch 9/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5186 - val_loss: 0.6902 - val_accuracy: 0.5174\n",
      "Epoch 10/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5188 - val_loss: 0.6901 - val_accuracy: 0.5120\n",
      "Epoch 11/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6910 - accuracy: 0.5191 - val_loss: 0.6903 - val_accuracy: 0.5172\n",
      "Epoch 12/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6909 - accuracy: 0.5192 - val_loss: 0.6903 - val_accuracy: 0.5178\n",
      "Epoch 13/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5199 - val_loss: 0.6902 - val_accuracy: 0.5182\n",
      "Epoch 14/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6908 - accuracy: 0.5203 - val_loss: 0.6902 - val_accuracy: 0.5178\n",
      "Epoch 15/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5200 - val_loss: 0.6903 - val_accuracy: 0.5177\n",
      "Epoch 16/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5189 - val_loss: 0.6902 - val_accuracy: 0.5182\n",
      "Epoch 17/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5204 - val_loss: 0.6901 - val_accuracy: 0.5171\n",
      "Epoch 18/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5194 - val_loss: 0.6903 - val_accuracy: 0.5174\n",
      "Epoch 19/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5203 - val_loss: 0.6900 - val_accuracy: 0.5173\n",
      "Epoch 20/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5205 - val_loss: 0.6900 - val_accuracy: 0.5172\n",
      "Epoch 21/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5193 - val_loss: 0.6900 - val_accuracy: 0.5186\n",
      "Epoch 22/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5217 - val_loss: 0.6900 - val_accuracy: 0.5161\n",
      "Epoch 23/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5221 - val_loss: 0.6902 - val_accuracy: 0.5169\n",
      "Epoch 24/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5208 - val_loss: 0.6902 - val_accuracy: 0.5166\n",
      "Epoch 25/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5215 - val_loss: 0.6901 - val_accuracy: 0.5166\n",
      "Epoch 26/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5207 - val_loss: 0.6902 - val_accuracy: 0.5161\n",
      "Epoch 27/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5205 - val_loss: 0.6901 - val_accuracy: 0.5191\n",
      "Epoch 28/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5214 - val_loss: 0.6902 - val_accuracy: 0.5177\n",
      "Epoch 29/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5210 - val_loss: 0.6901 - val_accuracy: 0.5182\n",
      "Epoch 30/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5202 - val_loss: 0.6902 - val_accuracy: 0.5169\n",
      "Epoch 31/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5208 - val_loss: 0.6901 - val_accuracy: 0.5163\n",
      "Epoch 32/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5201 - val_loss: 0.6901 - val_accuracy: 0.5174\n",
      "Epoch 33/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5231 - val_loss: 0.6901 - val_accuracy: 0.5169\n",
      "Epoch 34/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5217 - val_loss: 0.6901 - val_accuracy: 0.5168\n",
      "Epoch 35/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5227 - val_loss: 0.6902 - val_accuracy: 0.5169\n",
      "Epoch 36/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5215 - val_loss: 0.6900 - val_accuracy: 0.5182\n",
      "Epoch 37/1000\n",
      "41862/41862 [==============================] - 0s 12us/sample - loss: 0.6905 - accuracy: 0.5219 - val_loss: 0.6900 - val_accuracy: 0.5168\n",
      "Epoch 38/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5212 - val_loss: 0.6902 - val_accuracy: 0.5156\n",
      "Epoch 39/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5223 - val_loss: 0.6903 - val_accuracy: 0.5167\n",
      "Epoch 40/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5217 - val_loss: 0.6900 - val_accuracy: 0.5170\n",
      "Epoch 41/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5221 - val_loss: 0.6902 - val_accuracy: 0.5182\n",
      "Epoch 42/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5211 - val_loss: 0.6901 - val_accuracy: 0.5158\n",
      "Epoch 43/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5228 - val_loss: 0.6904 - val_accuracy: 0.5175\n",
      "Epoch 44/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5224 - val_loss: 0.6901 - val_accuracy: 0.5182\n",
      "Epoch 45/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5239 - val_loss: 0.6902 - val_accuracy: 0.5153\n",
      "Epoch 46/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5203 - val_loss: 0.6902 - val_accuracy: 0.5161\n",
      "Epoch 47/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5228 - val_loss: 0.6901 - val_accuracy: 0.5174\n",
      "Epoch 48/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5227 - val_loss: 0.6902 - val_accuracy: 0.5182\n",
      "Epoch 49/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5213 - val_loss: 0.6901 - val_accuracy: 0.5169\n",
      "Training with significance = 6.28, run 8\n",
      "Train on 41862 samples, validate on 10466 samples\n",
      "Epoch 1/1000\n",
      "41862/41862 [==============================] - 1s 26us/sample - loss: 0.6918 - accuracy: 0.5156 - val_loss: 0.6980 - val_accuracy: 0.4941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6915 - accuracy: 0.5186 - val_loss: 0.6925 - val_accuracy: 0.5141\n",
      "Epoch 3/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5174 - val_loss: 0.6915 - val_accuracy: 0.5231\n",
      "Epoch 4/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6913 - accuracy: 0.5180 - val_loss: 0.6907 - val_accuracy: 0.5283\n",
      "Epoch 5/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6912 - accuracy: 0.5162 - val_loss: 0.6907 - val_accuracy: 0.5265\n",
      "Epoch 6/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5183 - val_loss: 0.6904 - val_accuracy: 0.5287\n",
      "Epoch 7/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5169 - val_loss: 0.6903 - val_accuracy: 0.5307\n",
      "Epoch 8/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5169 - val_loss: 0.6906 - val_accuracy: 0.5285\n",
      "Epoch 9/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5173 - val_loss: 0.6908 - val_accuracy: 0.5263\n",
      "Epoch 10/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5177 - val_loss: 0.6906 - val_accuracy: 0.5270\n",
      "Epoch 11/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5174 - val_loss: 0.6904 - val_accuracy: 0.5270\n",
      "Epoch 12/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6908 - accuracy: 0.5198 - val_loss: 0.6904 - val_accuracy: 0.5281\n",
      "Epoch 13/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5171 - val_loss: 0.6903 - val_accuracy: 0.5272\n",
      "Epoch 14/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6908 - accuracy: 0.5176 - val_loss: 0.6904 - val_accuracy: 0.5280\n",
      "Epoch 15/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6907 - accuracy: 0.5176 - val_loss: 0.6906 - val_accuracy: 0.5257\n",
      "Epoch 16/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5202 - val_loss: 0.6908 - val_accuracy: 0.5233\n",
      "Epoch 17/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5187 - val_loss: 0.6901 - val_accuracy: 0.5305\n",
      "Epoch 18/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5191 - val_loss: 0.6904 - val_accuracy: 0.5271\n",
      "Epoch 19/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5168 - val_loss: 0.6902 - val_accuracy: 0.5303\n",
      "Epoch 20/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6907 - accuracy: 0.5192 - val_loss: 0.6903 - val_accuracy: 0.5260\n",
      "Epoch 21/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5196 - val_loss: 0.6903 - val_accuracy: 0.5297\n",
      "Epoch 22/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6907 - accuracy: 0.5172 - val_loss: 0.6902 - val_accuracy: 0.5289\n",
      "Epoch 23/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5188 - val_loss: 0.6903 - val_accuracy: 0.5290\n",
      "Epoch 24/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5199 - val_loss: 0.6903 - val_accuracy: 0.5274\n",
      "Epoch 25/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5195 - val_loss: 0.6906 - val_accuracy: 0.5222\n",
      "Epoch 26/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5217 - val_loss: 0.6903 - val_accuracy: 0.5294\n",
      "Epoch 27/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5189 - val_loss: 0.6901 - val_accuracy: 0.5290\n",
      "Epoch 28/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5191 - val_loss: 0.6901 - val_accuracy: 0.5294\n",
      "Epoch 29/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6904 - accuracy: 0.5209 - val_loss: 0.6902 - val_accuracy: 0.5286\n",
      "Epoch 30/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5204 - val_loss: 0.6906 - val_accuracy: 0.5253\n",
      "Epoch 31/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5200 - val_loss: 0.6902 - val_accuracy: 0.5313\n",
      "Epoch 32/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5206 - val_loss: 0.6907 - val_accuracy: 0.5257\n",
      "Epoch 33/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5212 - val_loss: 0.6903 - val_accuracy: 0.5284\n",
      "Epoch 34/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5210 - val_loss: 0.6901 - val_accuracy: 0.5284\n",
      "Epoch 35/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5193 - val_loss: 0.6903 - val_accuracy: 0.5275\n",
      "Epoch 36/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6904 - accuracy: 0.5200 - val_loss: 0.6902 - val_accuracy: 0.5299\n",
      "Epoch 37/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6904 - accuracy: 0.5209 - val_loss: 0.6903 - val_accuracy: 0.5269\n",
      "Epoch 38/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5199 - val_loss: 0.6901 - val_accuracy: 0.5304\n",
      "Epoch 39/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6904 - accuracy: 0.5207 - val_loss: 0.6902 - val_accuracy: 0.5281\n",
      "Epoch 40/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5207 - val_loss: 0.6904 - val_accuracy: 0.5246\n",
      "Epoch 41/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5197 - val_loss: 0.6903 - val_accuracy: 0.5291\n",
      "Epoch 42/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6903 - accuracy: 0.5224 - val_loss: 0.6903 - val_accuracy: 0.5255\n",
      "Epoch 43/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6904 - accuracy: 0.5194 - val_loss: 0.6906 - val_accuracy: 0.5233\n",
      "Epoch 44/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5202 - val_loss: 0.6902 - val_accuracy: 0.5274\n",
      "Epoch 45/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5217 - val_loss: 0.6903 - val_accuracy: 0.5247\n",
      "Epoch 46/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5211 - val_loss: 0.6903 - val_accuracy: 0.5276\n",
      "Epoch 47/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5203 - val_loss: 0.6905 - val_accuracy: 0.5225\n",
      "Training with significance = 6.28, run 9\n",
      "Train on 41862 samples, validate on 10466 samples\n",
      "Epoch 1/1000\n",
      "41862/41862 [==============================] - 1s 26us/sample - loss: 0.6923 - accuracy: 0.5162 - val_loss: 0.6961 - val_accuracy: 0.5017\n",
      "Epoch 2/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5171 - val_loss: 0.6929 - val_accuracy: 0.5081\n",
      "Epoch 3/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5205 - val_loss: 0.6924 - val_accuracy: 0.5129\n",
      "Epoch 4/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5206 - val_loss: 0.6920 - val_accuracy: 0.5134\n",
      "Epoch 5/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5205 - val_loss: 0.6920 - val_accuracy: 0.5124\n",
      "Epoch 6/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5211 - val_loss: 0.6919 - val_accuracy: 0.5132\n",
      "Epoch 7/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6911 - accuracy: 0.5211 - val_loss: 0.6919 - val_accuracy: 0.5138\n",
      "Epoch 8/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5198 - val_loss: 0.6919 - val_accuracy: 0.5139\n",
      "Epoch 9/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6910 - accuracy: 0.5208 - val_loss: 0.6919 - val_accuracy: 0.5143\n",
      "Epoch 10/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5206 - val_loss: 0.6920 - val_accuracy: 0.5130\n",
      "Epoch 11/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5209 - val_loss: 0.6920 - val_accuracy: 0.5147\n",
      "Epoch 12/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5209 - val_loss: 0.6920 - val_accuracy: 0.5131\n",
      "Epoch 13/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6907 - accuracy: 0.5217 - val_loss: 0.6922 - val_accuracy: 0.5125\n",
      "Epoch 14/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6908 - accuracy: 0.5218 - val_loss: 0.6920 - val_accuracy: 0.5124\n",
      "Epoch 15/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6907 - accuracy: 0.5205 - val_loss: 0.6922 - val_accuracy: 0.5141\n",
      "Epoch 16/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6907 - accuracy: 0.5223 - val_loss: 0.6921 - val_accuracy: 0.5142\n",
      "Epoch 17/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5213 - val_loss: 0.6922 - val_accuracy: 0.5138\n",
      "Epoch 18/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5204 - val_loss: 0.6922 - val_accuracy: 0.5142\n",
      "Epoch 19/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6907 - accuracy: 0.5232 - val_loss: 0.6921 - val_accuracy: 0.5131\n",
      "Epoch 20/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5234 - val_loss: 0.6920 - val_accuracy: 0.5139\n",
      "Epoch 21/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5224 - val_loss: 0.6921 - val_accuracy: 0.5115\n",
      "Epoch 22/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5219 - val_loss: 0.6921 - val_accuracy: 0.5158\n",
      "Epoch 23/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5224 - val_loss: 0.6922 - val_accuracy: 0.5071\n",
      "Epoch 24/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5218 - val_loss: 0.6921 - val_accuracy: 0.5142\n",
      "Epoch 25/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5233 - val_loss: 0.6922 - val_accuracy: 0.5159\n",
      "Epoch 26/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5231 - val_loss: 0.6921 - val_accuracy: 0.5147\n",
      "Epoch 27/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5241 - val_loss: 0.6922 - val_accuracy: 0.5148\n",
      "Epoch 28/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6904 - accuracy: 0.5230 - val_loss: 0.6924 - val_accuracy: 0.5148\n",
      "Epoch 29/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5221 - val_loss: 0.6922 - val_accuracy: 0.5145\n",
      "Epoch 30/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5240 - val_loss: 0.6924 - val_accuracy: 0.5120\n",
      "Epoch 31/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6904 - accuracy: 0.5220 - val_loss: 0.6923 - val_accuracy: 0.5155\n",
      "Epoch 32/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6904 - accuracy: 0.5231 - val_loss: 0.6922 - val_accuracy: 0.5155\n",
      "Epoch 33/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5214 - val_loss: 0.6922 - val_accuracy: 0.5154\n",
      "Epoch 34/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6903 - accuracy: 0.5225 - val_loss: 0.6922 - val_accuracy: 0.5153\n",
      "Epoch 35/1000\n",
      "41862/41862 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5224 - val_loss: 0.6923 - val_accuracy: 0.5122\n",
      "Epoch 36/1000\n",
      "41862/41862 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5234 - val_loss: 0.6924 - val_accuracy: 0.5130\n",
      "Training with significance = 6.91, run 0\n",
      "Train on 41963 samples, validate on 10491 samples\n",
      "Epoch 1/1000\n",
      "41963/41963 [==============================] - 1s 27us/sample - loss: 0.6922 - accuracy: 0.5146 - val_loss: 0.6934 - val_accuracy: 0.5062\n",
      "Epoch 2/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5168 - val_loss: 0.6926 - val_accuracy: 0.5172\n",
      "Epoch 3/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6915 - accuracy: 0.5162 - val_loss: 0.6917 - val_accuracy: 0.5152\n",
      "Epoch 4/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6913 - accuracy: 0.5192 - val_loss: 0.6920 - val_accuracy: 0.5126\n",
      "Epoch 5/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5160 - val_loss: 0.6916 - val_accuracy: 0.5190\n",
      "Epoch 6/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5175 - val_loss: 0.6915 - val_accuracy: 0.5178\n",
      "Epoch 7/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5179 - val_loss: 0.6914 - val_accuracy: 0.5217\n",
      "Epoch 8/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6910 - accuracy: 0.5175 - val_loss: 0.6914 - val_accuracy: 0.5167\n",
      "Epoch 9/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5194 - val_loss: 0.6914 - val_accuracy: 0.5212\n",
      "Epoch 10/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5182 - val_loss: 0.6913 - val_accuracy: 0.5193\n",
      "Epoch 11/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6909 - accuracy: 0.5202 - val_loss: 0.6914 - val_accuracy: 0.5168\n",
      "Epoch 12/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6908 - accuracy: 0.5208 - val_loss: 0.6914 - val_accuracy: 0.5122\n",
      "Epoch 13/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6908 - accuracy: 0.5175 - val_loss: 0.6913 - val_accuracy: 0.5177\n",
      "Epoch 14/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6907 - accuracy: 0.5215 - val_loss: 0.6913 - val_accuracy: 0.5174\n",
      "Epoch 15/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6907 - accuracy: 0.5193 - val_loss: 0.6914 - val_accuracy: 0.5108\n",
      "Epoch 16/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6908 - accuracy: 0.5206 - val_loss: 0.6912 - val_accuracy: 0.5212\n",
      "Epoch 17/1000\n",
      "41963/41963 [==============================] - 0s 12us/sample - loss: 0.6907 - accuracy: 0.5176 - val_loss: 0.6913 - val_accuracy: 0.5180\n",
      "Epoch 18/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5205 - val_loss: 0.6913 - val_accuracy: 0.5203\n",
      "Epoch 19/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5201 - val_loss: 0.6912 - val_accuracy: 0.5204\n",
      "Epoch 20/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5220 - val_loss: 0.6913 - val_accuracy: 0.5158\n",
      "Epoch 21/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5215 - val_loss: 0.6913 - val_accuracy: 0.5206\n",
      "Epoch 22/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6904 - accuracy: 0.5199 - val_loss: 0.6917 - val_accuracy: 0.5152\n",
      "Epoch 23/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5202 - val_loss: 0.6912 - val_accuracy: 0.5201\n",
      "Epoch 24/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5206 - val_loss: 0.6913 - val_accuracy: 0.5192\n",
      "Epoch 25/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5203 - val_loss: 0.6911 - val_accuracy: 0.5202\n",
      "Epoch 26/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5223 - val_loss: 0.6912 - val_accuracy: 0.5203\n",
      "Epoch 27/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6904 - accuracy: 0.5222 - val_loss: 0.6912 - val_accuracy: 0.5194\n",
      "Epoch 28/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6904 - accuracy: 0.5210 - val_loss: 0.6911 - val_accuracy: 0.5200\n",
      "Epoch 29/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6904 - accuracy: 0.5209 - val_loss: 0.6911 - val_accuracy: 0.5224\n",
      "Epoch 30/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5221 - val_loss: 0.6912 - val_accuracy: 0.5181\n",
      "Epoch 31/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5222 - val_loss: 0.6913 - val_accuracy: 0.5141\n",
      "Epoch 32/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5210 - val_loss: 0.6911 - val_accuracy: 0.5209\n",
      "Epoch 33/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5222 - val_loss: 0.6912 - val_accuracy: 0.5187\n",
      "Epoch 34/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6902 - accuracy: 0.5222 - val_loss: 0.6913 - val_accuracy: 0.5150\n",
      "Epoch 35/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5222 - val_loss: 0.6912 - val_accuracy: 0.5203\n",
      "Epoch 36/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6903 - accuracy: 0.5213 - val_loss: 0.6914 - val_accuracy: 0.5158\n",
      "Epoch 37/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5225 - val_loss: 0.6912 - val_accuracy: 0.5191\n",
      "Epoch 38/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5234 - val_loss: 0.6913 - val_accuracy: 0.5195\n",
      "Epoch 39/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5226 - val_loss: 0.6912 - val_accuracy: 0.5164\n",
      "Epoch 40/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5214 - val_loss: 0.6912 - val_accuracy: 0.5179\n",
      "Epoch 41/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5223 - val_loss: 0.6912 - val_accuracy: 0.5202\n",
      "Epoch 42/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5220 - val_loss: 0.6913 - val_accuracy: 0.5125\n",
      "Epoch 43/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5234 - val_loss: 0.6912 - val_accuracy: 0.5152\n",
      "Epoch 44/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6901 - accuracy: 0.5234 - val_loss: 0.6912 - val_accuracy: 0.5195\n",
      "Epoch 45/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6901 - accuracy: 0.5234 - val_loss: 0.6912 - val_accuracy: 0.5191\n",
      "Epoch 46/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6900 - accuracy: 0.5227 - val_loss: 0.6912 - val_accuracy: 0.5194\n",
      "Epoch 47/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5222 - val_loss: 0.6913 - val_accuracy: 0.5142\n",
      "Epoch 48/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5235 - val_loss: 0.6913 - val_accuracy: 0.5203\n",
      "Epoch 49/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6903 - accuracy: 0.5208 - val_loss: 0.6912 - val_accuracy: 0.5193\n",
      "Epoch 50/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5223 - val_loss: 0.6912 - val_accuracy: 0.5203\n",
      "Epoch 51/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5228 - val_loss: 0.6913 - val_accuracy: 0.5148\n",
      "Epoch 52/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5222 - val_loss: 0.6912 - val_accuracy: 0.5170\n",
      "Epoch 53/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6900 - accuracy: 0.5226 - val_loss: 0.6913 - val_accuracy: 0.5201\n",
      "Epoch 54/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5229 - val_loss: 0.6912 - val_accuracy: 0.5168\n",
      "Epoch 55/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5242 - val_loss: 0.6913 - val_accuracy: 0.5100\n",
      "Epoch 56/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6900 - accuracy: 0.5258 - val_loss: 0.6912 - val_accuracy: 0.5189\n",
      "Epoch 57/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6899 - accuracy: 0.5218 - val_loss: 0.6915 - val_accuracy: 0.5117\n",
      "Epoch 58/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6899 - accuracy: 0.5220 - val_loss: 0.6912 - val_accuracy: 0.5171\n",
      "Training with significance = 6.91, run 1\n",
      "Train on 41963 samples, validate on 10491 samples\n",
      "Epoch 1/1000\n",
      "41963/41963 [==============================] - 1s 26us/sample - loss: 0.6939 - accuracy: 0.5038 - val_loss: 0.6951 - val_accuracy: 0.5021\n",
      "Epoch 2/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6916 - accuracy: 0.5166 - val_loss: 0.6924 - val_accuracy: 0.5116\n",
      "Epoch 3/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6913 - accuracy: 0.5188 - val_loss: 0.6910 - val_accuracy: 0.5213\n",
      "Epoch 4/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6911 - accuracy: 0.5201 - val_loss: 0.6908 - val_accuracy: 0.5216\n",
      "Epoch 5/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6909 - accuracy: 0.5187 - val_loss: 0.6906 - val_accuracy: 0.5225\n",
      "Epoch 6/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6909 - accuracy: 0.5198 - val_loss: 0.6906 - val_accuracy: 0.5197\n",
      "Epoch 7/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6908 - accuracy: 0.5204 - val_loss: 0.6905 - val_accuracy: 0.5203\n",
      "Epoch 8/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5206 - val_loss: 0.6908 - val_accuracy: 0.5152\n",
      "Epoch 9/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5197 - val_loss: 0.6904 - val_accuracy: 0.5192\n",
      "Epoch 10/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5220 - val_loss: 0.6903 - val_accuracy: 0.5224\n",
      "Epoch 11/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5206 - val_loss: 0.6904 - val_accuracy: 0.5204\n",
      "Epoch 12/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5208 - val_loss: 0.6904 - val_accuracy: 0.5182\n",
      "Epoch 13/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5211 - val_loss: 0.6903 - val_accuracy: 0.5225\n",
      "Epoch 14/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5215 - val_loss: 0.6903 - val_accuracy: 0.5194\n",
      "Epoch 15/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5209 - val_loss: 0.6902 - val_accuracy: 0.5206\n",
      "Epoch 16/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5217 - val_loss: 0.6902 - val_accuracy: 0.5220\n",
      "Epoch 17/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6904 - accuracy: 0.5241 - val_loss: 0.6903 - val_accuracy: 0.5218\n",
      "Epoch 18/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6903 - accuracy: 0.5216 - val_loss: 0.6902 - val_accuracy: 0.5215\n",
      "Epoch 19/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6904 - accuracy: 0.5216 - val_loss: 0.6903 - val_accuracy: 0.5246\n",
      "Epoch 20/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5238 - val_loss: 0.6904 - val_accuracy: 0.5215\n",
      "Epoch 21/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5228 - val_loss: 0.6903 - val_accuracy: 0.5222\n",
      "Epoch 22/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6904 - accuracy: 0.5242 - val_loss: 0.6903 - val_accuracy: 0.5232\n",
      "Epoch 23/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5221 - val_loss: 0.6904 - val_accuracy: 0.5181\n",
      "Epoch 24/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5241 - val_loss: 0.6903 - val_accuracy: 0.5222\n",
      "Epoch 25/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5232 - val_loss: 0.6903 - val_accuracy: 0.5204\n",
      "Epoch 26/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5239 - val_loss: 0.6903 - val_accuracy: 0.5212\n",
      "Epoch 27/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6903 - accuracy: 0.5236 - val_loss: 0.6904 - val_accuracy: 0.5204\n",
      "Epoch 28/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5238 - val_loss: 0.6904 - val_accuracy: 0.5196\n",
      "Epoch 29/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5265 - val_loss: 0.6903 - val_accuracy: 0.5194\n",
      "Epoch 30/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5237 - val_loss: 0.6903 - val_accuracy: 0.5201\n",
      "Epoch 31/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5250 - val_loss: 0.6904 - val_accuracy: 0.5229\n",
      "Epoch 32/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6902 - accuracy: 0.5219 - val_loss: 0.6903 - val_accuracy: 0.5238\n",
      "Epoch 33/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5243 - val_loss: 0.6906 - val_accuracy: 0.5191\n",
      "Epoch 34/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6901 - accuracy: 0.5242 - val_loss: 0.6903 - val_accuracy: 0.5204\n",
      "Epoch 35/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6901 - accuracy: 0.5247 - val_loss: 0.6903 - val_accuracy: 0.5236\n",
      "Epoch 36/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6901 - accuracy: 0.5237 - val_loss: 0.6902 - val_accuracy: 0.5221\n",
      "Epoch 37/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5233 - val_loss: 0.6903 - val_accuracy: 0.5239\n",
      "Epoch 38/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5246 - val_loss: 0.6902 - val_accuracy: 0.5190\n",
      "Epoch 39/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5236 - val_loss: 0.6904 - val_accuracy: 0.5199\n",
      "Epoch 40/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6902 - accuracy: 0.5241 - val_loss: 0.6904 - val_accuracy: 0.5201\n",
      "Epoch 41/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5220 - val_loss: 0.6904 - val_accuracy: 0.5229\n",
      "Epoch 42/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6902 - accuracy: 0.5246 - val_loss: 0.6903 - val_accuracy: 0.5185\n",
      "Epoch 43/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5236 - val_loss: 0.6904 - val_accuracy: 0.5196\n",
      "Epoch 44/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5259 - val_loss: 0.6902 - val_accuracy: 0.5238\n",
      "Epoch 45/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6900 - accuracy: 0.5241 - val_loss: 0.6903 - val_accuracy: 0.5216\n",
      "Epoch 46/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5248 - val_loss: 0.6902 - val_accuracy: 0.5218\n",
      "Epoch 47/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5233 - val_loss: 0.6903 - val_accuracy: 0.5226\n",
      "Epoch 48/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5263 - val_loss: 0.6904 - val_accuracy: 0.5224\n",
      "Epoch 49/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5242 - val_loss: 0.6904 - val_accuracy: 0.5186\n",
      "Epoch 50/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6899 - accuracy: 0.5272 - val_loss: 0.6903 - val_accuracy: 0.5236\n",
      "Epoch 51/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6900 - accuracy: 0.5227 - val_loss: 0.6903 - val_accuracy: 0.5194\n",
      "Epoch 52/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6898 - accuracy: 0.5237 - val_loss: 0.6903 - val_accuracy: 0.5223\n",
      "Epoch 53/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6900 - accuracy: 0.5223 - val_loss: 0.6903 - val_accuracy: 0.5183\n",
      "Epoch 54/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5237 - val_loss: 0.6902 - val_accuracy: 0.5210\n",
      "Epoch 55/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6899 - accuracy: 0.5252 - val_loss: 0.6906 - val_accuracy: 0.5109\n",
      "Epoch 56/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6899 - accuracy: 0.5249 - val_loss: 0.6902 - val_accuracy: 0.5196\n",
      "Epoch 57/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6898 - accuracy: 0.5246 - val_loss: 0.6902 - val_accuracy: 0.5195\n",
      "Epoch 58/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5257 - val_loss: 0.6903 - val_accuracy: 0.5191\n",
      "Epoch 59/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6899 - accuracy: 0.5253 - val_loss: 0.6903 - val_accuracy: 0.5197\n",
      "Epoch 60/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5243 - val_loss: 0.6903 - val_accuracy: 0.5189\n",
      "Epoch 61/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5238 - val_loss: 0.6903 - val_accuracy: 0.5192\n",
      "Epoch 62/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6900 - accuracy: 0.5236 - val_loss: 0.6905 - val_accuracy: 0.5147\n",
      "Epoch 63/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6897 - accuracy: 0.5266 - val_loss: 0.6903 - val_accuracy: 0.5189\n",
      "Epoch 64/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6898 - accuracy: 0.5254 - val_loss: 0.6903 - val_accuracy: 0.5180\n",
      "Epoch 65/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6898 - accuracy: 0.5247 - val_loss: 0.6903 - val_accuracy: 0.5197\n",
      "Epoch 66/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6898 - accuracy: 0.5260 - val_loss: 0.6902 - val_accuracy: 0.5183\n",
      "Epoch 67/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6898 - accuracy: 0.5254 - val_loss: 0.6902 - val_accuracy: 0.5244\n",
      "Epoch 68/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6898 - accuracy: 0.5254 - val_loss: 0.6902 - val_accuracy: 0.5212\n",
      "Epoch 69/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6897 - accuracy: 0.5265 - val_loss: 0.6903 - val_accuracy: 0.5178\n",
      "Epoch 70/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6898 - accuracy: 0.5256 - val_loss: 0.6902 - val_accuracy: 0.5213\n",
      "Epoch 71/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6897 - accuracy: 0.5257 - val_loss: 0.6902 - val_accuracy: 0.5217\n",
      "Epoch 72/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6897 - accuracy: 0.5272 - val_loss: 0.6902 - val_accuracy: 0.5251\n",
      "Epoch 73/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6897 - accuracy: 0.5240 - val_loss: 0.6904 - val_accuracy: 0.5252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6896 - accuracy: 0.5240 - val_loss: 0.6904 - val_accuracy: 0.5228\n",
      "Epoch 75/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6897 - accuracy: 0.5257 - val_loss: 0.6903 - val_accuracy: 0.5196\n",
      "Epoch 76/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6897 - accuracy: 0.5268 - val_loss: 0.6903 - val_accuracy: 0.5204\n",
      "Training with significance = 6.91, run 2\n",
      "Train on 41963 samples, validate on 10491 samples\n",
      "Epoch 1/1000\n",
      "41963/41963 [==============================] - 3s 67us/sample - loss: 0.6927 - accuracy: 0.5068 - val_loss: 0.6934 - val_accuracy: 0.5059\n",
      "Epoch 2/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5169 - val_loss: 0.6918 - val_accuracy: 0.5201\n",
      "Epoch 3/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5189 - val_loss: 0.6915 - val_accuracy: 0.5201\n",
      "Epoch 4/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5191 - val_loss: 0.6914 - val_accuracy: 0.5113\n",
      "Epoch 5/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5189 - val_loss: 0.6915 - val_accuracy: 0.5157\n",
      "Epoch 6/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6912 - accuracy: 0.5217 - val_loss: 0.6912 - val_accuracy: 0.5153\n",
      "Epoch 7/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5223 - val_loss: 0.6914 - val_accuracy: 0.5181\n",
      "Epoch 8/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6912 - accuracy: 0.5209 - val_loss: 0.6915 - val_accuracy: 0.5130\n",
      "Epoch 9/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5230 - val_loss: 0.6911 - val_accuracy: 0.5101\n",
      "Epoch 10/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5218 - val_loss: 0.6912 - val_accuracy: 0.5095\n",
      "Epoch 11/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6910 - accuracy: 0.5218 - val_loss: 0.6913 - val_accuracy: 0.5135\n",
      "Epoch 12/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5217 - val_loss: 0.6915 - val_accuracy: 0.5150\n",
      "Epoch 13/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5226 - val_loss: 0.6914 - val_accuracy: 0.5093\n",
      "Epoch 14/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5226 - val_loss: 0.6913 - val_accuracy: 0.5132\n",
      "Epoch 15/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5237 - val_loss: 0.6911 - val_accuracy: 0.5128\n",
      "Epoch 16/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5223 - val_loss: 0.6913 - val_accuracy: 0.5138\n",
      "Epoch 17/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6908 - accuracy: 0.5224 - val_loss: 0.6912 - val_accuracy: 0.5140\n",
      "Epoch 18/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5217 - val_loss: 0.6910 - val_accuracy: 0.5086\n",
      "Epoch 19/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5229 - val_loss: 0.6913 - val_accuracy: 0.5151\n",
      "Epoch 20/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5221 - val_loss: 0.6909 - val_accuracy: 0.5131\n",
      "Epoch 21/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5206 - val_loss: 0.6910 - val_accuracy: 0.5109\n",
      "Epoch 22/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5224 - val_loss: 0.6911 - val_accuracy: 0.5096\n",
      "Epoch 23/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5212 - val_loss: 0.6909 - val_accuracy: 0.5151\n",
      "Epoch 24/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5234 - val_loss: 0.6913 - val_accuracy: 0.5131\n",
      "Epoch 25/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5233 - val_loss: 0.6911 - val_accuracy: 0.5134\n",
      "Epoch 26/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5228 - val_loss: 0.6916 - val_accuracy: 0.5138\n",
      "Epoch 27/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5245 - val_loss: 0.6912 - val_accuracy: 0.5107\n",
      "Epoch 28/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5224 - val_loss: 0.6911 - val_accuracy: 0.5163\n",
      "Epoch 29/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5255 - val_loss: 0.6913 - val_accuracy: 0.5124\n",
      "Epoch 30/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5233 - val_loss: 0.6910 - val_accuracy: 0.5105\n",
      "Epoch 31/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5247 - val_loss: 0.6915 - val_accuracy: 0.5120\n",
      "Epoch 32/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5237 - val_loss: 0.6911 - val_accuracy: 0.5143\n",
      "Epoch 33/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5232 - val_loss: 0.6912 - val_accuracy: 0.5134\n",
      "Epoch 34/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5246 - val_loss: 0.6914 - val_accuracy: 0.5117\n",
      "Epoch 35/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5243 - val_loss: 0.6914 - val_accuracy: 0.5111\n",
      "Epoch 36/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5248 - val_loss: 0.6913 - val_accuracy: 0.5102\n",
      "Epoch 37/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5267 - val_loss: 0.6911 - val_accuracy: 0.5139\n",
      "Epoch 38/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5240 - val_loss: 0.6912 - val_accuracy: 0.5147\n",
      "Epoch 39/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5249 - val_loss: 0.6910 - val_accuracy: 0.5141\n",
      "Epoch 40/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5249 - val_loss: 0.6910 - val_accuracy: 0.5124\n",
      "Epoch 41/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5244 - val_loss: 0.6911 - val_accuracy: 0.5143\n",
      "Epoch 42/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5258 - val_loss: 0.6911 - val_accuracy: 0.5122\n",
      "Epoch 43/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5241 - val_loss: 0.6910 - val_accuracy: 0.5143\n",
      "Epoch 44/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5254 - val_loss: 0.6910 - val_accuracy: 0.5140\n",
      "Epoch 45/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5259 - val_loss: 0.6915 - val_accuracy: 0.5130\n",
      "Epoch 46/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5261 - val_loss: 0.6909 - val_accuracy: 0.5137\n",
      "Epoch 47/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5245 - val_loss: 0.6912 - val_accuracy: 0.5135\n",
      "Epoch 48/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5235 - val_loss: 0.6910 - val_accuracy: 0.5160\n",
      "Epoch 49/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5268 - val_loss: 0.6910 - val_accuracy: 0.5142\n",
      "Epoch 50/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5253 - val_loss: 0.6909 - val_accuracy: 0.5137\n",
      "Epoch 51/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6904 - accuracy: 0.5264 - val_loss: 0.6912 - val_accuracy: 0.5148\n",
      "Epoch 52/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5261 - val_loss: 0.6911 - val_accuracy: 0.5148\n",
      "Epoch 53/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5247 - val_loss: 0.6913 - val_accuracy: 0.5140\n",
      "Epoch 54/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5249 - val_loss: 0.6909 - val_accuracy: 0.5137\n",
      "Epoch 55/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5259 - val_loss: 0.6914 - val_accuracy: 0.5140\n",
      "Epoch 56/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6903 - accuracy: 0.5273 - val_loss: 0.6909 - val_accuracy: 0.5159\n",
      "Epoch 57/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6904 - accuracy: 0.5246 - val_loss: 0.6914 - val_accuracy: 0.5143\n",
      "Epoch 58/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5269 - val_loss: 0.6910 - val_accuracy: 0.5138\n",
      "Epoch 59/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5270 - val_loss: 0.6912 - val_accuracy: 0.5151\n",
      "Epoch 60/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5237 - val_loss: 0.6913 - val_accuracy: 0.5134\n",
      "Epoch 61/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5255 - val_loss: 0.6912 - val_accuracy: 0.5131\n",
      "Epoch 62/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6903 - accuracy: 0.5270 - val_loss: 0.6915 - val_accuracy: 0.5125\n",
      "Epoch 63/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5269 - val_loss: 0.6914 - val_accuracy: 0.5143\n",
      "Epoch 64/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5262 - val_loss: 0.6912 - val_accuracy: 0.5159\n",
      "Epoch 65/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5283 - val_loss: 0.6909 - val_accuracy: 0.5157\n",
      "Epoch 66/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6902 - accuracy: 0.5269 - val_loss: 0.6911 - val_accuracy: 0.5148\n",
      "Epoch 67/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5255 - val_loss: 0.6913 - val_accuracy: 0.5122\n",
      "Epoch 68/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5272 - val_loss: 0.6914 - val_accuracy: 0.5152\n",
      "Epoch 69/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5269 - val_loss: 0.6909 - val_accuracy: 0.5151\n",
      "Epoch 70/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5275 - val_loss: 0.6912 - val_accuracy: 0.5146\n",
      "Epoch 71/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5265 - val_loss: 0.6912 - val_accuracy: 0.5176\n",
      "Epoch 72/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5283 - val_loss: 0.6916 - val_accuracy: 0.5143\n",
      "Epoch 73/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5268 - val_loss: 0.6917 - val_accuracy: 0.5140\n",
      "Epoch 74/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5266 - val_loss: 0.6910 - val_accuracy: 0.5157\n",
      "Epoch 75/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6901 - accuracy: 0.5271 - val_loss: 0.6914 - val_accuracy: 0.5128\n",
      "Epoch 76/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6902 - accuracy: 0.5268 - val_loss: 0.6913 - val_accuracy: 0.5135\n",
      "Epoch 77/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6901 - accuracy: 0.5255 - val_loss: 0.6910 - val_accuracy: 0.5125\n",
      "Epoch 78/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6901 - accuracy: 0.5273 - val_loss: 0.6911 - val_accuracy: 0.5140\n",
      "Epoch 79/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6901 - accuracy: 0.5264 - val_loss: 0.6914 - val_accuracy: 0.5124\n",
      "Epoch 80/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5280 - val_loss: 0.6912 - val_accuracy: 0.5133\n",
      "Epoch 81/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5278 - val_loss: 0.6910 - val_accuracy: 0.5115\n",
      "Epoch 82/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5299 - val_loss: 0.6914 - val_accuracy: 0.5130\n",
      "Epoch 83/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5279 - val_loss: 0.6912 - val_accuracy: 0.5133\n",
      "Epoch 84/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5271 - val_loss: 0.6915 - val_accuracy: 0.5137\n",
      "Training with significance = 6.91, run 3\n",
      "Train on 41963 samples, validate on 10491 samples\n",
      "Epoch 1/1000\n",
      "41963/41963 [==============================] - 1s 27us/sample - loss: 0.6922 - accuracy: 0.5142 - val_loss: 0.6949 - val_accuracy: 0.5140\n",
      "Epoch 2/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5166 - val_loss: 0.6916 - val_accuracy: 0.5150\n",
      "Epoch 3/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5177 - val_loss: 0.6915 - val_accuracy: 0.5132\n",
      "Epoch 4/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5175 - val_loss: 0.6912 - val_accuracy: 0.5123\n",
      "Epoch 5/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6910 - accuracy: 0.5187 - val_loss: 0.6912 - val_accuracy: 0.5142\n",
      "Epoch 6/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5193 - val_loss: 0.6911 - val_accuracy: 0.5149\n",
      "Epoch 7/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6910 - accuracy: 0.5195 - val_loss: 0.6911 - val_accuracy: 0.5128\n",
      "Epoch 8/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6909 - accuracy: 0.5206 - val_loss: 0.6910 - val_accuracy: 0.5164\n",
      "Epoch 9/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5200 - val_loss: 0.6910 - val_accuracy: 0.5134\n",
      "Epoch 10/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5206 - val_loss: 0.6911 - val_accuracy: 0.5133\n",
      "Epoch 11/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5215 - val_loss: 0.6910 - val_accuracy: 0.5129\n",
      "Epoch 12/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5215 - val_loss: 0.6910 - val_accuracy: 0.5123\n",
      "Epoch 13/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5201 - val_loss: 0.6910 - val_accuracy: 0.5133\n",
      "Epoch 14/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5197 - val_loss: 0.6910 - val_accuracy: 0.5130\n",
      "Epoch 15/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5210 - val_loss: 0.6910 - val_accuracy: 0.5137\n",
      "Epoch 16/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5211 - val_loss: 0.6910 - val_accuracy: 0.5168\n",
      "Epoch 17/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5208 - val_loss: 0.6910 - val_accuracy: 0.5130\n",
      "Epoch 18/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5211 - val_loss: 0.6910 - val_accuracy: 0.5110\n",
      "Epoch 19/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5219 - val_loss: 0.6911 - val_accuracy: 0.5147\n",
      "Epoch 20/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5217 - val_loss: 0.6910 - val_accuracy: 0.5103\n",
      "Epoch 21/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5225 - val_loss: 0.6910 - val_accuracy: 0.5157\n",
      "Epoch 22/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5226 - val_loss: 0.6910 - val_accuracy: 0.5123\n",
      "Epoch 23/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6904 - accuracy: 0.5215 - val_loss: 0.6910 - val_accuracy: 0.5118\n",
      "Epoch 24/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5220 - val_loss: 0.6909 - val_accuracy: 0.5109\n",
      "Epoch 25/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6904 - accuracy: 0.5209 - val_loss: 0.6910 - val_accuracy: 0.5149\n",
      "Epoch 26/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5233 - val_loss: 0.6910 - val_accuracy: 0.5145\n",
      "Epoch 27/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5217 - val_loss: 0.6909 - val_accuracy: 0.5116\n",
      "Epoch 28/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5214 - val_loss: 0.6909 - val_accuracy: 0.5111\n",
      "Epoch 29/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5243 - val_loss: 0.6909 - val_accuracy: 0.5122\n",
      "Epoch 30/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5200 - val_loss: 0.6910 - val_accuracy: 0.5115\n",
      "Epoch 31/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5215 - val_loss: 0.6912 - val_accuracy: 0.5125\n",
      "Epoch 32/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5208 - val_loss: 0.6910 - val_accuracy: 0.5125\n",
      "Epoch 33/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5198 - val_loss: 0.6911 - val_accuracy: 0.5128\n",
      "Epoch 34/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5212 - val_loss: 0.6911 - val_accuracy: 0.5150\n",
      "Epoch 35/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5224 - val_loss: 0.6911 - val_accuracy: 0.5145\n",
      "Epoch 36/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5235 - val_loss: 0.6910 - val_accuracy: 0.5153\n",
      "Epoch 37/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6901 - accuracy: 0.5222 - val_loss: 0.6910 - val_accuracy: 0.5143\n",
      "Epoch 38/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5225 - val_loss: 0.6910 - val_accuracy: 0.5135\n",
      "Epoch 39/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5223 - val_loss: 0.6910 - val_accuracy: 0.5137\n",
      "Epoch 40/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5234 - val_loss: 0.6910 - val_accuracy: 0.5108\n",
      "Epoch 41/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6901 - accuracy: 0.5244 - val_loss: 0.6910 - val_accuracy: 0.5137\n",
      "Epoch 42/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6902 - accuracy: 0.5221 - val_loss: 0.6910 - val_accuracy: 0.5120\n",
      "Epoch 43/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6901 - accuracy: 0.5230 - val_loss: 0.6910 - val_accuracy: 0.5104\n",
      "Epoch 44/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5245 - val_loss: 0.6910 - val_accuracy: 0.5140\n",
      "Epoch 45/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5229 - val_loss: 0.6910 - val_accuracy: 0.5148\n",
      "Epoch 46/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6901 - accuracy: 0.5240 - val_loss: 0.6910 - val_accuracy: 0.5114\n",
      "Epoch 47/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5240 - val_loss: 0.6910 - val_accuracy: 0.5147\n",
      "Epoch 48/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6902 - accuracy: 0.5231 - val_loss: 0.6911 - val_accuracy: 0.5143\n",
      "Epoch 49/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6902 - accuracy: 0.5239 - val_loss: 0.6911 - val_accuracy: 0.5145\n",
      "Epoch 50/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6901 - accuracy: 0.5244 - val_loss: 0.6911 - val_accuracy: 0.5132\n",
      "Epoch 51/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6899 - accuracy: 0.5234 - val_loss: 0.6909 - val_accuracy: 0.5146\n",
      "Epoch 52/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5232 - val_loss: 0.6910 - val_accuracy: 0.5119\n",
      "Epoch 53/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5237 - val_loss: 0.6910 - val_accuracy: 0.5141\n",
      "Epoch 54/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5242 - val_loss: 0.6911 - val_accuracy: 0.5126\n",
      "Training with significance = 6.91, run 4\n",
      "Train on 41963 samples, validate on 10491 samples\n",
      "Epoch 1/1000\n",
      "41963/41963 [==============================] - 1s 28us/sample - loss: 0.6920 - accuracy: 0.5145 - val_loss: 0.6980 - val_accuracy: 0.5044\n",
      "Epoch 2/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5181 - val_loss: 0.6937 - val_accuracy: 0.5129\n",
      "Epoch 3/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6909 - accuracy: 0.5207 - val_loss: 0.6929 - val_accuracy: 0.5150\n",
      "Epoch 4/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5208 - val_loss: 0.6922 - val_accuracy: 0.5161\n",
      "Epoch 5/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5222 - val_loss: 0.6923 - val_accuracy: 0.5163\n",
      "Epoch 6/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5231 - val_loss: 0.6923 - val_accuracy: 0.5139\n",
      "Epoch 7/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5230 - val_loss: 0.6921 - val_accuracy: 0.5120\n",
      "Epoch 8/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5219 - val_loss: 0.6921 - val_accuracy: 0.5111\n",
      "Epoch 9/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6903 - accuracy: 0.5228 - val_loss: 0.6922 - val_accuracy: 0.5111\n",
      "Epoch 10/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5219 - val_loss: 0.6921 - val_accuracy: 0.5114\n",
      "Epoch 11/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5237 - val_loss: 0.6920 - val_accuracy: 0.5102\n",
      "Epoch 12/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6901 - accuracy: 0.5218 - val_loss: 0.6921 - val_accuracy: 0.5101\n",
      "Epoch 13/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5237 - val_loss: 0.6921 - val_accuracy: 0.5126\n",
      "Epoch 14/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6900 - accuracy: 0.5239 - val_loss: 0.6922 - val_accuracy: 0.5105\n",
      "Epoch 15/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6900 - accuracy: 0.5227 - val_loss: 0.6922 - val_accuracy: 0.5073\n",
      "Epoch 16/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5230 - val_loss: 0.6920 - val_accuracy: 0.5128\n",
      "Epoch 17/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6900 - accuracy: 0.5222 - val_loss: 0.6921 - val_accuracy: 0.5118\n",
      "Epoch 18/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6899 - accuracy: 0.5236 - val_loss: 0.6921 - val_accuracy: 0.5088\n",
      "Epoch 19/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6898 - accuracy: 0.5236 - val_loss: 0.6920 - val_accuracy: 0.5157\n",
      "Epoch 20/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6900 - accuracy: 0.5236 - val_loss: 0.6924 - val_accuracy: 0.5070\n",
      "Epoch 21/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6899 - accuracy: 0.5227 - val_loss: 0.6923 - val_accuracy: 0.5106\n",
      "Epoch 22/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6897 - accuracy: 0.5251 - val_loss: 0.6921 - val_accuracy: 0.5149\n",
      "Epoch 23/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6899 - accuracy: 0.5220 - val_loss: 0.6922 - val_accuracy: 0.5105\n",
      "Epoch 24/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6898 - accuracy: 0.5238 - val_loss: 0.6923 - val_accuracy: 0.5101\n",
      "Epoch 25/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6898 - accuracy: 0.5244 - val_loss: 0.6922 - val_accuracy: 0.5100\n",
      "Epoch 26/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6898 - accuracy: 0.5233 - val_loss: 0.6922 - val_accuracy: 0.5114\n",
      "Epoch 27/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6897 - accuracy: 0.5221 - val_loss: 0.6921 - val_accuracy: 0.5137\n",
      "Epoch 28/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6897 - accuracy: 0.5240 - val_loss: 0.6923 - val_accuracy: 0.5095\n",
      "Epoch 29/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6898 - accuracy: 0.5245 - val_loss: 0.6921 - val_accuracy: 0.5100\n",
      "Epoch 30/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6897 - accuracy: 0.5256 - val_loss: 0.6922 - val_accuracy: 0.5114\n",
      "Epoch 31/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5241 - val_loss: 0.6922 - val_accuracy: 0.5141\n",
      "Epoch 32/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6896 - accuracy: 0.5244 - val_loss: 0.6923 - val_accuracy: 0.5102\n",
      "Epoch 33/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6897 - accuracy: 0.5243 - val_loss: 0.6923 - val_accuracy: 0.5107\n",
      "Epoch 34/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6896 - accuracy: 0.5245 - val_loss: 0.6922 - val_accuracy: 0.5129\n",
      "Epoch 35/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6896 - accuracy: 0.5239 - val_loss: 0.6922 - val_accuracy: 0.5126\n",
      "Epoch 36/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6896 - accuracy: 0.5231 - val_loss: 0.6922 - val_accuracy: 0.5133\n",
      "Epoch 37/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6895 - accuracy: 0.5239 - val_loss: 0.6923 - val_accuracy: 0.5100\n",
      "Epoch 38/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6895 - accuracy: 0.5244 - val_loss: 0.6924 - val_accuracy: 0.5104\n",
      "Epoch 39/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6896 - accuracy: 0.5254 - val_loss: 0.6923 - val_accuracy: 0.5085\n",
      "Epoch 40/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6896 - accuracy: 0.5248 - val_loss: 0.6923 - val_accuracy: 0.5064\n",
      "Epoch 41/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6897 - accuracy: 0.5268 - val_loss: 0.6921 - val_accuracy: 0.5138\n",
      "Epoch 42/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6894 - accuracy: 0.5264 - val_loss: 0.6922 - val_accuracy: 0.5111\n",
      "Epoch 43/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6895 - accuracy: 0.5248 - val_loss: 0.6924 - val_accuracy: 0.5078\n",
      "Epoch 44/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6894 - accuracy: 0.5267 - val_loss: 0.6923 - val_accuracy: 0.5131\n",
      "Epoch 45/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6895 - accuracy: 0.5255 - val_loss: 0.6923 - val_accuracy: 0.5122\n",
      "Epoch 46/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6893 - accuracy: 0.5253 - val_loss: 0.6922 - val_accuracy: 0.5115\n",
      "Epoch 47/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6895 - accuracy: 0.5241 - val_loss: 0.6922 - val_accuracy: 0.5102\n",
      "Epoch 48/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6894 - accuracy: 0.5264 - val_loss: 0.6922 - val_accuracy: 0.5140\n",
      "Epoch 49/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6895 - accuracy: 0.5252 - val_loss: 0.6923 - val_accuracy: 0.5102\n",
      "Training with significance = 6.91, run 5\n",
      "Train on 41963 samples, validate on 10491 samples\n",
      "Epoch 1/1000\n",
      "41963/41963 [==============================] - 1s 27us/sample - loss: 0.6917 - accuracy: 0.5132 - val_loss: 0.6999 - val_accuracy: 0.5036\n",
      "Epoch 2/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5182 - val_loss: 0.6948 - val_accuracy: 0.5094\n",
      "Epoch 3/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6910 - accuracy: 0.5196 - val_loss: 0.6933 - val_accuracy: 0.5148\n",
      "Epoch 4/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5202 - val_loss: 0.6922 - val_accuracy: 0.5110\n",
      "Epoch 5/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5191 - val_loss: 0.6923 - val_accuracy: 0.5111\n",
      "Epoch 6/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5212 - val_loss: 0.6924 - val_accuracy: 0.5128\n",
      "Epoch 7/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5210 - val_loss: 0.6921 - val_accuracy: 0.5126\n",
      "Epoch 8/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5204 - val_loss: 0.6923 - val_accuracy: 0.5134\n",
      "Epoch 9/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5210 - val_loss: 0.6917 - val_accuracy: 0.5141\n",
      "Epoch 10/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5210 - val_loss: 0.6923 - val_accuracy: 0.5119\n",
      "Epoch 11/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5223 - val_loss: 0.6918 - val_accuracy: 0.5151\n",
      "Epoch 12/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6904 - accuracy: 0.5206 - val_loss: 0.6922 - val_accuracy: 0.5128\n",
      "Epoch 13/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5218 - val_loss: 0.6919 - val_accuracy: 0.5155\n",
      "Epoch 14/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5204 - val_loss: 0.6916 - val_accuracy: 0.5164\n",
      "Epoch 15/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5219 - val_loss: 0.6918 - val_accuracy: 0.5143\n",
      "Epoch 16/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6904 - accuracy: 0.5225 - val_loss: 0.6918 - val_accuracy: 0.5144\n",
      "Epoch 17/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6903 - accuracy: 0.5217 - val_loss: 0.6917 - val_accuracy: 0.5160\n",
      "Epoch 18/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6903 - accuracy: 0.5220 - val_loss: 0.6916 - val_accuracy: 0.5156\n",
      "Epoch 19/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6902 - accuracy: 0.5227 - val_loss: 0.6916 - val_accuracy: 0.5171\n",
      "Epoch 20/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5212 - val_loss: 0.6917 - val_accuracy: 0.5157\n",
      "Epoch 21/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5208 - val_loss: 0.6917 - val_accuracy: 0.5164\n",
      "Epoch 22/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5232 - val_loss: 0.6915 - val_accuracy: 0.5197\n",
      "Epoch 23/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5220 - val_loss: 0.6916 - val_accuracy: 0.5184\n",
      "Epoch 24/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6902 - accuracy: 0.5236 - val_loss: 0.6920 - val_accuracy: 0.5112\n",
      "Epoch 25/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6902 - accuracy: 0.5241 - val_loss: 0.6915 - val_accuracy: 0.5174\n",
      "Epoch 26/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6901 - accuracy: 0.5237 - val_loss: 0.6917 - val_accuracy: 0.5153\n",
      "Epoch 27/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6902 - accuracy: 0.5225 - val_loss: 0.6917 - val_accuracy: 0.5153\n",
      "Epoch 28/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6902 - accuracy: 0.5219 - val_loss: 0.6916 - val_accuracy: 0.5178\n",
      "Epoch 29/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5231 - val_loss: 0.6920 - val_accuracy: 0.5124\n",
      "Epoch 30/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5263 - val_loss: 0.6914 - val_accuracy: 0.5189\n",
      "Epoch 31/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6900 - accuracy: 0.5245 - val_loss: 0.6916 - val_accuracy: 0.5173\n",
      "Epoch 32/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5228 - val_loss: 0.6915 - val_accuracy: 0.5167\n",
      "Epoch 33/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5249 - val_loss: 0.6920 - val_accuracy: 0.5124\n",
      "Epoch 34/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5223 - val_loss: 0.6916 - val_accuracy: 0.5189\n",
      "Epoch 35/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6900 - accuracy: 0.5239 - val_loss: 0.6917 - val_accuracy: 0.5154\n",
      "Epoch 36/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6899 - accuracy: 0.5235 - val_loss: 0.6920 - val_accuracy: 0.5154\n",
      "Epoch 37/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5227 - val_loss: 0.6921 - val_accuracy: 0.5124\n",
      "Epoch 38/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5233 - val_loss: 0.6922 - val_accuracy: 0.5126\n",
      "Epoch 39/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6900 - accuracy: 0.5259 - val_loss: 0.6915 - val_accuracy: 0.5173\n",
      "Epoch 40/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5248 - val_loss: 0.6915 - val_accuracy: 0.5187\n",
      "Epoch 41/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5253 - val_loss: 0.6917 - val_accuracy: 0.5171\n",
      "Epoch 42/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6898 - accuracy: 0.5235 - val_loss: 0.6914 - val_accuracy: 0.5185\n",
      "Epoch 43/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5263 - val_loss: 0.6917 - val_accuracy: 0.5166\n",
      "Epoch 44/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6899 - accuracy: 0.5256 - val_loss: 0.6918 - val_accuracy: 0.5178\n",
      "Epoch 45/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6898 - accuracy: 0.5260 - val_loss: 0.6916 - val_accuracy: 0.5177\n",
      "Epoch 46/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5255 - val_loss: 0.6916 - val_accuracy: 0.5170\n",
      "Epoch 47/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5253 - val_loss: 0.6917 - val_accuracy: 0.5167\n",
      "Epoch 48/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5241 - val_loss: 0.6916 - val_accuracy: 0.5168\n",
      "Epoch 49/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6899 - accuracy: 0.5245 - val_loss: 0.6920 - val_accuracy: 0.5137\n",
      "Epoch 50/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6898 - accuracy: 0.5269 - val_loss: 0.6920 - val_accuracy: 0.5114\n",
      "Epoch 51/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6897 - accuracy: 0.5269 - val_loss: 0.6922 - val_accuracy: 0.5112\n",
      "Epoch 52/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6899 - accuracy: 0.5245 - val_loss: 0.6915 - val_accuracy: 0.5192\n",
      "Epoch 53/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6898 - accuracy: 0.5238 - val_loss: 0.6916 - val_accuracy: 0.5172\n",
      "Epoch 54/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6898 - accuracy: 0.5254 - val_loss: 0.6916 - val_accuracy: 0.5176\n",
      "Epoch 55/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6898 - accuracy: 0.5262 - val_loss: 0.6917 - val_accuracy: 0.5170\n",
      "Epoch 56/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6898 - accuracy: 0.5242 - val_loss: 0.6918 - val_accuracy: 0.5161\n",
      "Epoch 57/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6896 - accuracy: 0.5257 - val_loss: 0.6919 - val_accuracy: 0.5154\n",
      "Epoch 58/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6897 - accuracy: 0.5235 - val_loss: 0.6918 - val_accuracy: 0.5173\n",
      "Epoch 59/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6897 - accuracy: 0.5242 - val_loss: 0.6919 - val_accuracy: 0.5164\n",
      "Epoch 60/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6898 - accuracy: 0.5257 - val_loss: 0.6919 - val_accuracy: 0.5157\n",
      "Epoch 61/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6897 - accuracy: 0.5258 - val_loss: 0.6915 - val_accuracy: 0.5183\n",
      "Epoch 62/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6897 - accuracy: 0.5261 - val_loss: 0.6916 - val_accuracy: 0.5178\n",
      "Epoch 63/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6896 - accuracy: 0.5265 - val_loss: 0.6918 - val_accuracy: 0.5173\n",
      "Epoch 64/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5239 - val_loss: 0.6916 - val_accuracy: 0.5199\n",
      "Epoch 65/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6896 - accuracy: 0.5238 - val_loss: 0.6916 - val_accuracy: 0.5183\n",
      "Epoch 66/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6896 - accuracy: 0.5257 - val_loss: 0.6921 - val_accuracy: 0.5156\n",
      "Epoch 67/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6895 - accuracy: 0.5249 - val_loss: 0.6916 - val_accuracy: 0.5164\n",
      "Epoch 68/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6896 - accuracy: 0.5264 - val_loss: 0.6915 - val_accuracy: 0.5182\n",
      "Epoch 69/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6895 - accuracy: 0.5257 - val_loss: 0.6916 - val_accuracy: 0.5163\n",
      "Epoch 70/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6895 - accuracy: 0.5259 - val_loss: 0.6919 - val_accuracy: 0.5162\n",
      "Epoch 71/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6895 - accuracy: 0.5271 - val_loss: 0.6917 - val_accuracy: 0.5146\n",
      "Epoch 72/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6896 - accuracy: 0.5273 - val_loss: 0.6917 - val_accuracy: 0.5163\n",
      "Training with significance = 6.91, run 6\n",
      "Train on 41963 samples, validate on 10491 samples\n",
      "Epoch 1/1000\n",
      "41963/41963 [==============================] - 1s 27us/sample - loss: 0.6923 - accuracy: 0.5129 - val_loss: 0.6971 - val_accuracy: 0.5003\n",
      "Epoch 2/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6914 - accuracy: 0.5178 - val_loss: 0.6942 - val_accuracy: 0.5088\n",
      "Epoch 3/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5196 - val_loss: 0.6925 - val_accuracy: 0.5163\n",
      "Epoch 4/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5185 - val_loss: 0.6922 - val_accuracy: 0.5159\n",
      "Epoch 5/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5203 - val_loss: 0.6917 - val_accuracy: 0.5155\n",
      "Epoch 6/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5213 - val_loss: 0.6914 - val_accuracy: 0.5193\n",
      "Epoch 7/1000\n",
      "41963/41963 [==============================] - 0s 12us/sample - loss: 0.6908 - accuracy: 0.5208 - val_loss: 0.6914 - val_accuracy: 0.5188\n",
      "Epoch 8/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6907 - accuracy: 0.5214 - val_loss: 0.6913 - val_accuracy: 0.5191\n",
      "Epoch 9/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5210 - val_loss: 0.6914 - val_accuracy: 0.5195\n",
      "Epoch 10/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5211 - val_loss: 0.6913 - val_accuracy: 0.5184\n",
      "Epoch 11/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5222 - val_loss: 0.6913 - val_accuracy: 0.5183\n",
      "Epoch 12/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5222 - val_loss: 0.6913 - val_accuracy: 0.5177\n",
      "Epoch 13/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5237 - val_loss: 0.6913 - val_accuracy: 0.5181\n",
      "Epoch 14/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5219 - val_loss: 0.6912 - val_accuracy: 0.5182\n",
      "Epoch 15/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5233 - val_loss: 0.6913 - val_accuracy: 0.5118\n",
      "Epoch 16/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6904 - accuracy: 0.5223 - val_loss: 0.6913 - val_accuracy: 0.5163\n",
      "Epoch 17/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6902 - accuracy: 0.5228 - val_loss: 0.6914 - val_accuracy: 0.5157\n",
      "Epoch 18/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6903 - accuracy: 0.5228 - val_loss: 0.6913 - val_accuracy: 0.5114\n",
      "Epoch 19/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5240 - val_loss: 0.6912 - val_accuracy: 0.5189\n",
      "Epoch 20/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5217 - val_loss: 0.6913 - val_accuracy: 0.5139\n",
      "Epoch 21/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5246 - val_loss: 0.6912 - val_accuracy: 0.5142\n",
      "Epoch 22/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5225 - val_loss: 0.6913 - val_accuracy: 0.5175\n",
      "Epoch 23/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5226 - val_loss: 0.6912 - val_accuracy: 0.5154\n",
      "Epoch 24/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5238 - val_loss: 0.6912 - val_accuracy: 0.5157\n",
      "Epoch 25/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5209 - val_loss: 0.6912 - val_accuracy: 0.5165\n",
      "Epoch 26/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5236 - val_loss: 0.6912 - val_accuracy: 0.5162\n",
      "Epoch 27/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5223 - val_loss: 0.6914 - val_accuracy: 0.5122\n",
      "Epoch 28/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5242 - val_loss: 0.6911 - val_accuracy: 0.5173\n",
      "Epoch 29/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6901 - accuracy: 0.5227 - val_loss: 0.6913 - val_accuracy: 0.5144\n",
      "Epoch 30/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6902 - accuracy: 0.5252 - val_loss: 0.6911 - val_accuracy: 0.5183\n",
      "Epoch 31/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6902 - accuracy: 0.5239 - val_loss: 0.6915 - val_accuracy: 0.5139\n",
      "Epoch 32/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6901 - accuracy: 0.5229 - val_loss: 0.6913 - val_accuracy: 0.5153\n",
      "Epoch 33/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6902 - accuracy: 0.5231 - val_loss: 0.6913 - val_accuracy: 0.5143\n",
      "Epoch 34/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6900 - accuracy: 0.5256 - val_loss: 0.6915 - val_accuracy: 0.5144\n",
      "Epoch 35/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6900 - accuracy: 0.5233 - val_loss: 0.6912 - val_accuracy: 0.5175\n",
      "Epoch 36/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5255 - val_loss: 0.6912 - val_accuracy: 0.5156\n",
      "Epoch 37/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6901 - accuracy: 0.5252 - val_loss: 0.6912 - val_accuracy: 0.5180\n",
      "Epoch 38/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6901 - accuracy: 0.5232 - val_loss: 0.6913 - val_accuracy: 0.5146\n",
      "Epoch 39/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6899 - accuracy: 0.5253 - val_loss: 0.6912 - val_accuracy: 0.5174\n",
      "Epoch 40/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5225 - val_loss: 0.6913 - val_accuracy: 0.5140\n",
      "Epoch 41/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6898 - accuracy: 0.5269 - val_loss: 0.6913 - val_accuracy: 0.5122\n",
      "Epoch 42/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5246 - val_loss: 0.6912 - val_accuracy: 0.5143\n",
      "Epoch 43/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5264 - val_loss: 0.6913 - val_accuracy: 0.5157\n",
      "Epoch 44/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6899 - accuracy: 0.5231 - val_loss: 0.6914 - val_accuracy: 0.5148\n",
      "Epoch 45/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5269 - val_loss: 0.6915 - val_accuracy: 0.5151\n",
      "Epoch 46/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6899 - accuracy: 0.5238 - val_loss: 0.6911 - val_accuracy: 0.5178\n",
      "Epoch 47/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5247 - val_loss: 0.6913 - val_accuracy: 0.5166\n",
      "Epoch 48/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6898 - accuracy: 0.5244 - val_loss: 0.6911 - val_accuracy: 0.5169\n",
      "Epoch 49/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5267 - val_loss: 0.6912 - val_accuracy: 0.5157\n",
      "Epoch 50/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6898 - accuracy: 0.5248 - val_loss: 0.6912 - val_accuracy: 0.5189\n",
      "Epoch 51/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6898 - accuracy: 0.5248 - val_loss: 0.6914 - val_accuracy: 0.5128\n",
      "Epoch 52/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6899 - accuracy: 0.5243 - val_loss: 0.6913 - val_accuracy: 0.5155\n",
      "Epoch 53/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6899 - accuracy: 0.5267 - val_loss: 0.6913 - val_accuracy: 0.5173\n",
      "Epoch 54/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6898 - accuracy: 0.5256 - val_loss: 0.6914 - val_accuracy: 0.5142\n",
      "Epoch 55/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6898 - accuracy: 0.5247 - val_loss: 0.6915 - val_accuracy: 0.5114\n",
      "Epoch 56/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6898 - accuracy: 0.5242 - val_loss: 0.6913 - val_accuracy: 0.5158\n",
      "Epoch 57/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6897 - accuracy: 0.5266 - val_loss: 0.6914 - val_accuracy: 0.5149\n",
      "Epoch 58/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6897 - accuracy: 0.5254 - val_loss: 0.6915 - val_accuracy: 0.5130\n",
      "Training with significance = 6.91, run 7\n",
      "Train on 41963 samples, validate on 10491 samples\n",
      "Epoch 1/1000\n",
      "41963/41963 [==============================] - 1s 26us/sample - loss: 0.6947 - accuracy: 0.5007 - val_loss: 0.6932 - val_accuracy: 0.5026\n",
      "Epoch 2/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6918 - accuracy: 0.5180 - val_loss: 0.6931 - val_accuracy: 0.5125\n",
      "Epoch 3/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5201 - val_loss: 0.6926 - val_accuracy: 0.5135\n",
      "Epoch 4/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5194 - val_loss: 0.6918 - val_accuracy: 0.5160\n",
      "Epoch 5/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5213 - val_loss: 0.6914 - val_accuracy: 0.5139\n",
      "Epoch 6/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5207 - val_loss: 0.6911 - val_accuracy: 0.5147\n",
      "Epoch 7/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5197 - val_loss: 0.6911 - val_accuracy: 0.5143\n",
      "Epoch 8/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5226 - val_loss: 0.6909 - val_accuracy: 0.5164\n",
      "Epoch 9/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5204 - val_loss: 0.6910 - val_accuracy: 0.5151\n",
      "Epoch 10/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5196 - val_loss: 0.6912 - val_accuracy: 0.5150\n",
      "Epoch 11/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5212 - val_loss: 0.6907 - val_accuracy: 0.5170\n",
      "Epoch 12/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6907 - accuracy: 0.5208 - val_loss: 0.6909 - val_accuracy: 0.5173\n",
      "Epoch 13/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5208 - val_loss: 0.6911 - val_accuracy: 0.5161\n",
      "Epoch 14/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5210 - val_loss: 0.6907 - val_accuracy: 0.5181\n",
      "Epoch 15/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5232 - val_loss: 0.6906 - val_accuracy: 0.5169\n",
      "Epoch 16/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5225 - val_loss: 0.6907 - val_accuracy: 0.5182\n",
      "Epoch 17/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5222 - val_loss: 0.6909 - val_accuracy: 0.5177\n",
      "Epoch 18/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5215 - val_loss: 0.6906 - val_accuracy: 0.5193\n",
      "Epoch 19/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5201 - val_loss: 0.6906 - val_accuracy: 0.5190\n",
      "Epoch 20/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5217 - val_loss: 0.6908 - val_accuracy: 0.5195\n",
      "Epoch 21/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5217 - val_loss: 0.6907 - val_accuracy: 0.5183\n",
      "Epoch 22/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6904 - accuracy: 0.5221 - val_loss: 0.6907 - val_accuracy: 0.5187\n",
      "Epoch 23/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6904 - accuracy: 0.5217 - val_loss: 0.6906 - val_accuracy: 0.5180\n",
      "Epoch 24/1000\n",
      "41963/41963 [==============================] - 0s 12us/sample - loss: 0.6904 - accuracy: 0.5200 - val_loss: 0.6907 - val_accuracy: 0.5178\n",
      "Epoch 25/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6903 - accuracy: 0.5209 - val_loss: 0.6906 - val_accuracy: 0.5196\n",
      "Epoch 26/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5220 - val_loss: 0.6906 - val_accuracy: 0.5185\n",
      "Epoch 27/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5223 - val_loss: 0.6906 - val_accuracy: 0.5186\n",
      "Epoch 28/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5227 - val_loss: 0.6905 - val_accuracy: 0.5168\n",
      "Epoch 29/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5238 - val_loss: 0.6905 - val_accuracy: 0.5185\n",
      "Epoch 30/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5230 - val_loss: 0.6905 - val_accuracy: 0.5215\n",
      "Epoch 31/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5217 - val_loss: 0.6909 - val_accuracy: 0.5182\n",
      "Epoch 32/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5228 - val_loss: 0.6906 - val_accuracy: 0.5171\n",
      "Epoch 33/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6903 - accuracy: 0.5227 - val_loss: 0.6904 - val_accuracy: 0.5205\n",
      "Epoch 34/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6902 - accuracy: 0.5230 - val_loss: 0.6906 - val_accuracy: 0.5189\n",
      "Epoch 35/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6903 - accuracy: 0.5222 - val_loss: 0.6906 - val_accuracy: 0.5190\n",
      "Epoch 36/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5219 - val_loss: 0.6906 - val_accuracy: 0.5192\n",
      "Epoch 37/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6903 - accuracy: 0.5237 - val_loss: 0.6905 - val_accuracy: 0.5195\n",
      "Epoch 38/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6902 - accuracy: 0.5239 - val_loss: 0.6908 - val_accuracy: 0.5187\n",
      "Epoch 39/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5230 - val_loss: 0.6904 - val_accuracy: 0.5218\n",
      "Epoch 40/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6902 - accuracy: 0.5217 - val_loss: 0.6905 - val_accuracy: 0.5182\n",
      "Epoch 41/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5237 - val_loss: 0.6905 - val_accuracy: 0.5210\n",
      "Epoch 42/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5211 - val_loss: 0.6906 - val_accuracy: 0.5175\n",
      "Epoch 43/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5234 - val_loss: 0.6906 - val_accuracy: 0.5183\n",
      "Epoch 44/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5241 - val_loss: 0.6907 - val_accuracy: 0.5185\n",
      "Epoch 45/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6900 - accuracy: 0.5234 - val_loss: 0.6906 - val_accuracy: 0.5211\n",
      "Epoch 46/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6902 - accuracy: 0.5224 - val_loss: 0.6905 - val_accuracy: 0.5184\n",
      "Epoch 47/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5225 - val_loss: 0.6909 - val_accuracy: 0.5218\n",
      "Epoch 48/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6900 - accuracy: 0.5232 - val_loss: 0.6905 - val_accuracy: 0.5197\n",
      "Epoch 49/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5231 - val_loss: 0.6904 - val_accuracy: 0.5176\n",
      "Epoch 50/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5249 - val_loss: 0.6905 - val_accuracy: 0.5189\n",
      "Epoch 51/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5226 - val_loss: 0.6906 - val_accuracy: 0.5196\n",
      "Epoch 52/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6899 - accuracy: 0.5251 - val_loss: 0.6904 - val_accuracy: 0.5183\n",
      "Epoch 53/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6901 - accuracy: 0.5245 - val_loss: 0.6908 - val_accuracy: 0.5197\n",
      "Epoch 54/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6899 - accuracy: 0.5257 - val_loss: 0.6905 - val_accuracy: 0.5174\n",
      "Epoch 55/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5241 - val_loss: 0.6906 - val_accuracy: 0.5175\n",
      "Epoch 56/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5234 - val_loss: 0.6904 - val_accuracy: 0.5218\n",
      "Epoch 57/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6900 - accuracy: 0.5236 - val_loss: 0.6905 - val_accuracy: 0.5182\n",
      "Epoch 58/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6900 - accuracy: 0.5234 - val_loss: 0.6907 - val_accuracy: 0.5173\n",
      "Epoch 59/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5232 - val_loss: 0.6906 - val_accuracy: 0.5190\n",
      "Epoch 60/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6898 - accuracy: 0.5252 - val_loss: 0.6908 - val_accuracy: 0.5176\n",
      "Epoch 61/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6899 - accuracy: 0.5246 - val_loss: 0.6906 - val_accuracy: 0.5194\n",
      "Epoch 62/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5249 - val_loss: 0.6906 - val_accuracy: 0.5195\n",
      "Epoch 63/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5217 - val_loss: 0.6905 - val_accuracy: 0.5207\n",
      "Epoch 64/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5251 - val_loss: 0.6905 - val_accuracy: 0.5185\n",
      "Epoch 65/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6898 - accuracy: 0.5238 - val_loss: 0.6904 - val_accuracy: 0.5198\n",
      "Epoch 66/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6900 - accuracy: 0.5240 - val_loss: 0.6905 - val_accuracy: 0.5192\n",
      "Epoch 67/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6899 - accuracy: 0.5240 - val_loss: 0.6905 - val_accuracy: 0.5193\n",
      "Epoch 68/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6897 - accuracy: 0.5250 - val_loss: 0.6904 - val_accuracy: 0.5185\n",
      "Epoch 69/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6900 - accuracy: 0.5232 - val_loss: 0.6905 - val_accuracy: 0.5186\n",
      "Epoch 70/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6899 - accuracy: 0.5249 - val_loss: 0.6905 - val_accuracy: 0.5213\n",
      "Epoch 71/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6899 - accuracy: 0.5244 - val_loss: 0.6906 - val_accuracy: 0.5170\n",
      "Epoch 72/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5249 - val_loss: 0.6904 - val_accuracy: 0.5164\n",
      "Epoch 73/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6898 - accuracy: 0.5273 - val_loss: 0.6904 - val_accuracy: 0.5200\n",
      "Epoch 74/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6899 - accuracy: 0.5231 - val_loss: 0.6904 - val_accuracy: 0.5183\n",
      "Epoch 75/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6898 - accuracy: 0.5233 - val_loss: 0.6905 - val_accuracy: 0.5180\n",
      "Epoch 76/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6897 - accuracy: 0.5252 - val_loss: 0.6904 - val_accuracy: 0.5192\n",
      "Epoch 77/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6898 - accuracy: 0.5241 - val_loss: 0.6904 - val_accuracy: 0.5171\n",
      "Epoch 78/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6898 - accuracy: 0.5261 - val_loss: 0.6906 - val_accuracy: 0.5215\n",
      "Epoch 79/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5247 - val_loss: 0.6907 - val_accuracy: 0.5197\n",
      "Epoch 80/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6898 - accuracy: 0.5253 - val_loss: 0.6905 - val_accuracy: 0.5170\n",
      "Epoch 81/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6899 - accuracy: 0.5270 - val_loss: 0.6906 - val_accuracy: 0.5190\n",
      "Epoch 82/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5250 - val_loss: 0.6906 - val_accuracy: 0.5184\n",
      "Epoch 83/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6897 - accuracy: 0.5246 - val_loss: 0.6906 - val_accuracy: 0.5180\n",
      "Epoch 84/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6898 - accuracy: 0.5239 - val_loss: 0.6905 - val_accuracy: 0.5174\n",
      "Epoch 85/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6897 - accuracy: 0.5262 - val_loss: 0.6908 - val_accuracy: 0.5171\n",
      "Epoch 86/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6898 - accuracy: 0.5253 - val_loss: 0.6906 - val_accuracy: 0.5197\n",
      "Epoch 87/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6897 - accuracy: 0.5249 - val_loss: 0.6906 - val_accuracy: 0.5163\n",
      "Epoch 88/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6897 - accuracy: 0.5250 - val_loss: 0.6904 - val_accuracy: 0.5184\n",
      "Epoch 89/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6898 - accuracy: 0.5270 - val_loss: 0.6905 - val_accuracy: 0.5150\n",
      "Epoch 90/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6898 - accuracy: 0.5264 - val_loss: 0.6905 - val_accuracy: 0.5189\n",
      "Epoch 91/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6897 - accuracy: 0.5251 - val_loss: 0.6906 - val_accuracy: 0.5183\n",
      "Epoch 92/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6897 - accuracy: 0.5255 - val_loss: 0.6905 - val_accuracy: 0.5186\n",
      "Epoch 93/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6897 - accuracy: 0.5241 - val_loss: 0.6905 - val_accuracy: 0.5163\n",
      "Epoch 94/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6896 - accuracy: 0.5265 - val_loss: 0.6905 - val_accuracy: 0.5149\n",
      "Epoch 95/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6898 - accuracy: 0.5250 - val_loss: 0.6906 - val_accuracy: 0.5177\n",
      "Epoch 96/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6898 - accuracy: 0.5260 - val_loss: 0.6908 - val_accuracy: 0.5186\n",
      "Epoch 97/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6897 - accuracy: 0.5257 - val_loss: 0.6907 - val_accuracy: 0.5161\n",
      "Epoch 98/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6897 - accuracy: 0.5272 - val_loss: 0.6909 - val_accuracy: 0.5163\n",
      "Epoch 99/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6898 - accuracy: 0.5266 - val_loss: 0.6906 - val_accuracy: 0.5156\n",
      "Epoch 100/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6897 - accuracy: 0.5268 - val_loss: 0.6905 - val_accuracy: 0.5162\n",
      "Epoch 101/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6896 - accuracy: 0.5260 - val_loss: 0.6906 - val_accuracy: 0.5194\n",
      "Epoch 102/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6896 - accuracy: 0.5253 - val_loss: 0.6905 - val_accuracy: 0.5176\n",
      "Epoch 103/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6895 - accuracy: 0.5274 - val_loss: 0.6905 - val_accuracy: 0.5183\n",
      "Epoch 104/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6896 - accuracy: 0.5272 - val_loss: 0.6905 - val_accuracy: 0.5158\n",
      "Epoch 105/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6896 - accuracy: 0.5267 - val_loss: 0.6908 - val_accuracy: 0.5191\n",
      "Epoch 106/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6896 - accuracy: 0.5253 - val_loss: 0.6904 - val_accuracy: 0.5183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6897 - accuracy: 0.5259 - val_loss: 0.6906 - val_accuracy: 0.5168\n",
      "Training with significance = 6.91, run 8\n",
      "Train on 41963 samples, validate on 10491 samples\n",
      "Epoch 1/1000\n",
      "41963/41963 [==============================] - 1s 27us/sample - loss: 0.6939 - accuracy: 0.5020 - val_loss: 0.6918 - val_accuracy: 0.5115\n",
      "Epoch 2/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6919 - accuracy: 0.5165 - val_loss: 0.6908 - val_accuracy: 0.5222\n",
      "Epoch 3/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6914 - accuracy: 0.5187 - val_loss: 0.6907 - val_accuracy: 0.5248\n",
      "Epoch 4/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5211 - val_loss: 0.6904 - val_accuracy: 0.5256\n",
      "Epoch 5/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5188 - val_loss: 0.6904 - val_accuracy: 0.5229\n",
      "Epoch 6/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5189 - val_loss: 0.6904 - val_accuracy: 0.5176\n",
      "Epoch 7/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5185 - val_loss: 0.6903 - val_accuracy: 0.5236\n",
      "Epoch 8/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6910 - accuracy: 0.5198 - val_loss: 0.6903 - val_accuracy: 0.5216\n",
      "Epoch 9/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5217 - val_loss: 0.6902 - val_accuracy: 0.5209\n",
      "Epoch 10/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5211 - val_loss: 0.6901 - val_accuracy: 0.5221\n",
      "Epoch 11/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5200 - val_loss: 0.6904 - val_accuracy: 0.5167\n",
      "Epoch 12/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5205 - val_loss: 0.6903 - val_accuracy: 0.5225\n",
      "Epoch 13/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5213 - val_loss: 0.6901 - val_accuracy: 0.5210\n",
      "Epoch 14/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5222 - val_loss: 0.6901 - val_accuracy: 0.5217\n",
      "Epoch 15/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5200 - val_loss: 0.6903 - val_accuracy: 0.5237\n",
      "Epoch 16/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6907 - accuracy: 0.5197 - val_loss: 0.6899 - val_accuracy: 0.5254\n",
      "Epoch 17/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6907 - accuracy: 0.5196 - val_loss: 0.6901 - val_accuracy: 0.5262\n",
      "Epoch 18/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5205 - val_loss: 0.6901 - val_accuracy: 0.5217\n",
      "Epoch 19/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5193 - val_loss: 0.6900 - val_accuracy: 0.5230\n",
      "Epoch 20/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5188 - val_loss: 0.6900 - val_accuracy: 0.5241\n",
      "Epoch 21/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5215 - val_loss: 0.6899 - val_accuracy: 0.5246\n",
      "Epoch 22/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5206 - val_loss: 0.6901 - val_accuracy: 0.5227\n",
      "Epoch 23/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5197 - val_loss: 0.6900 - val_accuracy: 0.5248\n",
      "Epoch 24/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5213 - val_loss: 0.6901 - val_accuracy: 0.5233\n",
      "Epoch 25/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5193 - val_loss: 0.6900 - val_accuracy: 0.5261\n",
      "Epoch 26/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5208 - val_loss: 0.6899 - val_accuracy: 0.5249\n",
      "Epoch 27/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5218 - val_loss: 0.6901 - val_accuracy: 0.5267\n",
      "Epoch 28/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5197 - val_loss: 0.6900 - val_accuracy: 0.5249\n",
      "Epoch 29/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5213 - val_loss: 0.6900 - val_accuracy: 0.5201\n",
      "Epoch 30/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6904 - accuracy: 0.5201 - val_loss: 0.6898 - val_accuracy: 0.5284\n",
      "Epoch 31/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6904 - accuracy: 0.5223 - val_loss: 0.6901 - val_accuracy: 0.5263\n",
      "Epoch 32/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5205 - val_loss: 0.6900 - val_accuracy: 0.5247\n",
      "Epoch 33/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5220 - val_loss: 0.6900 - val_accuracy: 0.5228\n",
      "Epoch 34/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6902 - accuracy: 0.5223 - val_loss: 0.6899 - val_accuracy: 0.5271\n",
      "Epoch 35/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5234 - val_loss: 0.6899 - val_accuracy: 0.5234\n",
      "Epoch 36/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5208 - val_loss: 0.6898 - val_accuracy: 0.5222\n",
      "Epoch 37/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5203 - val_loss: 0.6899 - val_accuracy: 0.5233\n",
      "Epoch 38/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6902 - accuracy: 0.5216 - val_loss: 0.6902 - val_accuracy: 0.5200\n",
      "Epoch 39/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6901 - accuracy: 0.5222 - val_loss: 0.6898 - val_accuracy: 0.5261\n",
      "Epoch 40/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5235 - val_loss: 0.6900 - val_accuracy: 0.5264\n",
      "Epoch 41/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6903 - accuracy: 0.5223 - val_loss: 0.6900 - val_accuracy: 0.5261\n",
      "Epoch 42/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5219 - val_loss: 0.6898 - val_accuracy: 0.5250\n",
      "Epoch 43/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5228 - val_loss: 0.6899 - val_accuracy: 0.5230\n",
      "Epoch 44/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6902 - accuracy: 0.5211 - val_loss: 0.6899 - val_accuracy: 0.5238\n",
      "Epoch 45/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6901 - accuracy: 0.5225 - val_loss: 0.6897 - val_accuracy: 0.5222\n",
      "Epoch 46/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6902 - accuracy: 0.5208 - val_loss: 0.6900 - val_accuracy: 0.5244\n",
      "Epoch 47/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5245 - val_loss: 0.6898 - val_accuracy: 0.5213\n",
      "Epoch 48/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6901 - accuracy: 0.5228 - val_loss: 0.6896 - val_accuracy: 0.5225\n",
      "Epoch 49/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5232 - val_loss: 0.6896 - val_accuracy: 0.5233\n",
      "Epoch 50/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6901 - accuracy: 0.5233 - val_loss: 0.6898 - val_accuracy: 0.5276\n",
      "Epoch 51/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6903 - accuracy: 0.5227 - val_loss: 0.6897 - val_accuracy: 0.5260\n",
      "Epoch 52/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6902 - accuracy: 0.5219 - val_loss: 0.6898 - val_accuracy: 0.5224\n",
      "Epoch 53/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5219 - val_loss: 0.6899 - val_accuracy: 0.5245\n",
      "Epoch 54/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6901 - accuracy: 0.5232 - val_loss: 0.6897 - val_accuracy: 0.5237\n",
      "Epoch 55/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6900 - accuracy: 0.5250 - val_loss: 0.6898 - val_accuracy: 0.5225\n",
      "Epoch 56/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5251 - val_loss: 0.6898 - val_accuracy: 0.5235\n",
      "Epoch 57/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5243 - val_loss: 0.6898 - val_accuracy: 0.5242\n",
      "Epoch 58/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6900 - accuracy: 0.5233 - val_loss: 0.6901 - val_accuracy: 0.5159\n",
      "Epoch 59/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6899 - accuracy: 0.5250 - val_loss: 0.6897 - val_accuracy: 0.5239\n",
      "Epoch 60/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5252 - val_loss: 0.6899 - val_accuracy: 0.5203\n",
      "Epoch 61/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5224 - val_loss: 0.6900 - val_accuracy: 0.5231\n",
      "Epoch 62/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6901 - accuracy: 0.5240 - val_loss: 0.6901 - val_accuracy: 0.5208\n",
      "Epoch 63/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6900 - accuracy: 0.5227 - val_loss: 0.6897 - val_accuracy: 0.5257\n",
      "Epoch 64/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6898 - accuracy: 0.5254 - val_loss: 0.6898 - val_accuracy: 0.5231\n",
      "Epoch 65/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5253 - val_loss: 0.6897 - val_accuracy: 0.5246\n",
      "Epoch 66/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6899 - accuracy: 0.5240 - val_loss: 0.6897 - val_accuracy: 0.5242\n",
      "Epoch 67/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6899 - accuracy: 0.5248 - val_loss: 0.6899 - val_accuracy: 0.5231\n",
      "Epoch 68/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6900 - accuracy: 0.5238 - val_loss: 0.6899 - val_accuracy: 0.5244\n",
      "Epoch 69/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6900 - accuracy: 0.5226 - val_loss: 0.6901 - val_accuracy: 0.5230\n",
      "Epoch 70/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6898 - accuracy: 0.5240 - val_loss: 0.6898 - val_accuracy: 0.5218\n",
      "Epoch 71/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6899 - accuracy: 0.5259 - val_loss: 0.6900 - val_accuracy: 0.5216\n",
      "Epoch 72/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6900 - accuracy: 0.5241 - val_loss: 0.6900 - val_accuracy: 0.5216\n",
      "Epoch 73/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6898 - accuracy: 0.5256 - val_loss: 0.6897 - val_accuracy: 0.5252\n",
      "Epoch 74/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6899 - accuracy: 0.5244 - val_loss: 0.6898 - val_accuracy: 0.5250\n",
      "Epoch 75/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6899 - accuracy: 0.5233 - val_loss: 0.6899 - val_accuracy: 0.5202\n",
      "Epoch 76/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5243 - val_loss: 0.6897 - val_accuracy: 0.5258\n",
      "Epoch 77/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6898 - accuracy: 0.5243 - val_loss: 0.6898 - val_accuracy: 0.5240\n",
      "Epoch 78/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6898 - accuracy: 0.5240 - val_loss: 0.6897 - val_accuracy: 0.5248\n",
      "Epoch 79/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5246 - val_loss: 0.6898 - val_accuracy: 0.5248\n",
      "Training with significance = 6.91, run 9\n",
      "Train on 41963 samples, validate on 10491 samples\n",
      "Epoch 1/1000\n",
      "41963/41963 [==============================] - 1s 26us/sample - loss: 0.6923 - accuracy: 0.5146 - val_loss: 0.6944 - val_accuracy: 0.5040\n",
      "Epoch 2/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6915 - accuracy: 0.5211 - val_loss: 0.6918 - val_accuracy: 0.5062\n",
      "Epoch 3/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6915 - accuracy: 0.5211 - val_loss: 0.6916 - val_accuracy: 0.5118\n",
      "Epoch 4/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5222 - val_loss: 0.6916 - val_accuracy: 0.5115\n",
      "Epoch 5/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5215 - val_loss: 0.6913 - val_accuracy: 0.5132\n",
      "Epoch 6/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5217 - val_loss: 0.6913 - val_accuracy: 0.5155\n",
      "Epoch 7/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5230 - val_loss: 0.6917 - val_accuracy: 0.5127\n",
      "Epoch 8/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5222 - val_loss: 0.6917 - val_accuracy: 0.5114\n",
      "Epoch 9/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5232 - val_loss: 0.6912 - val_accuracy: 0.5178\n",
      "Epoch 10/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5225 - val_loss: 0.6913 - val_accuracy: 0.5156\n",
      "Epoch 11/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6909 - accuracy: 0.5230 - val_loss: 0.6915 - val_accuracy: 0.5123\n",
      "Epoch 12/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6908 - accuracy: 0.5229 - val_loss: 0.6914 - val_accuracy: 0.5126\n",
      "Epoch 13/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6907 - accuracy: 0.5235 - val_loss: 0.6910 - val_accuracy: 0.5163\n",
      "Epoch 14/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5227 - val_loss: 0.6915 - val_accuracy: 0.5103\n",
      "Epoch 15/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5221 - val_loss: 0.6913 - val_accuracy: 0.5124\n",
      "Epoch 16/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5237 - val_loss: 0.6914 - val_accuracy: 0.5111\n",
      "Epoch 17/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6908 - accuracy: 0.5241 - val_loss: 0.6914 - val_accuracy: 0.5116\n",
      "Epoch 18/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6907 - accuracy: 0.5237 - val_loss: 0.6917 - val_accuracy: 0.5105\n",
      "Epoch 19/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5206 - val_loss: 0.6918 - val_accuracy: 0.5092\n",
      "Epoch 20/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5241 - val_loss: 0.6913 - val_accuracy: 0.5123\n",
      "Epoch 21/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5240 - val_loss: 0.6915 - val_accuracy: 0.5105\n",
      "Epoch 22/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5231 - val_loss: 0.6913 - val_accuracy: 0.5113\n",
      "Epoch 23/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5241 - val_loss: 0.6912 - val_accuracy: 0.5119\n",
      "Epoch 24/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5239 - val_loss: 0.6914 - val_accuracy: 0.5102\n",
      "Epoch 25/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5236 - val_loss: 0.6912 - val_accuracy: 0.5124\n",
      "Epoch 26/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5233 - val_loss: 0.6916 - val_accuracy: 0.5093\n",
      "Epoch 27/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5240 - val_loss: 0.6916 - val_accuracy: 0.5107\n",
      "Epoch 28/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5222 - val_loss: 0.6913 - val_accuracy: 0.5110\n",
      "Epoch 29/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5214 - val_loss: 0.6914 - val_accuracy: 0.5086\n",
      "Epoch 30/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6904 - accuracy: 0.5231 - val_loss: 0.6911 - val_accuracy: 0.5142\n",
      "Epoch 31/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5248 - val_loss: 0.6913 - val_accuracy: 0.5106\n",
      "Epoch 32/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5233 - val_loss: 0.6914 - val_accuracy: 0.5113\n",
      "Epoch 33/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5233 - val_loss: 0.6914 - val_accuracy: 0.5114\n",
      "Epoch 34/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5226 - val_loss: 0.6916 - val_accuracy: 0.5086\n",
      "Epoch 35/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5244 - val_loss: 0.6915 - val_accuracy: 0.5114\n",
      "Epoch 36/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6904 - accuracy: 0.5236 - val_loss: 0.6912 - val_accuracy: 0.5103\n",
      "Epoch 37/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6904 - accuracy: 0.5236 - val_loss: 0.6917 - val_accuracy: 0.5101\n",
      "Epoch 38/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6904 - accuracy: 0.5224 - val_loss: 0.6918 - val_accuracy: 0.5105\n",
      "Epoch 39/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6904 - accuracy: 0.5227 - val_loss: 0.6912 - val_accuracy: 0.5116\n",
      "Epoch 40/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6903 - accuracy: 0.5240 - val_loss: 0.6913 - val_accuracy: 0.5097\n",
      "Epoch 41/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6903 - accuracy: 0.5260 - val_loss: 0.6913 - val_accuracy: 0.5118\n",
      "Epoch 42/1000\n",
      "41963/41963 [==============================] - 1s 12us/sample - loss: 0.6903 - accuracy: 0.5235 - val_loss: 0.6911 - val_accuracy: 0.5122\n",
      "Epoch 43/1000\n",
      "41963/41963 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5245 - val_loss: 0.6913 - val_accuracy: 0.5087\n",
      "Training with significance = 7.53, run 0\n",
      "Train on 42064 samples, validate on 10516 samples\n",
      "Epoch 1/1000\n",
      "42064/42064 [==============================] - 1s 26us/sample - loss: 0.6926 - accuracy: 0.5112 - val_loss: 0.6988 - val_accuracy: 0.5007\n",
      "Epoch 2/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5181 - val_loss: 0.6942 - val_accuracy: 0.5114\n",
      "Epoch 3/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5188 - val_loss: 0.6928 - val_accuracy: 0.5126\n",
      "Epoch 4/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5206 - val_loss: 0.6925 - val_accuracy: 0.5146\n",
      "Epoch 5/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5192 - val_loss: 0.6922 - val_accuracy: 0.5151\n",
      "Epoch 6/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5194 - val_loss: 0.6920 - val_accuracy: 0.5175\n",
      "Epoch 7/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5195 - val_loss: 0.6922 - val_accuracy: 0.5148\n",
      "Epoch 8/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5193 - val_loss: 0.6920 - val_accuracy: 0.5104\n",
      "Epoch 9/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5230 - val_loss: 0.6917 - val_accuracy: 0.5139\n",
      "Epoch 10/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5201 - val_loss: 0.6917 - val_accuracy: 0.5158\n",
      "Epoch 11/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6904 - accuracy: 0.5212 - val_loss: 0.6920 - val_accuracy: 0.5083\n",
      "Epoch 12/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5204 - val_loss: 0.6919 - val_accuracy: 0.5134\n",
      "Epoch 13/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6903 - accuracy: 0.5218 - val_loss: 0.6918 - val_accuracy: 0.5184\n",
      "Epoch 14/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5194 - val_loss: 0.6916 - val_accuracy: 0.5125\n",
      "Epoch 15/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6902 - accuracy: 0.5238 - val_loss: 0.6920 - val_accuracy: 0.5092\n",
      "Epoch 16/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5204 - val_loss: 0.6917 - val_accuracy: 0.5173\n",
      "Epoch 17/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5225 - val_loss: 0.6918 - val_accuracy: 0.5155\n",
      "Epoch 18/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5206 - val_loss: 0.6918 - val_accuracy: 0.5157\n",
      "Epoch 19/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5209 - val_loss: 0.6920 - val_accuracy: 0.5185\n",
      "Epoch 20/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5218 - val_loss: 0.6919 - val_accuracy: 0.5140\n",
      "Epoch 21/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5226 - val_loss: 0.6918 - val_accuracy: 0.5164\n",
      "Epoch 22/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6901 - accuracy: 0.5213 - val_loss: 0.6918 - val_accuracy: 0.5140\n",
      "Epoch 23/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5210 - val_loss: 0.6917 - val_accuracy: 0.5152\n",
      "Epoch 24/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5215 - val_loss: 0.6919 - val_accuracy: 0.5163\n",
      "Epoch 25/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6898 - accuracy: 0.5230 - val_loss: 0.6916 - val_accuracy: 0.5194\n",
      "Epoch 26/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5201 - val_loss: 0.6917 - val_accuracy: 0.5164\n",
      "Epoch 27/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6900 - accuracy: 0.5230 - val_loss: 0.6918 - val_accuracy: 0.5160\n",
      "Epoch 28/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6901 - accuracy: 0.5199 - val_loss: 0.6918 - val_accuracy: 0.5149\n",
      "Epoch 29/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6899 - accuracy: 0.5211 - val_loss: 0.6917 - val_accuracy: 0.5179\n",
      "Epoch 30/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6899 - accuracy: 0.5213 - val_loss: 0.6918 - val_accuracy: 0.5131\n",
      "Epoch 31/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6898 - accuracy: 0.5213 - val_loss: 0.6918 - val_accuracy: 0.5147\n",
      "Epoch 32/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6898 - accuracy: 0.5220 - val_loss: 0.6919 - val_accuracy: 0.5169\n",
      "Epoch 33/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6898 - accuracy: 0.5225 - val_loss: 0.6922 - val_accuracy: 0.5118\n",
      "Epoch 34/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5233 - val_loss: 0.6917 - val_accuracy: 0.5133\n",
      "Epoch 35/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6897 - accuracy: 0.5246 - val_loss: 0.6919 - val_accuracy: 0.5162\n",
      "Epoch 36/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6897 - accuracy: 0.5234 - val_loss: 0.6919 - val_accuracy: 0.5159\n",
      "Epoch 37/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6897 - accuracy: 0.5222 - val_loss: 0.6919 - val_accuracy: 0.5169\n",
      "Epoch 38/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6898 - accuracy: 0.5235 - val_loss: 0.6919 - val_accuracy: 0.5142\n",
      "Epoch 39/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6897 - accuracy: 0.5235 - val_loss: 0.6919 - val_accuracy: 0.5162\n",
      "Epoch 40/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6898 - accuracy: 0.5210 - val_loss: 0.6917 - val_accuracy: 0.5167\n",
      "Epoch 41/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6897 - accuracy: 0.5219 - val_loss: 0.6921 - val_accuracy: 0.5134\n",
      "Epoch 42/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6896 - accuracy: 0.5248 - val_loss: 0.6918 - val_accuracy: 0.5146\n",
      "Epoch 43/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6897 - accuracy: 0.5234 - val_loss: 0.6918 - val_accuracy: 0.5156\n",
      "Epoch 44/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6897 - accuracy: 0.5221 - val_loss: 0.6920 - val_accuracy: 0.5145\n",
      "Training with significance = 7.53, run 1\n",
      "Train on 42064 samples, validate on 10516 samples\n",
      "Epoch 1/1000\n",
      "42064/42064 [==============================] - 1s 27us/sample - loss: 0.6926 - accuracy: 0.5094 - val_loss: 0.6927 - val_accuracy: 0.5072\n",
      "Epoch 2/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5178 - val_loss: 0.6913 - val_accuracy: 0.5140\n",
      "Epoch 3/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5206 - val_loss: 0.6906 - val_accuracy: 0.5188\n",
      "Epoch 4/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5199 - val_loss: 0.6901 - val_accuracy: 0.5241\n",
      "Epoch 5/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5189 - val_loss: 0.6900 - val_accuracy: 0.5227\n",
      "Epoch 6/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5197 - val_loss: 0.6898 - val_accuracy: 0.5225\n",
      "Epoch 7/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6907 - accuracy: 0.5208 - val_loss: 0.6899 - val_accuracy: 0.5207\n",
      "Epoch 8/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5203 - val_loss: 0.6898 - val_accuracy: 0.5243\n",
      "Epoch 9/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5206 - val_loss: 0.6898 - val_accuracy: 0.5236\n",
      "Epoch 10/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5217 - val_loss: 0.6897 - val_accuracy: 0.5216\n",
      "Epoch 11/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5197 - val_loss: 0.6898 - val_accuracy: 0.5223\n",
      "Epoch 12/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5233 - val_loss: 0.6897 - val_accuracy: 0.5230\n",
      "Epoch 13/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5218 - val_loss: 0.6898 - val_accuracy: 0.5248\n",
      "Epoch 14/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5223 - val_loss: 0.6898 - val_accuracy: 0.5243\n",
      "Epoch 15/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5232 - val_loss: 0.6898 - val_accuracy: 0.5235\n",
      "Epoch 16/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5222 - val_loss: 0.6896 - val_accuracy: 0.5228\n",
      "Epoch 17/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5230 - val_loss: 0.6897 - val_accuracy: 0.5222\n",
      "Epoch 18/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5231 - val_loss: 0.6897 - val_accuracy: 0.5225\n",
      "Epoch 19/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5201 - val_loss: 0.6896 - val_accuracy: 0.5242\n",
      "Epoch 20/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6903 - accuracy: 0.5215 - val_loss: 0.6897 - val_accuracy: 0.5236\n",
      "Epoch 21/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5216 - val_loss: 0.6897 - val_accuracy: 0.5244\n",
      "Epoch 22/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5223 - val_loss: 0.6896 - val_accuracy: 0.5239\n",
      "Epoch 23/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6903 - accuracy: 0.5215 - val_loss: 0.6896 - val_accuracy: 0.5241\n",
      "Epoch 24/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5219 - val_loss: 0.6897 - val_accuracy: 0.5247\n",
      "Epoch 25/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5235 - val_loss: 0.6897 - val_accuracy: 0.5227\n",
      "Epoch 26/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5229 - val_loss: 0.6896 - val_accuracy: 0.5255\n",
      "Epoch 27/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5236 - val_loss: 0.6897 - val_accuracy: 0.5244\n",
      "Epoch 28/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5239 - val_loss: 0.6896 - val_accuracy: 0.5242\n",
      "Epoch 29/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5231 - val_loss: 0.6897 - val_accuracy: 0.5233\n",
      "Epoch 30/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6901 - accuracy: 0.5225 - val_loss: 0.6897 - val_accuracy: 0.5233\n",
      "Epoch 31/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5238 - val_loss: 0.6895 - val_accuracy: 0.5248\n",
      "Epoch 32/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6901 - accuracy: 0.5233 - val_loss: 0.6897 - val_accuracy: 0.5243\n",
      "Epoch 33/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5238 - val_loss: 0.6897 - val_accuracy: 0.5242\n",
      "Epoch 34/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6902 - accuracy: 0.5233 - val_loss: 0.6898 - val_accuracy: 0.5247\n",
      "Epoch 35/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6899 - accuracy: 0.5238 - val_loss: 0.6896 - val_accuracy: 0.5242\n",
      "Epoch 36/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6899 - accuracy: 0.5246 - val_loss: 0.6897 - val_accuracy: 0.5213\n",
      "Epoch 37/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6898 - accuracy: 0.5254 - val_loss: 0.6898 - val_accuracy: 0.5219\n",
      "Epoch 38/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6899 - accuracy: 0.5231 - val_loss: 0.6896 - val_accuracy: 0.5237\n",
      "Epoch 39/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5240 - val_loss: 0.6896 - val_accuracy: 0.5231\n",
      "Epoch 40/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5248 - val_loss: 0.6896 - val_accuracy: 0.5250\n",
      "Epoch 41/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5244 - val_loss: 0.6896 - val_accuracy: 0.5242\n",
      "Epoch 42/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5242 - val_loss: 0.6897 - val_accuracy: 0.5224\n",
      "Epoch 43/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6900 - accuracy: 0.5240 - val_loss: 0.6897 - val_accuracy: 0.5233\n",
      "Epoch 44/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5251 - val_loss: 0.6896 - val_accuracy: 0.5255\n",
      "Epoch 45/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6897 - accuracy: 0.5243 - val_loss: 0.6897 - val_accuracy: 0.5234\n",
      "Epoch 46/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5252 - val_loss: 0.6897 - val_accuracy: 0.5233\n",
      "Epoch 47/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6899 - accuracy: 0.5237 - val_loss: 0.6897 - val_accuracy: 0.5246\n",
      "Epoch 48/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6898 - accuracy: 0.5269 - val_loss: 0.6896 - val_accuracy: 0.5220\n",
      "Epoch 49/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6898 - accuracy: 0.5261 - val_loss: 0.6896 - val_accuracy: 0.5257\n",
      "Epoch 50/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6898 - accuracy: 0.5254 - val_loss: 0.6897 - val_accuracy: 0.5239\n",
      "Epoch 51/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5256 - val_loss: 0.6896 - val_accuracy: 0.5256\n",
      "Epoch 52/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6898 - accuracy: 0.5262 - val_loss: 0.6896 - val_accuracy: 0.5239\n",
      "Epoch 53/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6897 - accuracy: 0.5269 - val_loss: 0.6898 - val_accuracy: 0.5223\n",
      "Epoch 54/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6898 - accuracy: 0.5263 - val_loss: 0.6897 - val_accuracy: 0.5245\n",
      "Epoch 55/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6897 - accuracy: 0.5247 - val_loss: 0.6897 - val_accuracy: 0.5220\n",
      "Epoch 56/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6898 - accuracy: 0.5255 - val_loss: 0.6897 - val_accuracy: 0.5240\n",
      "Epoch 57/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6898 - accuracy: 0.5251 - val_loss: 0.6896 - val_accuracy: 0.5251\n",
      "Epoch 58/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6897 - accuracy: 0.5245 - val_loss: 0.6899 - val_accuracy: 0.5212\n",
      "Epoch 59/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6896 - accuracy: 0.5251 - val_loss: 0.6896 - val_accuracy: 0.5251\n",
      "Epoch 60/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6897 - accuracy: 0.5256 - val_loss: 0.6896 - val_accuracy: 0.5230\n",
      "Epoch 61/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6897 - accuracy: 0.5248 - val_loss: 0.6896 - val_accuracy: 0.5245\n",
      "Training with significance = 7.53, run 2\n",
      "Train on 42064 samples, validate on 10516 samples\n",
      "Epoch 1/1000\n",
      "42064/42064 [==============================] - 1s 27us/sample - loss: 0.6945 - accuracy: 0.5088 - val_loss: 0.6929 - val_accuracy: 0.5093\n",
      "Epoch 2/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6916 - accuracy: 0.5185 - val_loss: 0.6922 - val_accuracy: 0.5186\n",
      "Epoch 3/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5189 - val_loss: 0.6921 - val_accuracy: 0.5147\n",
      "Epoch 4/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5192 - val_loss: 0.6917 - val_accuracy: 0.5187\n",
      "Epoch 5/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5195 - val_loss: 0.6915 - val_accuracy: 0.5172\n",
      "Epoch 6/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5206 - val_loss: 0.6914 - val_accuracy: 0.5177\n",
      "Epoch 7/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5195 - val_loss: 0.6914 - val_accuracy: 0.5156\n",
      "Epoch 8/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5207 - val_loss: 0.6915 - val_accuracy: 0.5201\n",
      "Epoch 9/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5232 - val_loss: 0.6913 - val_accuracy: 0.5182\n",
      "Epoch 10/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5206 - val_loss: 0.6912 - val_accuracy: 0.5168\n",
      "Epoch 11/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5216 - val_loss: 0.6913 - val_accuracy: 0.5206\n",
      "Epoch 12/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5220 - val_loss: 0.6913 - val_accuracy: 0.5208\n",
      "Epoch 13/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5216 - val_loss: 0.6913 - val_accuracy: 0.5182\n",
      "Epoch 14/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5228 - val_loss: 0.6912 - val_accuracy: 0.5167\n",
      "Epoch 15/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5228 - val_loss: 0.6913 - val_accuracy: 0.5171\n",
      "Epoch 16/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5233 - val_loss: 0.6911 - val_accuracy: 0.5184\n",
      "Epoch 17/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6907 - accuracy: 0.5210 - val_loss: 0.6912 - val_accuracy: 0.5198\n",
      "Epoch 18/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5239 - val_loss: 0.6912 - val_accuracy: 0.5198\n",
      "Epoch 19/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5237 - val_loss: 0.6911 - val_accuracy: 0.5189\n",
      "Epoch 20/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5214 - val_loss: 0.6911 - val_accuracy: 0.5203\n",
      "Epoch 21/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5220 - val_loss: 0.6911 - val_accuracy: 0.5203\n",
      "Epoch 22/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5226 - val_loss: 0.6911 - val_accuracy: 0.5175\n",
      "Epoch 23/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5227 - val_loss: 0.6912 - val_accuracy: 0.5165\n",
      "Epoch 24/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5238 - val_loss: 0.6912 - val_accuracy: 0.5199\n",
      "Epoch 25/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6904 - accuracy: 0.5241 - val_loss: 0.6912 - val_accuracy: 0.5199\n",
      "Epoch 26/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6903 - accuracy: 0.5243 - val_loss: 0.6912 - val_accuracy: 0.5203\n",
      "Epoch 27/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5233 - val_loss: 0.6911 - val_accuracy: 0.5165\n",
      "Epoch 28/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5242 - val_loss: 0.6910 - val_accuracy: 0.5191\n",
      "Epoch 29/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5236 - val_loss: 0.6912 - val_accuracy: 0.5202\n",
      "Epoch 30/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5238 - val_loss: 0.6911 - val_accuracy: 0.5199\n",
      "Epoch 31/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5263 - val_loss: 0.6911 - val_accuracy: 0.5170\n",
      "Epoch 32/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5231 - val_loss: 0.6911 - val_accuracy: 0.5185\n",
      "Epoch 33/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5251 - val_loss: 0.6911 - val_accuracy: 0.5209\n",
      "Epoch 34/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5243 - val_loss: 0.6911 - val_accuracy: 0.5197\n",
      "Epoch 35/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5246 - val_loss: 0.6910 - val_accuracy: 0.5177\n",
      "Epoch 36/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5249 - val_loss: 0.6911 - val_accuracy: 0.5209\n",
      "Epoch 37/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5251 - val_loss: 0.6910 - val_accuracy: 0.5192\n",
      "Epoch 38/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5259 - val_loss: 0.6912 - val_accuracy: 0.5173\n",
      "Epoch 39/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5235 - val_loss: 0.6911 - val_accuracy: 0.5193\n",
      "Epoch 40/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6903 - accuracy: 0.5252 - val_loss: 0.6911 - val_accuracy: 0.5176\n",
      "Epoch 41/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6902 - accuracy: 0.5258 - val_loss: 0.6911 - val_accuracy: 0.5200\n",
      "Epoch 42/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6900 - accuracy: 0.5255 - val_loss: 0.6910 - val_accuracy: 0.5163\n",
      "Epoch 43/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5255 - val_loss: 0.6910 - val_accuracy: 0.5150\n",
      "Epoch 44/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5267 - val_loss: 0.6910 - val_accuracy: 0.5159\n",
      "Epoch 45/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5255 - val_loss: 0.6910 - val_accuracy: 0.5183\n",
      "Epoch 46/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6902 - accuracy: 0.5258 - val_loss: 0.6910 - val_accuracy: 0.5192\n",
      "Epoch 47/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6901 - accuracy: 0.5267 - val_loss: 0.6910 - val_accuracy: 0.5180\n",
      "Epoch 48/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5258 - val_loss: 0.6910 - val_accuracy: 0.5189\n",
      "Epoch 49/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5259 - val_loss: 0.6913 - val_accuracy: 0.5202\n",
      "Epoch 50/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6903 - accuracy: 0.5255 - val_loss: 0.6911 - val_accuracy: 0.5196\n",
      "Epoch 51/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5262 - val_loss: 0.6909 - val_accuracy: 0.5174\n",
      "Epoch 52/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6901 - accuracy: 0.5254 - val_loss: 0.6910 - val_accuracy: 0.5200\n",
      "Epoch 53/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5255 - val_loss: 0.6911 - val_accuracy: 0.5178\n",
      "Epoch 54/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5266 - val_loss: 0.6912 - val_accuracy: 0.5196\n",
      "Epoch 55/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6900 - accuracy: 0.5283 - val_loss: 0.6910 - val_accuracy: 0.5168\n",
      "Epoch 56/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5269 - val_loss: 0.6911 - val_accuracy: 0.5214\n",
      "Epoch 57/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6900 - accuracy: 0.5265 - val_loss: 0.6911 - val_accuracy: 0.5159\n",
      "Epoch 58/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5255 - val_loss: 0.6910 - val_accuracy: 0.5162\n",
      "Epoch 59/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5273 - val_loss: 0.6912 - val_accuracy: 0.5182\n",
      "Epoch 60/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5273 - val_loss: 0.6912 - val_accuracy: 0.5186\n",
      "Epoch 61/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6900 - accuracy: 0.5261 - val_loss: 0.6910 - val_accuracy: 0.5171\n",
      "Epoch 62/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5275 - val_loss: 0.6910 - val_accuracy: 0.5162\n",
      "Epoch 63/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5275 - val_loss: 0.6909 - val_accuracy: 0.5159\n",
      "Epoch 64/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5258 - val_loss: 0.6910 - val_accuracy: 0.5193\n",
      "Epoch 65/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5284 - val_loss: 0.6911 - val_accuracy: 0.5184\n",
      "Epoch 66/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5279 - val_loss: 0.6910 - val_accuracy: 0.5179\n",
      "Epoch 67/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5252 - val_loss: 0.6911 - val_accuracy: 0.5163\n",
      "Epoch 68/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5254 - val_loss: 0.6912 - val_accuracy: 0.5201\n",
      "Epoch 69/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6899 - accuracy: 0.5286 - val_loss: 0.6910 - val_accuracy: 0.5182\n",
      "Epoch 70/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5277 - val_loss: 0.6911 - val_accuracy: 0.5171\n",
      "Epoch 71/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5271 - val_loss: 0.6909 - val_accuracy: 0.5165\n",
      "Epoch 72/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5275 - val_loss: 0.6910 - val_accuracy: 0.5161\n",
      "Epoch 73/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5252 - val_loss: 0.6913 - val_accuracy: 0.5226\n",
      "Epoch 74/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6898 - accuracy: 0.5274 - val_loss: 0.6910 - val_accuracy: 0.5168\n",
      "Epoch 75/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6897 - accuracy: 0.5283 - val_loss: 0.6911 - val_accuracy: 0.5180\n",
      "Epoch 76/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6898 - accuracy: 0.5276 - val_loss: 0.6911 - val_accuracy: 0.5171\n",
      "Epoch 77/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6897 - accuracy: 0.5271 - val_loss: 0.6911 - val_accuracy: 0.5163\n",
      "Epoch 78/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6898 - accuracy: 0.5271 - val_loss: 0.6911 - val_accuracy: 0.5199\n",
      "Epoch 79/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6898 - accuracy: 0.5283 - val_loss: 0.6910 - val_accuracy: 0.5161\n",
      "Epoch 80/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6898 - accuracy: 0.5267 - val_loss: 0.6910 - val_accuracy: 0.5177\n",
      "Epoch 81/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5272 - val_loss: 0.6912 - val_accuracy: 0.5200\n",
      "Epoch 82/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5267 - val_loss: 0.6910 - val_accuracy: 0.5148\n",
      "Epoch 83/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5259 - val_loss: 0.6909 - val_accuracy: 0.5189\n",
      "Epoch 84/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6898 - accuracy: 0.5252 - val_loss: 0.6910 - val_accuracy: 0.5177\n",
      "Epoch 85/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6898 - accuracy: 0.5276 - val_loss: 0.6910 - val_accuracy: 0.5176\n",
      "Epoch 86/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6898 - accuracy: 0.5268 - val_loss: 0.6910 - val_accuracy: 0.5159\n",
      "Epoch 87/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6897 - accuracy: 0.5299 - val_loss: 0.6910 - val_accuracy: 0.5161\n",
      "Epoch 88/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5262 - val_loss: 0.6909 - val_accuracy: 0.5187\n",
      "Epoch 89/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6897 - accuracy: 0.5301 - val_loss: 0.6911 - val_accuracy: 0.5201\n",
      "Epoch 90/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6897 - accuracy: 0.5275 - val_loss: 0.6910 - val_accuracy: 0.5165\n",
      "Epoch 91/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6898 - accuracy: 0.5301 - val_loss: 0.6911 - val_accuracy: 0.5193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6898 - accuracy: 0.5284 - val_loss: 0.6912 - val_accuracy: 0.5186\n",
      "Epoch 93/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6898 - accuracy: 0.5317 - val_loss: 0.6911 - val_accuracy: 0.5161\n",
      "Epoch 94/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6897 - accuracy: 0.5284 - val_loss: 0.6910 - val_accuracy: 0.5156\n",
      "Epoch 95/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6898 - accuracy: 0.5289 - val_loss: 0.6910 - val_accuracy: 0.5181\n",
      "Epoch 96/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6900 - accuracy: 0.5272 - val_loss: 0.6910 - val_accuracy: 0.5192\n",
      "Epoch 97/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6898 - accuracy: 0.5275 - val_loss: 0.6911 - val_accuracy: 0.5194\n",
      "Epoch 98/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6897 - accuracy: 0.5295 - val_loss: 0.6912 - val_accuracy: 0.5194\n",
      "Epoch 99/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6897 - accuracy: 0.5283 - val_loss: 0.6911 - val_accuracy: 0.5182\n",
      "Epoch 100/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6898 - accuracy: 0.5279 - val_loss: 0.6910 - val_accuracy: 0.5129\n",
      "Epoch 101/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6898 - accuracy: 0.5276 - val_loss: 0.6910 - val_accuracy: 0.5152\n",
      "Epoch 102/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6898 - accuracy: 0.5283 - val_loss: 0.6910 - val_accuracy: 0.5161\n",
      "Epoch 103/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6897 - accuracy: 0.5283 - val_loss: 0.6910 - val_accuracy: 0.5188\n",
      "Epoch 104/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6898 - accuracy: 0.5283 - val_loss: 0.6910 - val_accuracy: 0.5193\n",
      "Epoch 105/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6897 - accuracy: 0.5285 - val_loss: 0.6911 - val_accuracy: 0.5163\n",
      "Epoch 106/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6896 - accuracy: 0.5281 - val_loss: 0.6911 - val_accuracy: 0.5192\n",
      "Epoch 107/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6896 - accuracy: 0.5277 - val_loss: 0.6912 - val_accuracy: 0.5184\n",
      "Epoch 108/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6897 - accuracy: 0.5280 - val_loss: 0.6911 - val_accuracy: 0.5168\n",
      "Epoch 109/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6897 - accuracy: 0.5284 - val_loss: 0.6910 - val_accuracy: 0.5190\n",
      "Epoch 110/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6897 - accuracy: 0.5288 - val_loss: 0.6911 - val_accuracy: 0.5186\n",
      "Epoch 111/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6896 - accuracy: 0.5308 - val_loss: 0.6911 - val_accuracy: 0.5175\n",
      "Epoch 112/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6896 - accuracy: 0.5310 - val_loss: 0.6913 - val_accuracy: 0.5159\n",
      "Epoch 113/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6897 - accuracy: 0.5291 - val_loss: 0.6911 - val_accuracy: 0.5190\n",
      "Epoch 114/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6897 - accuracy: 0.5287 - val_loss: 0.6912 - val_accuracy: 0.5205\n",
      "Epoch 115/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6896 - accuracy: 0.5291 - val_loss: 0.6911 - val_accuracy: 0.5193\n",
      "Epoch 116/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6897 - accuracy: 0.5308 - val_loss: 0.6911 - val_accuracy: 0.5202\n",
      "Epoch 117/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6897 - accuracy: 0.5292 - val_loss: 0.6909 - val_accuracy: 0.5175\n",
      "Epoch 118/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6897 - accuracy: 0.5309 - val_loss: 0.6910 - val_accuracy: 0.5173\n",
      "Training with significance = 7.53, run 3\n",
      "Train on 42064 samples, validate on 10516 samples\n",
      "Epoch 1/1000\n",
      "42064/42064 [==============================] - 1s 26us/sample - loss: 0.6927 - accuracy: 0.5133 - val_loss: 0.6934 - val_accuracy: 0.4990\n",
      "Epoch 2/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6916 - accuracy: 0.5159 - val_loss: 0.6923 - val_accuracy: 0.5050\n",
      "Epoch 3/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5190 - val_loss: 0.6920 - val_accuracy: 0.5107\n",
      "Epoch 4/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5203 - val_loss: 0.6917 - val_accuracy: 0.5088\n",
      "Epoch 5/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5211 - val_loss: 0.6918 - val_accuracy: 0.5120\n",
      "Epoch 6/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5207 - val_loss: 0.6916 - val_accuracy: 0.5111\n",
      "Epoch 7/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6909 - accuracy: 0.5182 - val_loss: 0.6917 - val_accuracy: 0.5093\n",
      "Epoch 8/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5203 - val_loss: 0.6914 - val_accuracy: 0.5084\n",
      "Epoch 9/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5213 - val_loss: 0.6920 - val_accuracy: 0.5105\n",
      "Epoch 10/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5214 - val_loss: 0.6918 - val_accuracy: 0.5107\n",
      "Epoch 11/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5210 - val_loss: 0.6918 - val_accuracy: 0.5099\n",
      "Epoch 12/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5211 - val_loss: 0.6916 - val_accuracy: 0.5117\n",
      "Epoch 13/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5224 - val_loss: 0.6916 - val_accuracy: 0.5115\n",
      "Epoch 14/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5213 - val_loss: 0.6919 - val_accuracy: 0.5110\n",
      "Epoch 15/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6904 - accuracy: 0.5214 - val_loss: 0.6921 - val_accuracy: 0.5101\n",
      "Epoch 16/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6904 - accuracy: 0.5222 - val_loss: 0.6918 - val_accuracy: 0.5096\n",
      "Epoch 17/1000\n",
      "42064/42064 [==============================] - 0s 12us/sample - loss: 0.6902 - accuracy: 0.5240 - val_loss: 0.6916 - val_accuracy: 0.5109\n",
      "Epoch 18/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6903 - accuracy: 0.5218 - val_loss: 0.6916 - val_accuracy: 0.5074\n",
      "Epoch 19/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5227 - val_loss: 0.6917 - val_accuracy: 0.5068\n",
      "Epoch 20/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5229 - val_loss: 0.6918 - val_accuracy: 0.5108\n",
      "Epoch 21/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5226 - val_loss: 0.6916 - val_accuracy: 0.5095\n",
      "Epoch 22/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5230 - val_loss: 0.6918 - val_accuracy: 0.5118\n",
      "Epoch 23/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6902 - accuracy: 0.5243 - val_loss: 0.6916 - val_accuracy: 0.5085\n",
      "Epoch 24/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6902 - accuracy: 0.5237 - val_loss: 0.6920 - val_accuracy: 0.5087\n",
      "Epoch 25/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5223 - val_loss: 0.6916 - val_accuracy: 0.5074\n",
      "Epoch 26/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5247 - val_loss: 0.6916 - val_accuracy: 0.5107\n",
      "Epoch 27/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6902 - accuracy: 0.5225 - val_loss: 0.6915 - val_accuracy: 0.5096\n",
      "Epoch 28/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6902 - accuracy: 0.5230 - val_loss: 0.6919 - val_accuracy: 0.5081\n",
      "Epoch 29/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5230 - val_loss: 0.6917 - val_accuracy: 0.5090\n",
      "Epoch 30/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6902 - accuracy: 0.5213 - val_loss: 0.6920 - val_accuracy: 0.5095\n",
      "Epoch 31/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5213 - val_loss: 0.6918 - val_accuracy: 0.5094\n",
      "Epoch 32/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6899 - accuracy: 0.5245 - val_loss: 0.6916 - val_accuracy: 0.5094\n",
      "Epoch 33/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5230 - val_loss: 0.6917 - val_accuracy: 0.5097\n",
      "Epoch 34/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5244 - val_loss: 0.6915 - val_accuracy: 0.5085\n",
      "Epoch 35/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5237 - val_loss: 0.6916 - val_accuracy: 0.5093\n",
      "Epoch 36/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6899 - accuracy: 0.5225 - val_loss: 0.6916 - val_accuracy: 0.5087\n",
      "Epoch 37/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6899 - accuracy: 0.5250 - val_loss: 0.6918 - val_accuracy: 0.5108\n",
      "Epoch 38/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5240 - val_loss: 0.6916 - val_accuracy: 0.5097\n",
      "Training with significance = 7.53, run 4\n",
      "Train on 42064 samples, validate on 10516 samples\n",
      "Epoch 1/1000\n",
      "42064/42064 [==============================] - 3s 73us/sample - loss: 0.6929 - accuracy: 0.5113 - val_loss: 0.6933 - val_accuracy: 0.5055\n",
      "Epoch 2/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6914 - accuracy: 0.5172 - val_loss: 0.6920 - val_accuracy: 0.5124\n",
      "Epoch 3/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5193 - val_loss: 0.6914 - val_accuracy: 0.5160\n",
      "Epoch 4/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5200 - val_loss: 0.6912 - val_accuracy: 0.5179\n",
      "Epoch 5/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5207 - val_loss: 0.6911 - val_accuracy: 0.5208\n",
      "Epoch 6/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5209 - val_loss: 0.6910 - val_accuracy: 0.5183\n",
      "Epoch 7/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5214 - val_loss: 0.6910 - val_accuracy: 0.5191\n",
      "Epoch 8/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5209 - val_loss: 0.6909 - val_accuracy: 0.5175\n",
      "Epoch 9/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6904 - accuracy: 0.5220 - val_loss: 0.6910 - val_accuracy: 0.5175\n",
      "Epoch 10/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5214 - val_loss: 0.6909 - val_accuracy: 0.5196\n",
      "Epoch 11/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5205 - val_loss: 0.6908 - val_accuracy: 0.5193\n",
      "Epoch 12/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5221 - val_loss: 0.6909 - val_accuracy: 0.5194\n",
      "Epoch 13/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5223 - val_loss: 0.6909 - val_accuracy: 0.5198\n",
      "Epoch 14/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5214 - val_loss: 0.6909 - val_accuracy: 0.5186\n",
      "Epoch 15/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5232 - val_loss: 0.6909 - val_accuracy: 0.5191\n",
      "Epoch 16/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5231 - val_loss: 0.6908 - val_accuracy: 0.5179\n",
      "Epoch 17/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5225 - val_loss: 0.6907 - val_accuracy: 0.5185\n",
      "Epoch 18/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5208 - val_loss: 0.6907 - val_accuracy: 0.5182\n",
      "Epoch 19/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5235 - val_loss: 0.6907 - val_accuracy: 0.5184\n",
      "Epoch 20/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5227 - val_loss: 0.6907 - val_accuracy: 0.5180\n",
      "Epoch 21/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5221 - val_loss: 0.6907 - val_accuracy: 0.5190\n",
      "Epoch 22/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5251 - val_loss: 0.6907 - val_accuracy: 0.5168\n",
      "Epoch 23/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6899 - accuracy: 0.5219 - val_loss: 0.6906 - val_accuracy: 0.5174\n",
      "Epoch 24/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5225 - val_loss: 0.6907 - val_accuracy: 0.5207\n",
      "Epoch 25/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5234 - val_loss: 0.6907 - val_accuracy: 0.5198\n",
      "Epoch 26/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6899 - accuracy: 0.5245 - val_loss: 0.6908 - val_accuracy: 0.5175\n",
      "Epoch 27/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6899 - accuracy: 0.5215 - val_loss: 0.6906 - val_accuracy: 0.5192\n",
      "Epoch 28/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5237 - val_loss: 0.6906 - val_accuracy: 0.5184\n",
      "Epoch 29/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5233 - val_loss: 0.6906 - val_accuracy: 0.5190\n",
      "Epoch 30/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5236 - val_loss: 0.6905 - val_accuracy: 0.5187\n",
      "Epoch 31/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5241 - val_loss: 0.6906 - val_accuracy: 0.5176\n",
      "Epoch 32/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6898 - accuracy: 0.5255 - val_loss: 0.6906 - val_accuracy: 0.5201\n",
      "Epoch 33/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6898 - accuracy: 0.5239 - val_loss: 0.6906 - val_accuracy: 0.5188\n",
      "Epoch 34/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5223 - val_loss: 0.6906 - val_accuracy: 0.5172\n",
      "Epoch 35/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5250 - val_loss: 0.6906 - val_accuracy: 0.5183\n",
      "Epoch 36/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6898 - accuracy: 0.5264 - val_loss: 0.6908 - val_accuracy: 0.5190\n",
      "Epoch 37/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5251 - val_loss: 0.6907 - val_accuracy: 0.5221\n",
      "Epoch 38/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6897 - accuracy: 0.5246 - val_loss: 0.6906 - val_accuracy: 0.5205\n",
      "Epoch 39/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6898 - accuracy: 0.5247 - val_loss: 0.6905 - val_accuracy: 0.5183\n",
      "Epoch 40/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6897 - accuracy: 0.5245 - val_loss: 0.6906 - val_accuracy: 0.5165\n",
      "Epoch 41/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6897 - accuracy: 0.5245 - val_loss: 0.6904 - val_accuracy: 0.5168\n",
      "Epoch 42/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6897 - accuracy: 0.5262 - val_loss: 0.6905 - val_accuracy: 0.5180\n",
      "Epoch 43/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6897 - accuracy: 0.5239 - val_loss: 0.6905 - val_accuracy: 0.5188\n",
      "Epoch 44/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6897 - accuracy: 0.5248 - val_loss: 0.6905 - val_accuracy: 0.5172\n",
      "Epoch 45/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6897 - accuracy: 0.5261 - val_loss: 0.6906 - val_accuracy: 0.5149\n",
      "Epoch 46/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6896 - accuracy: 0.5250 - val_loss: 0.6905 - val_accuracy: 0.5176\n",
      "Epoch 47/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6896 - accuracy: 0.5243 - val_loss: 0.6905 - val_accuracy: 0.5163\n",
      "Epoch 48/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6897 - accuracy: 0.5244 - val_loss: 0.6905 - val_accuracy: 0.5164\n",
      "Epoch 49/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6896 - accuracy: 0.5240 - val_loss: 0.6905 - val_accuracy: 0.5188\n",
      "Epoch 50/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6895 - accuracy: 0.5258 - val_loss: 0.6904 - val_accuracy: 0.5190\n",
      "Epoch 51/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6896 - accuracy: 0.5265 - val_loss: 0.6905 - val_accuracy: 0.5159\n",
      "Epoch 52/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6897 - accuracy: 0.5255 - val_loss: 0.6904 - val_accuracy: 0.5150\n",
      "Epoch 53/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6896 - accuracy: 0.5253 - val_loss: 0.6903 - val_accuracy: 0.5191\n",
      "Epoch 54/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6898 - accuracy: 0.5244 - val_loss: 0.6903 - val_accuracy: 0.5188\n",
      "Epoch 55/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6894 - accuracy: 0.5280 - val_loss: 0.6905 - val_accuracy: 0.5188\n",
      "Epoch 56/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6896 - accuracy: 0.5257 - val_loss: 0.6904 - val_accuracy: 0.5166\n",
      "Epoch 57/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6895 - accuracy: 0.5262 - val_loss: 0.6904 - val_accuracy: 0.5172\n",
      "Epoch 58/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6895 - accuracy: 0.5257 - val_loss: 0.6904 - val_accuracy: 0.5185\n",
      "Epoch 59/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6895 - accuracy: 0.5269 - val_loss: 0.6904 - val_accuracy: 0.5185\n",
      "Epoch 60/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6894 - accuracy: 0.5268 - val_loss: 0.6904 - val_accuracy: 0.5181\n",
      "Epoch 61/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6895 - accuracy: 0.5268 - val_loss: 0.6904 - val_accuracy: 0.5178\n",
      "Epoch 62/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6894 - accuracy: 0.5261 - val_loss: 0.6904 - val_accuracy: 0.5184\n",
      "Epoch 63/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6895 - accuracy: 0.5265 - val_loss: 0.6905 - val_accuracy: 0.5162\n",
      "Epoch 64/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6895 - accuracy: 0.5245 - val_loss: 0.6904 - val_accuracy: 0.5156\n",
      "Epoch 65/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6895 - accuracy: 0.5253 - val_loss: 0.6904 - val_accuracy: 0.5166\n",
      "Epoch 66/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6894 - accuracy: 0.5259 - val_loss: 0.6904 - val_accuracy: 0.5179\n",
      "Epoch 67/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6894 - accuracy: 0.5268 - val_loss: 0.6903 - val_accuracy: 0.5168\n",
      "Epoch 68/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6895 - accuracy: 0.5280 - val_loss: 0.6905 - val_accuracy: 0.5180\n",
      "Epoch 69/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6896 - accuracy: 0.5256 - val_loss: 0.6904 - val_accuracy: 0.5146\n",
      "Epoch 70/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6895 - accuracy: 0.5262 - val_loss: 0.6904 - val_accuracy: 0.5169\n",
      "Epoch 71/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6894 - accuracy: 0.5278 - val_loss: 0.6904 - val_accuracy: 0.5160\n",
      "Epoch 72/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6894 - accuracy: 0.5270 - val_loss: 0.6905 - val_accuracy: 0.5167\n",
      "Epoch 73/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6893 - accuracy: 0.5279 - val_loss: 0.6903 - val_accuracy: 0.5187\n",
      "Epoch 74/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6894 - accuracy: 0.5259 - val_loss: 0.6904 - val_accuracy: 0.5168\n",
      "Epoch 75/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6894 - accuracy: 0.5249 - val_loss: 0.6904 - val_accuracy: 0.5171\n",
      "Epoch 76/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6894 - accuracy: 0.5278 - val_loss: 0.6904 - val_accuracy: 0.5166\n",
      "Epoch 77/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6893 - accuracy: 0.5265 - val_loss: 0.6903 - val_accuracy: 0.5169\n",
      "Epoch 78/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6893 - accuracy: 0.5277 - val_loss: 0.6904 - val_accuracy: 0.5179\n",
      "Epoch 79/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6893 - accuracy: 0.5260 - val_loss: 0.6903 - val_accuracy: 0.5182\n",
      "Epoch 80/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6893 - accuracy: 0.5266 - val_loss: 0.6904 - val_accuracy: 0.5182\n",
      "Epoch 81/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6893 - accuracy: 0.5268 - val_loss: 0.6904 - val_accuracy: 0.5146\n",
      "Epoch 82/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6894 - accuracy: 0.5283 - val_loss: 0.6904 - val_accuracy: 0.5147\n",
      "Epoch 83/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6894 - accuracy: 0.5277 - val_loss: 0.6904 - val_accuracy: 0.5168\n",
      "Epoch 84/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6893 - accuracy: 0.5295 - val_loss: 0.6904 - val_accuracy: 0.5148\n",
      "Epoch 85/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6893 - accuracy: 0.5279 - val_loss: 0.6904 - val_accuracy: 0.5148\n",
      "Epoch 86/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6894 - accuracy: 0.5286 - val_loss: 0.6903 - val_accuracy: 0.5166\n",
      "Epoch 87/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6893 - accuracy: 0.5290 - val_loss: 0.6904 - val_accuracy: 0.5158\n",
      "Epoch 88/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6893 - accuracy: 0.5282 - val_loss: 0.6904 - val_accuracy: 0.5160\n",
      "Epoch 89/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6893 - accuracy: 0.5264 - val_loss: 0.6904 - val_accuracy: 0.5150\n",
      "Epoch 90/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6892 - accuracy: 0.5272 - val_loss: 0.6904 - val_accuracy: 0.5195\n",
      "Epoch 91/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6893 - accuracy: 0.5260 - val_loss: 0.6903 - val_accuracy: 0.5162\n",
      "Epoch 92/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6894 - accuracy: 0.5268 - val_loss: 0.6904 - val_accuracy: 0.5165\n",
      "Epoch 93/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6893 - accuracy: 0.5281 - val_loss: 0.6904 - val_accuracy: 0.5152\n",
      "Epoch 94/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6893 - accuracy: 0.5273 - val_loss: 0.6903 - val_accuracy: 0.5160\n",
      "Epoch 95/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6891 - accuracy: 0.5292 - val_loss: 0.6904 - val_accuracy: 0.5159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6893 - accuracy: 0.5271 - val_loss: 0.6903 - val_accuracy: 0.5141\n",
      "Epoch 97/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6892 - accuracy: 0.5278 - val_loss: 0.6903 - val_accuracy: 0.5158\n",
      "Epoch 98/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6894 - accuracy: 0.5277 - val_loss: 0.6903 - val_accuracy: 0.5167\n",
      "Epoch 99/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6892 - accuracy: 0.5281 - val_loss: 0.6903 - val_accuracy: 0.5164\n",
      "Epoch 100/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6891 - accuracy: 0.5279 - val_loss: 0.6903 - val_accuracy: 0.5167\n",
      "Epoch 101/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6892 - accuracy: 0.5296 - val_loss: 0.6902 - val_accuracy: 0.5203\n",
      "Epoch 102/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6893 - accuracy: 0.5263 - val_loss: 0.6903 - val_accuracy: 0.5180\n",
      "Epoch 103/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6892 - accuracy: 0.5280 - val_loss: 0.6903 - val_accuracy: 0.5163\n",
      "Epoch 104/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6892 - accuracy: 0.5286 - val_loss: 0.6903 - val_accuracy: 0.5145\n",
      "Epoch 105/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6890 - accuracy: 0.5304 - val_loss: 0.6903 - val_accuracy: 0.5167\n",
      "Epoch 106/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6891 - accuracy: 0.5288 - val_loss: 0.6904 - val_accuracy: 0.5171\n",
      "Epoch 107/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6891 - accuracy: 0.5273 - val_loss: 0.6903 - val_accuracy: 0.5165\n",
      "Epoch 108/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6889 - accuracy: 0.5301 - val_loss: 0.6903 - val_accuracy: 0.5143\n",
      "Epoch 109/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6891 - accuracy: 0.5281 - val_loss: 0.6903 - val_accuracy: 0.5154\n",
      "Epoch 110/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6890 - accuracy: 0.5300 - val_loss: 0.6904 - val_accuracy: 0.5162\n",
      "Epoch 111/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6891 - accuracy: 0.5294 - val_loss: 0.6904 - val_accuracy: 0.5159\n",
      "Epoch 112/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6891 - accuracy: 0.5302 - val_loss: 0.6903 - val_accuracy: 0.5169\n",
      "Epoch 113/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6891 - accuracy: 0.5281 - val_loss: 0.6904 - val_accuracy: 0.5165\n",
      "Epoch 114/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6891 - accuracy: 0.5294 - val_loss: 0.6903 - val_accuracy: 0.5166\n",
      "Epoch 115/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6892 - accuracy: 0.5275 - val_loss: 0.6903 - val_accuracy: 0.5160\n",
      "Epoch 116/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6892 - accuracy: 0.5279 - val_loss: 0.6903 - val_accuracy: 0.5179\n",
      "Epoch 117/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6888 - accuracy: 0.5284 - val_loss: 0.6904 - val_accuracy: 0.5176\n",
      "Epoch 118/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6891 - accuracy: 0.5279 - val_loss: 0.6903 - val_accuracy: 0.5181\n",
      "Epoch 119/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6891 - accuracy: 0.5281 - val_loss: 0.6903 - val_accuracy: 0.5175\n",
      "Epoch 120/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6892 - accuracy: 0.5278 - val_loss: 0.6902 - val_accuracy: 0.5139\n",
      "Epoch 121/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6891 - accuracy: 0.5301 - val_loss: 0.6903 - val_accuracy: 0.5193\n",
      "Epoch 122/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6892 - accuracy: 0.5292 - val_loss: 0.6903 - val_accuracy: 0.5156\n",
      "Epoch 123/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6890 - accuracy: 0.5282 - val_loss: 0.6904 - val_accuracy: 0.5165\n",
      "Epoch 124/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6892 - accuracy: 0.5289 - val_loss: 0.6903 - val_accuracy: 0.5152\n",
      "Epoch 125/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6889 - accuracy: 0.5292 - val_loss: 0.6904 - val_accuracy: 0.5154\n",
      "Epoch 126/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6890 - accuracy: 0.5282 - val_loss: 0.6904 - val_accuracy: 0.5163\n",
      "Epoch 127/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6889 - accuracy: 0.5279 - val_loss: 0.6904 - val_accuracy: 0.5178\n",
      "Epoch 128/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6891 - accuracy: 0.5299 - val_loss: 0.6904 - val_accuracy: 0.5166\n",
      "Epoch 129/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6889 - accuracy: 0.5299 - val_loss: 0.6904 - val_accuracy: 0.5176\n",
      "Epoch 130/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6891 - accuracy: 0.5294 - val_loss: 0.6903 - val_accuracy: 0.5169\n",
      "Epoch 131/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6888 - accuracy: 0.5304 - val_loss: 0.6905 - val_accuracy: 0.5191\n",
      "Epoch 132/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6889 - accuracy: 0.5309 - val_loss: 0.6903 - val_accuracy: 0.5170\n",
      "Epoch 133/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6889 - accuracy: 0.5296 - val_loss: 0.6903 - val_accuracy: 0.5179\n",
      "Epoch 134/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6890 - accuracy: 0.5296 - val_loss: 0.6903 - val_accuracy: 0.5187\n",
      "Epoch 135/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6891 - accuracy: 0.5289 - val_loss: 0.6903 - val_accuracy: 0.5187\n",
      "Epoch 136/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6890 - accuracy: 0.5275 - val_loss: 0.6903 - val_accuracy: 0.5192\n",
      "Epoch 137/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6889 - accuracy: 0.5318 - val_loss: 0.6904 - val_accuracy: 0.5149\n",
      "Epoch 138/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6890 - accuracy: 0.5291 - val_loss: 0.6904 - val_accuracy: 0.5180\n",
      "Epoch 139/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6890 - accuracy: 0.5310 - val_loss: 0.6903 - val_accuracy: 0.5164\n",
      "Epoch 140/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6888 - accuracy: 0.5293 - val_loss: 0.6903 - val_accuracy: 0.5156\n",
      "Epoch 141/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6891 - accuracy: 0.5289 - val_loss: 0.6903 - val_accuracy: 0.5186\n",
      "Epoch 142/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6889 - accuracy: 0.5274 - val_loss: 0.6904 - val_accuracy: 0.5164\n",
      "Epoch 143/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6889 - accuracy: 0.5300 - val_loss: 0.6904 - val_accuracy: 0.5161\n",
      "Epoch 144/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6889 - accuracy: 0.5314 - val_loss: 0.6904 - val_accuracy: 0.5178\n",
      "Epoch 145/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6887 - accuracy: 0.5303 - val_loss: 0.6904 - val_accuracy: 0.5159\n",
      "Epoch 146/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6888 - accuracy: 0.5314 - val_loss: 0.6905 - val_accuracy: 0.5161\n",
      "Epoch 147/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6890 - accuracy: 0.5296 - val_loss: 0.6903 - val_accuracy: 0.5172\n",
      "Epoch 148/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6889 - accuracy: 0.5296 - val_loss: 0.6904 - val_accuracy: 0.5189\n",
      "Epoch 149/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6888 - accuracy: 0.5301 - val_loss: 0.6904 - val_accuracy: 0.5170\n",
      "Epoch 150/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6888 - accuracy: 0.5305 - val_loss: 0.6903 - val_accuracy: 0.5175\n",
      "Training with significance = 7.53, run 5\n",
      "Train on 42064 samples, validate on 10516 samples\n",
      "Epoch 1/1000\n",
      "42064/42064 [==============================] - 1s 27us/sample - loss: 0.6915 - accuracy: 0.5169 - val_loss: 0.6937 - val_accuracy: 0.5067\n",
      "Epoch 2/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5183 - val_loss: 0.6915 - val_accuracy: 0.5205\n",
      "Epoch 3/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6911 - accuracy: 0.5173 - val_loss: 0.6909 - val_accuracy: 0.5187\n",
      "Epoch 4/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5212 - val_loss: 0.6909 - val_accuracy: 0.5213\n",
      "Epoch 5/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5190 - val_loss: 0.6906 - val_accuracy: 0.5188\n",
      "Epoch 6/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5191 - val_loss: 0.6907 - val_accuracy: 0.5212\n",
      "Epoch 7/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5199 - val_loss: 0.6907 - val_accuracy: 0.5190\n",
      "Epoch 8/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5204 - val_loss: 0.6909 - val_accuracy: 0.5168\n",
      "Epoch 9/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5201 - val_loss: 0.6907 - val_accuracy: 0.5189\n",
      "Epoch 10/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5219 - val_loss: 0.6907 - val_accuracy: 0.5191\n",
      "Epoch 11/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5223 - val_loss: 0.6908 - val_accuracy: 0.5203\n",
      "Epoch 12/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5225 - val_loss: 0.6909 - val_accuracy: 0.5181\n",
      "Epoch 13/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5227 - val_loss: 0.6905 - val_accuracy: 0.5240\n",
      "Epoch 14/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6903 - accuracy: 0.5242 - val_loss: 0.6908 - val_accuracy: 0.5202\n",
      "Epoch 15/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5240 - val_loss: 0.6908 - val_accuracy: 0.5203\n",
      "Epoch 16/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5217 - val_loss: 0.6908 - val_accuracy: 0.5188\n",
      "Epoch 17/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5224 - val_loss: 0.6906 - val_accuracy: 0.5213\n",
      "Epoch 18/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5233 - val_loss: 0.6905 - val_accuracy: 0.5219\n",
      "Epoch 19/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5231 - val_loss: 0.6905 - val_accuracy: 0.5213\n",
      "Epoch 20/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5239 - val_loss: 0.6904 - val_accuracy: 0.5233\n",
      "Epoch 21/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5227 - val_loss: 0.6904 - val_accuracy: 0.5226\n",
      "Epoch 22/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5237 - val_loss: 0.6904 - val_accuracy: 0.5194\n",
      "Epoch 23/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5243 - val_loss: 0.6905 - val_accuracy: 0.5184\n",
      "Epoch 24/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5231 - val_loss: 0.6904 - val_accuracy: 0.5195\n",
      "Epoch 25/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5216 - val_loss: 0.6904 - val_accuracy: 0.5177\n",
      "Epoch 26/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6901 - accuracy: 0.5250 - val_loss: 0.6904 - val_accuracy: 0.5206\n",
      "Epoch 27/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5242 - val_loss: 0.6905 - val_accuracy: 0.5214\n",
      "Epoch 28/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5233 - val_loss: 0.6904 - val_accuracy: 0.5182\n",
      "Epoch 29/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5247 - val_loss: 0.6901 - val_accuracy: 0.5212\n",
      "Epoch 30/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5239 - val_loss: 0.6907 - val_accuracy: 0.5178\n",
      "Epoch 31/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5255 - val_loss: 0.6904 - val_accuracy: 0.5215\n",
      "Epoch 32/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5251 - val_loss: 0.6901 - val_accuracy: 0.5230\n",
      "Epoch 33/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5233 - val_loss: 0.6904 - val_accuracy: 0.5180\n",
      "Epoch 34/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5244 - val_loss: 0.6905 - val_accuracy: 0.5205\n",
      "Epoch 35/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5264 - val_loss: 0.6902 - val_accuracy: 0.5235\n",
      "Epoch 36/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5250 - val_loss: 0.6903 - val_accuracy: 0.5213\n",
      "Epoch 37/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5247 - val_loss: 0.6907 - val_accuracy: 0.5187\n",
      "Epoch 38/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6898 - accuracy: 0.5256 - val_loss: 0.6909 - val_accuracy: 0.5163\n",
      "Epoch 39/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5253 - val_loss: 0.6903 - val_accuracy: 0.5211\n",
      "Epoch 40/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6898 - accuracy: 0.5266 - val_loss: 0.6907 - val_accuracy: 0.5165\n",
      "Epoch 41/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6898 - accuracy: 0.5252 - val_loss: 0.6902 - val_accuracy: 0.5223\n",
      "Epoch 42/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5253 - val_loss: 0.6901 - val_accuracy: 0.5232\n",
      "Epoch 43/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6898 - accuracy: 0.5266 - val_loss: 0.6901 - val_accuracy: 0.5203\n",
      "Epoch 44/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6898 - accuracy: 0.5255 - val_loss: 0.6903 - val_accuracy: 0.5200\n",
      "Epoch 45/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6897 - accuracy: 0.5268 - val_loss: 0.6905 - val_accuracy: 0.5182\n",
      "Epoch 46/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5266 - val_loss: 0.6905 - val_accuracy: 0.5184\n",
      "Epoch 47/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6897 - accuracy: 0.5263 - val_loss: 0.6902 - val_accuracy: 0.5207\n",
      "Epoch 48/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5260 - val_loss: 0.6903 - val_accuracy: 0.5185\n",
      "Epoch 49/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5256 - val_loss: 0.6903 - val_accuracy: 0.5184\n",
      "Epoch 50/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5267 - val_loss: 0.6901 - val_accuracy: 0.5207\n",
      "Epoch 51/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6897 - accuracy: 0.5273 - val_loss: 0.6903 - val_accuracy: 0.5184\n",
      "Epoch 52/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6898 - accuracy: 0.5238 - val_loss: 0.6904 - val_accuracy: 0.5174\n",
      "Epoch 53/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6896 - accuracy: 0.5269 - val_loss: 0.6901 - val_accuracy: 0.5190\n",
      "Epoch 54/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6897 - accuracy: 0.5293 - val_loss: 0.6901 - val_accuracy: 0.5211\n",
      "Epoch 55/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6896 - accuracy: 0.5277 - val_loss: 0.6903 - val_accuracy: 0.5194\n",
      "Epoch 56/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6897 - accuracy: 0.5263 - val_loss: 0.6902 - val_accuracy: 0.5204\n",
      "Epoch 57/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6896 - accuracy: 0.5271 - val_loss: 0.6902 - val_accuracy: 0.5171\n",
      "Epoch 58/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6896 - accuracy: 0.5286 - val_loss: 0.6902 - val_accuracy: 0.5182\n",
      "Epoch 59/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6896 - accuracy: 0.5270 - val_loss: 0.6906 - val_accuracy: 0.5165\n",
      "Epoch 60/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6896 - accuracy: 0.5293 - val_loss: 0.6902 - val_accuracy: 0.5176\n",
      "Epoch 61/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6895 - accuracy: 0.5262 - val_loss: 0.6901 - val_accuracy: 0.5196\n",
      "Epoch 62/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6897 - accuracy: 0.5252 - val_loss: 0.6901 - val_accuracy: 0.5197\n",
      "Epoch 63/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6896 - accuracy: 0.5255 - val_loss: 0.6903 - val_accuracy: 0.5171\n",
      "Epoch 64/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6896 - accuracy: 0.5268 - val_loss: 0.6902 - val_accuracy: 0.5198\n",
      "Epoch 65/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6897 - accuracy: 0.5281 - val_loss: 0.6902 - val_accuracy: 0.5199\n",
      "Epoch 66/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6894 - accuracy: 0.5274 - val_loss: 0.6904 - val_accuracy: 0.5173\n",
      "Epoch 67/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6897 - accuracy: 0.5276 - val_loss: 0.6907 - val_accuracy: 0.5136\n",
      "Epoch 68/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6897 - accuracy: 0.5281 - val_loss: 0.6904 - val_accuracy: 0.5184\n",
      "Epoch 69/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6895 - accuracy: 0.5276 - val_loss: 0.6901 - val_accuracy: 0.5186\n",
      "Epoch 70/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6896 - accuracy: 0.5275 - val_loss: 0.6903 - val_accuracy: 0.5187\n",
      "Epoch 71/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6896 - accuracy: 0.5276 - val_loss: 0.6902 - val_accuracy: 0.5173\n",
      "Epoch 72/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6897 - accuracy: 0.5265 - val_loss: 0.6904 - val_accuracy: 0.5170\n",
      "Epoch 73/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6897 - accuracy: 0.5282 - val_loss: 0.6902 - val_accuracy: 0.5187\n",
      "Epoch 74/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6895 - accuracy: 0.5282 - val_loss: 0.6905 - val_accuracy: 0.5160\n",
      "Epoch 75/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6895 - accuracy: 0.5257 - val_loss: 0.6902 - val_accuracy: 0.5183\n",
      "Epoch 76/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6896 - accuracy: 0.5288 - val_loss: 0.6901 - val_accuracy: 0.5194\n",
      "Epoch 77/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6896 - accuracy: 0.5261 - val_loss: 0.6902 - val_accuracy: 0.5169\n",
      "Epoch 78/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6896 - accuracy: 0.5271 - val_loss: 0.6905 - val_accuracy: 0.5180\n",
      "Epoch 79/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6895 - accuracy: 0.5250 - val_loss: 0.6903 - val_accuracy: 0.5168\n",
      "Epoch 80/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6894 - accuracy: 0.5271 - val_loss: 0.6902 - val_accuracy: 0.5163\n",
      "Epoch 81/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6895 - accuracy: 0.5279 - val_loss: 0.6905 - val_accuracy: 0.5167\n",
      "Epoch 82/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6895 - accuracy: 0.5267 - val_loss: 0.6901 - val_accuracy: 0.5162\n",
      "Epoch 83/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6896 - accuracy: 0.5282 - val_loss: 0.6902 - val_accuracy: 0.5151\n",
      "Epoch 84/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6894 - accuracy: 0.5286 - val_loss: 0.6902 - val_accuracy: 0.5171\n",
      "Training with significance = 7.53, run 6\n",
      "Train on 42064 samples, validate on 10516 samples\n",
      "Epoch 1/1000\n",
      "42064/42064 [==============================] - 1s 28us/sample - loss: 0.6935 - accuracy: 0.5074 - val_loss: 0.6950 - val_accuracy: 0.5025\n",
      "Epoch 2/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6913 - accuracy: 0.5186 - val_loss: 0.6926 - val_accuracy: 0.5059\n",
      "Epoch 3/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5179 - val_loss: 0.6920 - val_accuracy: 0.5130\n",
      "Epoch 4/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5207 - val_loss: 0.6919 - val_accuracy: 0.5126\n",
      "Epoch 5/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5204 - val_loss: 0.6915 - val_accuracy: 0.5161\n",
      "Epoch 6/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5178 - val_loss: 0.6916 - val_accuracy: 0.5163\n",
      "Epoch 7/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5212 - val_loss: 0.6915 - val_accuracy: 0.5167\n",
      "Epoch 8/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5212 - val_loss: 0.6915 - val_accuracy: 0.5162\n",
      "Epoch 9/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5191 - val_loss: 0.6914 - val_accuracy: 0.5159\n",
      "Epoch 10/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5207 - val_loss: 0.6915 - val_accuracy: 0.5150\n",
      "Epoch 11/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6903 - accuracy: 0.5214 - val_loss: 0.6915 - val_accuracy: 0.5130\n",
      "Epoch 12/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5223 - val_loss: 0.6915 - val_accuracy: 0.5168\n",
      "Epoch 13/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5193 - val_loss: 0.6912 - val_accuracy: 0.5178\n",
      "Epoch 14/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5220 - val_loss: 0.6913 - val_accuracy: 0.5159\n",
      "Epoch 15/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5216 - val_loss: 0.6913 - val_accuracy: 0.5158\n",
      "Epoch 16/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5212 - val_loss: 0.6915 - val_accuracy: 0.5145\n",
      "Epoch 17/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6900 - accuracy: 0.5210 - val_loss: 0.6914 - val_accuracy: 0.5153\n",
      "Epoch 18/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5224 - val_loss: 0.6914 - val_accuracy: 0.5152\n",
      "Epoch 19/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5212 - val_loss: 0.6915 - val_accuracy: 0.5140\n",
      "Epoch 20/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5223 - val_loss: 0.6915 - val_accuracy: 0.5145\n",
      "Epoch 21/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5215 - val_loss: 0.6913 - val_accuracy: 0.5156\n",
      "Epoch 22/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5239 - val_loss: 0.6917 - val_accuracy: 0.5133\n",
      "Epoch 23/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5232 - val_loss: 0.6914 - val_accuracy: 0.5153\n",
      "Epoch 24/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5240 - val_loss: 0.6914 - val_accuracy: 0.5149\n",
      "Epoch 25/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5226 - val_loss: 0.6913 - val_accuracy: 0.5166\n",
      "Epoch 26/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6900 - accuracy: 0.5225 - val_loss: 0.6915 - val_accuracy: 0.5140\n",
      "Epoch 27/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5232 - val_loss: 0.6915 - val_accuracy: 0.5164\n",
      "Epoch 28/1000\n",
      "42064/42064 [==============================] - 0s 12us/sample - loss: 0.6900 - accuracy: 0.5216 - val_loss: 0.6914 - val_accuracy: 0.5176\n",
      "Epoch 29/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5226 - val_loss: 0.6913 - val_accuracy: 0.5173\n",
      "Epoch 30/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5210 - val_loss: 0.6917 - val_accuracy: 0.5143\n",
      "Epoch 31/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5217 - val_loss: 0.6914 - val_accuracy: 0.5159\n",
      "Epoch 32/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5222 - val_loss: 0.6916 - val_accuracy: 0.5160\n",
      "Epoch 33/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5248 - val_loss: 0.6914 - val_accuracy: 0.5145\n",
      "Epoch 34/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5258 - val_loss: 0.6916 - val_accuracy: 0.5146\n",
      "Epoch 35/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6897 - accuracy: 0.5225 - val_loss: 0.6914 - val_accuracy: 0.5155\n",
      "Epoch 36/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6897 - accuracy: 0.5257 - val_loss: 0.6914 - val_accuracy: 0.5151\n",
      "Epoch 37/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6898 - accuracy: 0.5237 - val_loss: 0.6914 - val_accuracy: 0.5148\n",
      "Epoch 38/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6898 - accuracy: 0.5247 - val_loss: 0.6917 - val_accuracy: 0.5138\n",
      "Epoch 39/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6898 - accuracy: 0.5241 - val_loss: 0.6914 - val_accuracy: 0.5149\n",
      "Epoch 40/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6897 - accuracy: 0.5244 - val_loss: 0.6916 - val_accuracy: 0.5165\n",
      "Epoch 41/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6897 - accuracy: 0.5246 - val_loss: 0.6913 - val_accuracy: 0.5160\n",
      "Epoch 42/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6898 - accuracy: 0.5233 - val_loss: 0.6918 - val_accuracy: 0.5119\n",
      "Epoch 43/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6898 - accuracy: 0.5226 - val_loss: 0.6914 - val_accuracy: 0.5140\n",
      "Training with significance = 7.53, run 7\n",
      "Train on 42064 samples, validate on 10516 samples\n",
      "Epoch 1/1000\n",
      "42064/42064 [==============================] - 1s 27us/sample - loss: 0.6924 - accuracy: 0.5117 - val_loss: 0.6940 - val_accuracy: 0.5039\n",
      "Epoch 2/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6912 - accuracy: 0.5186 - val_loss: 0.6921 - val_accuracy: 0.5081\n",
      "Epoch 3/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6910 - accuracy: 0.5189 - val_loss: 0.6916 - val_accuracy: 0.5166\n",
      "Epoch 4/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6909 - accuracy: 0.5193 - val_loss: 0.6914 - val_accuracy: 0.5130\n",
      "Epoch 5/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5193 - val_loss: 0.6910 - val_accuracy: 0.5183\n",
      "Epoch 6/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6907 - accuracy: 0.5204 - val_loss: 0.6910 - val_accuracy: 0.5161\n",
      "Epoch 7/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5209 - val_loss: 0.6909 - val_accuracy: 0.5174\n",
      "Epoch 8/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5199 - val_loss: 0.6909 - val_accuracy: 0.5166\n",
      "Epoch 9/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5196 - val_loss: 0.6908 - val_accuracy: 0.5167\n",
      "Epoch 10/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5205 - val_loss: 0.6909 - val_accuracy: 0.5181\n",
      "Epoch 11/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5201 - val_loss: 0.6908 - val_accuracy: 0.5164\n",
      "Epoch 12/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5213 - val_loss: 0.6908 - val_accuracy: 0.5130\n",
      "Epoch 13/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6904 - accuracy: 0.5221 - val_loss: 0.6908 - val_accuracy: 0.5169\n",
      "Epoch 14/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5206 - val_loss: 0.6907 - val_accuracy: 0.5131\n",
      "Epoch 15/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5204 - val_loss: 0.6907 - val_accuracy: 0.5177\n",
      "Epoch 16/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5201 - val_loss: 0.6907 - val_accuracy: 0.5159\n",
      "Epoch 17/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5213 - val_loss: 0.6908 - val_accuracy: 0.5177\n",
      "Epoch 18/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5218 - val_loss: 0.6908 - val_accuracy: 0.5153\n",
      "Epoch 19/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5219 - val_loss: 0.6907 - val_accuracy: 0.5192\n",
      "Epoch 20/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5228 - val_loss: 0.6907 - val_accuracy: 0.5158\n",
      "Epoch 21/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5238 - val_loss: 0.6907 - val_accuracy: 0.5184\n",
      "Epoch 22/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5222 - val_loss: 0.6907 - val_accuracy: 0.5188\n",
      "Epoch 23/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5225 - val_loss: 0.6907 - val_accuracy: 0.5154\n",
      "Epoch 24/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5228 - val_loss: 0.6907 - val_accuracy: 0.5165\n",
      "Epoch 25/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5242 - val_loss: 0.6906 - val_accuracy: 0.5162\n",
      "Epoch 26/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5208 - val_loss: 0.6906 - val_accuracy: 0.5160\n",
      "Epoch 27/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6898 - accuracy: 0.5246 - val_loss: 0.6906 - val_accuracy: 0.5164\n",
      "Epoch 28/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6898 - accuracy: 0.5242 - val_loss: 0.6907 - val_accuracy: 0.5135\n",
      "Epoch 29/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5215 - val_loss: 0.6906 - val_accuracy: 0.5148\n",
      "Epoch 30/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5219 - val_loss: 0.6906 - val_accuracy: 0.5171\n",
      "Epoch 31/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5231 - val_loss: 0.6907 - val_accuracy: 0.5184\n",
      "Epoch 32/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6898 - accuracy: 0.5245 - val_loss: 0.6907 - val_accuracy: 0.5178\n",
      "Epoch 33/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6897 - accuracy: 0.5233 - val_loss: 0.6907 - val_accuracy: 0.5161\n",
      "Epoch 34/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6898 - accuracy: 0.5241 - val_loss: 0.6907 - val_accuracy: 0.5126\n",
      "Epoch 35/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6898 - accuracy: 0.5225 - val_loss: 0.6907 - val_accuracy: 0.5145\n",
      "Epoch 36/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6898 - accuracy: 0.5242 - val_loss: 0.6907 - val_accuracy: 0.5156\n",
      "Epoch 37/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6897 - accuracy: 0.5246 - val_loss: 0.6906 - val_accuracy: 0.5180\n",
      "Epoch 38/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6897 - accuracy: 0.5239 - val_loss: 0.6906 - val_accuracy: 0.5131\n",
      "Epoch 39/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6898 - accuracy: 0.5250 - val_loss: 0.6906 - val_accuracy: 0.5169\n",
      "Epoch 40/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6898 - accuracy: 0.5224 - val_loss: 0.6906 - val_accuracy: 0.5172\n",
      "Epoch 41/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6897 - accuracy: 0.5253 - val_loss: 0.6906 - val_accuracy: 0.5130\n",
      "Epoch 42/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6897 - accuracy: 0.5236 - val_loss: 0.6906 - val_accuracy: 0.5162\n",
      "Epoch 43/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6897 - accuracy: 0.5225 - val_loss: 0.6906 - val_accuracy: 0.5141\n",
      "Epoch 44/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6896 - accuracy: 0.5235 - val_loss: 0.6906 - val_accuracy: 0.5143\n",
      "Epoch 45/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6898 - accuracy: 0.5232 - val_loss: 0.6907 - val_accuracy: 0.5165\n",
      "Epoch 46/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6898 - accuracy: 0.5246 - val_loss: 0.6907 - val_accuracy: 0.5169\n",
      "Epoch 47/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6896 - accuracy: 0.5234 - val_loss: 0.6906 - val_accuracy: 0.5155\n",
      "Epoch 48/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6896 - accuracy: 0.5228 - val_loss: 0.6906 - val_accuracy: 0.5158\n",
      "Epoch 49/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6897 - accuracy: 0.5239 - val_loss: 0.6907 - val_accuracy: 0.5154\n",
      "Epoch 50/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6896 - accuracy: 0.5243 - val_loss: 0.6906 - val_accuracy: 0.5136\n",
      "Epoch 51/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6895 - accuracy: 0.5256 - val_loss: 0.6907 - val_accuracy: 0.5186\n",
      "Epoch 52/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6894 - accuracy: 0.5248 - val_loss: 0.6906 - val_accuracy: 0.5165\n",
      "Epoch 53/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6894 - accuracy: 0.5264 - val_loss: 0.6907 - val_accuracy: 0.5138\n",
      "Epoch 54/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6896 - accuracy: 0.5239 - val_loss: 0.6906 - val_accuracy: 0.5131\n",
      "Epoch 55/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6896 - accuracy: 0.5246 - val_loss: 0.6906 - val_accuracy: 0.5147\n",
      "Epoch 56/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6894 - accuracy: 0.5246 - val_loss: 0.6907 - val_accuracy: 0.5107\n",
      "Epoch 57/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6896 - accuracy: 0.5251 - val_loss: 0.6907 - val_accuracy: 0.5174\n",
      "Epoch 58/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6897 - accuracy: 0.5241 - val_loss: 0.6906 - val_accuracy: 0.5118\n",
      "Epoch 59/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6894 - accuracy: 0.5259 - val_loss: 0.6906 - val_accuracy: 0.5163\n",
      "Epoch 60/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6895 - accuracy: 0.5239 - val_loss: 0.6906 - val_accuracy: 0.5144\n",
      "Epoch 61/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6895 - accuracy: 0.5278 - val_loss: 0.6906 - val_accuracy: 0.5136\n",
      "Epoch 62/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6894 - accuracy: 0.5258 - val_loss: 0.6907 - val_accuracy: 0.5132\n",
      "Epoch 63/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6894 - accuracy: 0.5259 - val_loss: 0.6906 - val_accuracy: 0.5144\n",
      "Epoch 64/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6893 - accuracy: 0.5247 - val_loss: 0.6907 - val_accuracy: 0.5126\n",
      "Epoch 65/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6895 - accuracy: 0.5249 - val_loss: 0.6906 - val_accuracy: 0.5106\n",
      "Epoch 66/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6894 - accuracy: 0.5257 - val_loss: 0.6907 - val_accuracy: 0.5111\n",
      "Epoch 67/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6893 - accuracy: 0.5265 - val_loss: 0.6907 - val_accuracy: 0.5133\n",
      "Epoch 68/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6894 - accuracy: 0.5251 - val_loss: 0.6907 - val_accuracy: 0.5164\n",
      "Epoch 69/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6893 - accuracy: 0.5266 - val_loss: 0.6906 - val_accuracy: 0.5131\n",
      "Training with significance = 7.53, run 8\n",
      "Train on 42064 samples, validate on 10516 samples\n",
      "Epoch 1/1000\n",
      "42064/42064 [==============================] - 1s 27us/sample - loss: 0.6922 - accuracy: 0.5131 - val_loss: 0.6925 - val_accuracy: 0.5088\n",
      "Epoch 2/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6911 - accuracy: 0.5200 - val_loss: 0.6910 - val_accuracy: 0.5173\n",
      "Epoch 3/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6910 - accuracy: 0.5196 - val_loss: 0.6908 - val_accuracy: 0.5214\n",
      "Epoch 4/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5222 - val_loss: 0.6906 - val_accuracy: 0.5217\n",
      "Epoch 5/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5194 - val_loss: 0.6906 - val_accuracy: 0.5207\n",
      "Epoch 6/1000\n",
      "42064/42064 [==============================] - 0s 12us/sample - loss: 0.6907 - accuracy: 0.5202 - val_loss: 0.6905 - val_accuracy: 0.5199\n",
      "Epoch 7/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5199 - val_loss: 0.6904 - val_accuracy: 0.5195\n",
      "Epoch 8/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5223 - val_loss: 0.6906 - val_accuracy: 0.5176\n",
      "Epoch 9/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6905 - accuracy: 0.5222 - val_loss: 0.6904 - val_accuracy: 0.5187\n",
      "Epoch 10/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5218 - val_loss: 0.6904 - val_accuracy: 0.5187\n",
      "Epoch 11/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5216 - val_loss: 0.6905 - val_accuracy: 0.5165\n",
      "Epoch 12/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5218 - val_loss: 0.6904 - val_accuracy: 0.5183\n",
      "Epoch 13/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5220 - val_loss: 0.6903 - val_accuracy: 0.5186\n",
      "Epoch 14/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5227 - val_loss: 0.6904 - val_accuracy: 0.5152\n",
      "Epoch 15/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5233 - val_loss: 0.6907 - val_accuracy: 0.5148\n",
      "Epoch 16/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5215 - val_loss: 0.6903 - val_accuracy: 0.5181\n",
      "Epoch 17/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5211 - val_loss: 0.6902 - val_accuracy: 0.5182\n",
      "Epoch 18/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5218 - val_loss: 0.6903 - val_accuracy: 0.5168\n",
      "Epoch 19/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6903 - accuracy: 0.5228 - val_loss: 0.6902 - val_accuracy: 0.5194\n",
      "Epoch 20/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5215 - val_loss: 0.6902 - val_accuracy: 0.5176\n",
      "Epoch 21/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6901 - accuracy: 0.5230 - val_loss: 0.6901 - val_accuracy: 0.5220\n",
      "Epoch 22/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5233 - val_loss: 0.6901 - val_accuracy: 0.5181\n",
      "Epoch 23/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5213 - val_loss: 0.6904 - val_accuracy: 0.5140\n",
      "Epoch 24/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6901 - accuracy: 0.5235 - val_loss: 0.6901 - val_accuracy: 0.5206\n",
      "Epoch 25/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6901 - accuracy: 0.5241 - val_loss: 0.6902 - val_accuracy: 0.5159\n",
      "Epoch 26/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6900 - accuracy: 0.5242 - val_loss: 0.6901 - val_accuracy: 0.5188\n",
      "Epoch 27/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6901 - accuracy: 0.5243 - val_loss: 0.6902 - val_accuracy: 0.5161\n",
      "Epoch 28/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5219 - val_loss: 0.6900 - val_accuracy: 0.5189\n",
      "Epoch 29/1000\n",
      "42064/42064 [==============================] - 1s 14us/sample - loss: 0.6899 - accuracy: 0.5233 - val_loss: 0.6901 - val_accuracy: 0.5172\n",
      "Epoch 30/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5224 - val_loss: 0.6900 - val_accuracy: 0.5188\n",
      "Epoch 31/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6899 - accuracy: 0.5231 - val_loss: 0.6902 - val_accuracy: 0.5159\n",
      "Epoch 32/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6900 - accuracy: 0.5250 - val_loss: 0.6900 - val_accuracy: 0.5185\n",
      "Epoch 33/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6901 - accuracy: 0.5221 - val_loss: 0.6901 - val_accuracy: 0.5180\n",
      "Epoch 34/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5244 - val_loss: 0.6901 - val_accuracy: 0.5165\n",
      "Epoch 35/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5250 - val_loss: 0.6901 - val_accuracy: 0.5181\n",
      "Epoch 36/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5242 - val_loss: 0.6901 - val_accuracy: 0.5171\n",
      "Epoch 37/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6900 - accuracy: 0.5226 - val_loss: 0.6901 - val_accuracy: 0.5168\n",
      "Epoch 38/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6900 - accuracy: 0.5229 - val_loss: 0.6900 - val_accuracy: 0.5179\n",
      "Epoch 39/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6899 - accuracy: 0.5237 - val_loss: 0.6902 - val_accuracy: 0.5154\n",
      "Epoch 40/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6898 - accuracy: 0.5247 - val_loss: 0.6900 - val_accuracy: 0.5175\n",
      "Epoch 41/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6899 - accuracy: 0.5247 - val_loss: 0.6901 - val_accuracy: 0.5165\n",
      "Epoch 42/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5254 - val_loss: 0.6900 - val_accuracy: 0.5169\n",
      "Epoch 43/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6899 - accuracy: 0.5241 - val_loss: 0.6901 - val_accuracy: 0.5160\n",
      "Epoch 44/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5254 - val_loss: 0.6900 - val_accuracy: 0.5168\n",
      "Epoch 45/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6898 - accuracy: 0.5259 - val_loss: 0.6901 - val_accuracy: 0.5158\n",
      "Epoch 46/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6899 - accuracy: 0.5254 - val_loss: 0.6901 - val_accuracy: 0.5153\n",
      "Epoch 47/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6898 - accuracy: 0.5244 - val_loss: 0.6903 - val_accuracy: 0.5150\n",
      "Epoch 48/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5252 - val_loss: 0.6899 - val_accuracy: 0.5174\n",
      "Epoch 49/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6897 - accuracy: 0.5237 - val_loss: 0.6900 - val_accuracy: 0.5164\n",
      "Epoch 50/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6897 - accuracy: 0.5254 - val_loss: 0.6901 - val_accuracy: 0.5137\n",
      "Epoch 51/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6898 - accuracy: 0.5238 - val_loss: 0.6900 - val_accuracy: 0.5187\n",
      "Epoch 52/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6898 - accuracy: 0.5251 - val_loss: 0.6900 - val_accuracy: 0.5172\n",
      "Epoch 53/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6896 - accuracy: 0.5270 - val_loss: 0.6900 - val_accuracy: 0.5185\n",
      "Epoch 54/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6898 - accuracy: 0.5248 - val_loss: 0.6900 - val_accuracy: 0.5180\n",
      "Epoch 55/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6898 - accuracy: 0.5258 - val_loss: 0.6899 - val_accuracy: 0.5166\n",
      "Epoch 56/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6896 - accuracy: 0.5241 - val_loss: 0.6899 - val_accuracy: 0.5187\n",
      "Epoch 57/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6897 - accuracy: 0.5267 - val_loss: 0.6899 - val_accuracy: 0.5201\n",
      "Epoch 58/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6897 - accuracy: 0.5250 - val_loss: 0.6900 - val_accuracy: 0.5184\n",
      "Epoch 59/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6897 - accuracy: 0.5273 - val_loss: 0.6901 - val_accuracy: 0.5163\n",
      "Epoch 60/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6897 - accuracy: 0.5243 - val_loss: 0.6901 - val_accuracy: 0.5157\n",
      "Epoch 61/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6896 - accuracy: 0.5249 - val_loss: 0.6899 - val_accuracy: 0.5183\n",
      "Epoch 62/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6897 - accuracy: 0.5266 - val_loss: 0.6900 - val_accuracy: 0.5157\n",
      "Epoch 63/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6897 - accuracy: 0.5259 - val_loss: 0.6899 - val_accuracy: 0.5201\n",
      "Epoch 64/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6897 - accuracy: 0.5272 - val_loss: 0.6899 - val_accuracy: 0.5170\n",
      "Epoch 65/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6896 - accuracy: 0.5248 - val_loss: 0.6901 - val_accuracy: 0.5130\n",
      "Epoch 66/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6896 - accuracy: 0.5247 - val_loss: 0.6899 - val_accuracy: 0.5180\n",
      "Epoch 67/1000\n",
      "42064/42064 [==============================] - 0s 12us/sample - loss: 0.6895 - accuracy: 0.5270 - val_loss: 0.6900 - val_accuracy: 0.5173\n",
      "Epoch 68/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6896 - accuracy: 0.5267 - val_loss: 0.6899 - val_accuracy: 0.5194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6895 - accuracy: 0.5264 - val_loss: 0.6900 - val_accuracy: 0.5155\n",
      "Epoch 70/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6896 - accuracy: 0.5270 - val_loss: 0.6899 - val_accuracy: 0.5160\n",
      "Epoch 71/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6895 - accuracy: 0.5264 - val_loss: 0.6899 - val_accuracy: 0.5204\n",
      "Epoch 72/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6895 - accuracy: 0.5271 - val_loss: 0.6899 - val_accuracy: 0.5181\n",
      "Epoch 73/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6897 - accuracy: 0.5258 - val_loss: 0.6900 - val_accuracy: 0.5176\n",
      "Epoch 74/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6896 - accuracy: 0.5282 - val_loss: 0.6899 - val_accuracy: 0.5184\n",
      "Epoch 75/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6897 - accuracy: 0.5256 - val_loss: 0.6898 - val_accuracy: 0.5181\n",
      "Epoch 76/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6896 - accuracy: 0.5240 - val_loss: 0.6899 - val_accuracy: 0.5187\n",
      "Epoch 77/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6896 - accuracy: 0.5275 - val_loss: 0.6900 - val_accuracy: 0.5175\n",
      "Epoch 78/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6894 - accuracy: 0.5270 - val_loss: 0.6899 - val_accuracy: 0.5202\n",
      "Epoch 79/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6896 - accuracy: 0.5263 - val_loss: 0.6899 - val_accuracy: 0.5143\n",
      "Epoch 80/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6895 - accuracy: 0.5256 - val_loss: 0.6899 - val_accuracy: 0.5172\n",
      "Epoch 81/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6896 - accuracy: 0.5280 - val_loss: 0.6899 - val_accuracy: 0.5169\n",
      "Epoch 82/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6896 - accuracy: 0.5262 - val_loss: 0.6902 - val_accuracy: 0.5147\n",
      "Epoch 83/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6895 - accuracy: 0.5262 - val_loss: 0.6900 - val_accuracy: 0.5156\n",
      "Epoch 84/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6896 - accuracy: 0.5257 - val_loss: 0.6901 - val_accuracy: 0.5170\n",
      "Epoch 85/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6894 - accuracy: 0.5272 - val_loss: 0.6899 - val_accuracy: 0.5176\n",
      "Epoch 86/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6896 - accuracy: 0.5280 - val_loss: 0.6899 - val_accuracy: 0.5184\n",
      "Epoch 87/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6894 - accuracy: 0.5285 - val_loss: 0.6900 - val_accuracy: 0.5150\n",
      "Epoch 88/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6896 - accuracy: 0.5274 - val_loss: 0.6899 - val_accuracy: 0.5227\n",
      "Epoch 89/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6892 - accuracy: 0.5268 - val_loss: 0.6901 - val_accuracy: 0.5148\n",
      "Epoch 90/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6895 - accuracy: 0.5271 - val_loss: 0.6900 - val_accuracy: 0.5156\n",
      "Epoch 91/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6894 - accuracy: 0.5285 - val_loss: 0.6900 - val_accuracy: 0.5176\n",
      "Epoch 92/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6894 - accuracy: 0.5256 - val_loss: 0.6899 - val_accuracy: 0.5169\n",
      "Epoch 93/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6895 - accuracy: 0.5266 - val_loss: 0.6900 - val_accuracy: 0.5148\n",
      "Epoch 94/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6893 - accuracy: 0.5281 - val_loss: 0.6900 - val_accuracy: 0.5176\n",
      "Epoch 95/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6896 - accuracy: 0.5241 - val_loss: 0.6899 - val_accuracy: 0.5165\n",
      "Epoch 96/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6895 - accuracy: 0.5269 - val_loss: 0.6899 - val_accuracy: 0.5210\n",
      "Epoch 97/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6894 - accuracy: 0.5284 - val_loss: 0.6898 - val_accuracy: 0.5170\n",
      "Epoch 98/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6893 - accuracy: 0.5282 - val_loss: 0.6901 - val_accuracy: 0.5150\n",
      "Epoch 99/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6895 - accuracy: 0.5252 - val_loss: 0.6899 - val_accuracy: 0.5182\n",
      "Epoch 100/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6892 - accuracy: 0.5291 - val_loss: 0.6899 - val_accuracy: 0.5197\n",
      "Epoch 101/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6894 - accuracy: 0.5296 - val_loss: 0.6899 - val_accuracy: 0.5170\n",
      "Epoch 102/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6894 - accuracy: 0.5276 - val_loss: 0.6900 - val_accuracy: 0.5146\n",
      "Epoch 103/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6893 - accuracy: 0.5273 - val_loss: 0.6899 - val_accuracy: 0.5184\n",
      "Epoch 104/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6893 - accuracy: 0.5286 - val_loss: 0.6898 - val_accuracy: 0.5191\n",
      "Epoch 105/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6893 - accuracy: 0.5286 - val_loss: 0.6899 - val_accuracy: 0.5161\n",
      "Epoch 106/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6895 - accuracy: 0.5286 - val_loss: 0.6900 - val_accuracy: 0.5194\n",
      "Epoch 107/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6892 - accuracy: 0.5292 - val_loss: 0.6899 - val_accuracy: 0.5201\n",
      "Epoch 108/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6894 - accuracy: 0.5266 - val_loss: 0.6900 - val_accuracy: 0.5143\n",
      "Epoch 109/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6893 - accuracy: 0.5280 - val_loss: 0.6902 - val_accuracy: 0.5116\n",
      "Epoch 110/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6892 - accuracy: 0.5282 - val_loss: 0.6900 - val_accuracy: 0.5186\n",
      "Epoch 111/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6894 - accuracy: 0.5296 - val_loss: 0.6899 - val_accuracy: 0.5170\n",
      "Epoch 112/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6892 - accuracy: 0.5305 - val_loss: 0.6900 - val_accuracy: 0.5158\n",
      "Epoch 113/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6892 - accuracy: 0.5290 - val_loss: 0.6900 - val_accuracy: 0.5145\n",
      "Epoch 114/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6893 - accuracy: 0.5277 - val_loss: 0.6900 - val_accuracy: 0.5167\n",
      "Epoch 115/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6892 - accuracy: 0.5272 - val_loss: 0.6901 - val_accuracy: 0.5143\n",
      "Epoch 116/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6893 - accuracy: 0.5285 - val_loss: 0.6900 - val_accuracy: 0.5154\n",
      "Epoch 117/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6892 - accuracy: 0.5285 - val_loss: 0.6900 - val_accuracy: 0.5138\n",
      "Epoch 118/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6892 - accuracy: 0.5286 - val_loss: 0.6899 - val_accuracy: 0.5170\n",
      "Epoch 119/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6892 - accuracy: 0.5270 - val_loss: 0.6902 - val_accuracy: 0.5108\n",
      "Epoch 120/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6891 - accuracy: 0.5289 - val_loss: 0.6900 - val_accuracy: 0.5162\n",
      "Epoch 121/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6892 - accuracy: 0.5283 - val_loss: 0.6900 - val_accuracy: 0.5155\n",
      "Epoch 122/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6892 - accuracy: 0.5283 - val_loss: 0.6899 - val_accuracy: 0.5203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6891 - accuracy: 0.5292 - val_loss: 0.6901 - val_accuracy: 0.5143\n",
      "Epoch 124/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6892 - accuracy: 0.5295 - val_loss: 0.6899 - val_accuracy: 0.5189\n",
      "Epoch 125/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6892 - accuracy: 0.5280 - val_loss: 0.6902 - val_accuracy: 0.5142\n",
      "Epoch 126/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6891 - accuracy: 0.5279 - val_loss: 0.6899 - val_accuracy: 0.5191\n",
      "Epoch 127/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6890 - accuracy: 0.5289 - val_loss: 0.6899 - val_accuracy: 0.5164\n",
      "Training with significance = 7.53, run 9\n",
      "Train on 42064 samples, validate on 10516 samples\n",
      "Epoch 1/1000\n",
      "42064/42064 [==============================] - 1s 27us/sample - loss: 0.6919 - accuracy: 0.5156 - val_loss: 0.6985 - val_accuracy: 0.5000\n",
      "Epoch 2/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6912 - accuracy: 0.5199 - val_loss: 0.6941 - val_accuracy: 0.5023\n",
      "Epoch 3/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6909 - accuracy: 0.5211 - val_loss: 0.6931 - val_accuracy: 0.5084\n",
      "Epoch 4/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6908 - accuracy: 0.5225 - val_loss: 0.6928 - val_accuracy: 0.5100\n",
      "Epoch 5/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6909 - accuracy: 0.5213 - val_loss: 0.6926 - val_accuracy: 0.5138\n",
      "Epoch 6/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6907 - accuracy: 0.5201 - val_loss: 0.6921 - val_accuracy: 0.5170\n",
      "Epoch 7/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6908 - accuracy: 0.5209 - val_loss: 0.6922 - val_accuracy: 0.5172\n",
      "Epoch 8/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6906 - accuracy: 0.5218 - val_loss: 0.6921 - val_accuracy: 0.5186\n",
      "Epoch 9/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5205 - val_loss: 0.6921 - val_accuracy: 0.5172\n",
      "Epoch 10/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6906 - accuracy: 0.5212 - val_loss: 0.6921 - val_accuracy: 0.5156\n",
      "Epoch 11/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5228 - val_loss: 0.6924 - val_accuracy: 0.5124\n",
      "Epoch 12/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5210 - val_loss: 0.6920 - val_accuracy: 0.5155\n",
      "Epoch 13/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5210 - val_loss: 0.6922 - val_accuracy: 0.5164\n",
      "Epoch 14/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6904 - accuracy: 0.5223 - val_loss: 0.6921 - val_accuracy: 0.5166\n",
      "Epoch 15/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6905 - accuracy: 0.5229 - val_loss: 0.6921 - val_accuracy: 0.5157\n",
      "Epoch 16/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6904 - accuracy: 0.5219 - val_loss: 0.6922 - val_accuracy: 0.5133\n",
      "Epoch 17/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6904 - accuracy: 0.5211 - val_loss: 0.6921 - val_accuracy: 0.5177\n",
      "Epoch 18/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6904 - accuracy: 0.5221 - val_loss: 0.6921 - val_accuracy: 0.5145\n",
      "Epoch 19/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6903 - accuracy: 0.5205 - val_loss: 0.6922 - val_accuracy: 0.5172\n",
      "Epoch 20/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5226 - val_loss: 0.6922 - val_accuracy: 0.5168\n",
      "Epoch 21/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6903 - accuracy: 0.5221 - val_loss: 0.6920 - val_accuracy: 0.5156\n",
      "Epoch 22/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6902 - accuracy: 0.5228 - val_loss: 0.6920 - val_accuracy: 0.5165\n",
      "Epoch 23/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6902 - accuracy: 0.5247 - val_loss: 0.6919 - val_accuracy: 0.5149\n",
      "Epoch 24/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6903 - accuracy: 0.5211 - val_loss: 0.6919 - val_accuracy: 0.5166\n",
      "Epoch 25/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5208 - val_loss: 0.6919 - val_accuracy: 0.5156\n",
      "Epoch 26/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5237 - val_loss: 0.6919 - val_accuracy: 0.5148\n",
      "Epoch 27/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5210 - val_loss: 0.6919 - val_accuracy: 0.5165\n",
      "Epoch 28/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6900 - accuracy: 0.5223 - val_loss: 0.6921 - val_accuracy: 0.5131\n",
      "Epoch 29/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6902 - accuracy: 0.5228 - val_loss: 0.6922 - val_accuracy: 0.5107\n",
      "Epoch 30/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6902 - accuracy: 0.5222 - val_loss: 0.6921 - val_accuracy: 0.5130\n",
      "Epoch 31/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5231 - val_loss: 0.6919 - val_accuracy: 0.5170\n",
      "Epoch 32/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6902 - accuracy: 0.5245 - val_loss: 0.6923 - val_accuracy: 0.5106\n",
      "Epoch 33/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5242 - val_loss: 0.6920 - val_accuracy: 0.5144\n",
      "Epoch 34/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6901 - accuracy: 0.5219 - val_loss: 0.6920 - val_accuracy: 0.5114\n",
      "Epoch 35/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6901 - accuracy: 0.5234 - val_loss: 0.6919 - val_accuracy: 0.5184\n",
      "Epoch 36/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6901 - accuracy: 0.5223 - val_loss: 0.6921 - val_accuracy: 0.5147\n",
      "Epoch 37/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5247 - val_loss: 0.6922 - val_accuracy: 0.5131\n",
      "Epoch 38/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6901 - accuracy: 0.5229 - val_loss: 0.6922 - val_accuracy: 0.5136\n",
      "Epoch 39/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6901 - accuracy: 0.5237 - val_loss: 0.6921 - val_accuracy: 0.5119\n",
      "Epoch 40/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5234 - val_loss: 0.6921 - val_accuracy: 0.5121\n",
      "Epoch 41/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6899 - accuracy: 0.5229 - val_loss: 0.6922 - val_accuracy: 0.5127\n",
      "Epoch 42/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6900 - accuracy: 0.5242 - val_loss: 0.6920 - val_accuracy: 0.5174\n",
      "Epoch 43/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5260 - val_loss: 0.6924 - val_accuracy: 0.5093\n",
      "Epoch 44/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5233 - val_loss: 0.6923 - val_accuracy: 0.5087\n",
      "Epoch 45/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6900 - accuracy: 0.5244 - val_loss: 0.6923 - val_accuracy: 0.5114\n",
      "Epoch 46/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5235 - val_loss: 0.6920 - val_accuracy: 0.5136\n",
      "Epoch 47/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6901 - accuracy: 0.5242 - val_loss: 0.6919 - val_accuracy: 0.5180\n",
      "Epoch 48/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6899 - accuracy: 0.5230 - val_loss: 0.6918 - val_accuracy: 0.5158\n",
      "Epoch 49/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6899 - accuracy: 0.5249 - val_loss: 0.6920 - val_accuracy: 0.5121\n",
      "Epoch 50/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6899 - accuracy: 0.5247 - val_loss: 0.6920 - val_accuracy: 0.5145\n",
      "Epoch 51/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6900 - accuracy: 0.5236 - val_loss: 0.6922 - val_accuracy: 0.5087\n",
      "Epoch 52/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6898 - accuracy: 0.5254 - val_loss: 0.6921 - val_accuracy: 0.5121\n",
      "Epoch 53/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5243 - val_loss: 0.6921 - val_accuracy: 0.5122\n",
      "Epoch 54/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6899 - accuracy: 0.5262 - val_loss: 0.6920 - val_accuracy: 0.5148\n",
      "Epoch 55/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6899 - accuracy: 0.5239 - val_loss: 0.6920 - val_accuracy: 0.5175\n",
      "Epoch 56/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6899 - accuracy: 0.5234 - val_loss: 0.6918 - val_accuracy: 0.5187\n",
      "Epoch 57/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5238 - val_loss: 0.6919 - val_accuracy: 0.5196\n",
      "Epoch 58/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6899 - accuracy: 0.5225 - val_loss: 0.6923 - val_accuracy: 0.5096\n",
      "Epoch 59/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6898 - accuracy: 0.5229 - val_loss: 0.6920 - val_accuracy: 0.5125\n",
      "Epoch 60/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6898 - accuracy: 0.5241 - val_loss: 0.6920 - val_accuracy: 0.5101\n",
      "Epoch 61/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6898 - accuracy: 0.5254 - val_loss: 0.6919 - val_accuracy: 0.5159\n",
      "Epoch 62/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6898 - accuracy: 0.5234 - val_loss: 0.6919 - val_accuracy: 0.5172\n",
      "Epoch 63/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6898 - accuracy: 0.5248 - val_loss: 0.6921 - val_accuracy: 0.5126\n",
      "Epoch 64/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6898 - accuracy: 0.5243 - val_loss: 0.6919 - val_accuracy: 0.5133\n",
      "Epoch 65/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6898 - accuracy: 0.5243 - val_loss: 0.6920 - val_accuracy: 0.5161\n",
      "Epoch 66/1000\n",
      "42064/42064 [==============================] - 0s 12us/sample - loss: 0.6897 - accuracy: 0.5277 - val_loss: 0.6921 - val_accuracy: 0.5122\n",
      "Epoch 67/1000\n",
      "42064/42064 [==============================] - 0s 12us/sample - loss: 0.6897 - accuracy: 0.5256 - val_loss: 0.6922 - val_accuracy: 0.5114\n",
      "Epoch 68/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6899 - accuracy: 0.5228 - val_loss: 0.6921 - val_accuracy: 0.5151\n",
      "Epoch 69/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6896 - accuracy: 0.5268 - val_loss: 0.6920 - val_accuracy: 0.5117\n",
      "Epoch 70/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6898 - accuracy: 0.5255 - val_loss: 0.6920 - val_accuracy: 0.5128\n",
      "Epoch 71/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6897 - accuracy: 0.5255 - val_loss: 0.6919 - val_accuracy: 0.5165\n",
      "Epoch 72/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6897 - accuracy: 0.5251 - val_loss: 0.6919 - val_accuracy: 0.5160\n",
      "Epoch 73/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6896 - accuracy: 0.5262 - val_loss: 0.6919 - val_accuracy: 0.5167\n",
      "Epoch 74/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6896 - accuracy: 0.5241 - val_loss: 0.6924 - val_accuracy: 0.5118\n",
      "Epoch 75/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6897 - accuracy: 0.5242 - val_loss: 0.6925 - val_accuracy: 0.5087\n",
      "Epoch 76/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6896 - accuracy: 0.5259 - val_loss: 0.6919 - val_accuracy: 0.5147\n",
      "Epoch 77/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6896 - accuracy: 0.5258 - val_loss: 0.6921 - val_accuracy: 0.5102\n",
      "Epoch 78/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6898 - accuracy: 0.5272 - val_loss: 0.6922 - val_accuracy: 0.5122\n",
      "Epoch 79/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6898 - accuracy: 0.5257 - val_loss: 0.6918 - val_accuracy: 0.5189\n",
      "Epoch 80/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6897 - accuracy: 0.5248 - val_loss: 0.6920 - val_accuracy: 0.5133\n",
      "Epoch 81/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6898 - accuracy: 0.5232 - val_loss: 0.6918 - val_accuracy: 0.5197\n",
      "Epoch 82/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6897 - accuracy: 0.5269 - val_loss: 0.6920 - val_accuracy: 0.5117\n",
      "Epoch 83/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6897 - accuracy: 0.5247 - val_loss: 0.6921 - val_accuracy: 0.5113\n",
      "Epoch 84/1000\n",
      "42064/42064 [==============================] - 1s 13us/sample - loss: 0.6895 - accuracy: 0.5263 - val_loss: 0.6920 - val_accuracy: 0.5116\n",
      "Epoch 85/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6896 - accuracy: 0.5257 - val_loss: 0.6924 - val_accuracy: 0.5104\n",
      "Epoch 86/1000\n",
      "42064/42064 [==============================] - 1s 12us/sample - loss: 0.6896 - accuracy: 0.5260 - val_loss: 0.6919 - val_accuracy: 0.5192\n"
     ]
    }
   ],
   "source": [
    "n_train_sr_bkg = 25000\n",
    "mean_results = []\n",
    "std_results = []\n",
    "for p_1 in [25]:#[25, 50, 75]:#[25, 50, 75]:\n",
    "    rng = np.random.default_rng(seed = 42)    \n",
    "    os.chdir('/home/manhducnmd/pp_dijet/Results_full')    \n",
    "    bkg_sr_jet_1 = np.load(f'retest_full_background_images_sr_{p_1}_jet_1.npy')\n",
    "    bkg_sr_jet_2 = np.load(f'retest_full_background_images_sr_{p_1}_jet_2.npy')\n",
    "    \n",
    "    bkg_sr_mass_jet_1 = np.load(f'test_full_background_sr_mass_jet_1.npy')\n",
    "    bkg_sr_mass_jet_2 = np.load(f'test_full_background_sr_mass_jet_2.npy')\n",
    "    \n",
    "    bkg_sr_eta_jet_1 = np.load(f'test_full_background_sr_eta_jet_1.npy')\n",
    "    bkg_sr_eta_jet_2 = np.load(f'test_full_background_sr_eta_jet_2.npy')\n",
    "    \n",
    "    bkg_sr_phi_jet_1 = np.load(f'test_full_background_sr_phi_jet_1.npy')\n",
    "    bkg_sr_phi_jet_2 = np.load(f'test_full_background_sr_phi_jet_2.npy')\n",
    "    \n",
    "    bkg_sr_lha_jet_1 = np.load(f'test_full_background_sr_lha_jet_1.npy')\n",
    "    bkg_sr_lha_jet_2 = np.load(f'test_full_background_sr_lha_jet_2.npy')\n",
    "    \n",
    "    bkg_sr_all_variables_jet_1 = np.stack((bkg_sr_mass_jet_1, bkg_sr_lha_jet_1)\n",
    "                                         , axis = -1)\n",
    "    bkg_sr_all_variables_jet_2 = np.stack((bkg_sr_mass_jet_2, bkg_sr_lha_jet_2)\n",
    "                                         , axis = -1)\n",
    "    \n",
    "    \n",
    "    bkg_sb_jet_1 = np.load(f'retest_full_background_images_sb_{p_1}_jet_1.npy')\n",
    "    bkg_sb_jet_2 = np.load(f'retest_full_background_images_sb_{p_1}_jet_2.npy')\n",
    "    \n",
    "    bkg_sb_mass_jet_1 = np.load(f'test_full_background_sb_mass_jet_1.npy')\n",
    "    bkg_sb_mass_jet_2 = np.load(f'test_full_background_sb_mass_jet_2.npy')\n",
    "    \n",
    "    bkg_sb_eta_jet_1 = np.load(f'test_full_background_sb_eta_jet_1.npy')\n",
    "    bkg_sb_eta_jet_2 = np.load(f'test_full_background_sb_eta_jet_2.npy')\n",
    "    \n",
    "    bkg_sb_phi_jet_1 = np.load(f'test_full_background_sb_phi_jet_1.npy')\n",
    "    bkg_sb_phi_jet_2 = np.load(f'test_full_background_sb_phi_jet_2.npy')\n",
    "    \n",
    "    bkg_sb_lha_jet_1 = np.load(f'test_full_background_sb_lha_jet_1.npy')\n",
    "    bkg_sb_lha_jet_2 = np.load(f'test_full_background_sb_lha_jet_2.npy')\n",
    "    \n",
    "    bkg_sb_all_variables_jet_1 = np.stack((bkg_sb_mass_jet_1, bkg_sb_lha_jet_1)\n",
    "                                         , axis = -1)\n",
    "    bkg_sb_all_variables_jet_2 = np.stack((bkg_sb_mass_jet_2, bkg_sb_lha_jet_2)\n",
    "                                         , axis = -1)\n",
    "    \n",
    "    \n",
    "    sb_sr_bkg = np.shape(bkg_sb_jet_1)[0]/np.shape(bkg_sr_jet_2)[0]\n",
    "    n_train_sb_bkg = int(np.round(n_train_sr_bkg*sb_sr_bkg))\n",
    "    n_test_sr_bkg = 20000\n",
    "    \n",
    "    #First jet, background, SR\n",
    "    bkg_pretrain_sr_1 = bkg_sr_jet_1[0:-n_test_sr_bkg]\n",
    "    #Second jet, background, SR\n",
    "    bkg_pretrain_sr_2 = bkg_sr_jet_2[0:-n_test_sr_bkg]\n",
    "    #Mass ratio, SR\n",
    "    bkg_pretrain_sr_all_variables_jet_1 = bkg_sr_all_variables_jet_1[0:-n_test_sr_bkg]\n",
    "    bkg_pretrain_sr_all_variables_jet_2 = bkg_sr_all_variables_jet_2[0:-n_test_sr_bkg]\n",
    "    #First jet, background, SB\n",
    "    bkg_pretrain_sb_1 = bkg_sb_jet_1[0:-n_test_sr_bkg]\n",
    "    #Second jet, background, SB\n",
    "    bkg_pretrain_sb_2 = bkg_sb_jet_2[0:-n_test_sr_bkg]\n",
    "    #Mass ratio, SB\n",
    "    bkg_pretrain_sb_all_variables_jet_1 = bkg_sb_all_variables_jet_1[0:-n_test_sr_bkg]\n",
    "    bkg_pretrain_sb_all_variables_jet_2 = bkg_sb_all_variables_jet_2[0:-n_test_sr_bkg]\n",
    "    \n",
    "    signal_sr_jet_1 = np.load(f'm_id10_sr_{p_1}_jet_1.npy')\n",
    "    signal_sr_jet_2 = np.load(f'm_id10_sr_{p_1}_jet_2.npy')\n",
    "    \n",
    "    signal_sr_mass_jet_1 = np.load(f'id10_sr_mass_jet_1.npy')\n",
    "    signal_sr_mass_jet_2 = np.load(f'id10_sr_mass_jet_2.npy')\n",
    "    \n",
    "    signal_sr_eta_jet_1 = np.load(f'id10_sr_eta_jet_1.npy')\n",
    "    signal_sr_eta_jet_2 = np.load(f'id10_sr_eta_jet_2.npy')\n",
    "    \n",
    "    signal_sr_phi_jet_1 = np.load(f'id10_sr_phi_jet_1.npy')\n",
    "    signal_sr_phi_jet_2 = np.load(f'id10_sr_phi_jet_2.npy')\n",
    "    \n",
    "    signal_sr_lha_jet_1 = np.load(f'id10_sr_lha_jet_1.npy')\n",
    "    signal_sr_lha_jet_2 = np.load(f'id10_sr_lha_jet_2.npy')\n",
    "    \n",
    "    signal_sr_all_variables_jet_1 = np.stack((signal_sr_mass_jet_1, signal_sr_lha_jet_1\n",
    "                                              ), axis = -1)\n",
    "    signal_sr_all_variables_jet_2 = np.stack((signal_sr_mass_jet_2, signal_sr_lha_jet_2\n",
    "                                             ), axis = -1)\n",
    "    \n",
    "    \n",
    "    signal_sb_jet_1 = np.load(f'm_id10_sb_{p_1}_jet_1.npy')\n",
    "    signal_sb_jet_2 = np.load(f'm_id10_sb_{p_1}_jet_2.npy')\n",
    "    \n",
    "    signal_sb_mass_jet_1 = np.load(f'id10_sb_mass_jet_1.npy')\n",
    "    signal_sb_mass_jet_2 = np.load(f'id10_sb_mass_jet_2.npy')\n",
    "    \n",
    "    signal_sb_eta_jet_1 = np.load(f'id10_sb_eta_jet_1.npy')\n",
    "    signal_sb_eta_jet_2 = np.load(f'id10_sb_eta_jet_2.npy')\n",
    "    \n",
    "    signal_sb_phi_jet_1 = np.load(f'id10_sb_phi_jet_1.npy')\n",
    "    signal_sb_phi_jet_2 = np.load(f'id10_sb_phi_jet_2.npy')\n",
    "    \n",
    "    signal_sb_lha_jet_1 = np.load(f'id10_sb_lha_jet_1.npy')\n",
    "    signal_sb_lha_jet_2 = np.load(f'id10_sb_lha_jet_2.npy')\n",
    "    \n",
    "    signal_sb_all_variables_jet_1 = np.stack((signal_sb_mass_jet_1, signal_sb_lha_jet_1\n",
    "                                             ), axis = -1)\n",
    "    signal_sb_all_variables_jet_2 = np.stack((signal_sb_mass_jet_2, signal_sb_lha_jet_2 \n",
    "                                             ), axis = -1)\n",
    "    \n",
    "    \n",
    "    sb_sr_signal = np.shape(signal_sb_jet_1)[0]/np.shape(signal_sr_jet_1)[0]\n",
    "    for n_train_sr_signal in [50, 100, 150, 200, 250, 300, 350, 400, 450, 500, 600, 700, 800, 900, 1000, 1100, 1200]:\n",
    "        significance = np.sqrt(2*((n_train_sr_signal+25000)*np.log(n_train_sr_signal/25000 + 1) - n_train_sr_signal))\n",
    "        \n",
    "        n_train_sb_signal = int(np.round(n_train_sr_signal*sb_sr_signal))\n",
    "        n_test_sr_signal = 20000\n",
    "        \n",
    "        #First jet, signal, SR\n",
    "        signal_pretrain_sr_1 = signal_sr_jet_1[0:20000] #10000 events are pooled for resampling\n",
    "        \n",
    "        #Second jet, signal, SR\n",
    "        signal_pretrain_sr_2 = signal_sr_jet_2[0:20000]\n",
    "        \n",
    "        #Mass ratio, SR\n",
    "        signal_pretrain_sr_all_variables_jet_1 = signal_sr_all_variables_jet_1[0:20000]\n",
    "        signal_pretrain_sr_all_variables_jet_2 = signal_sr_all_variables_jet_2[0:20000]\n",
    "\n",
    "        #First jet, signal, SB\n",
    "        signal_pretrain_sb_1 = signal_sb_jet_1[0:20000]\n",
    "\n",
    "        #Second jet, signal, SB\n",
    "        signal_pretrain_sb_2 = signal_sb_jet_2[0:20000]\n",
    "        \n",
    "        #Mass ratio, SB\n",
    "        signal_pretrain_sb_all_variables_jet_1 = signal_sb_all_variables_jet_1[0:20000]\n",
    "        signal_pretrain_sb_all_variables_jet_2 = signal_sb_all_variables_jet_2[0:20000]\n",
    "        \n",
    "        rng_2 = np.random.default_rng(seed=42)\n",
    "        \n",
    "        rng_3 = np.random.default_rng(seed=42)\n",
    "        for i in range(10):\n",
    "            indices_2 = rng_2.permutation(np.shape(bkg_pretrain_sr_1)[0])\n",
    "            \n",
    "            indices_3 = rng_3.permutation(np.shape(signal_pretrain_sr_1)[0])\n",
    "            \n",
    "            #First jet, background, SR\n",
    "            bkg_train_sr_1 = (bkg_pretrain_sr_1[indices_2])[0:n_train_sr_bkg]\n",
    "            #Second jet, background, SR\n",
    "            bkg_train_sr_2 = (bkg_pretrain_sr_2[indices_2])[0:n_train_sr_bkg]\n",
    "            #Mass ratio, background, SR\n",
    "            bkg_train_sr_all_variables_jet_1 = (bkg_pretrain_sr_all_variables_jet_1[indices_2])[0:n_train_sr_bkg]\n",
    "            bkg_train_sr_all_variables_jet_2 = (bkg_pretrain_sr_all_variables_jet_2[indices_2])[0:n_train_sr_bkg]\n",
    "\n",
    "            \n",
    "            #First jet, background, SB\n",
    "            bkg_train_sb_1 = (bkg_pretrain_sb_1[indices_2])[0:n_train_sb_bkg]\n",
    "            #Second jet, background, SB\n",
    "            bkg_train_sb_2 = (bkg_pretrain_sb_2[indices_2])[0:n_train_sb_bkg]\n",
    "            #Mass ratio, background, SB\n",
    "            bkg_train_sb_all_variables_jet_1 = (bkg_pretrain_sb_all_variables_jet_1[indices_2])[0:n_train_sb_bkg]\n",
    "            bkg_train_sb_all_variables_jet_2 = (bkg_pretrain_sb_all_variables_jet_2[indices_2])[0:n_train_sb_bkg]\n",
    "\n",
    "            \n",
    "            signal_train_sr_1 = (signal_pretrain_sr_1[indices_3])[0:n_train_sr_signal]\n",
    "            signal_train_sr_2 = (signal_pretrain_sr_2[indices_3])[0:n_train_sr_signal]\n",
    "            signal_train_sr_all_variables_jet_1 = (signal_pretrain_sr_all_variables_jet_1[indices_3])[0:n_train_sr_signal]\n",
    "            signal_train_sr_all_variables_jet_2 = (signal_pretrain_sr_all_variables_jet_2[indices_3])[0:n_train_sr_signal]\n",
    "            \n",
    "            signal_train_sb_1 = (signal_pretrain_sb_1[indices_3])[0:n_train_sb_signal]\n",
    "            signal_train_sb_2 = (signal_pretrain_sb_2[indices_3])[0:n_train_sb_signal]\n",
    "            signal_train_sb_all_variables_jet_1 = (signal_pretrain_sb_all_variables_jet_1[indices_3])[0:n_train_sb_signal]\n",
    "            signal_train_sb_all_variables_jet_2 = (signal_pretrain_sb_all_variables_jet_2[indices_3])[0:n_train_sb_signal]\n",
    "            \n",
    "            train_sr_1 = np.concatenate((signal_train_sr_1, bkg_train_sr_1))\n",
    "            train_sr_2 = np.concatenate((signal_train_sr_2, bkg_train_sr_2))\n",
    "            train_sr_all_variables_jet_1 = np.concatenate((signal_train_sr_all_variables_jet_1, \n",
    "                                                           bkg_train_sr_all_variables_jet_1))\n",
    "            train_sr_all_variables_jet_2 = np.concatenate((signal_train_sr_all_variables_jet_2, \n",
    "                                                           bkg_train_sr_all_variables_jet_2))\n",
    "\n",
    "            train_label_sr = np.ones(np.shape(train_sr_1)[0], dtype = int)\n",
    "\n",
    "            train_sb_1 = np.concatenate((signal_train_sb_1, bkg_train_sb_1))\n",
    "            train_sb_2 = np.concatenate((signal_train_sb_2, bkg_train_sb_2))\n",
    "            train_sb_all_variables_jet_1 = np.concatenate((signal_train_sb_all_variables_jet_1, \n",
    "                                                           bkg_train_sb_all_variables_jet_1))\n",
    "            train_sb_all_variables_jet_2 = np.concatenate((signal_train_sb_all_variables_jet_2, \n",
    "                                                           bkg_train_sb_all_variables_jet_2))\n",
    "            train_label_sb = np.zeros(np.shape(train_sb_1)[0], dtype = int)\n",
    "            \n",
    "            x_train_1 = np.concatenate((train_sr_1, train_sb_1))\n",
    "            x_train_2 = np.concatenate((train_sr_2, train_sb_2))\n",
    "            x_train_all_variables_jet_1 = np.concatenate((train_sr_all_variables_jet_1, train_sb_all_variables_jet_1))\n",
    "            x_train_all_variables_jet_2 = np.concatenate((train_sr_all_variables_jet_2, train_sb_all_variables_jet_2))\n",
    "            y_train = np.concatenate((train_label_sr, train_label_sb))\n",
    "\n",
    "            #Mix up the samples\n",
    "            indices = rng.permutation(np.shape(y_train)[0])\n",
    "\n",
    "            x_train_1 = x_train_1[indices]\n",
    "            x_train_2 = x_train_2[indices]\n",
    "            #x_train = np.stack([x_train_1, x_train_2], axis = -1)\n",
    "            x_train_all_variables_jet_1 = x_train_all_variables_jet_1[indices]\n",
    "            x_train_all_variables_jet_2 = x_train_all_variables_jet_2[indices]\n",
    "            y_train = y_train[indices]\n",
    "\n",
    "            x_train_1 = x_train_1.reshape((np.shape(x_train_1)[0], p_1, p_1, 1))\n",
    "            x_train_2 = x_train_2.reshape((np.shape(x_train_2)[0], p_1, p_1, 1))\n",
    "\n",
    "            print(f'Training with significance = {significance:.2f}, run {i}')\n",
    "            \n",
    "            cwola = CWoLA(p_1)\n",
    "            loss_object = keras.losses.BinaryCrossentropy()\n",
    "            optimizer = keras.optimizers.Adam(learning_rate = 1e-4)\n",
    "            cwola.compile(loss = loss_object, optimizer = optimizer, metrics = ['accuracy'])\n",
    "            early_stopping = keras.callbacks.EarlyStopping(monitor = 'val_loss', patience=30, restore_best_weights=True)\n",
    "            #history = cwola.fit(x_train, y_train, validation_split = 0.2,\n",
    "                                #shuffle = True, batch_size = 500, callbacks = [early_stopping], epochs = 1000)  \n",
    "            history = cwola.fit({'jet_1': x_train_1, 'jet_2': x_train_2, 'all_1': x_train_all_variables_jet_1, \n",
    "                                 'all_2': x_train_all_variables_jet_2}, \n",
    "                                y_train, validation_split = 0.2,\n",
    "                                  shuffle = True, batch_size = 500, callbacks = [early_stopping], epochs = 1000)  \n",
    "            cwola.save(f'/home/manhducnmd/pp_dijet/Model_results/one_run_{i}_id10_{n_train_sr_signal}_{p_1}.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0efb543",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "03de8579",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42940, 25, 25)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(bkg_pretrain_sb_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "3c3f7cfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(history.history['loss'], label = 'loss')\n",
    "plt.plot(history.history['val_loss'], label = 'val_loss')\n",
    "plt.legend(loc = 'upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "974e737a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(history.history['accuracy'], label = 'accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.legend(loc = 'upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e172c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/manhducnmd/pp_dijet/Model_results')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584d32d4",
   "metadata": {},
   "source": [
    "Loading a sample model for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "637e8f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loaded_model = keras.models.load_model('run_5_id10_500_25.keras')\n",
    "loaded_model = cwola"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6e7492ed",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.utils.plot_model(loaded_model, \"multi_input_and_output_model.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d8bd35b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "jet_1 (InputLayer)              [(None, 25, 25, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "jet_2 (InputLayer)              [(None, 25, 25, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 25, 25, 1)    4           jet_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 25, 25, 1)    4           jet_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "sequential_4 (Sequential)       (None, 1152)         325568      batch_normalization_4[0][0]      \n",
      "                                                                 batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "sequential_5 (Sequential)       (None, 1)            180737      sequential_4[0][0]               \n",
      "                                                                 sequential_4[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "multiply_2 (Multiply)           (None, 1)            0           sequential_5[0][0]               \n",
      "                                                                 sequential_5[1][0]               \n",
      "==================================================================================================\n",
      "Total params: 506,313\n",
      "Trainable params: 506,309\n",
      "Non-trainable params: 4\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(loaded_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "ad760b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'/home/manhducnmd/pp_dijet/Results_full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "15034f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3643233  0.2079619  0.29383322 ... 0.398844   0.5114936  0.66268079]\n"
     ]
    }
   ],
   "source": [
    "print(signal_sb_lha_jet_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "a768a022",
   "metadata": {},
   "outputs": [],
   "source": [
    "bkg_sr_jet_1 = np.load(f'retest_full_background_images_sr_50_jet_1.npy')\n",
    "bkg_sr_jet_2 = np.load(f'retest_full_background_images_sr_50_jet_2.npy')\n",
    "\n",
    "bkg_sr_mass_jet_1 = np.load(f'test_full_background_sr_mass_jet_1.npy')\n",
    "bkg_sr_mass_jet_2 = np.load(f'test_full_background_sr_mass_jet_2.npy')\n",
    "\n",
    "bkg_sr_eta_jet_1 = np.load(f'test_full_background_sr_eta_jet_1.npy')\n",
    "bkg_sr_eta_jet_2 = np.load(f'test_full_background_sr_eta_jet_2.npy')\n",
    "\n",
    "bkg_sr_phi_jet_1 = np.load(f'test_full_background_sr_phi_jet_1.npy')\n",
    "bkg_sr_phi_jet_2 = np.load(f'test_full_background_sr_phi_jet_2.npy')\n",
    "\n",
    "bkg_sr_lha_jet_1 = np.load(f'test_full_background_sr_lha_jet_1.npy')\n",
    "bkg_sr_lha_jet_2 = np.load(f'test_full_background_sr_lha_jet_2.npy')\n",
    "\n",
    "bkg_sr_all_variables_jet_1 = np.stack((bkg_sr_mass_jet_1, bkg_sr_lha_jet_1)\n",
    "                                     , axis = -1)\n",
    "bkg_sr_all_variables_jet_2 = np.stack((bkg_sr_mass_jet_2, bkg_sr_lha_jet_2)\n",
    "                                     , axis = -1)\n",
    "\n",
    "signal_sr_jet_1 = np.load(f'm_id10_sr_50_jet_1.npy')\n",
    "signal_sr_jet_2 = np.load(f'm_id10_sr_50_jet_2.npy')\n",
    "\n",
    "signal_sr_mass_jet_1 = np.load(f'id10_sr_mass_jet_1.npy')\n",
    "signal_sr_mass_jet_2 = np.load(f'id10_sr_mass_jet_2.npy')\n",
    "\n",
    "signal_sr_eta_jet_1 = np.load(f'id10_sr_eta_jet_1.npy')\n",
    "signal_sr_eta_jet_2 = np.load(f'id10_sr_eta_jet_2.npy')\n",
    "\n",
    "signal_sr_phi_jet_1 = np.load(f'id10_sr_phi_jet_1.npy')\n",
    "signal_sr_phi_jet_2 = np.load(f'id10_sr_phi_jet_2.npy')\n",
    "\n",
    "signal_sr_lha_jet_1 = np.load(f'id10_sr_lha_jet_1.npy')\n",
    "signal_sr_lha_jet_2 = np.load(f'id10_sr_lha_jet_2.npy')\n",
    "\n",
    "signal_sr_all_variables_jet_1 = np.stack((signal_sr_mass_jet_1, signal_sr_lha_jet_1), \n",
    "                                         axis = -1)\n",
    "signal_sr_all_variables_jet_2 = np.stack((signal_sr_mass_jet_2, signal_sr_lha_jet_2)\n",
    "                                         , axis = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092c7ce7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "8c17599e",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_test_1 = signal_sr_jet_1[-20000:]\n",
    "signal_test_2 = signal_sr_jet_2[-20000:]\n",
    "signal_test_all_variables_jet_1 = signal_sr_all_variables_jet_1[-20000:]\n",
    "signal_test_all_variables_jet_2 = signal_sr_all_variables_jet_2[-20000:]\n",
    "\n",
    "\n",
    "bkg_test_1 = bkg_sr_jet_1[-20000:]\n",
    "bkg_test_2 = bkg_sr_jet_2[-20000:]\n",
    "bkg_test_all_variables_jet_1 = bkg_sr_all_variables_jet_1[-20000:]\n",
    "bkg_test_all_variables_jet_2 = bkg_sr_all_variables_jet_2[-20000:]\n",
    "\n",
    "\n",
    "test_label_signal = np.ones(np.shape(signal_test_1)[0])\n",
    "test_label_bkg = np.zeros(np.shape(bkg_test_1)[0])\n",
    "\n",
    "x_test_1 = np.concatenate((signal_test_1, bkg_test_1))\n",
    "x_test_2 = np.concatenate((signal_test_2, bkg_test_2))\n",
    "x_test_all_variables_jet_1 = np.concatenate((signal_test_all_variables_jet_1, bkg_test_all_variables_jet_1))\n",
    "x_test_all_variables_jet_2 = np.concatenate((signal_test_all_variables_jet_2, bkg_test_all_variables_jet_2))\n",
    "\n",
    "y_test = np.concatenate((test_label_signal, test_label_bkg))\n",
    "\n",
    "#x_test = np.stack([x_test_1, x_test_2], axis = -1)\n",
    "x_test_1 = x_test_1.reshape((np.shape(x_test_1)[0],50,50,1))\n",
    "x_test_2 = x_test_2.reshape((np.shape(x_test_2)[0],50,50,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa00d99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "505b3c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_predict = loaded_model.predict([x_test_1, x_test_2, x_test_all_variables_jet_1, x_test_all_variables_jet_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "c0a251cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_predict_0 = x_predict[y_test == 0]\n",
    "x_predict_1 = x_predict[y_test == 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "7eded930",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(x_predict_0, bins = 20, color='blue', edgecolor='blue', fc=\"None\", lw=3)\n",
    "plt.hist(x_predict_1, bins = 20, color='orange', edgecolor='orange', fc=\"None\", lw=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "89217299",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.85750239\n"
     ]
    }
   ],
   "source": [
    "fpr, tpr, th = roc_curve(y_test, x_predict)\n",
    "plt.plot(fpr, tpr)\n",
    "plt.show()\n",
    "f = interpolate.interp1d(fpr, tpr)\n",
    "epsilon_s = f([0.001, 0.01, 0.1])\n",
    "print(roc_auc_score(y_test, x_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "d62bc666",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0286 0.2415 0.738 ]\n"
     ]
    }
   ],
   "source": [
    "print(epsilon_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "cdcfcfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train_sr_signal = 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "07aa400b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.612163856953451\n"
     ]
    }
   ],
   "source": [
    "print(np.sqrt(2*((n_train_sr_signal*epsilon_s[2]+25000*0.1)*np.log(n_train_sr_signal*epsilon_s[2]/(25000*0.1) + 1) - \n",
    "                 n_train_sr_signal*epsilon_s[2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d361a93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
